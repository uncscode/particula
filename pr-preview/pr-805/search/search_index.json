{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Particula","text":""},{"location":"#what-is-particula","title":"What is Particula?","text":"<p>Particula is an open-source, Python-based aerosol simulator that bridges experimental data with computational models. It captures gas-particle interactions, transformations, and dynamics to power predictive aerosol science\u2014so you can uncover deeper insights and accelerate progress.</p>"},{"location":"#why-use-particula","title":"Why Use Particula?","text":"<p>Aerosols influence atmospheric science, air quality, and human health in powerful ways. Gaining insight into how they behave is essential for effective pollution control, accurate cloud formation modeling, and safer indoor environments. Particula provides a robust, flexible framework to simulate, analyze, and visualize aerosol processes with precision\u2014empowering you to make breakthroughs and drive impactful science.</p>"},{"location":"#how-does-particula-help-you","title":"How Does Particula Help You?","text":"<p>Whether you\u2019re a researcher, educator, or industry expert, Particula is designed to empower your aerosol work by:</p> <ul> <li>Harnessing ChatGPT integration for real-time guidance, troubleshooting, and Q&amp;A, here.</li> <li>Providing a Python-based API for reproducible and modular simulations.</li> <li>Interrogating your experimental data to validate and expand your impact.</li> <li>Fostering open-source collaboration to share ideas and build on each other\u2019s work.</li> </ul>"},{"location":"#join-the-community","title":"Join the Community","text":"<p>We welcome contributions from scientists, developers, and students\u2014and anyone curious about aerosol science! Whether you\u2019re looking to ask questions, get help, or contribute fresh ideas, you\u2019ve come to the right place.</p> <p>Get more by posting on GitHub Discussions and tag any of the contributors using <code>@github-handle</code>.</p> <ul> <li>\ud83d\udcac Ask questions and get help.</li> <li>\ud83d\ude80 Share your research with the community to inspire others.</li> <li>\ud83d\udce3 Give us feedback.</li> <li>\ud83c\udf1f Contribute to Particula by submitting pull requests or reporting issues on GitHub.</li> <li>\ud83d\udd17 Read our Contributing Guide to learn how you can make an impact.</li> </ul> <p>We\u2019re excited to collaborate with you! \u2728</p>"},{"location":"#cite-particula-in-your-research","title":"Cite Particula in Your Research","text":"<p>Particula [Computer software]. DOI: 10.5281/zenodo.6634653</p>"},{"location":"#get-started-with-particula","title":"Get Started with Particula","text":"<p>Setup Particula API Reference Examples Theory</p>"},{"location":"#pypi-installation","title":"PyPI Installation","text":"<p>If your Python environment is already set up, install Particula directly from PyPI: <pre><code>pip install particula\n</code></pre></p>"},{"location":"#conda-installation","title":"Conda Installation","text":"<p>Alternatively, you can install Particula using conda: <pre><code>conda install -c conda-forge particula\n</code></pre></p> <p>If you are new to Python or plan on going through the Examples, head to Setup Particula for more comprehensive installation instructions.</p>"},{"location":"#quick-start-example","title":"Quick Start Example","text":"<p>This \u201cQuick Start Example\u201d demonstrates a concise workflow for building an aerosol system in Particula and performing a single condensation step.</p> <pre><code>import numpy as np\nimport particula as par\n\n# 1. Build the GasSpecies for an organic vapor:\norganic = (\n    par.gas.GasSpeciesBuilder()\n    .set_name(\"organic\")\n    .set_molar_mass(180e-3, \"kg/mol\")\n    .set_vapor_pressure_strategy(\n        par.gas.ConstantVaporPressureStrategy(1e2)  # Pa\n    )\n    .set_partitioning(True)\n    .set_concentration(np.array([1e2]), \"kg/m^3\")\n    .build()\n)\n\n# 2. Use AtmosphereBuilder to configure temperature, pressure, and species:\natmosphere = (\n    par.gas.AtmosphereBuilder()\n    .set_temperature(298.15, \"K\")\n    .set_pressure(101325, \"Pa\")\n    .set_more_partitioning_species(organic)\n    .build()\n)\n\n# 3. Build the particle distribution:\n#    Using PresetParticleRadiusBuilder, we set mode radius, GSD, etc.\nparticle = (\n    par.particles.PresetParticleRadiusBuilder()\n    .set_mode(np.array([100e-9]), \"m\")\n    .set_geometric_standard_deviation(np.array([1.2]))\n    .set_number_concentration(np.array([1e8]), \"1/m^3\")\n    .set_density(1e3, \"kg/m^3\")\n    .build()\n)\n\n# 4. Create the Aerosol combining the atmosphere and particle distribution:\naerosol = (\n    par.AerosolBuilder()\n    .set_atmosphere(atmosphere)\n    .set_particles(particle)\n    .build()\n)\n\n# 5. Define the isothermal condensation strategy:\ncondensation_strategy = par.dynamics.CondensationIsothermal(\n    molar_mass=180e-3,  # kg/mol\n    diffusion_coefficient=2e-5,  # m^2/s\n    accommodation_coefficient=1.0,\n)\n\n# 6. Build the MassCondensation process:\nprocess = par.dynamics.MassCondensation(condensation_strategy)\n\n# 7. Execute the condensation process over 10 seconds:\nresult = process.execute(aerosol, time_step=10.0)\n\n#   The result is an Aerosol instance with updated particle properties.\nprint(result)\n</code></pre>"},{"location":"Examples/","title":"Examples","text":"<p>Welcome to the Particula\u00a0Examples Gallery! Here you\u2019ll find a curated collection of notebooks and step\u2011by\u2011step tutorials designed to help you explore, learn, and extend the core functionality of Particula. Whether you\u2019re looking for a full end\u2011to\u2011end simulation, a focused how\u2011to guide, or a deep dive into individual components, each card below links to a ready\u2011to\u2011run example with contextual explanations and code snippets.</p> <p>Use the End\u2011to\u2011End Simulations to see complete workflows in action, then explore the How\u2011To Guides for targeted recipes that tackle specific processes (e.g., chamber wall losses, thermodynamic equilibria, or nucleation events). Finally, the Tutorials section breaks down the building blocks of Particula\u2019s architecture\u2014Aerosol objects, Dynamics modules, Gas Phase definitions, and Particle Phase representations\u2014so you can customize and combine them in your own research.</p> <p>Jump in by selecting any card below and follow along in your browser or local environment. Happy modeling!</p>"},{"location":"Examples/#end-to-end-simulations","title":"End-to-End Simulations","text":"<ul> <li> <p>Aerosol-Cloud Interactions</p> <p>Biomass burning aerosols that activate into cloud droplets, simulating the interactions between aerosols and clouds.</p> <p> Simulation</p> </li> <li> <p>Organic Partitioning and Coagulation</p> <p>Simulation of organic partitioning on to seed particles and coagulation.</p> <p> Simulation</p> </li> <li> <p>Cough Droplets Partitioning</p> <p>Simulates the evaporation of cough droplets, tracking size distribution and composition changes over time.</p> <p> Simulation</p> </li> <li> <p>Soot Formation in Flames</p> <p>Simulates soot formation in a cooling combustion plume, tracking particle growth and chemical speciation.</p> <p> Simulation</p> </li> </ul>"},{"location":"Examples/#how-to-guides","title":"How-To Guides","text":"<ul> <li> <p>Setup Particula</p> <p>How to setup python and install <code>Particula</code> via pip.</p> <p> Tutorial</p> </li> <li> <p>Chamber Wall Loss</p> <p>How to simulate experiments for the loss of particles to the chamber walls.</p> <p> Tutorial</p> </li> <li> <p>Equilibria</p> <p>How to simulate aerosol thermodynamic equilibria using the Binary Activity Thermodynamic <code>BAT</code> Model. Useful for water uptake and cloud droplet activation.</p> <p> Tutorial</p> </li> <li> <p>Nucleation</p> <p>How to simulate aerosol nucleation by adding particles during simulations. Showing how to add a nucleation event.</p> <p> Tutorial</p> </li> </ul>"},{"location":"Examples/#tutorials","title":"Tutorials","text":"<ul> <li> <p>Aerosol</p> <p>Learn what goes into the Aerosol object and why it is used.</p> <p> Tutorial</p> </li> <li> <p>Dynamics</p> <p>Dynamics is a collection of classes that processes <code>Aerosol</code> objects, to perform coagulation, condensation, and other processes.</p> <p> Tutorial</p> </li> <li> <p>Gas Phase</p> <p>Learn how to represent the Gas Phase, including vapor pressures and atmospheric properties.</p> <p> Tutorial</p> </li> <li> <p>Particle Phase</p> <p>Learn about how to represent the Particle Phase, including different particle representations; radius bins, speciated mass bins, and particle resolved.</p> <p> Tutorial</p> </li> </ul>"},{"location":"Examples/Aerosol/","title":"Index: Aerosols","text":""},{"location":"Examples/Aerosol/#notebooks","title":"Notebooks","text":"<ul> <li>Aerosol Tutorial</li> </ul>"},{"location":"Examples/Aerosol/Aerosol_Tutorial/","title":"Aerosol Tutorial","text":"In\u00a0[\u00a0]: Copied! <pre># In Colab uncomment the following command to install particula:\n#!pip install particula[extra] --quiet\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nimport particula as par\n</pre> # In Colab uncomment the following command to install particula: #!pip install particula[extra] --quiet  import numpy as np import matplotlib.pyplot as plt  import particula as par In\u00a0[2]: Copied! <pre># Glycerol gas\nmolar_mass_glycerol = 92.09382e-3  # kg/mol\nparameters_clausius = {\n    \"latent_heat\": 71.5 * molar_mass_glycerol,\n    \"latent_heat_units\": \"J/mol\",\n    \"temperature_initial\": 125.5,\n    \"temperature_initial_units\": \"degC\",\n    \"pressure_initial\": 1,\n    \"pressure_initial_units\": \"mmHg\",\n}\nvapor_pressure_strategy = par.gas.VaporPressureFactory().get_strategy(\n    \"clausius_clapeyron\", parameters_clausius\n)\n\nsat_concentration = vapor_pressure_strategy.saturation_concentration(\n    molar_mass_glycerol, 298.15\n)\nprint(f\"Saturation concentration: {sat_concentration:.2e} kg/m^3\")\n\nsat_factor = 0.5  # 50% of saturation concentration\nglycerol_gas = (\n    par.gas.GasSpeciesBuilder()\n    .set_molar_mass(molar_mass_glycerol, \"kg/mol\")\n    .set_vapor_pressure_strategy(vapor_pressure_strategy)\n    .set_concentration(sat_concentration * sat_factor, \"kg/m^3\")\n    .set_name(\"Glycerol\")\n    .set_partitioning(True)\n    .build()\n)\nprint(glycerol_gas)\n\natmosphere = (\n    par.gas.AtmosphereBuilder()\n    .set_more_partitioning_species(glycerol_gas)\n    .set_temperature(25, temperature_units=\"degC\")\n    .set_pressure(1, pressure_units=\"atm\")\n    .build()\n)\nprint(atmosphere)\n\n# Glycerol particle distribution\nlognormal_rep = (\n    par.particles.PresetParticleRadiusBuilder()\n    .set_mode(np.array([100]), \"nm\")\n    .set_geometric_standard_deviation(np.array([1.5]))\n    .set_number_concentration(np.array([1e4]), \"1/cm^3\")\n    .set_density(1.26, \"g/cm^3\")\n    .build()\n)\n</pre> # Glycerol gas molar_mass_glycerol = 92.09382e-3  # kg/mol parameters_clausius = {     \"latent_heat\": 71.5 * molar_mass_glycerol,     \"latent_heat_units\": \"J/mol\",     \"temperature_initial\": 125.5,     \"temperature_initial_units\": \"degC\",     \"pressure_initial\": 1,     \"pressure_initial_units\": \"mmHg\", } vapor_pressure_strategy = par.gas.VaporPressureFactory().get_strategy(     \"clausius_clapeyron\", parameters_clausius )  sat_concentration = vapor_pressure_strategy.saturation_concentration(     molar_mass_glycerol, 298.15 ) print(f\"Saturation concentration: {sat_concentration:.2e} kg/m^3\")  sat_factor = 0.5  # 50% of saturation concentration glycerol_gas = (     par.gas.GasSpeciesBuilder()     .set_molar_mass(molar_mass_glycerol, \"kg/mol\")     .set_vapor_pressure_strategy(vapor_pressure_strategy)     .set_concentration(sat_concentration * sat_factor, \"kg/m^3\")     .set_name(\"Glycerol\")     .set_partitioning(True)     .build() ) print(glycerol_gas)  atmosphere = (     par.gas.AtmosphereBuilder()     .set_more_partitioning_species(glycerol_gas)     .set_temperature(25, temperature_units=\"degC\")     .set_pressure(1, pressure_units=\"atm\")     .build() ) print(atmosphere)  # Glycerol particle distribution lognormal_rep = (     par.particles.PresetParticleRadiusBuilder()     .set_mode(np.array([100]), \"nm\")     .set_geometric_standard_deviation(np.array([1.5]))     .set_number_concentration(np.array([1e4]), \"1/cm^3\")     .set_density(1.26, \"g/cm^3\")     .build() ) <pre>Saturation concentration: 4.95e-03 kg/m^3\nGlycerol\nGas mixture at 298.15 K, 101325.0 Pa, partitioning=Glycerol, gas_only_species=None\n</pre> <p>Notice, that there are two different types of gas phase species possible. <code>partitioning</code> and <code>gas_only_spcies</code>. The <code>partitioning</code> species are the ones that will be partitioned between the gas and particle phase, while the <code>gas_only_species</code> are the ones that will only be in the gas phase.</p> In\u00a0[3]: Copied! <pre>aerosol = par.Aerosol(atmosphere=atmosphere, particles=lognormal_rep)\n\nprint(aerosol)\n</pre> aerosol = par.Aerosol(atmosphere=atmosphere, particles=lognormal_rep)  print(aerosol) <pre>Gas mixture at 298.15 K, 101325.0 Pa, partitioning=Glycerol, gas_only_species=None\nParticle Representation:\n\tStrategy: RadiiBasedMovingBin\n\tActivity: ActivityIdealMass\n\tSurface: SurfaceStrategyVolume\n\tMass Concentration: 1.106e-07 [kg/m^3]\n\tNumber Concentration: 1.000e+10 [#/m^3]\n</pre>"},{"location":"Examples/Aerosol/Aerosol_Tutorial/#aerosol-tutorial","title":"Aerosol Tutorial\u00b6","text":"<p>Aerosols are complex systems comprising both gaseous components and particulate matter. To accurately model such systems, we introduce the <code>Aerosol</code> class, which serves as a collection the <code>Atmosphere</code> and <code>ParticleRepresentation</code> objects.</p> <p>In this quick tutorial, we will demonstrate how to create an <code>Aerosol</code> object, as this is the key object that will track the state of the aerosol system during dynamics.</p>"},{"location":"Examples/Aerosol/Aerosol_Tutorial/#gas-atmosphere-and-particles","title":"Gas-&gt;Atmosphere and Particles\u00b6","text":"<p>First we'll create a simple <code>Atmosphere</code> object, which will represent the gas phase of the aerosol system. We'll also create a <code>ParticleRepresentation</code> object, which will represent the particulate phase of the aerosol system.</p> <p>For the chemical species, we will use a pure component glycerol system.</p>"},{"location":"Examples/Aerosol/Aerosol_Tutorial/#creating-an-aerosol-object","title":"Creating an Aerosol object\u00b6","text":"<p>With both the <code>Atmosphere</code> and <code>ParticleRepresentation</code> objects created, we can now create an <code>Aerosol</code> object. This object will contain both the gas and particle phase objects, and will be used to track the state of the aerosol system during dynamics.</p>"},{"location":"Examples/Aerosol/Aerosol_Tutorial/#summary","title":"Summary\u00b6","text":"<p>In this tutorial, we demonstrated how to create an <code>Aerosol</code> object, which is the key object that will track the state of the aerosol system during dynamics. It is pretty simple, as the <code>Aerosol</code> object is just a collection of the <code>Atmosphere</code> and <code>ParticleRepresentation</code> objects and only functions as a container for these objects. It can also iterate over the <code>Atmosphere</code> and <code>ParticleRepresentation</code> objects.</p>"},{"location":"Examples/Chamber_Wall_Loss/","title":"Index: Chamber Wall Loss","text":"<p>In this example we'll go through the steps for simulation of wall loss in a chamber.</p>"},{"location":"Examples/Chamber_Wall_Loss/#notebooks","title":"Notebooks","text":"<ul> <li>Wall Loss Forward Simulation</li> </ul>"},{"location":"Examples/Chamber_Wall_Loss/Notebooks/Chamber_Forward_Simulation/","title":"Chamber Forward Simulation","text":"In\u00a0[\u00a0]: Copied! <pre># In Colab uncomment the following command to install particula:\n#!pip install particula[extra] --quiet\nimport numpy as np\nfrom matplotlib import pyplot as plt\n\nimport particula as par\n</pre> # In Colab uncomment the following command to install particula: #!pip install particula[extra] --quiet import numpy as np from matplotlib import pyplot as plt  import particula as par In\u00a0[\u00a0]: Copied! <pre># Define initial simulation parameters\nmode = np.array([100e-9, 500e-9])  # Median diameter of the particles in meters\ngeometric_standard_deviation = np.array(\n    [1.3, 1.5]\n)  # Geometric standard deviation of particle size distribution\nnumber_in_mode = (\n    np.array([5e4, 5e3]) * 1e6\n)  # Number of particles in each mode  1/m^3\n\n\n# define the radius bins for the simulation\nradius_bins = np.logspace(-8, -5, 250)\n\n\n# Create particle distribution using the defined parameters\n\nconcentration_pmf = par.particles.get_lognormal_pmf_distribution(\n    x_values=radius_bins,\n    mode=mode,\n    geometric_standard_deviation=geometric_standard_deviation,\n    number_of_particles=number_in_mode,\n)\n\n\n# plot the initial particle distribution\nfig, ax = plt.subplots()\nax.plot(\n    radius_bins, concentration_pmf, label=\"Initial distribution\", marker=\".\"\n)\nax.set_xscale(\"log\")\nax.set_xlabel(\"Particle radius (m)\")\nax.set_ylabel(r\"Particle Concentration (dN), $\\dfrac{1}{m^{3}}$\")\nplt.show()\n</pre> # Define initial simulation parameters mode = np.array([100e-9, 500e-9])  # Median diameter of the particles in meters geometric_standard_deviation = np.array(     [1.3, 1.5] )  # Geometric standard deviation of particle size distribution number_in_mode = (     np.array([5e4, 5e3]) * 1e6 )  # Number of particles in each mode  1/m^3   # define the radius bins for the simulation radius_bins = np.logspace(-8, -5, 250)   # Create particle distribution using the defined parameters  concentration_pmf = par.particles.get_lognormal_pmf_distribution(     x_values=radius_bins,     mode=mode,     geometric_standard_deviation=geometric_standard_deviation,     number_of_particles=number_in_mode, )   # plot the initial particle distribution fig, ax = plt.subplots() ax.plot(     radius_bins, concentration_pmf, label=\"Initial distribution\", marker=\".\" ) ax.set_xscale(\"log\") ax.set_xlabel(\"Particle radius (m)\") ax.set_ylabel(r\"Particle Concentration (dN), $\\dfrac{1}{m^{3}}$\") plt.show() In\u00a0[\u00a0]: Copied! <pre># coagulation rate\n\nparticle_mass = (\n    4 / 3 * np.pi * radius_bins**3 * 1000\n)  # mass of the particles in kg\n\nkernel = par.dynamics.get_brownian_kernel_via_system_state(\n    particle_radius=radius_bins,\n    particle_mass=particle_mass,\n    temperature=293.15,\n    pressure=101325,\n    alpha_collision_efficiency=1,\n)\ncoagulation_loss = par.dynamics.get_coagulation_loss_rate_discrete(\n    concentration=concentration_pmf,\n    kernel=kernel,\n)\ncoagulation_gain = par.dynamics.get_coagulation_gain_rate_discrete(\n    radius=radius_bins,\n    concentration=concentration_pmf,\n    kernel=kernel,\n)\ncoagulation_net = coagulation_gain - coagulation_loss\n\n# dilution rate\ndilution_coefficent = par.dynamics.get_volume_dilution_coefficient(\n    volume=1,  # m^3\n    input_flow_rate=2 * 1e-6,  # m^3/s\n)\ndilution_loss = par.dynamics.get_dilution_rate(\n    coefficient=dilution_coefficent,\n    concentration=concentration_pmf,\n)\n\n# wall loss rate\nchamber_wall_loss_rate = par.dynamics.get_rectangle_wall_loss_rate(\n    wall_eddy_diffusivity=0.1,\n    particle_radius=radius_bins,\n    particle_density=1000,\n    particle_concentration=concentration_pmf,\n    temperature=293.15,\n    pressure=101325,\n    chamber_dimensions=(1, 1, 1),  # m\n)\n\n# plot rates\nfig, ax = plt.subplots()\nax.plot(\n    radius_bins,\n    coagulation_net,\n    label=\"Coagulation Net\",\n)\nax.plot(\n    radius_bins,\n    dilution_loss,\n    label=\"Dilution Loss\",\n)\nax.plot(\n    radius_bins,\n    chamber_wall_loss_rate,\n    label=\"Chamber Wall Loss\",\n)\nax.plot(\n    radius_bins,\n    coagulation_net + dilution_loss + chamber_wall_loss_rate,\n    label=\"Net Rate\",\n    linestyle=\"--\",\n)\nax.set_xscale(\"log\")\n# ax.set_yscale(\"log\")\nax.set_xlabel(\"Particle radius (m)\")\nax.set_ylabel(r\"Rate $\\dfrac{1}{m^{3} s^{1}}$\")\nax.grid()\nplt.legend()\nplt.show()\n</pre> # coagulation rate  particle_mass = (     4 / 3 * np.pi * radius_bins**3 * 1000 )  # mass of the particles in kg  kernel = par.dynamics.get_brownian_kernel_via_system_state(     particle_radius=radius_bins,     particle_mass=particle_mass,     temperature=293.15,     pressure=101325,     alpha_collision_efficiency=1, ) coagulation_loss = par.dynamics.get_coagulation_loss_rate_discrete(     concentration=concentration_pmf,     kernel=kernel, ) coagulation_gain = par.dynamics.get_coagulation_gain_rate_discrete(     radius=radius_bins,     concentration=concentration_pmf,     kernel=kernel, ) coagulation_net = coagulation_gain - coagulation_loss  # dilution rate dilution_coefficent = par.dynamics.get_volume_dilution_coefficient(     volume=1,  # m^3     input_flow_rate=2 * 1e-6,  # m^3/s ) dilution_loss = par.dynamics.get_dilution_rate(     coefficient=dilution_coefficent,     concentration=concentration_pmf, )  # wall loss rate chamber_wall_loss_rate = par.dynamics.get_rectangle_wall_loss_rate(     wall_eddy_diffusivity=0.1,     particle_radius=radius_bins,     particle_density=1000,     particle_concentration=concentration_pmf,     temperature=293.15,     pressure=101325,     chamber_dimensions=(1, 1, 1),  # m )  # plot rates fig, ax = plt.subplots() ax.plot(     radius_bins,     coagulation_net,     label=\"Coagulation Net\", ) ax.plot(     radius_bins,     dilution_loss,     label=\"Dilution Loss\", ) ax.plot(     radius_bins,     chamber_wall_loss_rate,     label=\"Chamber Wall Loss\", ) ax.plot(     radius_bins,     coagulation_net + dilution_loss + chamber_wall_loss_rate,     label=\"Net Rate\",     linestyle=\"--\", ) ax.set_xscale(\"log\") # ax.set_yscale(\"log\") ax.set_xlabel(\"Particle radius (m)\") ax.set_ylabel(r\"Rate $\\dfrac{1}{m^{3} s^{1}}$\") ax.grid() plt.legend() plt.show() In\u00a0[\u00a0]: Copied! <pre># time steps\ntime_array = np.linspace(start=0, stop=3600, num=1000)\ndt = time_array[1] - time_array[0]\n\n# create a matrix to store the particle distribution at each time step\nconcentration_matrix = np.zeros((len(time_array), len(radius_bins)))\ncoagulation_net_matrix = np.zeros((len(time_array), len(radius_bins)))\ndilution_loss_matrix = np.zeros((len(time_array), len(radius_bins)))\nchamber_wall_loss_rate_matrix = np.zeros((len(time_array), len(radius_bins)))\n\n# set the initial concentration\nconcentration_matrix[0, :] = concentration_pmf\n\nkernel = par.dynamics.get_brownian_kernel_via_system_state(\n    particle_radius=radius_bins,\n    particle_mass=particle_mass,\n    temperature=293.15,\n    pressure=101325,\n    alpha_collision_efficiency=1,\n)\n# iterate over the time steps\nfor i, time in enumerate(time_array[1:], start=1):\n\n    # calculate the coagulation rate\n    coagulation_loss = par.dynamics.get_coagulation_loss_rate_discrete(\n        concentration=concentration_matrix[i - 1, :],\n        kernel=kernel,\n    )\n    coagulation_gain = par.dynamics.get_coagulation_gain_rate_discrete(\n        radius=radius_bins,\n        concentration=concentration_matrix[i - 1, :],\n        kernel=kernel,\n    )\n    coagulation_net = coagulation_gain - coagulation_loss\n\n    # calculate the dilution rate\n    dilution_coefficent = par.dynamics.get_volume_dilution_coefficient(\n        volume=1,  # m^3\n        input_flow_rate=2 * 1e-6,  # m^3/s\n    )\n    dilution_loss = par.dynamics.get_dilution_rate(\n        coefficient=dilution_coefficent,\n        concentration=concentration_matrix[i - 1, :],\n    )\n\n    # calculate the wall loss rate\n    chamber_wall_loss_rate = par.dynamics.get_rectangle_wall_loss_rate(\n        wall_eddy_diffusivity=0.1,\n        particle_radius=radius_bins,\n        particle_density=1000,\n        particle_concentration=concentration_matrix[i - 1, :],\n        temperature=293.15,\n        pressure=101325,\n        chamber_dimensions=(1, 1, 1),  # m\n    )\n\n    # update the concentration matrix\n    concentration_matrix[i, :] = (\n        concentration_matrix[i - 1, :]\n        + (coagulation_net + dilution_loss + chamber_wall_loss_rate) * dt\n    )\n\n    # update the rate matrices\n    coagulation_net_matrix[i, :] = coagulation_net\n    dilution_loss_matrix[i, :] = dilution_loss\n    chamber_wall_loss_rate_matrix[i, :] = chamber_wall_loss_rate\n\nprint(\"Done\")\n</pre> # time steps time_array = np.linspace(start=0, stop=3600, num=1000) dt = time_array[1] - time_array[0]  # create a matrix to store the particle distribution at each time step concentration_matrix = np.zeros((len(time_array), len(radius_bins))) coagulation_net_matrix = np.zeros((len(time_array), len(radius_bins))) dilution_loss_matrix = np.zeros((len(time_array), len(radius_bins))) chamber_wall_loss_rate_matrix = np.zeros((len(time_array), len(radius_bins)))  # set the initial concentration concentration_matrix[0, :] = concentration_pmf  kernel = par.dynamics.get_brownian_kernel_via_system_state(     particle_radius=radius_bins,     particle_mass=particle_mass,     temperature=293.15,     pressure=101325,     alpha_collision_efficiency=1, ) # iterate over the time steps for i, time in enumerate(time_array[1:], start=1):      # calculate the coagulation rate     coagulation_loss = par.dynamics.get_coagulation_loss_rate_discrete(         concentration=concentration_matrix[i - 1, :],         kernel=kernel,     )     coagulation_gain = par.dynamics.get_coagulation_gain_rate_discrete(         radius=radius_bins,         concentration=concentration_matrix[i - 1, :],         kernel=kernel,     )     coagulation_net = coagulation_gain - coagulation_loss      # calculate the dilution rate     dilution_coefficent = par.dynamics.get_volume_dilution_coefficient(         volume=1,  # m^3         input_flow_rate=2 * 1e-6,  # m^3/s     )     dilution_loss = par.dynamics.get_dilution_rate(         coefficient=dilution_coefficent,         concentration=concentration_matrix[i - 1, :],     )      # calculate the wall loss rate     chamber_wall_loss_rate = par.dynamics.get_rectangle_wall_loss_rate(         wall_eddy_diffusivity=0.1,         particle_radius=radius_bins,         particle_density=1000,         particle_concentration=concentration_matrix[i - 1, :],         temperature=293.15,         pressure=101325,         chamber_dimensions=(1, 1, 1),  # m     )      # update the concentration matrix     concentration_matrix[i, :] = (         concentration_matrix[i - 1, :]         + (coagulation_net + dilution_loss + chamber_wall_loss_rate) * dt     )      # update the rate matrices     coagulation_net_matrix[i, :] = coagulation_net     dilution_loss_matrix[i, :] = dilution_loss     chamber_wall_loss_rate_matrix[i, :] = chamber_wall_loss_rate  print(\"Done\") In\u00a0[\u00a0]: Copied! <pre># Plotting the simulation results\n# Adjusting the figure size for better clarity\nfig, ax = plt.subplots(1, 1, figsize=[8, 6])\n\n# plot the initial particle distribution\nax.plot(\n    radius_bins,\n    concentration_matrix[0, :],\n    label=\"Initial distribution\",\n)\n# plot the final particle distribution\nax.plot(\n    radius_bins,\n    concentration_matrix[-1, :],\n    label=\"Final distribution\",\n)\nax.set_xscale(\"log\")\nax.set_xlabel(\"Particle radius (m)\")\nax.set_ylabel(r\"Particle Concentration (dN), $\\dfrac{1}{m^{3}}$\")\nplt.legend()\nplt.show()\n</pre> # Plotting the simulation results # Adjusting the figure size for better clarity fig, ax = plt.subplots(1, 1, figsize=[8, 6])  # plot the initial particle distribution ax.plot(     radius_bins,     concentration_matrix[0, :],     label=\"Initial distribution\", ) # plot the final particle distribution ax.plot(     radius_bins,     concentration_matrix[-1, :],     label=\"Final distribution\", ) ax.set_xscale(\"log\") ax.set_xlabel(\"Particle radius (m)\") ax.set_ylabel(r\"Particle Concentration (dN), $\\dfrac{1}{m^{3}}$\") plt.legend() plt.show() In\u00a0[\u00a0]: Copied! <pre># plot the Initial and Final rates\nfig, ax = plt.subplots()\nax.plot(\n    radius_bins,\n    coagulation_net_matrix[1, :],\n    color=\"tab:blue\",\n    label=\"Initial Coagulation Net\",\n)\nax.plot(\n    radius_bins,\n    dilution_loss_matrix[1, :],\n    color=\"tab:orange\",\n    label=\"Initial Dilution Loss\",\n)\nax.plot(\n    radius_bins,\n    chamber_wall_loss_rate_matrix[1, :],\n    color=\"tab:green\",\n    label=\"Initial Chamber Wall Loss\",\n)\nax.plot(\n    radius_bins,\n    coagulation_net_matrix[-1, :],\n    color=\"tab:blue\",\n    label=\"Final Coagulation Net\",\n    linestyle=\"--\",\n)\nax.plot(\n    radius_bins,\n    dilution_loss_matrix[-1, :],\n    color=\"tab:orange\",\n    label=\"Final Dilution Loss\",\n    linestyle=\"--\",\n)\nax.plot(\n    radius_bins,\n    chamber_wall_loss_rate_matrix[-1, :],\n    color=\"tab:green\",\n    label=\"Final Chamber Wall Loss\",\n    linestyle=\"--\",\n)\nax.set_xscale(\"log\")\nax.set_xlabel(\"Particle radius (m)\")\nax.set_ylabel(r\"Rate $\\dfrac{1}{m^{3} s^{1}}$\")\nax.grid()\nplt.legend()\nplt.show()\n</pre> # plot the Initial and Final rates fig, ax = plt.subplots() ax.plot(     radius_bins,     coagulation_net_matrix[1, :],     color=\"tab:blue\",     label=\"Initial Coagulation Net\", ) ax.plot(     radius_bins,     dilution_loss_matrix[1, :],     color=\"tab:orange\",     label=\"Initial Dilution Loss\", ) ax.plot(     radius_bins,     chamber_wall_loss_rate_matrix[1, :],     color=\"tab:green\",     label=\"Initial Chamber Wall Loss\", ) ax.plot(     radius_bins,     coagulation_net_matrix[-1, :],     color=\"tab:blue\",     label=\"Final Coagulation Net\",     linestyle=\"--\", ) ax.plot(     radius_bins,     dilution_loss_matrix[-1, :],     color=\"tab:orange\",     label=\"Final Dilution Loss\",     linestyle=\"--\", ) ax.plot(     radius_bins,     chamber_wall_loss_rate_matrix[-1, :],     color=\"tab:green\",     label=\"Final Chamber Wall Loss\",     linestyle=\"--\", ) ax.set_xscale(\"log\") ax.set_xlabel(\"Particle radius (m)\") ax.set_ylabel(r\"Rate $\\dfrac{1}{m^{3} s^{1}}$\") ax.grid() plt.legend() plt.show()"},{"location":"Examples/Chamber_Wall_Loss/Notebooks/Chamber_Forward_Simulation/#chamber-forward-simulation","title":"Chamber Forward Simulation\u00b6","text":"<p>Comprehending particle dynamics within controlled environments is fundamental for the precise interpretation of experimental measurements. An aerosol chamber forward simulation is an approach employed to analyze and predict the behavior of particles under laboratory conditions. This method enables us to construct a virtual representation of the chamber dynamics, providing a platform to systematically examine the influence of different physical and chemical processes on aerosol populations. Specifically, we focus on three key processes: chamber aerosol dilution, particle coagulation, and wall loss (deposition). Each of these plays a pivotal role in shaping the size distribution of particles:</p> <ul> <li>Chamber Aerosol Dilution: Dilution refers to the reduction in particle concentration due to the introduction of clean air into the chamber. This process can lead to a decrease in the overall number of particles without altering the size distribution significantly. However, it can indirectly influence the dynamics of coagulation and deposition by changing the particle concentration.</li> <li>Particle Coagulation: Coagulation is the process where particles collide and stick together, forming larger particles. This leads to a shift in the size distribution towards larger sizes, reducing the number of smaller particles and increasing the average size of particles in the chamber. Coagulation is particularly significant for smaller particles due to their higher Brownian motion and likelihood of interaction.</li> <li>Wall Loss (Deposition): Wall loss occurs when particles deposit onto the walls of the chamber, removing them from the airborne population. This process preferentially affects larger particles due to their greater settling velocity and can lead to a decrease in the overall number of particles and a subtle shift in the size distribution towards smaller sizes.</li> </ul> <p>We'll be running a simulation of a chamber experiment, and turn on/off each of these processes to see how they affect the size distribution of particles. We'll also be able to see how the size distribution changes over time as the experiment progresses.</p> <p>The initial <code>particula</code> imports are next.</p>"},{"location":"Examples/Chamber_Wall_Loss/Notebooks/Chamber_Forward_Simulation/#rates","title":"Rates\u00b6","text":"<p>With the initial concentration setup we can now get the rates of change for the distribution of particles. These come from the <code>dynamics</code> module, which contains the functions to calculate the rates of change for each process. The <code>dynamics</code> module contains the following functions:</p> <ul> <li><code>dilution_rate</code>: Calculates the rate of change due to dilution.</li> <li><code>coagulation_rate</code>: Calculates the rate of change due to coagulation.</li> <li><code>wall_loss_rate</code>: Calculates the rate of change due to wall loss.</li> </ul>"},{"location":"Examples/Chamber_Wall_Loss/Notebooks/Chamber_Forward_Simulation/#for-loop-simulation","title":"For-loop Simulation\u00b6","text":"<p>With the an example of how to calculate the rates of change for each process, we can now simulate the chamber experiment. We'll iterate over a series of time steps and calculate the change in particle concentration due to each process. This is an iterative process where we update the particle distribution at each time step based on the rates of change calculated for dilution, coagulation, and wall loss. The rates are also updated at each time step to account for the changing particle concentration within the chamber.</p>"},{"location":"Examples/Chamber_Wall_Loss/Notebooks/Chamber_Forward_Simulation/#visualization-of-particle-size-distribution-over-time","title":"Visualization of Particle Size Distribution Over Time\u00b6","text":"<p>In our chamber simulation, the output solution is a matrix representing the evolution of particle size distribution over time. Specifically, the solution is a 500x100 matrix where each row corresponds to a specific particle size (500 size bins in total), and each column represents the particle distribution at a given time point (100 time steps in total).</p> <p>The semi-logarithmic plot visualizes how the particle size distribution changes over the course of the simulation. We are focusing on three specific time points to illustrate these dynamics:</p> <ul> <li>Initial Distribution: This is the distribution at the beginning of the simulation (t=0). It sets the baseline for how particles are initially distributed across different sizes.</li> <li>Mid-Time Distribution: Represents the distribution at a midpoint in time (here, at the 50th time step out of 100). This snapshot provides insight into the evolution of the distribution as particles undergo processes like coagulation, dilution, and wall loss.</li> <li>Final Distribution: Shows the distribution at the end of the simulation (at the 100th time step). It indicates the final state of the particle sizes after all the simulated processes have taken place over the full time course.</li> </ul> <p>By comparing these three distributions, we can observe and analyze how the particle sizes have coalesced, dispersed, or shifted due to the underlying aerosol dynamics within the chamber.</p>"},{"location":"Examples/Chamber_Wall_Loss/Notebooks/Chamber_Forward_Simulation/#takeaways","title":"Takeaways\u00b6","text":"<p>In this notebook, we conducted a series of simulations to study the behavior of aerosol particles within a controlled chamber environment. Our objective was to understand how different processes \u2014 namely coagulation, dilution, and wall loss \u2014 individually and collectively influence the size distribution of particles over time.</p> <p>Our simulations revealed several key findings:</p> <ul> <li>Coagulation Alone: When only coagulation was considered, the particle size distribution shifted towards larger particles as expected, since smaller particles tend to combine. However, this view was incomplete as it did not account for other loss mechanisms.</li> <li>Importance of Wall Loss: The inclusion of wall loss in the simulations proved to be significant. Wall loss, or deposition, especially affected the larger particles due to their higher probability of contact with the chamber walls. This process led to a noticeable reduction in the number concentration of particles, altering the peak and width of the size distribution.</li> <li>Combined Processes: By simulating a combination of processes, we observed a more complex and realistic representation of particle dynamics. The coagulation plus dilution scenario showed a lower overall concentration across all sizes, while adding wall loss further decreased the number concentration and altered the distribution shape, underscoring the importance of including wall loss in chamber simulations.</li> </ul> <p>The comparison between the different scenarios highlighted that coagulation alone could not fully explain the experimental observations. The absence of wall loss from the simulation would lead to discrepancies when comparing with empirical data, as wall loss is a critical process in chamber dynamics.</p>"},{"location":"Examples/Dynamics/","title":"Dynamics","text":"<p>Here we collect tutorials on the dynamic processes that can affect aerosol populations,  including condensation, coagulation, and special customizations.</p>"},{"location":"Examples/Dynamics/#condensation","title":"Condensation","text":"<p>These notebooks demonstrate bin-based and fully resolved approaches to modeling condensation.</p> <ul> <li>Condensation 1: Bins</li> <li>Condensation 2: Masses Binned</li> <li>Condensation 3: Masses Resolved</li> </ul>"},{"location":"Examples/Dynamics/#coagulation","title":"Coagulation","text":"<ul> <li>Coagulation 1: PMF Pattern \u2013 Shows probability mass function approach.</li> <li>Coagulation 3: Particle Resolved \u2013 Demonstrates a particle-resolved approach.</li> <li>Coagulation 4: Methods Compared \u2013 Compares multiple coagulation strategies.</li> </ul>"},{"location":"Examples/Dynamics/#functional","title":"Functional","text":"<p>These illustrate functional approaches to coagulation, comparing PMF- and PDF-based methods against particle-resolved methods.</p> <ul> <li>Coagulation 1: Probability Mass Function</li> <li>Coagulation Tutorial: Basic 2-PDF</li> <li>Coagulation Tutorial: Basic 3-Compared</li> </ul>"},{"location":"Examples/Dynamics/#charge","title":"Charge","text":"<p>Here we show how to include charge effects in the coagulation kernel:</p> <ul> <li>Coagulation Charges via functions</li> <li>Coagulation Charges via objects</li> </ul>"},{"location":"Examples/Dynamics/#customization","title":"Customization","text":"<ul> <li>Adding Particles During Simulation \u2013    Demonstrates customizing the simulation by injecting new particles.</li> </ul>"},{"location":"Examples/Dynamics/Coagulation/Coagulation_1_PMF_Pattern/","title":"Coagulation Patterns: PMF Particle Distribution","text":"In\u00a0[\u00a0]: Copied! <pre># In Colab uncomment the following command to install particula:\n#!pip install particula[extra] --quiet\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nimport particula as par\n</pre> # In Colab uncomment the following command to install particula: #!pip install particula[extra] --quiet import numpy as np import matplotlib.pyplot as plt  import particula as par In\u00a0[5]: Copied! <pre># Preset gas species that does not condense in the atmosphere\n# AtmosphereBuilder constructs the atmosphere with predefined species\natmosphere = (\n    par.gas.AtmosphereBuilder()\n    .set_temperature(25, temperature_units=\"degC\")  # Set temperature to 25\u00b0C\n    .set_pressure(1, pressure_units=\"atm\")  # Set pressure to 1 atmosphere\n    .build()  # Finalize the atmosphere object\n)\n\n\n# Build a resolved mass representation for each particle\n# This defines how particle mass, activity, and surface are represented\nradius_bins = np.logspace(\n    -8, -5, 250\n)  # Define the radius bins for the resolved mass representation\nresolved_masses = (\n    par.particles.PresetParticleRadiusBuilder()\n    .set_mode(np.array([100, 800]), mode_units=\"nm\")  # Set the mode radius\n    .set_geometric_standard_deviation(\n        np.array([1.2, 1.5])\n    )  # Set the geometric standard deviation\n    .set_number_concentration(\n        np.array([1e5, 2e5]), number_concentration_units=\"cm^-3\"\n    )  # Set the number concentration\n    .set_distribution_type(\"pmf\")  # Set the distribution type to PMF\n    .set_radius_bins(radius_bins, radius_bins_units=\"m\")  # Set the radius bins\n    .build()  # Finalize the resolved mass representation\n)\n\n# Create an aerosol object with the defined atmosphere and resolved particles\naerosol = par.Aerosol(atmosphere=atmosphere, particles=resolved_masses)\n\n# Print the properties\nprint(aerosol)\n</pre> # Preset gas species that does not condense in the atmosphere # AtmosphereBuilder constructs the atmosphere with predefined species atmosphere = (     par.gas.AtmosphereBuilder()     .set_temperature(25, temperature_units=\"degC\")  # Set temperature to 25\u00b0C     .set_pressure(1, pressure_units=\"atm\")  # Set pressure to 1 atmosphere     .build()  # Finalize the atmosphere object )   # Build a resolved mass representation for each particle # This defines how particle mass, activity, and surface are represented radius_bins = np.logspace(     -8, -5, 250 )  # Define the radius bins for the resolved mass representation resolved_masses = (     par.particles.PresetParticleRadiusBuilder()     .set_mode(np.array([100, 800]), mode_units=\"nm\")  # Set the mode radius     .set_geometric_standard_deviation(         np.array([1.2, 1.5])     )  # Set the geometric standard deviation     .set_number_concentration(         np.array([1e5, 2e5]), number_concentration_units=\"cm^-3\"     )  # Set the number concentration     .set_distribution_type(\"pmf\")  # Set the distribution type to PMF     .set_radius_bins(radius_bins, radius_bins_units=\"m\")  # Set the radius bins     .build()  # Finalize the resolved mass representation )  # Create an aerosol object with the defined atmosphere and resolved particles aerosol = par.Aerosol(atmosphere=atmosphere, particles=resolved_masses)  # Print the properties print(aerosol) <pre>Gas mixture at 298.15 K, 101325.0 Pa, partitioning=None, gas_only_species=None\nParticle Representation:\n\tStrategy: RadiiBasedMovingBin\n\tActivity: ActivityIdealMass\n\tSurface: SurfaceStrategyVolume\n\tMass Concentration: 8.993e-04 [kg/m^3]\n\tNumber Concentration: 3.000e+11 [#/m^3]\n</pre> In\u00a0[6]: Copied! <pre># Define the coagulation strategy and process\ncoagulation_strategy = (\n    par.dynamics.BrownianCoagulationBuilder()\n    .set_distribution_type(distribution_type=\"discrete\")\n    .build()\n)\ncoagulation_process = par.dynamics.Coagulation(\n    coagulation_strategy=coagulation_strategy\n)\n\n# Set up time and sub-steps for the coagulation process\ntime_step = 1000\nsub_steps = 100\n\ninitial_radii = aerosol.particles.get_radius()\nconcentration_initial = np.copy(aerosol.particles.concentration)\n\n# # Perform coagulation process for step 1\naerosol = coagulation_process.execute(\n    aerosol, time_step=time_step, sub_steps=sub_steps\n)\nradii_after_step_1 = aerosol.particles.get_radius()\nconcentration_step_1 = np.copy(aerosol.particles.concentration)\n\n# Perform coagulation process for step 2\naerosol = coagulation_process.execute(\n    aerosol, time_step=time_step, sub_steps=sub_steps\n)\nradii_after_step_2 = aerosol.particles.get_radius()\nconcentration_step_2 = np.copy(aerosol.particles.concentration)\n</pre> # Define the coagulation strategy and process coagulation_strategy = (     par.dynamics.BrownianCoagulationBuilder()     .set_distribution_type(distribution_type=\"discrete\")     .build() ) coagulation_process = par.dynamics.Coagulation(     coagulation_strategy=coagulation_strategy )  # Set up time and sub-steps for the coagulation process time_step = 1000 sub_steps = 100  initial_radii = aerosol.particles.get_radius() concentration_initial = np.copy(aerosol.particles.concentration)  # # Perform coagulation process for step 1 aerosol = coagulation_process.execute(     aerosol, time_step=time_step, sub_steps=sub_steps ) radii_after_step_1 = aerosol.particles.get_radius() concentration_step_1 = np.copy(aerosol.particles.concentration)  # Perform coagulation process for step 2 aerosol = coagulation_process.execute(     aerosol, time_step=time_step, sub_steps=sub_steps ) radii_after_step_2 = aerosol.particles.get_radius() concentration_step_2 = np.copy(aerosol.particles.concentration) In\u00a0[7]: Copied! <pre># Create figure for visualizing the histogram of particle radii\nfig, ax = plt.subplots(figsize=(8, 6))\n\n# Plot the histogram of particle radii after step 1\nax.plot(initial_radii, concentration_initial, label=\"Initial\")\nax.plot(radii_after_step_1, concentration_step_1, label=\"Step 1\")\nax.plot(radii_after_step_2, concentration_step_2, label=\"Step 2\")\n\n# Set the labels and title of the plot\nax.set_xlabel(\"Particle Radius (m)\")\nax.set_ylabel(r\"Number Concentration ($m^{-3}$)\")\nax.set_title(\"Particle Radius Distribution After Coagulation Steps\")\nax.legend()\nax.set_xscale(\"log\")\nplt.show()\n</pre> # Create figure for visualizing the histogram of particle radii fig, ax = plt.subplots(figsize=(8, 6))  # Plot the histogram of particle radii after step 1 ax.plot(initial_radii, concentration_initial, label=\"Initial\") ax.plot(radii_after_step_1, concentration_step_1, label=\"Step 1\") ax.plot(radii_after_step_2, concentration_step_2, label=\"Step 2\")  # Set the labels and title of the plot ax.set_xlabel(\"Particle Radius (m)\") ax.set_ylabel(r\"Number Concentration ($m^{-3}$)\") ax.set_title(\"Particle Radius Distribution After Coagulation Steps\") ax.legend() ax.set_xscale(\"log\") plt.show()"},{"location":"Examples/Dynamics/Coagulation/Coagulation_1_PMF_Pattern/#coagulation-patterns-pmf-particle-distribution","title":"Coagulation Patterns: PMF Particle Distribution\u00b6","text":"<p>This notebook explores the coagulation process using a Probability Mass Function (PMF) to define the initial particle size distribution. A PMF provides a representation of discrete particle sizes bins and their associated counts.</p> <p>The PMF-based distribution allows us to model how the number of particles in each size category changes over time due to coagulation, providing insights into the size distribution's shift toward larger particles.</p> <p>PMF Particle Distribution: We initialize the particle size distribution using a PMF, where each particle bin has a concentration count. This discrete distribution captures the initial population of particles, categorized by size. The PMF provides flexibility in representing systems where specific particle sizes are dominant or where particles are grouped into size bins.</p> <p>Coagulation Process: The coagulation process is modeled using a discrete bin approach. We define the coagulation process using a flexible <code>Coagulation</code> class, which allows us to choose different coagulation strategies. In this notebook, we employ the <code>DiscreteSimple</code> strategy, which tracks each particle's properties as it undergoes coagulation.</p> <p>Imports:</p>"},{"location":"Examples/Dynamics/Coagulation/Coagulation_1_PMF_Pattern/#aerosol-setup","title":"Aerosol Setup\u00b6","text":"<p>This section sets up the aerosol system, defining both the atmospheric conditions and the properties of the particles within it. We use the Builder pattern to construct the atmosphere and the particle mass distribution, ensuring that all parameters are defined explicitly and can be validated during the setup process.</p> <p>Atmospheric Setup</p> <p>The atmosphere is created using the <code>AtmosphereBuilder</code>. This class allows us to define key environmental parameters such as the gas species, temperature, and pressure.</p> <ul> <li>Gas Species: We add a preset gas species using the <code>PresetGasSpeciesBuilder</code>, which represents a non-condensing gas in the atmosphere.</li> <li>Temperature: The temperature is set to 25\u00b0C, representing typical atmospheric conditions.</li> <li>Pressure: Atmospheric pressure is set to 1 atm, simulating standard sea-level pressure.</li> </ul> <p>The <code>build()</code> method finalizes the atmosphere object, which will be used in the aerosol simulation.</p> <p>Resolved Particle Mass Representation</p> <p>Next, we define the particle mass distribution using the <code>PresetParticleRadiusBuilder</code>. This builder allows for setting up a detailed particle distribution based on physical properties such as particle size (mode), geometric standard deviation (GSD), and number concentration.</p> <ul> <li>Mode: The particle size modes are set to 100 nm and 800 nm, defining two distinct groups of particles within the aerosol.</li> <li>Geometric Standard Deviation (GSD): GSD values of 1.2 and 1.5 represent the spread of particle sizes within each mode, with the larger GSD indicating a broader distribution of particle sizes.</li> <li>Number Concentration: The number concentration for the two modes is defined as 1e5 and 2e5 particles per cm\u00b3, respectively.</li> <li>Distribution Type: We specify that the distribution follows a Probability Mass Function (PMF), which allows for a discrete representation of particle sizes.</li> <li>Radius Bins: The radius bins are defined using <code>np.logspace</code> to create a logarithmic spacing between particle radii ranging from 10 nm to 100 \u00b5m. This ensures that the distribution captures a wide range of particle sizes.</li> </ul> <p>Once all parameters are set, the <code>build()</code> method finalizes the particle mass representation.</p> <p>Aerosol Object Creation</p> <p>Finally, the aerosol system is created by combining the atmospheric conditions and the resolved particle masses. The resulting <code>aerosol</code> object contains both the gas phase and particle distribution, ready for use in the coagulation simulation.</p>"},{"location":"Examples/Dynamics/Coagulation/Coagulation_1_PMF_Pattern/#simulation","title":"Simulation\u00b6","text":"<p>In this section, we define the coagulation process and run it over multiple time steps. Coagulation is the process by which particles in an aerosol collide and merge, resulting in fewer, larger particles over time. The <code>Coagulation</code> class is used to simulate this behavior in a stepwise manner, updating the particle size distribution as the simulation progresses.</p> <p>Defining the Coagulation Strategy and Process</p> <p>We start by selecting a coagulation strategy using <code>DiscreteSimple()</code>, which defines how particles will interact and merge during the coagulation process. In this case, the <code>DiscreteSimple</code> strategy simplifies the coagulation by treating particle collisions discretely, allowing for straightforward tracking of particle size and number changes.</p> <ul> <li>Coagulation Strategy: The strategy dictates how particle interactions are handled. Here, <code>DiscreteSimple</code> offers a simplified, yet effective, approach for discrete particle interactions.</li> <li>Coagulation Process: The <code>Coagulation</code> class orchestrates the entire process, taking the defined strategy and applying it to the aerosol particles over the specified time and sub-steps.</li> </ul> <p>Simulation Setup: Time and Sub-Steps</p> <p>The coagulation process runs over defined time steps and sub-steps:</p> <ul> <li>Time Step: Each time step simulates the evolution of the aerosol system over a specific interval. In this case, it is set to 1000, representing a coarse time resolution.</li> <li>Sub-Steps: The time step is further divided into 100 sub-steps, which ensures a finer resolution for particle interactions, capturing the nuances of the coagulation process more accurately.</li> </ul> <p>Running the Coagulation Process</p> <p>The coagulation process is executed for the first time step using the <code>execute()</code> method. This method updates the aerosol object, modifying the particle size distribution as particles collide and merge. After this step:</p> <ul> <li>Radii After Step: The particle radii are extracted again to observe the changes in size distribution due to coagulation.</li> <li>Concentration After Step: The concentration of particles in each size bin is updated and saved for comparison.</li> </ul>"},{"location":"Examples/Dynamics/Coagulation/Coagulation_1_PMF_Pattern/#graphing","title":"Graphing\u00b6","text":"<p>In this section, we visualize how the particle size distribution evolves after each step of the coagulation process. The graph displays the number concentration of particles (in m\u207b\u00b3) as a function of particle radius (in meters). We use three curves to represent the distribution at different stages of the simulation:</p> <ol> <li>Initial: This curve represents the particle distribution before any coagulation occurs.</li> <li>Step 1: This curve shows how the distribution has changed after one step of the coagulation process.</li> <li>Step 2: This curve reflects the further evolution of the particle sizes after a second step of coagulation.</li> </ol> <p>Coagulation Effect:</p> <ul> <li>After the first step (orange line), the peaks shift downward, indicating a reduction in the number concentration of particles across both size ranges. This is due to smaller particles merging through coagulation, resulting in fewer particles overall.</li> <li>After the second step (green line), the number concentration of particles continues to decrease, with the peaks further reducing in height.</li> <li>The shift towards larger particles becomes more evident as the second peak moves slightly to the right. This is a typical result of coagulation, where larger particles grow as smaller particles merge into them.</li> </ul> <p>Distribution Changes:</p> <ul> <li>Decrease in Number Concentration: Coagulation leads to a reduction in the number of smaller particles as they combine to form larger ones. This is reflected in the decrease in concentration after each step.</li> <li>Shift Toward Larger Particles: The coagulation process shifts the distribution toward larger particle sizes. While the first step results in some particles merging, the second step pushes this trend further, as seen in the slight shift of the second peak to larger radii.</li> <li>Wider Distribution: As the simulation progresses, the particle size distribution becomes broader, indicating increased variability in particle sizes. This suggests that coagulation is affecting particles across a range of sizes, not just those at the peaks.</li> </ul>"},{"location":"Examples/Dynamics/Coagulation/Coagulation_1_PMF_Pattern/#conclusion","title":"Conclusion\u00b6","text":"<p>This notebook demonstrates how a PMF-based particle distribution can be used to model the coagulation process in an aerosol system. By tracking the changes in particle size distribution over time, we can observe the shift towards larger particles due to coagulation. The discrete representation of particle sizes allows for detailed insights into how particles interact and merge, leading to changes in the aerosol composition.</p>"},{"location":"Examples/Dynamics/Coagulation/Coagulation_3_Particle_Resolved_Pattern/","title":"Coagulation Patterns: Particle-Resolved Approach","text":"In\u00a0[\u00a0]: Copied! <pre># In Colab uncomment the following command to install particula:\n#!pip install particula[extra] --quiet\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# particula imports\nimport particula as par\n</pre> # In Colab uncomment the following command to install particula: #!pip install particula[extra] --quiet import numpy as np import matplotlib.pyplot as plt  # particula imports import particula as par In\u00a0[2]: Copied! <pre># Preset gas species that does not condense in the atmosphere\n# AtmosphereBuilder constructs the atmosphere with predefined species\natmosphere = (\n    par.gas.AtmosphereBuilder()\n    .set_temperature(25, temperature_units=\"degC\")  # Set temperature to 25\u00b0C\n    .set_pressure(1, pressure_units=\"atm\")  # Set pressure to 1 atmosphere\n    .build()  # Finalize the atmosphere object\n)\n\n# Generate a particle distribution using a lognormal sample distribution\n# This distribution has a mean particle diameter (mode) and geometric standard deviation (GSD)\nparticle_sample = par.particles.get_lognormal_sample_distribution(\n    mode=np.array([100e-9]),  # Mean particle diameter of 100 nm\n    geometric_standard_deviation=np.array([1.3]),  # GSD of 1.3\n    number_of_particles=np.array([1e4]),  # Total number of particles\n    number_of_samples=100_000,  # Number of samples for particle distribution\n)\n\n# Calculate the mass of each particle in the sample, assuming density of 1500 kg/m^3\nparticle_mass_sample = (\n    4 / 3 * np.pi * particle_sample**3 * 1500\n)  # Particle mass in kg\n\n# Build a resolved mass representation for each particle\n# This defines how particle mass, activity, and surface are represented\nresolved_masses = (\n    par.particles.ResolvedParticleMassRepresentationBuilder()\n    .set_distribution_strategy(\n        par.particles.ParticleResolvedSpeciatedMass()\n    )  # Use speciated mass distribution\n    .set_activity_strategy(\n        par.particles.ActivityIdealMass()\n    )  # Define activity based on ideal mass\n    .set_surface_strategy(\n        par.particles.SurfaceStrategyVolume()\n    )  # Define surface area based on particle volume\n    .set_mass(particle_mass_sample, \"kg\")  # Assign mass of particles (in kg)\n    .set_density(1500, \"kg/m^3\")  # Set particle density to 1500 kg/m^3\n    .set_charge(0)  # Assume neutral particles with no charge\n    .set_volume(0.1, \"cm^3\")  # Set volume of particle distribution\n    .build()  # Finalize the resolved mass representation\n)\n\n# Create an aerosol object with the defined atmosphere and resolved particles\naerosol = par.Aerosol(atmosphere=atmosphere, particles=resolved_masses)\n\n# Print the properties of the atmosphere\nprint(aerosol)\n</pre> # Preset gas species that does not condense in the atmosphere # AtmosphereBuilder constructs the atmosphere with predefined species atmosphere = (     par.gas.AtmosphereBuilder()     .set_temperature(25, temperature_units=\"degC\")  # Set temperature to 25\u00b0C     .set_pressure(1, pressure_units=\"atm\")  # Set pressure to 1 atmosphere     .build()  # Finalize the atmosphere object )  # Generate a particle distribution using a lognormal sample distribution # This distribution has a mean particle diameter (mode) and geometric standard deviation (GSD) particle_sample = par.particles.get_lognormal_sample_distribution(     mode=np.array([100e-9]),  # Mean particle diameter of 100 nm     geometric_standard_deviation=np.array([1.3]),  # GSD of 1.3     number_of_particles=np.array([1e4]),  # Total number of particles     number_of_samples=100_000,  # Number of samples for particle distribution )  # Calculate the mass of each particle in the sample, assuming density of 1500 kg/m^3 particle_mass_sample = (     4 / 3 * np.pi * particle_sample**3 * 1500 )  # Particle mass in kg  # Build a resolved mass representation for each particle # This defines how particle mass, activity, and surface are represented resolved_masses = (     par.particles.ResolvedParticleMassRepresentationBuilder()     .set_distribution_strategy(         par.particles.ParticleResolvedSpeciatedMass()     )  # Use speciated mass distribution     .set_activity_strategy(         par.particles.ActivityIdealMass()     )  # Define activity based on ideal mass     .set_surface_strategy(         par.particles.SurfaceStrategyVolume()     )  # Define surface area based on particle volume     .set_mass(particle_mass_sample, \"kg\")  # Assign mass of particles (in kg)     .set_density(1500, \"kg/m^3\")  # Set particle density to 1500 kg/m^3     .set_charge(0)  # Assume neutral particles with no charge     .set_volume(0.1, \"cm^3\")  # Set volume of particle distribution     .build()  # Finalize the resolved mass representation )  # Create an aerosol object with the defined atmosphere and resolved particles aerosol = par.Aerosol(atmosphere=atmosphere, particles=resolved_masses)  # Print the properties of the atmosphere print(aerosol) <pre>Gas mixture at 298.15 K, 101325.0 Pa, partitioning=None, gas_only_species=None\nParticle Representation:\n\tStrategy: ParticleResolvedSpeciatedMass\n\tActivity: ActivityIdealMass\n\tSurface: SurfaceStrategyVolume\n\tMass Concentration: 8.544e-06 [kg/m^3]\n\tNumber Concentration: 1.000e+12 [#/m^3]\n</pre> In\u00a0[3]: Copied! <pre># Define the coagulation strategy and process\ncoagulation_strategy = (\n    par.dynamics.BrownianCoagulationBuilder()\n    .set_distribution_type(distribution_type=\"particle_resolved\")\n    .build()\n)\ncoagulation_process = par.dynamics.Coagulation(\n    coagulation_strategy=coagulation_strategy\n)\n\n# Set up time and sub-steps for the coagulation process\ntime_step = 1000\nsub_steps = 100\n\n# Define lognormal bins for particle radius histogram\nbins_lognormal = np.logspace(-8, -6, 100)\n\n# Get initial particle radii before the coagulation process\ninitial_radii = aerosol.particles.get_radius()\n\n# Perform coagulation process for step 1\naerosol = coagulation_process.execute(\n    aerosol, time_step=time_step, sub_steps=sub_steps\n)\nradii_after_step_1 = aerosol.particles.get_radius()\n\n# Perform coagulation process for step 2\naerosol = coagulation_process.execute(\n    aerosol, time_step=time_step, sub_steps=sub_steps\n)\nradii_after_step_2 = aerosol.particles.get_radius()\n\n# Count particles that have coagulated (i.e., have zero mass)\nzero_count = np.sum(aerosol.particles.get_mass() == 0)\nprint(f\"Particles that coagulated: {zero_count}\")\n</pre> # Define the coagulation strategy and process coagulation_strategy = (     par.dynamics.BrownianCoagulationBuilder()     .set_distribution_type(distribution_type=\"particle_resolved\")     .build() ) coagulation_process = par.dynamics.Coagulation(     coagulation_strategy=coagulation_strategy )  # Set up time and sub-steps for the coagulation process time_step = 1000 sub_steps = 100  # Define lognormal bins for particle radius histogram bins_lognormal = np.logspace(-8, -6, 100)  # Get initial particle radii before the coagulation process initial_radii = aerosol.particles.get_radius()  # Perform coagulation process for step 1 aerosol = coagulation_process.execute(     aerosol, time_step=time_step, sub_steps=sub_steps ) radii_after_step_1 = aerosol.particles.get_radius()  # Perform coagulation process for step 2 aerosol = coagulation_process.execute(     aerosol, time_step=time_step, sub_steps=sub_steps ) radii_after_step_2 = aerosol.particles.get_radius()  # Count particles that have coagulated (i.e., have zero mass) zero_count = np.sum(aerosol.particles.get_mass() == 0) print(f\"Particles that coagulated: {zero_count}\") <pre>Particles that coagulated: 51679\n</pre> In\u00a0[4]: Copied! <pre># Create figure for visualizing the histogram of particle radii\nfig, ax = plt.subplots(figsize=(8, 6))\n\n# Plot initial radii distribution\nbins, edges = np.histogram(initial_radii, bins=bins_lognormal)\nax.bar(edges[:-1], bins, width=np.diff(edges), align=\"edge\", label=\"Initial\")\n\n# Plot radii distribution after step 1\nbins, edges = np.histogram(radii_after_step_1, bins=bins_lognormal)\nax.bar(\n    edges[:-1],\n    bins,\n    width=np.diff(edges),\n    align=\"edge\",\n    label=\"After 1 step\",\n    alpha=0.7,\n)\n\n# Plot radii distribution after step 2\nbins, edges = np.histogram(radii_after_step_2, bins=bins_lognormal)\nax.bar(\n    edges[:-1],\n    bins,\n    width=np.diff(edges),\n    align=\"edge\",\n    label=\"After 2 steps\",\n    alpha=0.6,\n)\n\n# Set axes to logarithmic scale for x-axis (particle radius)\nax.set_xscale(\"log\")\n\n# Add labels and legend\nax.set_xlabel(\"Radius (m)\")\nax.set_ylabel(\"Number of particles\")\nplt.legend()\n\n# Show the plot\nplt.show()\n</pre> # Create figure for visualizing the histogram of particle radii fig, ax = plt.subplots(figsize=(8, 6))  # Plot initial radii distribution bins, edges = np.histogram(initial_radii, bins=bins_lognormal) ax.bar(edges[:-1], bins, width=np.diff(edges), align=\"edge\", label=\"Initial\")  # Plot radii distribution after step 1 bins, edges = np.histogram(radii_after_step_1, bins=bins_lognormal) ax.bar(     edges[:-1],     bins,     width=np.diff(edges),     align=\"edge\",     label=\"After 1 step\",     alpha=0.7, )  # Plot radii distribution after step 2 bins, edges = np.histogram(radii_after_step_2, bins=bins_lognormal) ax.bar(     edges[:-1],     bins,     width=np.diff(edges),     align=\"edge\",     label=\"After 2 steps\",     alpha=0.6, )  # Set axes to logarithmic scale for x-axis (particle radius) ax.set_xscale(\"log\")  # Add labels and legend ax.set_xlabel(\"Radius (m)\") ax.set_ylabel(\"Number of particles\") plt.legend()  # Show the plot plt.show()"},{"location":"Examples/Dynamics/Coagulation/Coagulation_3_Particle_Resolved_Pattern/#coagulation-patterns-particle-resolved-approach","title":"Coagulation Patterns: Particle-Resolved Approach\u00b6","text":"<p>In this notebook, we explore coagulation patterns through a particle-resolved approach. Rather than directly invoking coagulation functions for each calculation, we adopt a more modular and object-oriented programming structure. By employing design patterns, such as the <code>Builder</code> pattern, we simplify the setup and validation of parameters, making the process more maintainable and scalable.</p> <p>This approach allows for the efficient management of both the gas phase and the particle distribution, incorporating the verification of input parameters for accuracy and consistency. The <code>Builder</code> classes facilitate setting up the coagulation environment, from defining the atmospheric conditions to creating particle distributions and specifying their resolved masses.</p> <p>In this example, we preset a non-condensing gas species in the atmosphere and use a lognormal distribution for particles. We represent the particles using a particle-resolved mass framework, where we handle properties like density, charge, and mass with strategies to define the activity, surface area, and distribution.</p> <p>Imports</p>"},{"location":"Examples/Dynamics/Coagulation/Coagulation_3_Particle_Resolved_Pattern/#aerosol-setup","title":"Aerosol Setup\u00b6","text":"<p>In this section, we define the core components of our particle-resolved coagulation system, focusing on the atmosphere setup, particle distribution, and mass resolution. This step-by-step breakdown helps clarify how the <code>Builder</code> pattern organizes the construction of complex objects and ensures input parameters are properly verified.</p> <p>Atmospheric Setup We begin by configuring the atmosphere using the <code>AtmosphereBuilder</code>. This allows for flexibility in defining environmental parameters such as temperature and pressure, as well as adding gas species. In this case, we add a preset gas species that does not condense and set the atmospheric conditions to 25\u00b0C and 1 atm.</p> <p>Particle Distribution The particle distribution is generated using a lognormal distribution, a common approach for representing aerosol particle sizes. The parameters for this distribution include:</p> <ul> <li>A mode of 100 nm, representing the mean particle diameter.</li> <li>A geometric standard deviation (GSD) of 1.3, which controls the spread of particle sizes.</li> <li>The total number of particles is 100,000 samples taken to capture the variability of the distribution.</li> </ul> <p>Mass Calculation The mass of each particle is calculated assuming a particle density of 1500 kg/m\u00b3. This density corresponds to typical aerosol materials like dust or certain types of particulate matter. The particle masses are computed using the formula for the volume of a sphere, multiplied by the density.</p> <p>Resolved Particle Mass Representation To capture the diversity of the aerosol population, we use a particle-resolved representation for mass. This approach explicitly tracks individual particle masses and assigns properties such as density and charge. The key strategies used are:</p> <ul> <li>Distribution strategy: Defines how mass is distributed among particles.</li> <li>Activity strategy: Describes how the activity of the particles is represented, in this case, assuming ideal mass behavior.</li> <li>Surface strategy: Calculates particle surface behavior by volume mixing.</li> </ul> <p>Final Aerosol Object The <code>Aerosol</code> object brings together the atmosphere and the resolved particle masses into a cohesive framework. This encapsulated representation can then be used to simulate particle interactions and coagulation events within the atmosphere.</p> <p>Finally, we print the properties of the <code>aerosol</code> object\u2019s atmosphere to verify the correct setup.</p>"},{"location":"Examples/Dynamics/Coagulation/Coagulation_3_Particle_Resolved_Pattern/#simulation","title":"Simulation\u00b6","text":"<p>In this section, we run the coagulation simulation by first defining the coagulation strategy and the process through which it is executed.</p> <ul> <li><p>Coagulation Strategy: The strategy for how coagulation is performed is selected using <code>coagulation.ParticleResolved()</code>. This specific strategy dictates how particle interactions are handled at the individual particle level, ensuring that the coagulation process respects the details of a particle-resolved approach. In this context, particles are treated as distinct entities, and the merging process is computed explicitly for each pair that interacts.</p> </li> <li><p>Particle Process: Once the strategy is defined, the <code>Coagulation</code> process is initialized by passing the chosen strategy (<code>coagulation_strategy</code>) to the <code>particle_process.Coagulation</code> class. This <code>Coagulation</code> class is responsible for running the actual simulation. It orchestrates the execution of coagulation by applying the selected strategy over the particle distribution. During each execution step, the particle properties\u2014such as mass, size, and count\u2014are updated according to the rules defined by the particle-resolved strategy.</p> </li> <li><p>Execution of the Process: The coagulation process is applied in steps using the <code>coagulation_process.execute()</code> method. In each step, the particles' masses are updated based on the time step and sub-steps provided. The time step controls the temporal resolution of the simulation, while the sub-steps break the time step into finer increments to ensure accurate resolution of coagulation events.</p> </li> </ul> <p>For each step:</p> <ol> <li>The radii of particles are obtained before and after the coagulation step.</li> <li>The updated particle properties, such as radius and mass, are recorded.</li> <li>After the final step, we count the number of particles that have fully coagulated, i.e., those that have a mass of zero.</li> </ol>"},{"location":"Examples/Dynamics/Coagulation/Coagulation_3_Particle_Resolved_Pattern/#graphing","title":"Graphing\u00b6","text":"<p>In this section, we visualize the evolution of the particle size distribution as the coagulation process progresses.</p> <ul> <li>We use a histogram to show the distribution of particle radii at three stages: initially, after step 1, and after step 2.</li> <li>The x-axis is scaled logarithmically to properly represent the range of particle sizes, which can span multiple orders of magnitude.</li> <li>The plot helps illustrate the effect of coagulation, where particles merge over time, shifting the distribution towards larger sizes and reducing the number of smaller particles.</li> </ul> <p>This visual representation provides an intuitive understanding of how the coagulation process influences particle sizes, which is key to understanding aerosol dynamics in various atmospheric conditions.</p>"},{"location":"Examples/Dynamics/Coagulation/Coagulation_3_Particle_Resolved_Pattern/#conclusion","title":"Conclusion\u00b6","text":"<p>In this notebook, we have demonstrated a particle-resolved approach to modeling coagulation patterns in aerosol systems. By leveraging the <code>Builder</code> pattern and modular design, we have created a flexible and extensible framework for simulating particle interactions and tracking their properties over time.</p>"},{"location":"Examples/Dynamics/Coagulation/Coagulation_4_Compared/","title":"Coagulation Patterns: Comparison of Number and Mass","text":"In\u00a0[\u00a0]: Copied! <pre># In Colab uncomment the following command to install particula:\n#!pip install particula[extra] --quiet\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nimport particula as par\n</pre> # In Colab uncomment the following command to install particula: #!pip install particula[extra] --quiet import numpy as np import matplotlib.pyplot as plt  import particula as par In\u00a0[2]: Copied! <pre># common parameters\nmode = np.array([100e-9, 300e-9])  # m\ngeometric_standard_deviation = np.array([1.3, 1.3])\nnumber_of_particles = np.array(\n    [0.75, 0.25]\n)  # effective when pdf has multiple modes\ndensity = np.array([1.0e3])\nvolume = 1 * par.util.get_unit_conversion(\"cm^3\", \"m^3\")  # cm^-3 to m^-3\n\n# Preset gas species that does not condense in the atmosphere\n# AtmosphereBuilder constructs the atmosphere with predefined species\natmosphere = (\n    par.gas.AtmosphereBuilder()\n    .set_temperature(25, temperature_units=\"degC\")  # Set temperature to 25\u00b0C\n    .set_pressure(1, pressure_units=\"atm\")  # Set pressure to 1 atmosphere\n    .build()  # Finalize the atmosphere object\n)\n</pre> # common parameters mode = np.array([100e-9, 300e-9])  # m geometric_standard_deviation = np.array([1.3, 1.3]) number_of_particles = np.array(     [0.75, 0.25] )  # effective when pdf has multiple modes density = np.array([1.0e3]) volume = 1 * par.util.get_unit_conversion(\"cm^3\", \"m^3\")  # cm^-3 to m^-3  # Preset gas species that does not condense in the atmosphere # AtmosphereBuilder constructs the atmosphere with predefined species atmosphere = (     par.gas.AtmosphereBuilder()     .set_temperature(25, temperature_units=\"degC\")  # Set temperature to 25\u00b0C     .set_pressure(1, pressure_units=\"atm\")  # Set pressure to 1 atmosphere     .build()  # Finalize the atmosphere object ) <p>Particle Resolved</p> <p>In this section, we generate a particle distribution using a lognormal sample distribution, which is characterized by a specified mode (mean particle diameter) and geometric standard deviation (GSD). We then calculate the mass of each particle, assuming a constant density.</p> <p>Following this, we create a resolved mass representation for each particle, which defines how properties like mass, activity, and particle surfaces represented. The resolved mass representation is built using predefined strategies for mass distribution, activity, and surface area. We assign particle mass, set density, assume neutral particles (with no charge), and define the volume of the distribution.</p> <p>Finally, we combine the resolved particle properties with the atmospheric conditions to create an <code>Aerosol</code> object, which encapsulates both the particles and the atmosphere. The aerosol properties are then printed to provide an overview of the system.</p> In\u00a0[3]: Copied! <pre>number_of_samples = 100_000  # Number of samples for particle distribution\n\n# Generate a particle distribution using a lognormal sample distribution\n# This distribution has a mean particle diameter (mode) and geometric standard deviation (GSD)\nradii_sample = par.particles.get_lognormal_sample_distribution(\n    mode=mode,\n    geometric_standard_deviation=geometric_standard_deviation,\n    number_of_particles=number_of_particles,\n    number_of_samples=number_of_samples,  # Number of samples for particle distribution\n)\n\n# Calculate the mass of each particle in the sample, assuming density of 1500 kg/m^3\nparticle_mass_sample = (\n    4 / 3 * np.pi * radii_sample**3 * density\n)  # Particle mass in kg\n\nprint(f\"Total mass of particles: {np.sum(particle_mass_sample):.2e} kg\")\n# Build a resolved mass representation for each particle\n# This defines how particle mass, activity, and surface are represented\nresolved_masses = (\n    par.particles.ResolvedParticleMassRepresentationBuilder()\n    # Use specieated mass distribution, ideal mass activity, and volume surface strategy\n    .set_distribution_strategy(par.particles.ParticleResolvedSpeciatedMass())\n    .set_activity_strategy(par.particles.ActivityIdealMass())\n    .set_surface_strategy(par.particles.SurfaceStrategyVolume())\n    .set_mass(particle_mass_sample, \"kg\")  # Assign mass of particles (in kg)\n    .set_density(density, \"kg/m^3\")  # Set particle density\n    .set_charge(0)  # Assume neutral particles with no charge\n    .set_volume(volume, \"m^3\")  # Set volume of particle distribution\n    .build()  # Finalize the resolved mass representation\n)\n\n# Create an aerosol object with the defined atmosphere and resolved particles\naerosol_resolved = par.Aerosol(\n    atmosphere=atmosphere, particles=resolved_masses\n)\n\n# Print the properties of the aerosol\nprint(aerosol_resolved)\n</pre> number_of_samples = 100_000  # Number of samples for particle distribution  # Generate a particle distribution using a lognormal sample distribution # This distribution has a mean particle diameter (mode) and geometric standard deviation (GSD) radii_sample = par.particles.get_lognormal_sample_distribution(     mode=mode,     geometric_standard_deviation=geometric_standard_deviation,     number_of_particles=number_of_particles,     number_of_samples=number_of_samples,  # Number of samples for particle distribution )  # Calculate the mass of each particle in the sample, assuming density of 1500 kg/m^3 particle_mass_sample = (     4 / 3 * np.pi * radii_sample**3 * density )  # Particle mass in kg  print(f\"Total mass of particles: {np.sum(particle_mass_sample):.2e} kg\") # Build a resolved mass representation for each particle # This defines how particle mass, activity, and surface are represented resolved_masses = (     par.particles.ResolvedParticleMassRepresentationBuilder()     # Use specieated mass distribution, ideal mass activity, and volume surface strategy     .set_distribution_strategy(par.particles.ParticleResolvedSpeciatedMass())     .set_activity_strategy(par.particles.ActivityIdealMass())     .set_surface_strategy(par.particles.SurfaceStrategyVolume())     .set_mass(particle_mass_sample, \"kg\")  # Assign mass of particles (in kg)     .set_density(density, \"kg/m^3\")  # Set particle density     .set_charge(0)  # Assume neutral particles with no charge     .set_volume(volume, \"m^3\")  # Set volume of particle distribution     .build()  # Finalize the resolved mass representation )  # Create an aerosol object with the defined atmosphere and resolved particles aerosol_resolved = par.Aerosol(     atmosphere=atmosphere, particles=resolved_masses )  # Print the properties of the aerosol print(aerosol_resolved) <pre>Total mass of particles: 4.29e-12 kg\nGas mixture at 298.15 K, 101325.0 Pa, partitioning=None, gas_only_species=None\nParticle Representation:\n\tStrategy: ParticleResolvedSpeciatedMass\n\tActivity: ActivityIdealMass\n\tSurface: SurfaceStrategyVolume\n\tMass Concentration: 4.287e-06 [kg/m^3]\n\tNumber Concentration: 1.000e+11 [#/m^3]\n</pre> <p>PMF</p> <p>Here, we generate a Probability Mass Function (PMF) approach. We define the radius bins using a logarithmic scale and calculate the number concentration of particles based on the total number of particles and the system volume. The PMF distribution is then built by specifying the particle mode, geometric standard deviation, and number concentration.</p> <p>We set the distribution type to 'PMF' and define the radius bins, which represent the particle size categories. The particle density is also specified, and the PMF-based particle representation is finalized.</p> <p>After setting up the PMF particle distribution, we create an aerosol object that combines the PMF particle properties with the previously defined atmospheric conditions. The properties of the aerosol object are printed to give a summary of the system configuration.</p> In\u00a0[4]: Copied! <pre>radius_bins = np.logspace(\n    -8, -6, 250\n)  # Define the radius bins for the resolved mass representation\n\nnumber_concentration = number_of_particles * np.array(\n    [number_of_samples / volume]\n)  # Calculate the number concentration of particles\nprint(f\"Number concentration: {number_concentration[0]:.2e} m^-3\")\nparticle_pmf = (\n    par.particles.PresetParticleRadiusBuilder()\n    .set_mode(mode, mode_units=\"m\")  # Set the mode of the distribution\n    .set_geometric_standard_deviation(geometric_standard_deviation)\n    .set_number_concentration(\n        number_concentration, \"m^-3\"\n    )  # Set the number concentration\n    .set_distribution_type(\"pmf\")  # Set the distribution type to PMF\n    .set_radius_bins(radius_bins, radius_bins_units=\"m\")  # Set the radius bins\n    .set_density(density, \"kg/m^3\")  # Set particle density\n    .build()  # Finalize the resolved mass representation\n)\n\n# Create an aerosol object with the defined atmosphere and resolved particles\naerosol_pmf = par.Aerosol(atmosphere=atmosphere, particles=particle_pmf)\n\n# Print the properties of the aerosol\nprint(aerosol_pmf)\n</pre> radius_bins = np.logspace(     -8, -6, 250 )  # Define the radius bins for the resolved mass representation  number_concentration = number_of_particles * np.array(     [number_of_samples / volume] )  # Calculate the number concentration of particles print(f\"Number concentration: {number_concentration[0]:.2e} m^-3\") particle_pmf = (     par.particles.PresetParticleRadiusBuilder()     .set_mode(mode, mode_units=\"m\")  # Set the mode of the distribution     .set_geometric_standard_deviation(geometric_standard_deviation)     .set_number_concentration(         number_concentration, \"m^-3\"     )  # Set the number concentration     .set_distribution_type(\"pmf\")  # Set the distribution type to PMF     .set_radius_bins(radius_bins, radius_bins_units=\"m\")  # Set the radius bins     .set_density(density, \"kg/m^3\")  # Set particle density     .build()  # Finalize the resolved mass representation )  # Create an aerosol object with the defined atmosphere and resolved particles aerosol_pmf = par.Aerosol(atmosphere=atmosphere, particles=particle_pmf)  # Print the properties of the aerosol print(aerosol_pmf) <pre>Number concentration: 7.50e+10 m^-3\nGas mixture at 298.15 K, 101325.0 Pa, partitioning=None, gas_only_species=None\nParticle Representation:\n\tStrategy: RadiiBasedMovingBin\n\tActivity: ActivityIdealMass\n\tSurface: SurfaceStrategyVolume\n\tMass Concentration: 4.282e-06 [kg/m^3]\n\tNumber Concentration: 1.000e+11 [#/m^3]\n</pre> <p>PDF</p> <p>Lastly, we generate a particle distribution using the Probability Density Function (PDF) approach. Similar to the PMF setup, we specify the particle mode, geometric standard deviation, and number concentration. However, in this case, the distribution type is set to \"PDF\", which models the particle distribution as a continuous probability density function over the defined radius bins.</p> <p>We assign the same logarithmic radius bins as before, specify the particle density, and assume the particles are neutral by setting their charge to zero. After defining all necessary parameters, we finalize the PDF-based particle representation.</p> <p>As with the PMF approach, we create an aerosol object by combining the PDF-based particle distribution with the predefined atmospheric conditions. The properties of the resulting aerosol are printed to summarize the system configuration.</p> In\u00a0[5]: Copied! <pre>particle_pdf = (\n    par.particles.PresetParticleRadiusBuilder()\n    .set_mode(mode, mode_units=\"m\")  # Set the mode of the distribution\n    .set_geometric_standard_deviation(geometric_standard_deviation)\n    .set_number_concentration(\n        number_concentration, \"m^-3\"\n    )  # Set the number concentration\n    .set_distribution_type(\"pdf\")  # Set the distribution type to PMF\n    .set_radius_bins(radius_bins, radius_bins_units=\"m\")  # Set the radius bins\n    .set_density(density, \"kg/m^3\")  # Set particle density\n    .set_charge(\n        np.zeros_like(radius_bins)\n    )  # Assume neutral particles with no charge\n    .build()  # Finalize the resolved mass representation\n)\n\n# Create an aerosol object with the defined atmosphere and resolved particles\naerosol_pdf = par.Aerosol(atmosphere=atmosphere, particles=particle_pdf)\n\n# Print the properties of the aerosol\nprint(aerosol_pdf)\n</pre> particle_pdf = (     par.particles.PresetParticleRadiusBuilder()     .set_mode(mode, mode_units=\"m\")  # Set the mode of the distribution     .set_geometric_standard_deviation(geometric_standard_deviation)     .set_number_concentration(         number_concentration, \"m^-3\"     )  # Set the number concentration     .set_distribution_type(\"pdf\")  # Set the distribution type to PMF     .set_radius_bins(radius_bins, radius_bins_units=\"m\")  # Set the radius bins     .set_density(density, \"kg/m^3\")  # Set particle density     .set_charge(         np.zeros_like(radius_bins)     )  # Assume neutral particles with no charge     .build()  # Finalize the resolved mass representation )  # Create an aerosol object with the defined atmosphere and resolved particles aerosol_pdf = par.Aerosol(atmosphere=atmosphere, particles=particle_pdf)  # Print the properties of the aerosol print(aerosol_pdf) <pre>Gas mixture at 298.15 K, 101325.0 Pa, partitioning=None, gas_only_species=None\nParticle Representation:\n\tStrategy: RadiiBasedMovingBin\n\tActivity: ActivityIdealMass\n\tSurface: SurfaceStrategyVolume\n\tMass Concentration: 7.797e+02 [kg/m^3]\n\tNumber Concentration: 4.663e+19 [#/m^3]\n</pre> <p>Plot Initial Distributions</p> <p>In this section, we plot the initial particle distributions for the PMF, and particle-resolved approaches. The plots show the number concentration of particles as a function of particle radius for each method. The PMF is a line, and the particle-resolved has been binned into discrete sizes.</p> In\u00a0[6]: Copied! <pre># plot both\nradius_bins = particle_pmf.get_radius()\nradii_resolved = resolved_masses.get_radius()\n\nfig, ax = plt.subplots()\nbins, edges = np.histogram(radii_resolved, bins=radius_bins)\nax.bar(\n    edges[:-1],\n    bins / volume,\n    width=np.diff(edges),\n    align=\"edge\",\n    label=\"Resolved\",\n    alpha=0.7,\n)\nax.plot(\n    radius_bins,\n    particle_pmf.get_concentration(),\n    label=\"PMF\",\n    color=\"red\",\n)\nax.set_xscale(\"log\")\n# ax.set_yscale(\"log\")\nax.set_xlabel(\"Particle radius (m)\")\nax.set_ylabel(\"Number concentration (m^-3)\")\nax.legend()\nplt.show()\n</pre> # plot both radius_bins = particle_pmf.get_radius() radii_resolved = resolved_masses.get_radius()  fig, ax = plt.subplots() bins, edges = np.histogram(radii_resolved, bins=radius_bins) ax.bar(     edges[:-1],     bins / volume,     width=np.diff(edges),     align=\"edge\",     label=\"Resolved\",     alpha=0.7, ) ax.plot(     radius_bins,     particle_pmf.get_concentration(),     label=\"PMF\",     color=\"red\", ) ax.set_xscale(\"log\") # ax.set_yscale(\"log\") ax.set_xlabel(\"Particle radius (m)\") ax.set_ylabel(\"Number concentration (m^-3)\") ax.legend() plt.show() In\u00a0[7]: Copied! <pre># simulate aerosols, and save total mass and number distribution\n\n# Define the coagulation process\ncoagulation_process_pmf = par.dynamics.Coagulation(\n    coagulation_strategy=par.dynamics.BrownianCoagulationStrategy(\n        distribution_type=\"discrete\"\n    )\n)\n\ncoagulation_process_resolved = par.dynamics.Coagulation(\n    coagulation_strategy=par.dynamics.BrownianCoagulationStrategy(\n        distribution_type=\"particle_resolved\"\n    )\n)\ncoagulation_process_pdf = par.dynamics.Coagulation(\n    coagulation_strategy=par.dynamics.BrownianCoagulationStrategy(\n        distribution_type=\"continuous_pdf\"\n    )\n)\n\n# Set up time and sub-steps for the coagulation process\ntotal_time = 10000\ntime_step = 100\nsub_steps = 1\n\n# output arrays\ntime = np.arange(0, total_time, time_step)\ntotal_mass_pmf = np.zeros_like(time, dtype=np.float64)\ntotal_mass_resolved = np.ones_like(time, dtype=np.float64)\ntotal_mass_pdf = np.zeros_like(time, dtype=np.float64)\nnumber_distribution_pmf = np.zeros((len(time), len(radius_bins)))\nnumber_distribution_resolved = np.zeros((len(time), number_of_samples))\nnumber_distribution_pdf = np.zeros((len(time), len(radius_bins)))\ntotal_number_pmf = np.zeros_like(time, dtype=np.float64)\ntotal_number_resolved = np.ones_like(time, dtype=np.float64)\ntotal_number_pdf = np.zeros_like(time, dtype=np.float64)\n</pre> # simulate aerosols, and save total mass and number distribution  # Define the coagulation process coagulation_process_pmf = par.dynamics.Coagulation(     coagulation_strategy=par.dynamics.BrownianCoagulationStrategy(         distribution_type=\"discrete\"     ) )  coagulation_process_resolved = par.dynamics.Coagulation(     coagulation_strategy=par.dynamics.BrownianCoagulationStrategy(         distribution_type=\"particle_resolved\"     ) ) coagulation_process_pdf = par.dynamics.Coagulation(     coagulation_strategy=par.dynamics.BrownianCoagulationStrategy(         distribution_type=\"continuous_pdf\"     ) )  # Set up time and sub-steps for the coagulation process total_time = 10000 time_step = 100 sub_steps = 1  # output arrays time = np.arange(0, total_time, time_step) total_mass_pmf = np.zeros_like(time, dtype=np.float64) total_mass_resolved = np.ones_like(time, dtype=np.float64) total_mass_pdf = np.zeros_like(time, dtype=np.float64) number_distribution_pmf = np.zeros((len(time), len(radius_bins))) number_distribution_resolved = np.zeros((len(time), number_of_samples)) number_distribution_pdf = np.zeros((len(time), len(radius_bins))) total_number_pmf = np.zeros_like(time, dtype=np.float64) total_number_resolved = np.ones_like(time, dtype=np.float64) total_number_pdf = np.zeros_like(time, dtype=np.float64) <p>Simulation Loop</p> <p>We then run a simulation loop that iterates over the specified time range, updating the particle distribution at each time step.</p> In\u00a0[10]: Copied! <pre># Simulation loop\n\nfor i, t in enumerate(time):\n    if i &gt; 0:\n        # Perform coagulation for the PDF aerosol\n        aerosol_pdf = coagulation_process_pdf.execute(\n            aerosol_pdf, time_step, sub_steps\n        )\n        # Perform coagulation for the PMF aerosol\n        aerosol_pmf = coagulation_process_pmf.execute(\n            aerosol_pmf, time_step, sub_steps\n        )\n        # Perform coagulation for the resolved aerosol\n        aerosol_resolved = coagulation_process_resolved.execute(\n            aerosol_resolved, time_step, sub_steps\n        )\n\n    total_mass_resolved[i] = aerosol_resolved.particles.get_mass_concentration()\n    number_distribution_resolved[i, :] = aerosol_resolved.particles.get_radius(clone=True)\n    total_number_resolved[i] = np.sum(number_distribution_resolved[i, :] &gt; 0)\n\n    total_mass_pmf[i] = aerosol_pmf.particles.get_mass_concentration()\n    number_distribution_pmf[i, :] = aerosol_pmf.particles.get_concentration(\n        clone=True\n    )\n    total_number_pmf[i] = np.sum(number_distribution_pmf[i, :])\n\n    total_mass_pdf[i] = aerosol_pdf.particles.get_mass_concentration()\n    number_distribution_pdf[i, :] = aerosol_pdf.particles.get_concentration(\n        clone=True\n    )\n    total_number_pdf[i] = np.trapezoid(\n        number_distribution_pdf[i, :], radius_bins\n    )\n</pre> # Simulation loop  for i, t in enumerate(time):     if i &gt; 0:         # Perform coagulation for the PDF aerosol         aerosol_pdf = coagulation_process_pdf.execute(             aerosol_pdf, time_step, sub_steps         )         # Perform coagulation for the PMF aerosol         aerosol_pmf = coagulation_process_pmf.execute(             aerosol_pmf, time_step, sub_steps         )         # Perform coagulation for the resolved aerosol         aerosol_resolved = coagulation_process_resolved.execute(             aerosol_resolved, time_step, sub_steps         )      total_mass_resolved[i] = aerosol_resolved.particles.get_mass_concentration()     number_distribution_resolved[i, :] = aerosol_resolved.particles.get_radius(clone=True)     total_number_resolved[i] = np.sum(number_distribution_resolved[i, :] &gt; 0)      total_mass_pmf[i] = aerosol_pmf.particles.get_mass_concentration()     number_distribution_pmf[i, :] = aerosol_pmf.particles.get_concentration(         clone=True     )     total_number_pmf[i] = np.sum(number_distribution_pmf[i, :])      total_mass_pdf[i] = aerosol_pdf.particles.get_mass_concentration()     number_distribution_pdf[i, :] = aerosol_pdf.particles.get_concentration(         clone=True     )     total_number_pdf[i] = np.trapezoid(         number_distribution_pdf[i, :], radius_bins     ) In\u00a0[11]: Copied! <pre>print(aerosol_resolved)\nprint(aerosol_pmf)\n# print(aerosol_pdf)\n</pre> print(aerosol_resolved) print(aerosol_pmf) # print(aerosol_pdf) <pre>Gas mixture at 298.15 K, 101325.0 Pa, partitioning=None, gas_only_species=None\nParticle Representation:\n\tStrategy: ParticleResolvedSpeciatedMass\n\tActivity: ActivityIdealMass\n\tSurface: SurfaceStrategyVolume\n\tMass Concentration: 4.286e-06 [kg/m^3]\n\tNumber Concentration: 6.263e+10 [#/m^3]\nGas mixture at 298.15 K, 101325.0 Pa, partitioning=None, gas_only_species=None\nParticle Representation:\n\tStrategy: RadiiBasedMovingBin\n\tActivity: ActivityIdealMass\n\tSurface: SurfaceStrategyVolume\n\tMass Concentration: 4.242e-06 [kg/m^3]\n\tNumber Concentration: 6.259e+10 [#/m^3]\n</pre> In\u00a0[12]: Copied! <pre># plot the initial and final distributions\nfig, ax = plt.subplots(figsize=(8, 5))\n\nbins, edges = np.histogram(\n    number_distribution_resolved[0, :], bins=radius_bins\n)\nax.bar(\n    edges[:-1],\n    bins / volume,\n    width=np.diff(edges),\n    align=\"edge\",\n    label=\"Resolved initial\",\n    color=\"red\",\n    alpha=0.7,\n)\nbins, edges = np.histogram(\n    number_distribution_resolved[-1, :], bins=radius_bins\n)\nax.bar(\n    edges[:-1],\n    bins / volume,\n    width=np.diff(edges),\n    align=\"edge\",\n    label=\"Resolved final\",\n    color=\"blue\",\n    alpha=0.7,\n)\n\nax.plot(\n    radius_bins,\n    number_distribution_pmf[0, :],\n    label=\"PMF initial\",\n    color=\"red\",\n)\nax.plot(\n    radius_bins,\n    number_distribution_pmf[-1, :],\n    label=\"PMF final\",\n    color=\"blue\",\n)\n\nax.set_xscale(\"log\")\nax.set_xlabel(\"Particle radius (m)\")\nax.set_ylabel(\"Number concentration (m^-3)\")\nax.legend()\nplt.show()\n</pre> # plot the initial and final distributions fig, ax = plt.subplots(figsize=(8, 5))  bins, edges = np.histogram(     number_distribution_resolved[0, :], bins=radius_bins ) ax.bar(     edges[:-1],     bins / volume,     width=np.diff(edges),     align=\"edge\",     label=\"Resolved initial\",     color=\"red\",     alpha=0.7, ) bins, edges = np.histogram(     number_distribution_resolved[-1, :], bins=radius_bins ) ax.bar(     edges[:-1],     bins / volume,     width=np.diff(edges),     align=\"edge\",     label=\"Resolved final\",     color=\"blue\",     alpha=0.7, )  ax.plot(     radius_bins,     number_distribution_pmf[0, :],     label=\"PMF initial\",     color=\"red\", ) ax.plot(     radius_bins,     number_distribution_pmf[-1, :],     label=\"PMF final\",     color=\"blue\", )  ax.set_xscale(\"log\") ax.set_xlabel(\"Particle radius (m)\") ax.set_ylabel(\"Number concentration (m^-3)\") ax.legend() plt.show() <p>Plot Mass Conservation</p> <p>In and ideal system, the mass should be conserved. In this section, we plot the mass conservation for the PMF, PDF, and particle-resolved approaches. The plots show the total mass of particles as a function of time during the coagulation process. The mass should remain constant over time, indicating that mass is conserved in the system.</p> <p>In our case, there is some numerical error in the mass conservation, this is particularly evident in the PMF method.</p> In\u00a0[13]: Copied! <pre># mass conservation plot\n\nmass_pmf_error = (total_mass_pmf - total_mass_pmf[0]) / total_mass_pmf[0]\nmass_resolved_error = (\n    total_mass_resolved - total_mass_resolved[0]\n) / total_mass_resolved[0]\n\n\nfig, ax = plt.subplots(figsize=(8, 5))\nax.plot(time, mass_pmf_error, label=\"Probability Mass Function\")\nax.plot(time, mass_resolved_error, label=\"Particle Resolved\")\n# ax.set_yscale(\"log\")\nax.set_xlabel(\"Time (s)\")\nax.set_ylabel(\"Mass Error (relative to start)\")\nax.set_title(\"Error in mass conservation\")\nax.legend()\nplt.show()\n</pre> # mass conservation plot  mass_pmf_error = (total_mass_pmf - total_mass_pmf[0]) / total_mass_pmf[0] mass_resolved_error = (     total_mass_resolved - total_mass_resolved[0] ) / total_mass_resolved[0]   fig, ax = plt.subplots(figsize=(8, 5)) ax.plot(time, mass_pmf_error, label=\"Probability Mass Function\") ax.plot(time, mass_resolved_error, label=\"Particle Resolved\") # ax.set_yscale(\"log\") ax.set_xlabel(\"Time (s)\") ax.set_ylabel(\"Mass Error (relative to start)\") ax.set_title(\"Error in mass conservation\") ax.legend() plt.show() <p>Plot Number Error</p> <p>For the number concentration, we use the PDF distribution as the reference. We calculate the percent error in the number concentration for the PMF and particle-resolved approaches compared to the PDF distribution.</p> In\u00a0[14]: Copied! <pre># sum number concentration and plot\n\ntotal_pmf = np.sum(number_distribution_pmf, axis=1)\ntotal_resolved_non_zero = number_distribution_resolved &gt; 0\ntotal_resolved = np.sum(total_resolved_non_zero, axis=1) / volume\n\npercent_diff_resolved = (\n    (total_number_pdf - total_resolved) / total_number_pdf * 100\n)\npercent_diff_pmf = (total_number_pdf - total_pmf) / total_number_pdf * 100\n\nprint(\n    f\"Resolved number final: {total_resolved[-1]:.2e}, PMF number final: {total_pmf[-1]:.2e}\"\n)\n\nfig, ax = plt.subplots(figsize=(8, 5))\nax.plot(time, percent_diff_resolved, label=\"Particle Resolved\", linestyle=\"--\")\nax.plot(\n    time, percent_diff_pmf, label=\"Probability Mass Function\", linestyle=\"--\"\n)\nax.set_xlabel(\"Time (s)\")\nax.set_ylabel(\"Percent Difference vs Probability Density Function\")\nax.set_title(\"Numerical Error in Number Concentration\")\nax.legend()\nplt.show()\n</pre> # sum number concentration and plot  total_pmf = np.sum(number_distribution_pmf, axis=1) total_resolved_non_zero = number_distribution_resolved &gt; 0 total_resolved = np.sum(total_resolved_non_zero, axis=1) / volume  percent_diff_resolved = (     (total_number_pdf - total_resolved) / total_number_pdf * 100 ) percent_diff_pmf = (total_number_pdf - total_pmf) / total_number_pdf * 100  print(     f\"Resolved number final: {total_resolved[-1]:.2e}, PMF number final: {total_pmf[-1]:.2e}\" )  fig, ax = plt.subplots(figsize=(8, 5)) ax.plot(time, percent_diff_resolved, label=\"Particle Resolved\", linestyle=\"--\") ax.plot(     time, percent_diff_pmf, label=\"Probability Mass Function\", linestyle=\"--\" ) ax.set_xlabel(\"Time (s)\") ax.set_ylabel(\"Percent Difference vs Probability Density Function\") ax.set_title(\"Numerical Error in Number Concentration\") ax.legend() plt.show() <pre>Resolved number final: 6.26e+10, PMF number final: 6.26e+10\n</pre>"},{"location":"Examples/Dynamics/Coagulation/Coagulation_4_Compared/#coagulation-patterns-comparison-of-number-and-mass","title":"Coagulation Patterns: Comparison of Number and Mass\u00b6","text":"<p>In this notebook, we explore and compare three distinct methods for representing particle distributions and modeling the coagulation process: the probability mass function (PMF), the probability density function (PDF), and the particle-resolved approach. The goal is to evaluate how each method impacts the number and mass of particles as coagulation progresses, providing insight into their strengths and limitations.</p> <p>Imports</p>"},{"location":"Examples/Dynamics/Coagulation/Coagulation_4_Compared/#setup-distributions","title":"Setup Distributions\u00b6","text":"<p>In this section, we define the common parameters used throughout the notebook for modeling the particle distribution and atmosphere. These parameters include the mode of the particle size distribution, the geometric standard deviation, the number of particles in each mode, and the particle density. Additionally, we set the volume of the system for our simulations. The volume is only needed for the particle resolved approach, as the PMF and PDF methods do not require a volume to be defined.</p> <p>We also construct a simplified atmospheric environment using an <code>AtmosphereBuilder</code>, which includes a preset gas species that does not condense in the atmosphere. The temperature is set to 25\u00b0C and the pressure to 1 atmosphere, reflecting typical ambient conditions.</p>"},{"location":"Examples/Dynamics/Coagulation/Coagulation_4_Compared/#simulate-coagulation","title":"Simulate Coagulation\u00b6","text":"<p>In this section, we simulate the coagulation process for the PMF, PDF, and particle-resolved approaches. We define the time step for the simulation and the total simulation time. The time step is used to update the particle distribution at regular intervals, while the total simulation time determines the duration of the coagulation process.</p>"},{"location":"Examples/Dynamics/Coagulation/Coagulation_4_Compared/#results","title":"Results\u00b6","text":"<p>The results of the coagulation simulations are presented in this section. We compare the number and mass of particles for the PMF, PDF, and particle-resolved approaches at different time points during the coagulation process.</p> <p>The fist thing to check is the final state of the aerosol system.</p>"},{"location":"Examples/Dynamics/Coagulation/Coagulation_4_Compared/#conclusion","title":"Conclusion\u00b6","text":"<p>In this notebook, we compared the PMF, PDF, and particle-resolved approaches for modeling particle distributions and the coagulation process. We found that each method has its strengths and limitations, with the PMF and PDF approaches providing a more continuous representation of the particle distribution, while the particle-resolved approach offers a more detailed view of individual particles.</p> <p>They all have numerical errors, but the PDF method is the most accurate in terms of mass conservation and number concentration. The PMF method has the largest error in mass concentration. The particle-resolved method has variable error in number concentration.</p>"},{"location":"Examples/Dynamics/Coagulation/Charge/Coagulation_with_Charge_functional/","title":"Coagulation with Charge Effects","text":"<p>Import Necessary Libraries We import standard libraries like <code>numpy</code> and <code>matplotlib</code> for numerical computations and plotting. We also import specific functions from the <code>particula</code> package, which is used for aerosol dynamics simulations.</p> In\u00a0[\u00a0]: Copied! <pre># In Colab uncomment the following command to install particula:\n#!pip install particula[extra] --quiet\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# particula imports\nimport particula as par\n</pre> # In Colab uncomment the following command to install particula: #!pip install particula[extra] --quiet  import numpy as np import matplotlib.pyplot as plt  # particula imports import particula as par In\u00a0[2]: Copied! <pre>radius_bins = np.logspace(start=-9, stop=-4, num=250)  # m (1 nm to 10 \u03bcm)\n\n# Calculate the mass of particles for each size bin\n# The mass is calculated using the formula for the volume of a sphere (4/3 * \u03c0 * r^3)\n# and assuming a particle density of 1 g/cm^3 (which is 1000 kg/m^3 in SI units).\nmass_bins = 4 / 3 * np.pi * radius_bins**3 * 1e3  # kg\n</pre> radius_bins = np.logspace(start=-9, stop=-4, num=250)  # m (1 nm to 10 \u03bcm)  # Calculate the mass of particles for each size bin # The mass is calculated using the formula for the volume of a sphere (4/3 * \u03c0 * r^3) # and assuming a particle density of 1 g/cm^3 (which is 1000 kg/m^3 in SI units). mass_bins = 4 / 3 * np.pi * radius_bins**3 * 1e3  # kg In\u00a0[3]: Copied! <pre>n_bins = len(radius_bins)\n\n# Define the split index where charges transition from negative to positive\nsplit_index = n_bins // 3  # Assign the first 25% of particles negative charges\n\n# Generate logarithmically spaced magnitudes for negative charges from 10 to 1\nneg_magnitudes = np.logspace(np.log10(10), np.log10(1), num=split_index)\nneg_charges = -neg_magnitudes  # Assign negative sign\n\n# Generate logarithmically spaced magnitudes for positive charges from 1 to 500\npos_magnitudes = np.logspace(\n    np.log10(1), np.log10(500), num=n_bins - split_index\n)\npos_charges = pos_magnitudes  # Positive charges\n\n# Combine the negative and positive charges into one array\ncharge_array = np.concatenate((neg_charges, pos_charges))\n\n# Plot charge vs. radius\nfig, ax = plt.subplots()\nax.plot(radius_bins, charge_array, marker=\"o\", linestyle=\"none\")\nax.set_xscale(\"log\")\nax.set_yscale(\"symlog\", linthresh=1)\nax.set_xlabel(\"Particle radius (m)\")\nax.set_ylabel(\"Particle charge (elementary charges)\")\nax.set_title(\"Particle Charge vs. Radius\")\nax.grid(True, which=\"both\", ls=\"--\")\nplt.show()\n\ntemperature = 298.15\n</pre> n_bins = len(radius_bins)  # Define the split index where charges transition from negative to positive split_index = n_bins // 3  # Assign the first 25% of particles negative charges  # Generate logarithmically spaced magnitudes for negative charges from 10 to 1 neg_magnitudes = np.logspace(np.log10(10), np.log10(1), num=split_index) neg_charges = -neg_magnitudes  # Assign negative sign  # Generate logarithmically spaced magnitudes for positive charges from 1 to 500 pos_magnitudes = np.logspace(     np.log10(1), np.log10(500), num=n_bins - split_index ) pos_charges = pos_magnitudes  # Positive charges  # Combine the negative and positive charges into one array charge_array = np.concatenate((neg_charges, pos_charges))  # Plot charge vs. radius fig, ax = plt.subplots() ax.plot(radius_bins, charge_array, marker=\"o\", linestyle=\"none\") ax.set_xscale(\"log\") ax.set_yscale(\"symlog\", linthresh=1) ax.set_xlabel(\"Particle radius (m)\") ax.set_ylabel(\"Particle charge (elementary charges)\") ax.set_title(\"Particle Charge vs. Radius\") ax.grid(True, which=\"both\", ls=\"--\") plt.show()  temperature = 298.15 In\u00a0[7]: Copied! <pre>coulomb_potential_ratio = par.particles.get_coulomb_enhancement_ratio(\n    radius_bins, charge_array, temperature=temperature\n)\ndynamic_viscosity = par.gas.get_dynamic_viscosity(temperature=temperature)\nmol_free_path = par.gas.get_molecule_mean_free_path(\n    temperature=temperature, dynamic_viscosity=dynamic_viscosity\n)\nknudsen_number = par.particles.get_knudsen_number(\n    mean_free_path=mol_free_path, particle_radius=radius_bins\n)\nslip_correction = par.particles.get_cunningham_slip_correction(\n    knudsen_number=knudsen_number\n)\n\n\nfriction_factor_value = par.particles.get_friction_factor(\n    particle_radius=radius_bins,\n    dynamic_viscosity=dynamic_viscosity,\n    slip_correction=slip_correction,\n)\n\ndiffusive_knudsen_values = par.particles.get_diffusive_knudsen_number(\n    particle_radius=radius_bins,\n    particle_mass=mass_bins,\n    friction_factor=friction_factor_value,\n    coulomb_potential_ratio=coulomb_potential_ratio,\n    temperature=temperature,\n)\n</pre> coulomb_potential_ratio = par.particles.get_coulomb_enhancement_ratio(     radius_bins, charge_array, temperature=temperature ) dynamic_viscosity = par.gas.get_dynamic_viscosity(temperature=temperature) mol_free_path = par.gas.get_molecule_mean_free_path(     temperature=temperature, dynamic_viscosity=dynamic_viscosity ) knudsen_number = par.particles.get_knudsen_number(     mean_free_path=mol_free_path, particle_radius=radius_bins ) slip_correction = par.particles.get_cunningham_slip_correction(     knudsen_number=knudsen_number )   friction_factor_value = par.particles.get_friction_factor(     particle_radius=radius_bins,     dynamic_viscosity=dynamic_viscosity,     slip_correction=slip_correction, )  diffusive_knudsen_values = par.particles.get_diffusive_knudsen_number(     particle_radius=radius_bins,     particle_mass=mass_bins,     friction_factor=friction_factor_value,     coulomb_potential_ratio=coulomb_potential_ratio,     temperature=temperature, ) In\u00a0[8]: Copied! <pre>non_dimensional_kernel = par.dynamics.get_coulomb_kernel_chahl2019(\n    diffusive_knudsen=diffusive_knudsen_values,\n    coulomb_potential_ratio=coulomb_potential_ratio,\n)\n</pre> non_dimensional_kernel = par.dynamics.get_coulomb_kernel_chahl2019(     diffusive_knudsen=diffusive_knudsen_values,     coulomb_potential_ratio=coulomb_potential_ratio, ) In\u00a0[9]: Copied! <pre>coulomb_kinetic_limit = par.particles.get_coulomb_kinetic_limit(\n    coulomb_potential_ratio\n)\ncoulomb_continuum_limit = par.particles.get_coulomb_continuum_limit(\n    coulomb_potential_ratio\n)\n\nsum_of_radii = radius_bins[:, np.newaxis] + radius_bins[np.newaxis, :]\nreduced_mass = par.util.get_reduced_self_broadcast(mass_bins)\n</pre> coulomb_kinetic_limit = par.particles.get_coulomb_kinetic_limit(     coulomb_potential_ratio ) coulomb_continuum_limit = par.particles.get_coulomb_continuum_limit(     coulomb_potential_ratio )  sum_of_radii = radius_bins[:, np.newaxis] + radius_bins[np.newaxis, :] reduced_mass = par.util.get_reduced_self_broadcast(mass_bins) In\u00a0[10]: Copied! <pre>dimensional_kernel = (\n    non_dimensional_kernel\n    * friction_factor_value\n    * sum_of_radii**3\n    * coulomb_kinetic_limit**2\n    / (reduced_mass * coulomb_continuum_limit)\n)\n</pre> dimensional_kernel = (     non_dimensional_kernel     * friction_factor_value     * sum_of_radii**3     * coulomb_kinetic_limit**2     / (reduced_mass * coulomb_continuum_limit) ) In\u00a0[11]: Copied! <pre>fig, ax = plt.subplots()\n\n# Plot negative charges in blue\nax.plot(\n    radius_bins,\n    dimensional_kernel[:, :split_index],\n    linewidth=0.2,\n    color=\"blue\",\n    label=\"Negative Charges\",\n)\n\n# Plot positive charges in red\nax.plot(\n    radius_bins,\n    dimensional_kernel[:, split_index:],\n    linewidth=0.2,\n    color=\"red\",\n    label=\"Positive Charges\",\n)\n\n# ax.legend()\nax.set_xscale(\"log\")\nax.set_yscale(\"log\")\nax.set_ylim(1e-30, 1e4)\nax.set_xlabel(\"Particle radius (m)\")\nax.set_ylabel(\"Coagulation kernel (m^3/s)\")\nax.set_title(\"Coagulation kernel vs particle radius\")\nax.text(1e-9, 1e-22, \"Negative Charges\", color=\"blue\")\nax.text(1e-6, 1e-6, \"Positive Charges\", color=\"red\")\nplt.show()\n</pre> fig, ax = plt.subplots()  # Plot negative charges in blue ax.plot(     radius_bins,     dimensional_kernel[:, :split_index],     linewidth=0.2,     color=\"blue\",     label=\"Negative Charges\", )  # Plot positive charges in red ax.plot(     radius_bins,     dimensional_kernel[:, split_index:],     linewidth=0.2,     color=\"red\",     label=\"Positive Charges\", )  # ax.legend() ax.set_xscale(\"log\") ax.set_yscale(\"log\") ax.set_ylim(1e-30, 1e4) ax.set_xlabel(\"Particle radius (m)\") ax.set_ylabel(\"Coagulation kernel (m^3/s)\") ax.set_title(\"Coagulation kernel vs particle radius\") ax.text(1e-9, 1e-22, \"Negative Charges\", color=\"blue\") ax.text(1e-6, 1e-6, \"Positive Charges\", color=\"red\") plt.show() In\u00a0[12]: Copied! <pre>number_concentration = par.particles.get_lognormal_pmf_distribution(\n    x_values=radius_bins,\n    mode=np.array([10e-9, 200e-9, 1000e-9]),  # m\n    geometric_standard_deviation=np.array([1.4, 1.5, 1.8]),\n    number_of_particles=np.array([1e12, 1e12, 1e12]),  # per m^3\n)\n\ngain_rate = par.dynamics.get_coagulation_gain_rate_discrete(\n    radius=radius_bins,\n    concentration=number_concentration,\n    kernel=dimensional_kernel,\n)\nloss_rate = par.dynamics.get_coagulation_loss_rate_discrete(\n    concentration=number_concentration,\n    kernel=dimensional_kernel,\n)\n\nnet_rate = gain_rate - loss_rate\n</pre> number_concentration = par.particles.get_lognormal_pmf_distribution(     x_values=radius_bins,     mode=np.array([10e-9, 200e-9, 1000e-9]),  # m     geometric_standard_deviation=np.array([1.4, 1.5, 1.8]),     number_of_particles=np.array([1e12, 1e12, 1e12]),  # per m^3 )  gain_rate = par.dynamics.get_coagulation_gain_rate_discrete(     radius=radius_bins,     concentration=number_concentration,     kernel=dimensional_kernel, ) loss_rate = par.dynamics.get_coagulation_loss_rate_discrete(     concentration=number_concentration,     kernel=dimensional_kernel, )  net_rate = gain_rate - loss_rate In\u00a0[13]: Copied! <pre>fig, ax = plt.subplots()\nax.plot(radius_bins, number_concentration)\nax.set_xscale(\"log\")\n# ax.set_yscale(\"log\")\nax.set_xlabel(\"Particle radius (m)\")\nax.set_ylabel(\"Number concentration (1/m^3)\")\nax.set_title(\"Number concentration vs particle radius\")\nplt.show()\n\n# plot the rates\nfig, ax = plt.subplots()\nax.plot(radius_bins, gain_rate, label=\"Gain rate\")\nax.plot(radius_bins, -1 * loss_rate, label=\"Loss rate\")\nax.plot(radius_bins, net_rate, label=\"Net rate\", linestyle=\"--\")\nax.set_xscale(\"log\")\n# ax.set_yscale(\"log\")\nax.set_xlabel(\"Particle radius (m)\")\nax.set_ylabel(\"Coagulation rate 1/ (m^3 s)\")\nax.set_title(\"Coagulation rate vs particle radius\")\nax.legend()\nplt.show()\n</pre> fig, ax = plt.subplots() ax.plot(radius_bins, number_concentration) ax.set_xscale(\"log\") # ax.set_yscale(\"log\") ax.set_xlabel(\"Particle radius (m)\") ax.set_ylabel(\"Number concentration (1/m^3)\") ax.set_title(\"Number concentration vs particle radius\") plt.show()  # plot the rates fig, ax = plt.subplots() ax.plot(radius_bins, gain_rate, label=\"Gain rate\") ax.plot(radius_bins, -1 * loss_rate, label=\"Loss rate\") ax.plot(radius_bins, net_rate, label=\"Net rate\", linestyle=\"--\") ax.set_xscale(\"log\") # ax.set_yscale(\"log\") ax.set_xlabel(\"Particle radius (m)\") ax.set_ylabel(\"Coagulation rate 1/ (m^3 s)\") ax.set_title(\"Coagulation rate vs particle radius\") ax.legend() plt.show()"},{"location":"Examples/Dynamics/Coagulation/Charge/Coagulation_with_Charge_functional/#coagulation-with-charge-effects","title":"Coagulation with Charge Effects\u00b6","text":"<p>In this tutorial, we explore how electrical charge influences the coagulation (collisions and coalescence) of aerosol particles. We will:</p> <ul> <li>Create a size distribution for aerosol particles.</li> <li>Calculate the Coulomb potential ratio and related properties.</li> <li>Compute the coagulation kernel considering charge effects.</li> <li>Plot the coagulation kernel.</li> <li>Simulate the time evolution of the particle size distribution due to coagulation.</li> <li>Plot the particle concentration and coagulation rates.</li> </ul>"},{"location":"Examples/Dynamics/Coagulation/Charge/Coagulation_with_Charge_functional/#define-the-particle-size-distribution","title":"Define the Particle Size Distribution\u00b6","text":"<p>We create a size distribution for aerosol particles using a logarithmic scale for particle radius, ranging from 1 nm to 10 \u03bcm. We calculate the mass of particles in each size bin assuming they are spherical and have a standard density. Define the bins for particle radius using a logarithmic scale</p>"},{"location":"Examples/Dynamics/Coagulation/Charge/Coagulation_with_Charge_functional/#define-particle-charges","title":"Define Particle Charges\u00b6","text":"<p>We assign charges to the particles. In this example, we assign negative charges to the first 33% of particles and positive charges to the remaining 66% of particles. The charges are assigned based on the particle radius, with negative charges ranging from 10 to 1 and positive charges ranging from 1 to 500. We then plot the charge distribution against the particle radius. Determine the number of radius bins</p>"},{"location":"Examples/Dynamics/Coagulation/Charge/Coagulation_with_Charge_functional/#calculate-coulomb-potential-ratio-and-related-properties","title":"Calculate Coulomb Potential Ratio and Related Properties\u00b6","text":"<p>In this section, we compute several properties necessary for calculating the coagulation kernel with charge effects:</p> <ul> <li>Coulomb Potential Ratio: Using <code>coulomb_enhancement.ratio</code>, we calculate the dimensionless Coulomb potential ratio, which quantifies the electrostatic interaction between charged particles.</li> <li>Dynamic Viscosity: Obtained from <code>get_dynamic_viscosity</code>, needed for calculating friction factors.</li> <li>Mean Free Path: Calculated using <code>molecule_mean_free_path</code>, important for determining the Knudsen number.</li> <li>Knudsen Number: Computed with <code>calculate_knudsen_number</code>, it characterizes the flow regime of the particles.</li> <li>Slip Correction Factor: Using <code>cunningham_slip_correction</code>, accounts for non-continuum effects at small particle sizes.</li> <li>Friction Factor: Calculated with <code>friction_factor</code>, needed for determining particle mobility.</li> <li>Diffusive Knudsen Number: Using <code>diffusive_knudsen_number</code>, combines the effects of particle diffusion and electrostatic interactions.</li> </ul>"},{"location":"Examples/Dynamics/Coagulation/Charge/Coagulation_with_Charge_functional/#compute-the-non-dimensional-coagulation-kernel","title":"Compute the Non-Dimensional Coagulation Kernel\u00b6","text":"<p>The non-dimensional coagulation kernel is calculated using <code>coulomb_chahl2019</code>, which incorporates charge effects into the rate at which particles collide.</p>"},{"location":"Examples/Dynamics/Coagulation/Charge/Coagulation_with_Charge_functional/#calculate-coulomb-enhancement-factors","title":"Calculate Coulomb Enhancement Factors\u00b6","text":"<p>We compute the Coulomb enhancement factors in both the kinetic and continuum limits:</p> <ul> <li>Kinetic Limit: Using <code>coulomb_enhancement.kinetic</code>, applicable when particle motions are dominated by random thermal motion.</li> <li>Continuum Limit: Using <code>coulomb_enhancement.continuum</code>, applicable when particles are larger and motions are influenced by continuous fluid flow.</li> </ul>"},{"location":"Examples/Dynamics/Coagulation/Charge/Coagulation_with_Charge_functional/#compute-the-dimensional-coagulation-kernel","title":"Compute the Dimensional Coagulation Kernel\u00b6","text":"<p>The dimensional coagulation kernel combines all the previously calculated factors and gives the actual rate at which particles of different sizes collide and stick together due to coagulation, considering charge effects.</p>"},{"location":"Examples/Dynamics/Coagulation/Charge/Coagulation_with_Charge_functional/#plot-the-coagulation-kernel","title":"Plot the Coagulation Kernel\u00b6","text":"<p>We plot the coagulation kernel as a function of particle radius to visualize how charge affects the coagulation rates across different particle sizes.</p>"},{"location":"Examples/Dynamics/Coagulation/Charge/Coagulation_with_Charge_functional/#simulate-coagulation-over-a-time-step","title":"Simulate Coagulation Over a Time Step\u00b6","text":"<p>We calculate the gain and loss rates of particle concentrations due to coagulation using the previously computed kernel. The net rate of change in particle concentration is obtained by subtracting the loss rate from the gain rate. get rates of coagulation dn/dt make a number concentration distribution</p>"},{"location":"Examples/Dynamics/Coagulation/Charge/Coagulation_with_Charge_functional/#plot-particle-concentration-and-coagulation-rates","title":"Plot Particle Concentration and Coagulation Rates\u00b6","text":"<p>We visualize the initial particle concentration distribution and the coagulation rates to understand how charge effects influence the coagulation process over time.</p> <ul> <li>Particle Concentration: Shows the number concentration of particles across different sizes.</li> <li>Coagulation Rates: Displays the gain, loss, and net rates of coagulation, highlighting how particles of different sizes contribute to the overall process.</li> </ul>"},{"location":"Examples/Dynamics/Coagulation/Charge/Coagulation_with_Charge_objects/","title":"Coagulation with Various Kernel Strategies","text":"In\u00a0[\u00a0]: Copied! <pre># In Colab uncomment the following command to install particula:\n#!pip install particula[extra] --quiet\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Particula imports\nimport particula as par\n</pre> # In Colab uncomment the following command to install particula: #!pip install particula[extra] --quiet import numpy as np import matplotlib.pyplot as plt  # Particula imports import particula as par In\u00a0[2]: Copied! <pre># Define the bins for particle radius using a logarithmic scale\nradius_bins = np.logspace(start=-9, stop=-4, num=250)  # m (1 nm to 100 \u03bcm)\n\n# Calculate the mass of particles for each size bin\nmass_bins = 4 / 3 * np.pi * radius_bins**3 * 1e3  # kg\n</pre> # Define the bins for particle radius using a logarithmic scale radius_bins = np.logspace(start=-9, stop=-4, num=250)  # m (1 nm to 100 \u03bcm)  # Calculate the mass of particles for each size bin mass_bins = 4 / 3 * np.pi * radius_bins**3 * 1e3  # kg In\u00a0[3]: Copied! <pre># Determine the number of radius bins\nn_bins = len(radius_bins)\n\n# Define the split index where charges transition from negative to positive\nsplit_index = (\n    n_bins // 3\n)  # Assign the first third of particles negative charges\n\n# Generate logarithmically spaced magnitudes for negative charges from 10 to 1\nneg_magnitudes = np.logspace(np.log10(10), np.log10(1), num=split_index)\nneg_charges = -neg_magnitudes  # Assign negative sign\n\n# Generate logarithmically spaced magnitudes for positive charges from 1 to 500\npos_magnitudes = np.logspace(\n    np.log10(1), np.log10(500), num=n_bins - split_index\n)\npos_charges = pos_magnitudes  # Positive charges\n\n# Combine the negative and positive charges into one array\ncharge_array = np.concatenate((neg_charges, pos_charges))\n\n# Plot charge vs. radius\nfig, ax = plt.subplots()\nax.plot(radius_bins, charge_array, marker=\"o\", linestyle=\"none\")\nax.set_xscale(\"log\")\nax.set_yscale(\"symlog\", linthresh=1)\nax.set_xlabel(\"Particle radius (m)\")\nax.set_ylabel(\"Particle charge (elementary charges)\")\nax.set_title(\"Particle Charge vs. Radius\")\nax.grid(True, which=\"both\", ls=\"--\")\nplt.show()\n</pre> # Determine the number of radius bins n_bins = len(radius_bins)  # Define the split index where charges transition from negative to positive split_index = (     n_bins // 3 )  # Assign the first third of particles negative charges  # Generate logarithmically spaced magnitudes for negative charges from 10 to 1 neg_magnitudes = np.logspace(np.log10(10), np.log10(1), num=split_index) neg_charges = -neg_magnitudes  # Assign negative sign  # Generate logarithmically spaced magnitudes for positive charges from 1 to 500 pos_magnitudes = np.logspace(     np.log10(1), np.log10(500), num=n_bins - split_index ) pos_charges = pos_magnitudes  # Positive charges  # Combine the negative and positive charges into one array charge_array = np.concatenate((neg_charges, pos_charges))  # Plot charge vs. radius fig, ax = plt.subplots() ax.plot(radius_bins, charge_array, marker=\"o\", linestyle=\"none\") ax.set_xscale(\"log\") ax.set_yscale(\"symlog\", linthresh=1) ax.set_xlabel(\"Particle radius (m)\") ax.set_ylabel(\"Particle charge (elementary charges)\") ax.set_title(\"Particle Charge vs. Radius\") ax.grid(True, which=\"both\", ls=\"--\") plt.show() In\u00a0[5]: Copied! <pre>temperature = 298.15  # Temperature in Kelvin\n\n# Calculate Coulomb potential ratio\ncoulomb_potential_ratio = par.particles.get_coulomb_enhancement_ratio(\n    radius_bins, charge_array, temperature=temperature\n)\n\n# Calculate gas properties\ndynamic_viscosity = par.gas.get_dynamic_viscosity(temperature=temperature)\nmol_free_path = par.gas.get_molecule_mean_free_path(\n    temperature=temperature, dynamic_viscosity=dynamic_viscosity\n)\n\n# Calculate Knudsen number\nknudsen_number = par.particles.get_knudsen_number(\n    mean_free_path=mol_free_path, particle_radius=radius_bins\n)\n\n# Calculate slip correction factor\nslip_correction = par.particles.get_cunningham_slip_correction(\n    knudsen_number=knudsen_number\n)\n\n# Calculate friction factor\nfriction_factor_value = par.particles.get_friction_factor(\n    particle_radius=radius_bins,\n    dynamic_viscosity=dynamic_viscosity,\n    slip_correction=slip_correction,\n)\n\n# Calculate diffusive Knudsen number\ndiffusive_knudsen_values = par.particles.get_diffusive_knudsen_number(\n    particle_radius=radius_bins,\n    particle_mass=mass_bins,\n    friction_factor=friction_factor_value,\n    coulomb_potential_ratio=coulomb_potential_ratio,\n    temperature=temperature,\n)\n\n# Prepare quantities for kernel calculations\nsum_of_radii = radius_bins[:, np.newaxis] + radius_bins[np.newaxis, :]\nreduced_mass = par.util.get_reduced_self_broadcast(mass_bins)\nreduced_friction_factor = (\n    friction_factor_value[:, np.newaxis]\n    * friction_factor_value[np.newaxis, :]\n    / (\n        friction_factor_value[:, np.newaxis]\n        + friction_factor_value[np.newaxis, :]\n    )\n)\n</pre> temperature = 298.15  # Temperature in Kelvin  # Calculate Coulomb potential ratio coulomb_potential_ratio = par.particles.get_coulomb_enhancement_ratio(     radius_bins, charge_array, temperature=temperature )  # Calculate gas properties dynamic_viscosity = par.gas.get_dynamic_viscosity(temperature=temperature) mol_free_path = par.gas.get_molecule_mean_free_path(     temperature=temperature, dynamic_viscosity=dynamic_viscosity )  # Calculate Knudsen number knudsen_number = par.particles.get_knudsen_number(     mean_free_path=mol_free_path, particle_radius=radius_bins )  # Calculate slip correction factor slip_correction = par.particles.get_cunningham_slip_correction(     knudsen_number=knudsen_number )  # Calculate friction factor friction_factor_value = par.particles.get_friction_factor(     particle_radius=radius_bins,     dynamic_viscosity=dynamic_viscosity,     slip_correction=slip_correction, )  # Calculate diffusive Knudsen number diffusive_knudsen_values = par.particles.get_diffusive_knudsen_number(     particle_radius=radius_bins,     particle_mass=mass_bins,     friction_factor=friction_factor_value,     coulomb_potential_ratio=coulomb_potential_ratio,     temperature=temperature, )  # Prepare quantities for kernel calculations sum_of_radii = radius_bins[:, np.newaxis] + radius_bins[np.newaxis, :] reduced_mass = par.util.get_reduced_self_broadcast(mass_bins) reduced_friction_factor = (     friction_factor_value[:, np.newaxis]     * friction_factor_value[np.newaxis, :]     / (         friction_factor_value[:, np.newaxis]         + friction_factor_value[np.newaxis, :]     ) ) In\u00a0[6]: Copied! <pre># Instantiate the Hard Sphere kernel strategy\nkernel_strategy_hs = par.dynamics.HardSphereKernelStrategy()\n\n# Compute the dimensionless kernel\ndimensionless_kernel_hs = kernel_strategy_hs.dimensionless(\n    diffusive_knudsen=diffusive_knudsen_values,\n    coulomb_potential_ratio=None,  # Not used in this strategy\n)\n\n# Compute the dimensional kernel\ndimensional_kernel_hs = kernel_strategy_hs.kernel(\n    dimensionless_kernel=dimensionless_kernel_hs,\n    coulomb_potential_ratio=coulomb_potential_ratio,\n    sum_of_radii=sum_of_radii,\n    reduced_mass=reduced_mass,\n    reduced_friction_factor=reduced_friction_factor,\n)\n\n# Plot the Hard Sphere kernel\nfig, ax = plt.subplots()\nc = ax.pcolormesh(\n    radius_bins, radius_bins, np.log10(dimensional_kernel_hs), shading=\"auto\"\n)\nax.set_xscale(\"log\")\nax.set_yscale(\"log\")\nax.set_xlabel(\"Particle radius r_i (m)\")\nax.set_ylabel(\"Particle radius r_j (m)\")\nax.set_title(\"Hard Sphere Coagulation Kernel\")\nfig.colorbar(c, ax=ax, label=\"log10(Kernel) (m\u00b3/s)\")\nplt.show()\n</pre> # Instantiate the Hard Sphere kernel strategy kernel_strategy_hs = par.dynamics.HardSphereKernelStrategy()  # Compute the dimensionless kernel dimensionless_kernel_hs = kernel_strategy_hs.dimensionless(     diffusive_knudsen=diffusive_knudsen_values,     coulomb_potential_ratio=None,  # Not used in this strategy )  # Compute the dimensional kernel dimensional_kernel_hs = kernel_strategy_hs.kernel(     dimensionless_kernel=dimensionless_kernel_hs,     coulomb_potential_ratio=coulomb_potential_ratio,     sum_of_radii=sum_of_radii,     reduced_mass=reduced_mass,     reduced_friction_factor=reduced_friction_factor, )  # Plot the Hard Sphere kernel fig, ax = plt.subplots() c = ax.pcolormesh(     radius_bins, radius_bins, np.log10(dimensional_kernel_hs), shading=\"auto\" ) ax.set_xscale(\"log\") ax.set_yscale(\"log\") ax.set_xlabel(\"Particle radius r_i (m)\") ax.set_ylabel(\"Particle radius r_j (m)\") ax.set_title(\"Hard Sphere Coagulation Kernel\") fig.colorbar(c, ax=ax, label=\"log10(Kernel) (m\u00b3/s)\") plt.show() In\u00a0[7]: Copied! <pre># %%\n\n# Instantiate the Coulomb Dyachkov 2007 kernel strategy\nkernel_strategy_dyachkov = par.dynamics.CoulombDyachkov2007KernelStrategy()\n\n# Compute the dimensionless kernel\ndimensionless_kernel_dyachkov = kernel_strategy_dyachkov.dimensionless(\n    diffusive_knudsen=diffusive_knudsen_values,\n    coulomb_potential_ratio=coulomb_potential_ratio,\n)\n\n# Compute the dimensional kernel\ndimensional_kernel_dyachkov = kernel_strategy_dyachkov.kernel(\n    dimensionless_kernel=dimensionless_kernel_dyachkov,\n    coulomb_potential_ratio=coulomb_potential_ratio,\n    sum_of_radii=sum_of_radii,\n    reduced_mass=reduced_mass,\n    reduced_friction_factor=reduced_friction_factor,\n)\n\n# Plot the Coulomb Dyachkov 2007 kernel\nfig, ax = plt.subplots()\nc = ax.pcolormesh(\n    radius_bins,\n    radius_bins,\n    np.log10(dimensional_kernel_dyachkov),\n    shading=\"auto\",\n)\nax.set_xscale(\"log\")\nax.set_yscale(\"log\")\nax.set_xlabel(\"Particle radius r_i (m)\")\nax.set_ylabel(\"Particle radius r_j (m)\")\nax.set_title(\"Coulomb Dyachkov 2007 Coagulation Kernel\")\nfig.colorbar(c, ax=ax, label=\"Kernel (m\u00b3/s)\")\nplt.show()\n</pre> # %%  # Instantiate the Coulomb Dyachkov 2007 kernel strategy kernel_strategy_dyachkov = par.dynamics.CoulombDyachkov2007KernelStrategy()  # Compute the dimensionless kernel dimensionless_kernel_dyachkov = kernel_strategy_dyachkov.dimensionless(     diffusive_knudsen=diffusive_knudsen_values,     coulomb_potential_ratio=coulomb_potential_ratio, )  # Compute the dimensional kernel dimensional_kernel_dyachkov = kernel_strategy_dyachkov.kernel(     dimensionless_kernel=dimensionless_kernel_dyachkov,     coulomb_potential_ratio=coulomb_potential_ratio,     sum_of_radii=sum_of_radii,     reduced_mass=reduced_mass,     reduced_friction_factor=reduced_friction_factor, )  # Plot the Coulomb Dyachkov 2007 kernel fig, ax = plt.subplots() c = ax.pcolormesh(     radius_bins,     radius_bins,     np.log10(dimensional_kernel_dyachkov),     shading=\"auto\", ) ax.set_xscale(\"log\") ax.set_yscale(\"log\") ax.set_xlabel(\"Particle radius r_i (m)\") ax.set_ylabel(\"Particle radius r_j (m)\") ax.set_title(\"Coulomb Dyachkov 2007 Coagulation Kernel\") fig.colorbar(c, ax=ax, label=\"Kernel (m\u00b3/s)\") plt.show() In\u00a0[8]: Copied! <pre># %%\n\n# Instantiate the Coulomb Gatti 2008 kernel strategy\nkernel_strategy_gatti = par.dynamics.CoulombGatti2008KernelStrategy()\n\n# Compute the dimensionless kernel\ndimensionless_kernel_gatti = kernel_strategy_gatti.dimensionless(\n    diffusive_knudsen=diffusive_knudsen_values,\n    coulomb_potential_ratio=coulomb_potential_ratio,\n)\n\n# Compute the dimensional kernel\ndimensional_kernel_gatti = kernel_strategy_gatti.kernel(\n    dimensionless_kernel=dimensionless_kernel_gatti,\n    coulomb_potential_ratio=coulomb_potential_ratio,\n    sum_of_radii=sum_of_radii,\n    reduced_mass=reduced_mass,\n    reduced_friction_factor=reduced_friction_factor,\n)\n\n# Plot the Coulomb Gatti 2008 kernel\nfig, ax = plt.subplots()\nc = ax.pcolormesh(\n    radius_bins,\n    radius_bins,\n    np.log10(dimensional_kernel_gatti),\n    shading=\"auto\",\n)\nax.set_xscale(\"log\")\nax.set_yscale(\"log\")\nax.set_xlabel(\"Particle radius r_i (m)\")\nax.set_ylabel(\"Particle radius r_j (m)\")\nax.set_title(\"Coulomb Gatti 2008 Coagulation Kernel\")\nfig.colorbar(c, ax=ax, label=\"Kernel (m\u00b3/s)\")\nplt.show()\n</pre> # %%  # Instantiate the Coulomb Gatti 2008 kernel strategy kernel_strategy_gatti = par.dynamics.CoulombGatti2008KernelStrategy()  # Compute the dimensionless kernel dimensionless_kernel_gatti = kernel_strategy_gatti.dimensionless(     diffusive_knudsen=diffusive_knudsen_values,     coulomb_potential_ratio=coulomb_potential_ratio, )  # Compute the dimensional kernel dimensional_kernel_gatti = kernel_strategy_gatti.kernel(     dimensionless_kernel=dimensionless_kernel_gatti,     coulomb_potential_ratio=coulomb_potential_ratio,     sum_of_radii=sum_of_radii,     reduced_mass=reduced_mass,     reduced_friction_factor=reduced_friction_factor, )  # Plot the Coulomb Gatti 2008 kernel fig, ax = plt.subplots() c = ax.pcolormesh(     radius_bins,     radius_bins,     np.log10(dimensional_kernel_gatti),     shading=\"auto\", ) ax.set_xscale(\"log\") ax.set_yscale(\"log\") ax.set_xlabel(\"Particle radius r_i (m)\") ax.set_ylabel(\"Particle radius r_j (m)\") ax.set_title(\"Coulomb Gatti 2008 Coagulation Kernel\") fig.colorbar(c, ax=ax, label=\"Kernel (m\u00b3/s)\") plt.show() In\u00a0[\u00a0]: Copied! <pre># Instantiate the Coulomb Gopalakrishnan 2012 kernel strategy\nkernel_strategy_gopalakrishnan = (\n    par.dynamics.CoulombGopalakrishnan2012KernelStrategy()\n)\n\n# Compute the dimensionless kernel\ndimensionless_kernel_gopalakrishnan = (\n    kernel_strategy_gopalakrishnan.dimensionless(\n        diffusive_knudsen=diffusive_knudsen_values,\n        coulomb_potential_ratio=coulomb_potential_ratio,\n    )\n)\n\n# Compute the dimensional kernel\ndimensional_kernel_gopalakrishnan = kernel_strategy_gopalakrishnan.kernel(\n    dimensionless_kernel=dimensionless_kernel_gopalakrishnan,\n    coulomb_potential_ratio=coulomb_potential_ratio,\n    sum_of_radii=sum_of_radii,\n    reduced_mass=reduced_mass,\n    reduced_friction_factor=reduced_friction_factor,\n)\n\n# Plot the Coulomb Gopalakrishnan 2012 kernel\nfig, ax = plt.subplots()\nc = ax.pcolormesh(\n    radius_bins,\n    radius_bins,\n    np.log10(dimensional_kernel_gopalakrishnan),\n    shading=\"auto\",\n)\nax.set_xscale(\"log\")\nax.set_yscale(\"log\")\nax.set_xlabel(\"Particle radius r_i (m)\")\nax.set_ylabel(\"Particle radius r_j (m)\")\nax.set_title(\"Coulomb Gopalakrishnan 2012 Coagulation Kernel\")\nfig.colorbar(c, ax=ax, label=\"Kernel (m\u00b3/s)\")\nplt.show()\n</pre> # Instantiate the Coulomb Gopalakrishnan 2012 kernel strategy kernel_strategy_gopalakrishnan = (     par.dynamics.CoulombGopalakrishnan2012KernelStrategy() )  # Compute the dimensionless kernel dimensionless_kernel_gopalakrishnan = (     kernel_strategy_gopalakrishnan.dimensionless(         diffusive_knudsen=diffusive_knudsen_values,         coulomb_potential_ratio=coulomb_potential_ratio,     ) )  # Compute the dimensional kernel dimensional_kernel_gopalakrishnan = kernel_strategy_gopalakrishnan.kernel(     dimensionless_kernel=dimensionless_kernel_gopalakrishnan,     coulomb_potential_ratio=coulomb_potential_ratio,     sum_of_radii=sum_of_radii,     reduced_mass=reduced_mass,     reduced_friction_factor=reduced_friction_factor, )  # Plot the Coulomb Gopalakrishnan 2012 kernel fig, ax = plt.subplots() c = ax.pcolormesh(     radius_bins,     radius_bins,     np.log10(dimensional_kernel_gopalakrishnan),     shading=\"auto\", ) ax.set_xscale(\"log\") ax.set_yscale(\"log\") ax.set_xlabel(\"Particle radius r_i (m)\") ax.set_ylabel(\"Particle radius r_j (m)\") ax.set_title(\"Coulomb Gopalakrishnan 2012 Coagulation Kernel\") fig.colorbar(c, ax=ax, label=\"Kernel (m\u00b3/s)\") plt.show() In\u00a0[10]: Copied! <pre># %%\n\n# Instantiate the Coulomb Chahl 2019 kernel strategy\nkernel_strategy_chahl = par.dynamics.CoulumbChahl2019KernelStrategy()\n\n# Compute the dimensionless kernel\ndimensionless_kernel_chahl = kernel_strategy_chahl.dimensionless(\n    diffusive_knudsen=diffusive_knudsen_values,\n    coulomb_potential_ratio=coulomb_potential_ratio,\n)\n\n# Compute the dimensional kernel\ndimensional_kernel_chahl = kernel_strategy_chahl.kernel(\n    dimensionless_kernel=dimensionless_kernel_chahl,\n    coulomb_potential_ratio=coulomb_potential_ratio,\n    sum_of_radii=sum_of_radii,\n    reduced_mass=reduced_mass,\n    reduced_friction_factor=reduced_friction_factor,\n)\n\n# Plot the Coulomb Chahl 2019 kernel\nfig, ax = plt.subplots()\nc = ax.pcolormesh(\n    radius_bins,\n    radius_bins,\n    np.log10(dimensional_kernel_chahl),\n    shading=\"auto\",\n)\nax.set_xscale(\"log\")\nax.set_yscale(\"log\")\nax.set_xlabel(\"Particle radius r_i (m)\")\nax.set_ylabel(\"Particle radius r_j (m)\")\nax.set_title(\"Coulomb Chahl 2019 Coagulation Kernel\")\nfig.colorbar(c, ax=ax, label=\"Kernel (m\u00b3/s)\")\nplt.show()\n</pre> # %%  # Instantiate the Coulomb Chahl 2019 kernel strategy kernel_strategy_chahl = par.dynamics.CoulumbChahl2019KernelStrategy()  # Compute the dimensionless kernel dimensionless_kernel_chahl = kernel_strategy_chahl.dimensionless(     diffusive_knudsen=diffusive_knudsen_values,     coulomb_potential_ratio=coulomb_potential_ratio, )  # Compute the dimensional kernel dimensional_kernel_chahl = kernel_strategy_chahl.kernel(     dimensionless_kernel=dimensionless_kernel_chahl,     coulomb_potential_ratio=coulomb_potential_ratio,     sum_of_radii=sum_of_radii,     reduced_mass=reduced_mass,     reduced_friction_factor=reduced_friction_factor, )  # Plot the Coulomb Chahl 2019 kernel fig, ax = plt.subplots() c = ax.pcolormesh(     radius_bins,     radius_bins,     np.log10(dimensional_kernel_chahl),     shading=\"auto\", ) ax.set_xscale(\"log\") ax.set_yscale(\"log\") ax.set_xlabel(\"Particle radius r_i (m)\") ax.set_ylabel(\"Particle radius r_j (m)\") ax.set_title(\"Coulomb Chahl 2019 Coagulation Kernel\") fig.colorbar(c, ax=ax, label=\"Kernel (m\u00b3/s)\") plt.show() In\u00a0[11]: Copied! <pre># Select a pair of particles for comparison (e.g., index 100)\nindex = 50\n\n# Plot the kernel values for a selected particle size\nfig, ax = plt.subplots()\nax.plot(\n    radius_bins,\n    dimensional_kernel_hs[index, :],\n    label=\"Hard Sphere\",\n    linestyle=\"--\",\n    linewidth=5,\n    alpha=0.6,\n)\nax.plot(\n    radius_bins,\n    dimensional_kernel_dyachkov[index, :],\n    label=\"Dyachkov 2007\",\n    linestyle=\"-.\",\n    linewidth=4,\n    alpha=0.7,\n)\nax.plot(\n    radius_bins,\n    dimensional_kernel_gatti[index, :],\n    label=\"Gatti 2008\",\n    linestyle=\":\",\n    linewidth=4,\n    alpha=0.5,\n)\nax.plot(\n    radius_bins,\n    dimensional_kernel_gopalakrishnan[index, :],\n    label=\"Gopalakrishnan 2012\",\n    linestyle=\"-\",\n    linewidth=3,\n    alpha=0.5,\n)\nax.plot(\n    radius_bins,\n    dimensional_kernel_chahl[index, :],\n    label=\"Chahl 2019\",\n    linestyle=\"-\",\n    linewidth=2,\n    alpha=0.9,\n)\nax.set_xscale(\"log\")\nax.set_yscale(\"log\")\nax.set_xlabel(\"Particle radius r_j (m)\")\nax.set_ylabel(\"Kernel K(r_i, r_j) (m\u00b3/s)\")\nax.set_title(\n    f\"Comparison of Coagulation Kernels, radius_i = {radius_bins[index]:.2e} m\"\n)\nax.legend()\nplt.show()\n</pre> # Select a pair of particles for comparison (e.g., index 100) index = 50  # Plot the kernel values for a selected particle size fig, ax = plt.subplots() ax.plot(     radius_bins,     dimensional_kernel_hs[index, :],     label=\"Hard Sphere\",     linestyle=\"--\",     linewidth=5,     alpha=0.6, ) ax.plot(     radius_bins,     dimensional_kernel_dyachkov[index, :],     label=\"Dyachkov 2007\",     linestyle=\"-.\",     linewidth=4,     alpha=0.7, ) ax.plot(     radius_bins,     dimensional_kernel_gatti[index, :],     label=\"Gatti 2008\",     linestyle=\":\",     linewidth=4,     alpha=0.5, ) ax.plot(     radius_bins,     dimensional_kernel_gopalakrishnan[index, :],     label=\"Gopalakrishnan 2012\",     linestyle=\"-\",     linewidth=3,     alpha=0.5, ) ax.plot(     radius_bins,     dimensional_kernel_chahl[index, :],     label=\"Chahl 2019\",     linestyle=\"-\",     linewidth=2,     alpha=0.9, ) ax.set_xscale(\"log\") ax.set_yscale(\"log\") ax.set_xlabel(\"Particle radius r_j (m)\") ax.set_ylabel(\"Kernel K(r_i, r_j) (m\u00b3/s)\") ax.set_title(     f\"Comparison of Coagulation Kernels, radius_i = {radius_bins[index]:.2e} m\" ) ax.legend() plt.show() In\u00a0[12]: Copied! <pre># Select a pair of particles for comparison (e.g., index 100)\nindex = 100\n\n# Plot the kernel values for a selected particle size\nfig, ax = plt.subplots()\nax.plot(\n    radius_bins,\n    dimensional_kernel_hs[index, :],\n    label=\"Hard Sphere\",\n    linestyle=\"--\",\n    linewidth=5,\n    alpha=0.6,\n)\nax.plot(\n    radius_bins,\n    dimensional_kernel_dyachkov[index, :],\n    label=\"Dyachkov 2007\",\n    linestyle=\"-.\",\n    linewidth=4,\n    alpha=0.7,\n)\nax.plot(\n    radius_bins,\n    dimensional_kernel_gatti[index, :],\n    label=\"Gatti 2008\",\n    linestyle=\":\",\n    linewidth=4,\n    alpha=0.5,\n)\nax.plot(\n    radius_bins,\n    dimensional_kernel_gopalakrishnan[index, :],\n    label=\"Gopalakrishnan 2012\",\n    linestyle=\"-\",\n    linewidth=3,\n    alpha=0.5,\n)\nax.plot(\n    radius_bins,\n    dimensional_kernel_chahl[index, :],\n    label=\"Chahl 2019\",\n    linestyle=\"-\",\n    linewidth=2,\n    alpha=0.9,\n)\nax.set_xscale(\"log\")\nax.set_yscale(\"log\")\nax.set_xlabel(\"Particle radius r_j (m)\")\nax.set_ylabel(\"Kernel K(r_i, r_j) (m\u00b3/s)\")\nax.set_title(\n    f\"Comparison of Coagulation Kernels, radius_i = {radius_bins[index]:.2e} m\"\n)\nax.legend()\nplt.show()\n</pre> # Select a pair of particles for comparison (e.g., index 100) index = 100  # Plot the kernel values for a selected particle size fig, ax = plt.subplots() ax.plot(     radius_bins,     dimensional_kernel_hs[index, :],     label=\"Hard Sphere\",     linestyle=\"--\",     linewidth=5,     alpha=0.6, ) ax.plot(     radius_bins,     dimensional_kernel_dyachkov[index, :],     label=\"Dyachkov 2007\",     linestyle=\"-.\",     linewidth=4,     alpha=0.7, ) ax.plot(     radius_bins,     dimensional_kernel_gatti[index, :],     label=\"Gatti 2008\",     linestyle=\":\",     linewidth=4,     alpha=0.5, ) ax.plot(     radius_bins,     dimensional_kernel_gopalakrishnan[index, :],     label=\"Gopalakrishnan 2012\",     linestyle=\"-\",     linewidth=3,     alpha=0.5, ) ax.plot(     radius_bins,     dimensional_kernel_chahl[index, :],     label=\"Chahl 2019\",     linestyle=\"-\",     linewidth=2,     alpha=0.9, ) ax.set_xscale(\"log\") ax.set_yscale(\"log\") ax.set_xlabel(\"Particle radius r_j (m)\") ax.set_ylabel(\"Kernel K(r_i, r_j) (m\u00b3/s)\") ax.set_title(     f\"Comparison of Coagulation Kernels, radius_i = {radius_bins[index]:.2e} m\" ) ax.legend() plt.show() In\u00a0[13]: Copied! <pre># Select a pair of particles for comparison (e.g., index 100)\nindex = 200\n\n# Plot the kernel values for a selected particle size\nfig, ax = plt.subplots()\nax.plot(\n    radius_bins,\n    dimensional_kernel_hs[index, :],\n    label=\"Hard Sphere\",\n    linestyle=\"--\",\n    linewidth=5,\n    alpha=0.6,\n)\nax.plot(\n    radius_bins,\n    dimensional_kernel_dyachkov[index, :],\n    label=\"Dyachkov 2007\",\n    linestyle=\"-.\",\n    linewidth=4,\n    alpha=0.7,\n)\nax.plot(\n    radius_bins,\n    dimensional_kernel_gatti[index, :],\n    label=\"Gatti 2008\",\n    linestyle=\":\",\n    linewidth=4,\n    alpha=0.5,\n)\nax.plot(\n    radius_bins,\n    dimensional_kernel_gopalakrishnan[index, :],\n    label=\"Gopalakrishnan 2012\",\n    linestyle=\"-\",\n    linewidth=3,\n    alpha=0.5,\n)\nax.plot(\n    radius_bins,\n    dimensional_kernel_chahl[index, :],\n    label=\"Chahl 2019\",\n    linestyle=\"-\",\n    linewidth=2,\n    alpha=0.9,\n)\nax.set_xscale(\"log\")\nax.set_yscale(\"log\")\nax.set_xlabel(\"Particle radius r_j (m)\")\nax.set_ylabel(\"Kernel K(r_i, r_j) (m\u00b3/s)\")\nax.set_title(\n    f\"Comparison of Coagulation Kernels, radius_i = {radius_bins[index]:.2e} m\"\n)\nax.legend()\nplt.show()\n</pre> # Select a pair of particles for comparison (e.g., index 100) index = 200  # Plot the kernel values for a selected particle size fig, ax = plt.subplots() ax.plot(     radius_bins,     dimensional_kernel_hs[index, :],     label=\"Hard Sphere\",     linestyle=\"--\",     linewidth=5,     alpha=0.6, ) ax.plot(     radius_bins,     dimensional_kernel_dyachkov[index, :],     label=\"Dyachkov 2007\",     linestyle=\"-.\",     linewidth=4,     alpha=0.7, ) ax.plot(     radius_bins,     dimensional_kernel_gatti[index, :],     label=\"Gatti 2008\",     linestyle=\":\",     linewidth=4,     alpha=0.5, ) ax.plot(     radius_bins,     dimensional_kernel_gopalakrishnan[index, :],     label=\"Gopalakrishnan 2012\",     linestyle=\"-\",     linewidth=3,     alpha=0.5, ) ax.plot(     radius_bins,     dimensional_kernel_chahl[index, :],     label=\"Chahl 2019\",     linestyle=\"-\",     linewidth=2,     alpha=0.9, ) ax.set_xscale(\"log\") ax.set_yscale(\"log\") ax.set_xlabel(\"Particle radius r_j (m)\") ax.set_ylabel(\"Kernel K(r_i, r_j) (m\u00b3/s)\") ax.set_title(     f\"Comparison of Coagulation Kernels, radius_i = {radius_bins[index]:.2e} m\" ) ax.legend() plt.show() In\u00a0[14]: Copied! <pre># Make a number concentration distribution\nnumber_concentration = par.particles.get_lognormal_pmf_distribution(\n    x_values=radius_bins,\n    mode=np.array([10e-9, 200e-9, 1000e-9]),  # m\n    geometric_standard_deviation=np.array([1.4, 1.5, 1.8]),\n    number_of_particles=np.array([1e12, 1e12, 1e12]),  # per m^3\n)\n\n# Calculate gain and loss rates\ngain_rate = par.dynamics.get_coagulation_gain_rate_discrete(\n    radius=radius_bins,\n    concentration=number_concentration,\n    kernel=dimensional_kernel_chahl,\n)\nloss_rate = par.dynamics.get_coagulation_loss_rate_discrete(\n    concentration=number_concentration,\n    kernel=dimensional_kernel_chahl,\n)\n\nnet_rate = gain_rate - loss_rate\n</pre> # Make a number concentration distribution number_concentration = par.particles.get_lognormal_pmf_distribution(     x_values=radius_bins,     mode=np.array([10e-9, 200e-9, 1000e-9]),  # m     geometric_standard_deviation=np.array([1.4, 1.5, 1.8]),     number_of_particles=np.array([1e12, 1e12, 1e12]),  # per m^3 )  # Calculate gain and loss rates gain_rate = par.dynamics.get_coagulation_gain_rate_discrete(     radius=radius_bins,     concentration=number_concentration,     kernel=dimensional_kernel_chahl, ) loss_rate = par.dynamics.get_coagulation_loss_rate_discrete(     concentration=number_concentration,     kernel=dimensional_kernel_chahl, )  net_rate = gain_rate - loss_rate In\u00a0[15]: Copied! <pre># Plot the number concentration\nfig, ax1 = plt.subplots()\nax1.plot(radius_bins, number_concentration, color=\"green\")\nax1.set_xscale(\"log\")\nax1.set_xlabel(\"Particle radius (m)\")\nax1.set_ylabel(\"Number concentration (1/m\u00b3)\")\nax1.set_title(\"Particle Number Concentration vs. Radius\")\nax1.grid(True, which=\"both\", ls=\"--\")\nplt.show()\n\n# Plot the coagulation rates\nfig, ax2 = plt.subplots()\nax2.plot(radius_bins, gain_rate, label=\"Gain Rate\")\nax2.plot(radius_bins, -loss_rate, label=\"Loss Rate\")\nax2.plot(radius_bins, net_rate, label=\"Net Rate\", linestyle=\"--\")\nax2.set_xscale(\"log\")\n# ax2.set_yscale('log')\nax2.set_xlabel(\"Particle radius (m)\")\nax2.set_ylabel(\"Coagulation rate (1/(m\u00b3\u00b7s))\")\nax2.set_title(\"Coagulation Rates vs. Particle Radius\")\nax2.legend()\nax2.grid(True, which=\"both\", ls=\"--\")\nplt.show()\n</pre> # Plot the number concentration fig, ax1 = plt.subplots() ax1.plot(radius_bins, number_concentration, color=\"green\") ax1.set_xscale(\"log\") ax1.set_xlabel(\"Particle radius (m)\") ax1.set_ylabel(\"Number concentration (1/m\u00b3)\") ax1.set_title(\"Particle Number Concentration vs. Radius\") ax1.grid(True, which=\"both\", ls=\"--\") plt.show()  # Plot the coagulation rates fig, ax2 = plt.subplots() ax2.plot(radius_bins, gain_rate, label=\"Gain Rate\") ax2.plot(radius_bins, -loss_rate, label=\"Loss Rate\") ax2.plot(radius_bins, net_rate, label=\"Net Rate\", linestyle=\"--\") ax2.set_xscale(\"log\") # ax2.set_yscale('log') ax2.set_xlabel(\"Particle radius (m)\") ax2.set_ylabel(\"Coagulation rate (1/(m\u00b3\u00b7s))\") ax2.set_title(\"Coagulation Rates vs. Particle Radius\") ax2.legend() ax2.grid(True, which=\"both\", ls=\"--\") plt.show()"},{"location":"Examples/Dynamics/Coagulation/Charge/Coagulation_with_Charge_objects/#coagulation-with-various-kernel-strategies","title":"Coagulation with Various Kernel Strategies\u00b6","text":"<p>In this tutorial, we demonstrate how to compute coagulation kernels using different kernel strategies, including the effects of electrical charge on aerosol particles. We will:</p> <ul> <li>Define a particle size distribution.</li> <li>Assign charges to particles.</li> <li>Calculate necessary particle properties.</li> <li>Compute the coagulation kernel using different <code>KernelStrategy</code> classes.</li> <li>Plot and compare the results.</li> </ul>"},{"location":"Examples/Dynamics/Coagulation/Charge/Coagulation_with_Charge_objects/#import-necessary-libraries","title":"Import Necessary Libraries\u00b6","text":"<p>We import standard libraries and specific functions from the <code>particula</code> package that will be used in this tutorial.</p>"},{"location":"Examples/Dynamics/Coagulation/Charge/Coagulation_with_Charge_objects/#define-the-particle-size-distribution","title":"Define the Particle Size Distribution\u00b6","text":"<p>We create a size distribution for aerosol particles using a logarithmic scale for particle radius, ranging from 1 nm to 10 \u03bcm. We calculate the mass of particles in each size bin assuming they are spherical and have a standard density.</p>"},{"location":"Examples/Dynamics/Coagulation/Charge/Coagulation_with_Charge_objects/#define-particle-charges","title":"Define Particle Charges\u00b6","text":"<p>We assign charges to the particles. In this example, we assign negative charges to the smallest particles and positive charges to the larger particles. The charges are assigned based on the particle radius, with negative charges ranging from -10 to -1 and positive charges ranging from +1 to +500 on a logarithmic scale. We then plot the charge distribution against the particle radius.</p>"},{"location":"Examples/Dynamics/Coagulation/Charge/Coagulation_with_Charge_objects/#calculate-coulomb-potential-ratio-and-related-properties","title":"Calculate Coulomb Potential Ratio and Related Properties\u00b6","text":"<p>In this section, we compute several properties necessary for calculating the coagulation kernel with charge effects:</p> <ul> <li>Coulomb Potential Ratio: Using <code>coulomb_enhancement.ratio</code>, we calculate the dimensionless Coulomb potential ratio, which quantifies the electrostatic interaction between charged particles.</li> <li>Dynamic Viscosity: Obtained from <code>get_dynamic_viscosity</code>, needed for calculating friction factors.</li> <li>Mean Free Path: Calculated using <code>molecule_mean_free_path</code>, important for determining the Knudsen number.</li> <li>Knudsen Number: Computed with <code>calculate_knudsen_number</code>, it characterizes the flow regime of the particles.</li> <li>Slip Correction Factor: Using <code>cunningham_slip_correction</code>, accounts for non-continuum effects at small particle sizes.</li> <li>Friction Factor: Calculated with <code>friction_factor</code>, needed for determining particle mobility.</li> <li>Diffusive Knudsen Number: Using <code>diffusive_knudsen_number</code>, combines the effects of particle diffusion and electrostatic interactions.</li> </ul>"},{"location":"Examples/Dynamics/Coagulation/Charge/Coagulation_with_Charge_objects/#hard-sphere-kernel-strategy","title":"Hard Sphere Kernel Strategy\u00b6","text":"<p>The Hard Sphere kernel strategy assumes that particles interact as hard spheres without any additional forces like electrostatic interactions. This is the simplest kernel and serves as a baseline for comparison. References:</p> <ul> <li>This strategy is based on classical collision theory.</li> </ul>"},{"location":"Examples/Dynamics/Coagulation/Charge/Coagulation_with_Charge_objects/#coulomb-dyachkov-2007-kernel-strategy","title":"Coulomb Dyachkov 2007 Kernel Strategy\u00b6","text":"<p>The Coulomb Dyachkov 2007 kernel strategy accounts for the Coulomb potential between charged particles, as described by Dyachkov et al. (2007). It modifies the collision kernel to include electrostatic interactions. References:</p> <ul> <li>Dyachkov, S. A., Kustova, E. V., &amp; Kustov, A. V. (2007). Coagulation of particles in the transition regime: The effect of the Coulomb potential. Journal of Chemical Physics, 126(12). Link</li> </ul>"},{"location":"Examples/Dynamics/Coagulation/Charge/Coagulation_with_Charge_objects/#coulomb-gatti-2008-kernel-strategy","title":"Coulomb Gatti 2008 Kernel Strategy\u00b6","text":"<p>The Coulomb Gatti 2008 kernel strategy introduces an analytical model for particle charging in plasmas over a wide range of collisionality, as presented by Gatti and Kortshagen (2008). References:</p> <ul> <li>Gatti, M., &amp; Kortshagen, U. (2008). Analytical model of particle charging in plasmas over a wide range of collisionality. Physical Review E, 78(4). Link</li> </ul>"},{"location":"Examples/Dynamics/Coagulation/Charge/Coagulation_with_Charge_objects/#coulomb-gopalakrishnan-2012-kernel-strategy","title":"Coulomb Gopalakrishnan 2012 Kernel Strategy\u00b6","text":"<p>The Coulomb Gopalakrishnan 2012 kernel strategy accounts for Coulomb-influenced collisions in aerosols and dusty plasmas, as described by Gopalakrishnan and Hogan (2012). References:</p> <ul> <li>Gopalakrishnan, R., &amp; Hogan, C. J. (2012). Coulomb-influenced collisions in aerosols and dusty plasmas. Physical Review E, 85(2). Link</li> </ul>"},{"location":"Examples/Dynamics/Coagulation/Charge/Coagulation_with_Charge_objects/#coulomb-chahl-2019-kernel-strategy","title":"Coulomb Chahl 2019 Kernel Strategy\u00b6","text":"<p>The Coulomb Chahl 2019 kernel strategy provides an approximation for high potential, near free molecular regime Coulombic collisions in aerosols and dusty plasmas, as detailed by Chahl and Gopalakrishnan (2019). References:</p> <ul> <li>Chahl, H. S., &amp; Gopalakrishnan, R. (2019). High potential, near free molecular regime Coulombic collisions in aerosols and dusty plasmas. Aerosol Science and Technology, 53(8), 933-957. Link</li> </ul>"},{"location":"Examples/Dynamics/Coagulation/Charge/Coagulation_with_Charge_objects/#compare-different-kernel-strategies","title":"Compare Different Kernel Strategies\u00b6","text":"<p>We compare the coagulation kernels obtained from different strategies to understand the influence of the chosen kernel on the coagulation process.</p> <p>We step through small to large particles.</p>"},{"location":"Examples/Dynamics/Coagulation/Charge/Coagulation_with_Charge_objects/#simulate-coagulation-over-a-time-step-using-coulomb-chahl-2019-kernel","title":"Simulate Coagulation Over a Time Step Using Coulomb Chahl 2019 Kernel\u00b6","text":"<p>We use the Coulomb Chahl 2019 kernel to simulate the coagulation process over a time step. This involves calculating the gain and loss rates of particle concentrations due to coagulation and the net rate of change.</p>"},{"location":"Examples/Dynamics/Coagulation/Charge/Coagulation_with_Charge_objects/#plot-particle-concentration-and-coagulation-rates","title":"Plot Particle Concentration and Coagulation Rates\u00b6","text":"<p>We visualize the initial particle concentration distribution and the coagulation rates to understand how charge effects influence the coagulation process over time.</p> <ul> <li>Particle Concentration: Shows the number concentration of particles across different sizes.</li> <li>Coagulation Rates: Displays the gain, loss, and net rates of coagulation, highlighting how particles of different sizes contribute to the overall process.</li> </ul>"},{"location":"Examples/Dynamics/Coagulation/Functional/Coagulation_Basic_1_PMF/","title":"Coagulation Basic 1: PMF Representation","text":"In\u00a0[\u00a0]: Copied! <pre># In Colab uncomment the following command to install particula:\n#!pip install particula[extra] --quiet\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\nimport particula as par\n</pre> # In Colab uncomment the following command to install particula: #!pip install particula[extra] --quiet import numpy as np import matplotlib.pyplot as plt import pandas as pd  import particula as par In\u00a0[17]: Copied! <pre># Create a size distribution for aerosol particles\n\n# Define the bins for particle radius using a logarithmic scale\nradius_bins = np.logspace(start=-9, stop=-5, num=10)  # m (1 nm to 10 \u03bcm)\n\n# Calculate the mass of particles for each size bin\n# The mass is calculated using the formula for the volume of a sphere (4/3 * \u03c0 * r^3)\n# and assuming a particle density of 1 g/cm^3 (which is 1000 kg/m^3 in SI units).\nmass_bins = 4 / 3 * np.pi * radius_bins**3 * 1e3  # kg\n</pre> # Create a size distribution for aerosol particles  # Define the bins for particle radius using a logarithmic scale radius_bins = np.logspace(start=-9, stop=-5, num=10)  # m (1 nm to 10 \u03bcm)  # Calculate the mass of particles for each size bin # The mass is calculated using the formula for the volume of a sphere (4/3 * \u03c0 * r^3) # and assuming a particle density of 1 g/cm^3 (which is 1000 kg/m^3 in SI units). mass_bins = 4 / 3 * np.pi * radius_bins**3 * 1e3  # kg In\u00a0[\u00a0]: Copied! <pre># Calculate the Brownian coagulation kernel matrix\n\n# The Brownian coagulation kernel is calculated using the `brownian_coagulation_kernel_via_system_state` function.\n# This function takes into account the particle size, mass, temperature, pressure, and collision efficiency\n# to compute the coagulation rates between particles of different sizes.\nkernel = par.dynamics.get_brownian_kernel_via_system_state(\n    particle_radius=radius_bins,\n    particle_mass=mass_bins,\n    temperature=293.15,  # Temperature in Kelvin (20\u00b0C)\n    pressure=101325,  # Pressure in Pascals (1 atm)\n    alpha_collision_efficiency=1.0,  # Assume perfect collision efficiency\n)\n\n# Display the shape of the kernel matrix to confirm its dimensions\nprint(f\"Kernel shape: {kernel.shape}\")\n\n# Create a pandas DataFrame from the kernel matrix\n# The DataFrame allows for easier analysis and visualization of the coagulation kernel.\n# Rows and columns are indexed by the particle radius bins, making it clear which sizes are interacting.\ndf_kernel = pd.DataFrame(kernel, index=radius_bins, columns=radius_bins)\n\n# Print the first 5 rows of the DataFrame to inspect the computed kernel values\ndf_kernel.head(5)\n\n# Optional: Save the kernel matrix to a CSV file for further analysis or sharing\n# df_kernel.to_csv(\"kernel.csv\")\n</pre> # Calculate the Brownian coagulation kernel matrix  # The Brownian coagulation kernel is calculated using the `brownian_coagulation_kernel_via_system_state` function. # This function takes into account the particle size, mass, temperature, pressure, and collision efficiency # to compute the coagulation rates between particles of different sizes. kernel = par.dynamics.get_brownian_kernel_via_system_state(     particle_radius=radius_bins,     particle_mass=mass_bins,     temperature=293.15,  # Temperature in Kelvin (20\u00b0C)     pressure=101325,  # Pressure in Pascals (1 atm)     alpha_collision_efficiency=1.0,  # Assume perfect collision efficiency )  # Display the shape of the kernel matrix to confirm its dimensions print(f\"Kernel shape: {kernel.shape}\")  # Create a pandas DataFrame from the kernel matrix # The DataFrame allows for easier analysis and visualization of the coagulation kernel. # Rows and columns are indexed by the particle radius bins, making it clear which sizes are interacting. df_kernel = pd.DataFrame(kernel, index=radius_bins, columns=radius_bins)  # Print the first 5 rows of the DataFrame to inspect the computed kernel values df_kernel.head(5)  # Optional: Save the kernel matrix to a CSV file for further analysis or sharing # df_kernel.to_csv(\"kernel.csv\") <pre>Kernel shape: (10, 10)\n</pre> Out[\u00a0]: 1.000000e-09 2.782559e-09 7.742637e-09 2.154435e-08 5.994843e-08 1.668101e-07 4.641589e-07 1.291550e-06 3.593814e-06 1.000000e-05 1.000000e-09 8.812734e-16 2.277171e-15 1.181152e-14 7.503580e-14 4.506909e-13 2.024284e-12 6.824175e-12 2.020759e-11 5.737860e-11 1.607645e-10 2.782559e-09 2.277171e-15 1.461722e-15 3.692369e-15 1.733024e-14 8.141373e-14 3.005388e-13 9.275265e-13 2.670597e-12 7.517319e-12 2.100038e-11 7.742637e-09 1.181152e-14 3.692369e-15 2.224511e-15 4.558035e-15 1.429060e-14 4.375392e-14 1.267816e-13 3.580220e-13 1.001331e-12 2.790647e-12 2.154435e-08 7.503580e-14 1.733024e-14 4.558035e-15 2.123764e-15 3.008409e-15 7.020882e-15 1.858550e-14 5.087944e-14 1.407135e-13 3.904922e-13 5.994843e-08 4.506909e-13 8.141373e-14 1.429060e-14 3.008409e-15 1.304527e-15 1.624475e-15 3.413800e-15 8.588241e-15 2.303139e-14 6.320152e-14 In\u00a0[19]: Copied! <pre># Plot the Brownian coagulation kernel\n\n# Create a figure and axis object using matplotlib\nfig, ax = plt.subplots(figsize=(8, 6))\n\n# Plot the kernel values against the particle radius bins\n# The kernel values are plotted on a logarithmic scale (log10) for better visualization.\nax.plot(radius_bins, np.log10(kernel))\n\n# Set the x-axis label to indicate the particle radius in meters\nax.set_xlabel(\"Particle radius (m)\")\n\n# Set the y-axis label to indicate the logarithm of the kernel values\nax.set_ylabel(\"Log10(Kernel)\")\n\n# Use a logarithmic scale for the x-axis to properly represent the wide range of particle sizes\nax.set_xscale(\"log\")\n\n# Optionally, the y-axis can also be set to a logarithmic scale if needed\n# ax.set_yscale(\"log\")\n\n# Display the plot\nplt.show()\n</pre> # Plot the Brownian coagulation kernel  # Create a figure and axis object using matplotlib fig, ax = plt.subplots(figsize=(8, 6))  # Plot the kernel values against the particle radius bins # The kernel values are plotted on a logarithmic scale (log10) for better visualization. ax.plot(radius_bins, np.log10(kernel))  # Set the x-axis label to indicate the particle radius in meters ax.set_xlabel(\"Particle radius (m)\")  # Set the y-axis label to indicate the logarithm of the kernel values ax.set_ylabel(\"Log10(Kernel)\")  # Use a logarithmic scale for the x-axis to properly represent the wide range of particle sizes ax.set_xscale(\"log\")  # Optionally, the y-axis can also be set to a logarithmic scale if needed # ax.set_yscale(\"log\")  # Display the plot plt.show() In\u00a0[20]: Copied! <pre># Define the initial particle concentration\n\n# Set the initial concentration for each size bin\n# The concentration is set uniformly across all bins at 100 particles per cubic centimeter (100 cm^-3),\n# which is equivalent to 100 * 1e6 particles per cubic meter (m^-3).\nconcentration_0 = np.ones_like(radius_bins) * 100 * 1e6  # m^-3\n\n# Plot the initial concentration distribution\n\n# Create a figure and axis object for the plot\nfig, ax = plt.subplots(figsize=(8, 6))\n\n# Plot the concentration against the particle radius\nax.plot(radius_bins, concentration_0)\n\n# Set the x-axis label to indicate the particle radius in meters\nax.set_xlabel(\"Particle radius (m)\")\n\n# Set the y-axis label to indicate the concentration in particles per cubic meter\nax.set_ylabel(\"Concentration (m^-3)\")\n\n# Use a logarithmic scale for both the x-axis and y-axis\n# This is because the concentration distribution is typically viewed across several orders of magnitude\nax.set_xscale(\"log\")\nax.set_yscale(\"log\")\n\n# Display the plot\nplt.show()\n</pre> # Define the initial particle concentration  # Set the initial concentration for each size bin # The concentration is set uniformly across all bins at 100 particles per cubic centimeter (100 cm^-3), # which is equivalent to 100 * 1e6 particles per cubic meter (m^-3). concentration_0 = np.ones_like(radius_bins) * 100 * 1e6  # m^-3  # Plot the initial concentration distribution  # Create a figure and axis object for the plot fig, ax = plt.subplots(figsize=(8, 6))  # Plot the concentration against the particle radius ax.plot(radius_bins, concentration_0)  # Set the x-axis label to indicate the particle radius in meters ax.set_xlabel(\"Particle radius (m)\")  # Set the y-axis label to indicate the concentration in particles per cubic meter ax.set_ylabel(\"Concentration (m^-3)\")  # Use a logarithmic scale for both the x-axis and y-axis # This is because the concentration distribution is typically viewed across several orders of magnitude ax.set_xscale(\"log\") ax.set_yscale(\"log\")  # Display the plot plt.show() In\u00a0[21]: Copied! <pre># Coagulation rate calculation\n\n# Calculate the gain, loss, and net change in particle concentration due to coagulation\n# `discrete_gain`: Calculates the rate at which particles are gained due to coagulation\n# `discrete_loss`: Calculates the rate at which particles are lost due to coagulation\ngain_0 = par.dynamics.get_coagulation_gain_rate_discrete(\n    radius_bins, concentration_0, kernel\n)\nloss_0 = par.dynamics.get_coagulation_loss_rate_discrete(\n    concentration_0, kernel\n)\nnet_0 = gain_0 - loss_0  # Net change in concentration\n\n# Create a DataFrame to display the gain, loss, and net coagulation rates\n# The DataFrame is indexed by particle radius bins for clarity\ndf = pd.DataFrame(\n    data={\"Gain\": gain_0, \"Loss\": loss_0, \"Net\": net_0}, index=radius_bins\n)\n\n# Display the first 5 rows of the DataFrame\ndf.head(5)\n</pre> # Coagulation rate calculation  # Calculate the gain, loss, and net change in particle concentration due to coagulation # `discrete_gain`: Calculates the rate at which particles are gained due to coagulation # `discrete_loss`: Calculates the rate at which particles are lost due to coagulation gain_0 = par.dynamics.get_coagulation_gain_rate_discrete(     radius_bins, concentration_0, kernel ) loss_0 = par.dynamics.get_coagulation_loss_rate_discrete(     concentration_0, kernel ) net_0 = gain_0 - loss_0  # Net change in concentration  # Create a DataFrame to display the gain, loss, and net coagulation rates # The DataFrame is indexed by particle radius bins for clarity df = pd.DataFrame(     data={\"Gain\": gain_0, \"Loss\": loss_0, \"Net\": net_0}, index=radius_bins )  # Display the first 5 rows of the DataFrame df.head(5) Out[21]: Gain Loss Net 1.000000e-09 4.379653 2.477398e+06 -2.477394e+06 2.782559e-09 25.830601 3.252254e+05 -3.251995e+05 7.742637e-09 79.877700 4.357112e+04 -4.349124e+04 2.154435e-08 1666.815122 7.097477e+03 -5.430662e+03 5.994843e-08 -12799.281898 6.505676e+03 -1.930496e+04 In\u00a0[22]: Copied! <pre># Plot the coagulation gain, loss, and net rates\n\n# Create a figure and axis object for the plot\nfig, ax = plt.subplots(figsize=(8, 6))\n\n# Plot the net coagulation rate\n# The net rate is plotted with a thicker gray line for emphasis\nax.plot(radius_bins, net_0, label=\"Net\", color=\"gray\", linewidth=4)\n\n# Plot the gain rate\n# The gain rate is plotted in dark green\nax.plot(radius_bins, gain_0, label=\"Gain\", color=\"darkgreen\")\n\n# Plot the loss rate\n# The loss rate is plotted in red, and multiplied by -1 for plotting to indicate that it's a removal process\nax.plot(radius_bins, -1 * loss_0, label=\"Loss\", color=\"red\")\n\n# Set the x-axis label to indicate the particle radius in meters\nax.set_xlabel(\"Particle radius (m)\")\n\n# Set the y-axis label to indicate the rate of change in concentration, with appropriate units\nax.set_ylabel(r\"Rate $\\dfrac{1}{m^{3} s^{1}}$\")\n\n# Use a logarithmic scale for the x-axis to account for the wide range of particle sizes\nax.set_xscale(\"log\")\n\n# Add a legend to the plot to identify the gain, loss, and net lines\nplt.legend()\n\n# Display the plot\nplt.show()\n</pre> # Plot the coagulation gain, loss, and net rates  # Create a figure and axis object for the plot fig, ax = plt.subplots(figsize=(8, 6))  # Plot the net coagulation rate # The net rate is plotted with a thicker gray line for emphasis ax.plot(radius_bins, net_0, label=\"Net\", color=\"gray\", linewidth=4)  # Plot the gain rate # The gain rate is plotted in dark green ax.plot(radius_bins, gain_0, label=\"Gain\", color=\"darkgreen\")  # Plot the loss rate # The loss rate is plotted in red, and multiplied by -1 for plotting to indicate that it's a removal process ax.plot(radius_bins, -1 * loss_0, label=\"Loss\", color=\"red\")  # Set the x-axis label to indicate the particle radius in meters ax.set_xlabel(\"Particle radius (m)\")  # Set the y-axis label to indicate the rate of change in concentration, with appropriate units ax.set_ylabel(r\"Rate $\\dfrac{1}{m^{3} s^{1}}$\")  # Use a logarithmic scale for the x-axis to account for the wide range of particle sizes ax.set_xscale(\"log\")  # Add a legend to the plot to identify the gain, loss, and net lines plt.legend()  # Display the plot plt.show() In\u00a0[23]: Copied! <pre># Simulating the coagulation process over time manually\n\n# Define the time step for the simulation\nTIME_STEP = 0.1  # seconds\n\n# Time step 1: Calculate the gain, loss, and net rate, then update concentration\n\n# Calculate the rate of change in concentration (gain and loss) for the initial concentration\ngain = par.dynamics.get_coagulation_gain_rate_discrete(\n    radius_bins, concentration_0, kernel\n)\nloss = par.dynamics.get_coagulation_loss_rate_discrete(concentration_0, kernel)\nnet = gain - loss  # Net rate of change\n\n# Update the concentration for the next time step\nconcentration_1 = concentration_0 + net * TIME_STEP\n\n# Time step 2: Recalculate rates with the updated concentration and update again\n\n# Recalculate gain and loss based on the updated concentration from time step 1\ngain = par.dynamics.get_coagulation_gain_rate_discrete(\n    radius_bins, concentration_1, kernel\n)\nloss = par.dynamics.get_coagulation_loss_rate_discrete(concentration_1, kernel)\nnet = gain - loss\n\n# Update the concentration for the next time step\nconcentration_2 = concentration_1 + net * TIME_STEP\n\n# Time step 3: Recalculate rates again and update concentration\n\n# Recalculate gain and loss based on the updated concentration from time step 2\ngain = par.dynamics.get_coagulation_gain_rate_discrete(\n    radius_bins, concentration_2, kernel\n)\nloss = par.dynamics.get_coagulation_loss_rate_discrete(concentration_2, kernel)\nnet = gain - loss\n\n# Update the concentration for the next time step\nconcentration_3 = concentration_2 + net * TIME_STEP\n\n# Print the maximum concentration at each time step to observe changes\nprint(f\"Concentration 0 max: {concentration_0.max()}\")\nprint(f\"Concentration 1 max: {concentration_1.max()}\")\nprint(f\"Concentration 2 max: {concentration_2.max()}\")\nprint(f\"Concentration 3 max: {concentration_3.max()}\")\n\n# Combine the concentrations at each time step into a DataFrame for easy comparison\ndf_concentration = pd.DataFrame(\n    {\n        \"0\": concentration_0,\n        \"1\": concentration_1,\n        \"2\": concentration_2,\n        \"3\": concentration_3,\n    },\n    index=radius_bins,\n)\n\n# Display the first five rows of the DataFrame to inspect the concentration changes\ndf_concentration.head(5)\n\n# Optional: Save the concentration data to a CSV file for further analysis\n# df_concentration.to_csv(\"concentration_uniform_sim.csv\")\n</pre> # Simulating the coagulation process over time manually  # Define the time step for the simulation TIME_STEP = 0.1  # seconds  # Time step 1: Calculate the gain, loss, and net rate, then update concentration  # Calculate the rate of change in concentration (gain and loss) for the initial concentration gain = par.dynamics.get_coagulation_gain_rate_discrete(     radius_bins, concentration_0, kernel ) loss = par.dynamics.get_coagulation_loss_rate_discrete(concentration_0, kernel) net = gain - loss  # Net rate of change  # Update the concentration for the next time step concentration_1 = concentration_0 + net * TIME_STEP  # Time step 2: Recalculate rates with the updated concentration and update again  # Recalculate gain and loss based on the updated concentration from time step 1 gain = par.dynamics.get_coagulation_gain_rate_discrete(     radius_bins, concentration_1, kernel ) loss = par.dynamics.get_coagulation_loss_rate_discrete(concentration_1, kernel) net = gain - loss  # Update the concentration for the next time step concentration_2 = concentration_1 + net * TIME_STEP  # Time step 3: Recalculate rates again and update concentration  # Recalculate gain and loss based on the updated concentration from time step 2 gain = par.dynamics.get_coagulation_gain_rate_discrete(     radius_bins, concentration_2, kernel ) loss = par.dynamics.get_coagulation_loss_rate_discrete(concentration_2, kernel) net = gain - loss  # Update the concentration for the next time step concentration_3 = concentration_2 + net * TIME_STEP  # Print the maximum concentration at each time step to observe changes print(f\"Concentration 0 max: {concentration_0.max()}\") print(f\"Concentration 1 max: {concentration_1.max()}\") print(f\"Concentration 2 max: {concentration_2.max()}\") print(f\"Concentration 3 max: {concentration_3.max()}\")  # Combine the concentrations at each time step into a DataFrame for easy comparison df_concentration = pd.DataFrame(     {         \"0\": concentration_0,         \"1\": concentration_1,         \"2\": concentration_2,         \"3\": concentration_3,     },     index=radius_bins, )  # Display the first five rows of the DataFrame to inspect the concentration changes df_concentration.head(5)  # Optional: Save the concentration data to a CSV file for further analysis # df_concentration.to_csv(\"concentration_uniform_sim.csv\") <pre>Concentration 0 max: 100000000.0\nConcentration 1 max: 1263633883.0015862\nConcentration 2 max: 11241880825.442844\nConcentration 3 max: 98778247873.61397\n</pre> Out[23]: 0 1 2 3 1.000000e-09 100000000.0 9.975226e+07 9.765578e+07 7.995004e+07 2.782559e-09 100000000.0 9.996748e+07 9.969288e+07 9.733161e+07 7.742637e-09 100000000.0 9.999565e+07 9.995912e+07 9.964448e+07 2.154435e-08 100000000.0 9.999946e+07 9.999441e+07 9.995043e+07 5.994843e-08 100000000.0 9.999807e+07 9.999542e+07 9.998650e+07 In\u00a0[24]: Copied! <pre># Plot the evolution of particle concentration over time\n\n# Create a figure and axis object for the plot\nfig, ax = plt.subplots(figsize=(8, 6))\n\n# Plot the concentration distribution at each time step\nax.plot(radius_bins, concentration_0, label=\"t=0\", linestyle=\"-\", color=\"blue\")\nax.plot(\n    radius_bins, concentration_1, label=\"t=1\", linestyle=\"--\", color=\"green\"\n)\nax.plot(\n    radius_bins, concentration_2, label=\"t=2\", linestyle=\"-.\", color=\"orange\"\n)\nax.plot(radius_bins, concentration_3, label=\"t=3\", linestyle=\":\", color=\"red\")\n\n# Set the x-axis label to indicate the particle radius in meters\nax.set_xlabel(\"Particle radius (m)\")\n\n# Set the y-axis label to indicate the concentration in particles per cubic meter\nax.set_ylabel(r\"Concentration $\\dfrac{1}{m^{3}}$\")\n\n# Use logarithmic scales for both the x-axis and y-axis\n# This helps in visualizing the broad range of particle sizes and concentration changes\nax.set_xscale(\"log\")\nax.set_yscale(\"log\")\n\n# Add a legend to differentiate between the time steps\nplt.legend()\n\n# Display the plot\nplt.show()\n</pre> # Plot the evolution of particle concentration over time  # Create a figure and axis object for the plot fig, ax = plt.subplots(figsize=(8, 6))  # Plot the concentration distribution at each time step ax.plot(radius_bins, concentration_0, label=\"t=0\", linestyle=\"-\", color=\"blue\") ax.plot(     radius_bins, concentration_1, label=\"t=1\", linestyle=\"--\", color=\"green\" ) ax.plot(     radius_bins, concentration_2, label=\"t=2\", linestyle=\"-.\", color=\"orange\" ) ax.plot(radius_bins, concentration_3, label=\"t=3\", linestyle=\":\", color=\"red\")  # Set the x-axis label to indicate the particle radius in meters ax.set_xlabel(\"Particle radius (m)\")  # Set the y-axis label to indicate the concentration in particles per cubic meter ax.set_ylabel(r\"Concentration $\\dfrac{1}{m^{3}}$\")  # Use logarithmic scales for both the x-axis and y-axis # This helps in visualizing the broad range of particle sizes and concentration changes ax.set_xscale(\"log\") ax.set_yscale(\"log\")  # Add a legend to differentiate between the time steps plt.legend()  # Display the plot plt.show() In\u00a0[25]: Copied! <pre># Define fine scale radius bins and corresponding mass bins for a lognormal distribution\n\n# Create fine scale radius bins on a logarithmic scale from 1 nm to 10 \u03bcm\nradius_bins = np.logspace(start=-9, stop=-4, num=250)  # m (1 nm to 10 \u03bcm)\n\n# Calculate the mass for each particle size bin assuming a density of 1 g/cm^3 (1000 kg/m^3)\nmass_bins = 4 / 3 * np.pi * (radius_bins) ** 3 * 1e3  # kg\n\n# Generate a lognormal particle size distribution\n# This distribution is characterized by a mode (most probable size) of 100 nm,\n# a geometric standard deviation of 1.4, and a total number concentration of 10000 particles per cm^3.\nconcentration_lognormal_0 = par.particles.get_lognormal_pmf_distribution(\n    x_values=radius_bins,\n    mode=np.array(100e-9),  # Mode of the distribution (100 nm)\n    geometric_standard_deviation=np.array(1.4),  # Geometric standard deviation\n    number_of_particles=np.array(\n        1e6 * 1e6  # Total concentration (10000 cm^-3 converted to m^-3)\n    ),\n)\n\n# Plot the lognormal concentration distribution\nfig, ax = plt.subplots(figsize=(8, 6))\nax.plot(radius_bins, concentration_lognormal_0)\n\n# Set the x-axis to a logarithmic scale to capture the wide range of particle sizes\nax.set_xlabel(\"Particle radius (m)\")\n\n# Label the y-axis to show the concentration in particles per cubic meter\nax.set_ylabel(r\"Concentration $\\dfrac{1}{m^{3}}$\")\n\n# Use a logarithmic scale for the x-axis to better visualize the distribution across particle sizes\nax.set_xscale(\"log\")\n\n# Set Title\nax.set_title(\"PMF: Lognormal Particle Size Distribution\")\n\n# Display the plot\nplt.show()\n</pre> # Define fine scale radius bins and corresponding mass bins for a lognormal distribution  # Create fine scale radius bins on a logarithmic scale from 1 nm to 10 \u03bcm radius_bins = np.logspace(start=-9, stop=-4, num=250)  # m (1 nm to 10 \u03bcm)  # Calculate the mass for each particle size bin assuming a density of 1 g/cm^3 (1000 kg/m^3) mass_bins = 4 / 3 * np.pi * (radius_bins) ** 3 * 1e3  # kg  # Generate a lognormal particle size distribution # This distribution is characterized by a mode (most probable size) of 100 nm, # a geometric standard deviation of 1.4, and a total number concentration of 10000 particles per cm^3. concentration_lognormal_0 = par.particles.get_lognormal_pmf_distribution(     x_values=radius_bins,     mode=np.array(100e-9),  # Mode of the distribution (100 nm)     geometric_standard_deviation=np.array(1.4),  # Geometric standard deviation     number_of_particles=np.array(         1e6 * 1e6  # Total concentration (10000 cm^-3 converted to m^-3)     ), )  # Plot the lognormal concentration distribution fig, ax = plt.subplots(figsize=(8, 6)) ax.plot(radius_bins, concentration_lognormal_0)  # Set the x-axis to a logarithmic scale to capture the wide range of particle sizes ax.set_xlabel(\"Particle radius (m)\")  # Label the y-axis to show the concentration in particles per cubic meter ax.set_ylabel(r\"Concentration $\\dfrac{1}{m^{3}}$\")  # Use a logarithmic scale for the x-axis to better visualize the distribution across particle sizes ax.set_xscale(\"log\")  # Set Title ax.set_title(\"PMF: Lognormal Particle Size Distribution\")  # Display the plot plt.show() In\u00a0[\u00a0]: Copied! <pre># Simulating the coagulation process over time for a lognormal distribution\n\n# Define the time step for the simulation\nTIME_STEP = 100  # seconds\n\n# Calculate the coagulation kernel\nkernel = par.dynamics.get_brownian_kernel_via_system_state(\n    particle_radius=radius_bins,\n    particle_mass=mass_bins,\n    temperature=293.15,  # Temperature in Kelvin\n    pressure=101325,  # Pressure in Pascals (1 atm)\n    alpha_collision_efficiency=1.0,  # Assume perfect collision efficiency\n)\n\n# Time step 1: Calculate gain, loss, and update concentration\ngain = par.dynamics.get_coagulation_gain_rate_discrete(\n    radius_bins, concentration_lognormal_0, kernel\n)\nloss = par.dynamics.get_coagulation_loss_rate_discrete(\n    concentration_lognormal_0, kernel\n)\nnet = gain - loss\nconcentration_lognormal_1 = concentration_lognormal_0 + net * TIME_STEP\nconcentration_lognormal_1[concentration_lognormal_1 &lt; 0] = (\n    0  # Ensure no negative concentrations\n)\n\n# Time step 2: Recalculate rates and update concentration\ngain = par.dynamics.get_coagulation_gain_rate_discrete(\n    radius_bins, concentration_lognormal_1, kernel\n)\nloss = par.dynamics.get_coagulation_loss_rate_discrete(\n    concentration_lognormal_1, kernel\n)\nnet = gain - loss\nconcentration_lognormal_2 = concentration_lognormal_1 + net * TIME_STEP\nconcentration_lognormal_2[concentration_lognormal_2 &lt; 0] = (\n    0  # Ensure no negative concentrations\n)\n\n# Time step 3: Recalculate rates and update concentration\ngain = par.dynamics.get_coagulation_gain_rate_discrete(\n    radius_bins, concentration_lognormal_2, kernel\n)\nloss = par.dynamics.get_coagulation_loss_rate_discrete(\n    concentration_lognormal_2, kernel\n)\nnet = gain - loss\nconcentration_lognormal_3 = concentration_lognormal_2 + net * TIME_STEP\nconcentration_lognormal_3[concentration_lognormal_3 &lt; 0] = (\n    0  # Ensure no negative concentrations\n)\n\n# Combine the concentrations at each time step into a DataFrame for easy comparison\ndf_concentration = pd.DataFrame(\n    {\n        \"0\": concentration_lognormal_0,\n        \"1\": concentration_lognormal_1,\n        \"2\": concentration_lognormal_2,\n        \"3\": concentration_lognormal_3,\n    },\n    index=radius_bins,\n)\n\n# Optional: Save the concentration data to a CSV file for further analysis\n# df_concentration.to_csv(\"concentration_lognormal_sim.csv\")\n</pre> # Simulating the coagulation process over time for a lognormal distribution  # Define the time step for the simulation TIME_STEP = 100  # seconds  # Calculate the coagulation kernel kernel = par.dynamics.get_brownian_kernel_via_system_state(     particle_radius=radius_bins,     particle_mass=mass_bins,     temperature=293.15,  # Temperature in Kelvin     pressure=101325,  # Pressure in Pascals (1 atm)     alpha_collision_efficiency=1.0,  # Assume perfect collision efficiency )  # Time step 1: Calculate gain, loss, and update concentration gain = par.dynamics.get_coagulation_gain_rate_discrete(     radius_bins, concentration_lognormal_0, kernel ) loss = par.dynamics.get_coagulation_loss_rate_discrete(     concentration_lognormal_0, kernel ) net = gain - loss concentration_lognormal_1 = concentration_lognormal_0 + net * TIME_STEP concentration_lognormal_1[concentration_lognormal_1 &lt; 0] = (     0  # Ensure no negative concentrations )  # Time step 2: Recalculate rates and update concentration gain = par.dynamics.get_coagulation_gain_rate_discrete(     radius_bins, concentration_lognormal_1, kernel ) loss = par.dynamics.get_coagulation_loss_rate_discrete(     concentration_lognormal_1, kernel ) net = gain - loss concentration_lognormal_2 = concentration_lognormal_1 + net * TIME_STEP concentration_lognormal_2[concentration_lognormal_2 &lt; 0] = (     0  # Ensure no negative concentrations )  # Time step 3: Recalculate rates and update concentration gain = par.dynamics.get_coagulation_gain_rate_discrete(     radius_bins, concentration_lognormal_2, kernel ) loss = par.dynamics.get_coagulation_loss_rate_discrete(     concentration_lognormal_2, kernel ) net = gain - loss concentration_lognormal_3 = concentration_lognormal_2 + net * TIME_STEP concentration_lognormal_3[concentration_lognormal_3 &lt; 0] = (     0  # Ensure no negative concentrations )  # Combine the concentrations at each time step into a DataFrame for easy comparison df_concentration = pd.DataFrame(     {         \"0\": concentration_lognormal_0,         \"1\": concentration_lognormal_1,         \"2\": concentration_lognormal_2,         \"3\": concentration_lognormal_3,     },     index=radius_bins, )  # Optional: Save the concentration data to a CSV file for further analysis # df_concentration.to_csv(\"concentration_lognormal_sim.csv\") In\u00a0[27]: Copied! <pre># Print the maximum and minimum concentrations at each time step\n\nprint(f\"Max concentration at t=0: {concentration_lognormal_0.max()}\")\nprint(f\"Min concentration at t=0: {concentration_lognormal_0.min()}\")\n\nprint(f\"Max concentration at t=1: {concentration_lognormal_1.max()}\")\nprint(f\"Min concentration at t=1: {concentration_lognormal_1.min()}\")\n\nprint(f\"Max concentration at t=2: {concentration_lognormal_2.max()}\")\nprint(f\"Min concentration at t=2: {concentration_lognormal_2.min()}\")\n\nprint(f\"Max concentration at t=3: {concentration_lognormal_3.max()}\")\nprint(f\"Min concentration at t=3: {concentration_lognormal_3.min()}\")\n</pre> # Print the maximum and minimum concentrations at each time step  print(f\"Max concentration at t=0: {concentration_lognormal_0.max()}\") print(f\"Min concentration at t=0: {concentration_lognormal_0.min()}\")  print(f\"Max concentration at t=1: {concentration_lognormal_1.max()}\") print(f\"Min concentration at t=1: {concentration_lognormal_1.min()}\")  print(f\"Max concentration at t=2: {concentration_lognormal_2.max()}\") print(f\"Min concentration at t=2: {concentration_lognormal_2.min()}\")  print(f\"Max concentration at t=3: {concentration_lognormal_3.max()}\") print(f\"Min concentration at t=3: {concentration_lognormal_3.min()}\") <pre>Max concentration at t=0: 54738275267.16476\nMin concentration at t=0: 1.6445825598006672e-81\nMax concentration at t=1: 51186782324.56813\nMin concentration at t=1: 0.0\nMax concentration at t=2: 48026245801.09982\nMin concentration at t=2: 0.0\nMax concentration at t=3: 45351022236.99084\nMin concentration at t=3: 0.0\n</pre> In\u00a0[28]: Copied! <pre># Plot the coagulation gain, loss, and net rates for the lognormal distribution\n\n# Create a figure and axis object for the plot\nfig, ax = plt.subplots(figsize=(8, 6))\n\n# Plot the net coagulation rate\n# The net rate is plotted with a thicker gray line for emphasis\nax.plot(radius_bins, net, label=\"Net\", color=\"gray\", linewidth=4)\n\n# Plot the gain rate\n# The gain rate is plotted in dark green\nax.plot(radius_bins, gain, label=\"Gain\", color=\"darkgreen\")\n\n# Plot the loss rate\n# The loss rate is plotted in red, and multiplied by -1 for plotting to indicate that it's a removal process\nax.plot(radius_bins, -1 * loss, label=\"Loss\", color=\"red\")\n\n# Set the x-axis label to indicate the particle radius in meters\nax.set_xlabel(\"Particle radius (m)\")\n\n# Set the y-axis label to indicate the rate of change in concentration, with appropriate units\nax.set_ylabel(r\"Rate $\\dfrac{1}{m^{3} s^{1}}$\")\n\n# Use a logarithmic scale for the x-axis to account for the wide range of particle sizes\nax.set_xscale(\"log\")\n\n# set title\nax.set_title(\"PMF: Coagulation gain, loss, and net rates\")\n\n# Add a legend to identify the gain, loss, and net lines\nplt.legend()\n\n# Display the plot\nplt.show()\n</pre> # Plot the coagulation gain, loss, and net rates for the lognormal distribution  # Create a figure and axis object for the plot fig, ax = plt.subplots(figsize=(8, 6))  # Plot the net coagulation rate # The net rate is plotted with a thicker gray line for emphasis ax.plot(radius_bins, net, label=\"Net\", color=\"gray\", linewidth=4)  # Plot the gain rate # The gain rate is plotted in dark green ax.plot(radius_bins, gain, label=\"Gain\", color=\"darkgreen\")  # Plot the loss rate # The loss rate is plotted in red, and multiplied by -1 for plotting to indicate that it's a removal process ax.plot(radius_bins, -1 * loss, label=\"Loss\", color=\"red\")  # Set the x-axis label to indicate the particle radius in meters ax.set_xlabel(\"Particle radius (m)\")  # Set the y-axis label to indicate the rate of change in concentration, with appropriate units ax.set_ylabel(r\"Rate $\\dfrac{1}{m^{3} s^{1}}$\")  # Use a logarithmic scale for the x-axis to account for the wide range of particle sizes ax.set_xscale(\"log\")  # set title ax.set_title(\"PMF: Coagulation gain, loss, and net rates\")  # Add a legend to identify the gain, loss, and net lines plt.legend()  # Display the plot plt.show() In\u00a0[29]: Copied! <pre># Plot the evolution of particle concentration over time for the lognormal distribution\n\n# Create a figure and axis object for the plot\nfig, ax = plt.subplots(figsize=(8, 6))\n\n# Plot the concentration distribution at each time step\nax.plot(\n    radius_bins,\n    concentration_lognormal_0,\n    label=\"t=0\",\n    linestyle=\"-\",\n    color=\"blue\",\n)\nax.plot(\n    radius_bins,\n    concentration_lognormal_1,\n    label=\"t=1\",\n    linestyle=\"--\",\n    color=\"green\",\n)\nax.plot(\n    radius_bins,\n    concentration_lognormal_2,\n    label=\"t=2\",\n    linestyle=\"-.\",\n    color=\"orange\",\n)\nax.plot(\n    radius_bins,\n    concentration_lognormal_3,\n    label=\"t=3\",\n    linestyle=\":\",\n    color=\"red\",\n)\n\n# Set the x-axis label to indicate the particle radius in meters\nax.set_xlabel(\"Particle radius (m)\")\n\n# Set the y-axis label to indicate the concentration in particles per cubic meter\nax.set_ylabel(r\"Concentration $\\dfrac{1}{m^{3}}$\")\n\n# set title\nax.set_title(\"PMF: Particle concentration evolution over time\")\n\n# Use a logarithmic scale for both the x-axis and y-axis\n# This is essential for visualizing the wide range of particle sizes and concentration changes\nax.set_xscale(\"log\")\n# ax.set_yscale(\"log\")\n\n# Add a legend to differentiate between the time steps\nplt.legend()\n\n# Display the plot\nplt.show()\n</pre> # Plot the evolution of particle concentration over time for the lognormal distribution  # Create a figure and axis object for the plot fig, ax = plt.subplots(figsize=(8, 6))  # Plot the concentration distribution at each time step ax.plot(     radius_bins,     concentration_lognormal_0,     label=\"t=0\",     linestyle=\"-\",     color=\"blue\", ) ax.plot(     radius_bins,     concentration_lognormal_1,     label=\"t=1\",     linestyle=\"--\",     color=\"green\", ) ax.plot(     radius_bins,     concentration_lognormal_2,     label=\"t=2\",     linestyle=\"-.\",     color=\"orange\", ) ax.plot(     radius_bins,     concentration_lognormal_3,     label=\"t=3\",     linestyle=\":\",     color=\"red\", )  # Set the x-axis label to indicate the particle radius in meters ax.set_xlabel(\"Particle radius (m)\")  # Set the y-axis label to indicate the concentration in particles per cubic meter ax.set_ylabel(r\"Concentration $\\dfrac{1}{m^{3}}$\")  # set title ax.set_title(\"PMF: Particle concentration evolution over time\")  # Use a logarithmic scale for both the x-axis and y-axis # This is essential for visualizing the wide range of particle sizes and concentration changes ax.set_xscale(\"log\") # ax.set_yscale(\"log\")  # Add a legend to differentiate between the time steps plt.legend()  # Display the plot plt.show() In\u00a0[30]: Copied! <pre># Summation of PMF distribution\n# Calculate the total concentration of particles at each time step\ntotal_concentration_0 = concentration_lognormal_0.sum()\ntotal_concentration_1 = concentration_lognormal_1.sum()\ntotal_concentration_2 = concentration_lognormal_2.sum()\ntotal_concentration_3 = concentration_lognormal_3.sum()\n\n# Create a figure and axis object for the plot\nfig, ax = plt.subplots(figsize=(8, 6))\n\n# Plot the total concentration at each time step\nax.plot(\n    [\n        total_concentration_0,\n        total_concentration_1,\n        total_concentration_2,\n        total_concentration_3,\n    ],\n    label=\"Total concentration\",\n    marker=\"o\",  # Add markers to indicate each time step\n    linestyle=\"-\",  # Use a solid line to connect the markers\n    color=\"blue\",  # Set the line color to blue\n)\n\n# Set the x-axis label to indicate the time step\nax.set_xlabel(\"Time step\")\n\n# Set the y-axis label to indicate the total concentration in particles per cubic meter\nax.set_ylabel(\"Total concentration $(m^{-3})$\")\nax.set_ylim(bottom=0.84e12)\n\nax.set_title(\"PMF: Total concentration at each time step\")\n\n# Display the plot\nplt.show()\n</pre> # Summation of PMF distribution # Calculate the total concentration of particles at each time step total_concentration_0 = concentration_lognormal_0.sum() total_concentration_1 = concentration_lognormal_1.sum() total_concentration_2 = concentration_lognormal_2.sum() total_concentration_3 = concentration_lognormal_3.sum()  # Create a figure and axis object for the plot fig, ax = plt.subplots(figsize=(8, 6))  # Plot the total concentration at each time step ax.plot(     [         total_concentration_0,         total_concentration_1,         total_concentration_2,         total_concentration_3,     ],     label=\"Total concentration\",     marker=\"o\",  # Add markers to indicate each time step     linestyle=\"-\",  # Use a solid line to connect the markers     color=\"blue\",  # Set the line color to blue )  # Set the x-axis label to indicate the time step ax.set_xlabel(\"Time step\")  # Set the y-axis label to indicate the total concentration in particles per cubic meter ax.set_ylabel(\"Total concentration $(m^{-3})$\") ax.set_ylim(bottom=0.84e12)  ax.set_title(\"PMF: Total concentration at each time step\")  # Display the plot plt.show()"},{"location":"Examples/Dynamics/Coagulation/Functional/Coagulation_Basic_1_PMF/#coagulation-basic-1-pmf-representation","title":"Coagulation Basic 1: PMF Representation\u00b6","text":""},{"location":"Examples/Dynamics/Coagulation/Functional/Coagulation_Basic_1_PMF/#direct-implementation-for-discrete-particle-size-distributions","title":"Direct Implementation for Discrete Particle Size Distributions\u00b6","text":"<p>In this section, we present a direct implementation of the coagulation process based on the methodology outlined in Seinfeld and Pandis (2006). This notebook is designed to provide a clear understanding of the fundamental code required to simulate particle coagulation, without the abstraction layers provided by more advanced object-oriented approaches.</p>"},{"location":"Examples/Dynamics/Coagulation/Functional/Coagulation_Basic_1_PMF/#objective","title":"Objective\u00b6","text":"<p>The primary goal is to demonstrate how to calculate the coagulation kernel and the resulting coagulation rates for a given particle size distribution. We will start with a uniform size bin and distribution to establish the basic principles. Then, we will extend this to a more realistic lognormal distribution, which is commonly observed in aerosol science.</p>"},{"location":"Examples/Dynamics/Coagulation/Functional/Coagulation_Basic_1_PMF/#approach","title":"Approach\u00b6","text":"<ul> <li>Uniform Distribution: We first initialize a simple, uniform particle size distribution. This helps in understanding the basic coagulation mechanics.</li> <li>Lognormal Probability Mass Function: After establishing the basics, we move on to a lognormal size distribution, which better represents real-world aerosol size distributions. Probability mass functions (PMFs) is a bin representation of the lognormal distribution, so the sum of all bins equals total concentration.</li> </ul> <p>This step-by-step approach will provide a foundation for understanding more complex implementations, such as those available in the <code>particula</code> library.</p>"},{"location":"Examples/Dynamics/Coagulation/Functional/Coagulation_Basic_1_PMF/#required-libraries","title":"Required Libraries\u00b6","text":"<p>We will utilize standard scientific libraries such as <code>numpy</code> for numerical computations, <code>matplotlib</code> for plotting, and <code>pandas</code> for data handling. Additionally, we import specific functions from the <code>particula</code> library to calculate the coagulation kernel and generate size distributions.</p>"},{"location":"Examples/Dynamics/Coagulation/Functional/Coagulation_Basic_1_PMF/#creating-a-size-distribution","title":"Creating a Size Distribution\u00b6","text":"<p>In this section, we define the size distribution for aerosol particles. The particle sizes are distributed across several bins, allowing us to model the behavior of particles across a wide size range.</p>"},{"location":"Examples/Dynamics/Coagulation/Functional/Coagulation_Basic_1_PMF/#particle-size-bins","title":"Particle Size Bins\u00b6","text":"<p>We first define the bins for particle radii using a logarithmic scale. The logarithmic scale (<code>np.logspace</code>) is particularly useful when dealing with aerosol particles because their sizes often span several orders of magnitude\u2014from nanometers to micrometers. This approach ensures that we capture the full range of particle sizes with more granularity where it matters.</p> <ul> <li><code>radius_bins</code>: These bins represent the particle radii, ranging from 1 nanometer (1e-9 m) to 10 micrometers (1e-5 m).</li> </ul>"},{"location":"Examples/Dynamics/Coagulation/Functional/Coagulation_Basic_1_PMF/#particle-mass-calculation","title":"Particle Mass Calculation\u00b6","text":"<p>Next, we calculate the mass of particles in each size bin. The mass is determined using the formula for the volume of a sphere (<code>4/3 * \u03c0 * r^3</code>), assuming a uniform particle density of 1 g/cm\u00b3 (which corresponds to 1000 kg/m\u00b3 in SI units).</p> <ul> <li><code>mass_bins</code>: The resulting array contains the masses of particles corresponding to each size bin, which is a key parameter for understanding how these particles will interact and coagulate.</li> </ul> <p>This setup provides a foundation for further analysis of the coagulation process by linking particle size and mass, essential components in determining coagulation rates.</p>"},{"location":"Examples/Dynamics/Coagulation/Functional/Coagulation_Basic_1_PMF/#calculating-the-brownian-coagulation-kernel","title":"Calculating the Brownian Coagulation Kernel\u00b6","text":"<p>In this section, we calculate the Brownian coagulation kernel matrix, which quantifies the rate at which particles of different sizes collide and coagulate due to Brownian motion. The kernel matrix is central to understanding the dynamics of particle coagulation.</p>"},{"location":"Examples/Dynamics/Coagulation/Functional/Coagulation_Basic_1_PMF/#kernel-calculation","title":"Kernel Calculation\u00b6","text":"<p>We use the <code>brownian_coagulation_kernel_via_system_state</code> function from the <code>particula</code> library to compute the kernel matrix. This function requires the following inputs:</p> <ul> <li><code>particle_radius</code>: The array of particle radii, which we previously defined in <code>radius_bins</code>.</li> <li><code>mass_particle</code>: The corresponding array of particle masses from <code>mass_bins</code>.</li> <li><code>temperature</code>: The ambient temperature, set here to 293.15 K (equivalent to 20\u00b0C).</li> <li><code>pressure</code>: The ambient pressure, set to 101325 Pa (standard atmospheric pressure).</li> <li><code>alpha_collision_efficiency</code>: A dimensionless factor representing the efficiency of particle collisions, assumed to be 1.0 for perfect efficiency.</li> </ul> <p>The output is a matrix (kernel) where each element represents the coagulation rate between two specific particle sizes.</p>"},{"location":"Examples/Dynamics/Coagulation/Functional/Coagulation_Basic_1_PMF/#analyzing-the-kernel","title":"Analyzing the Kernel\u00b6","text":"<p>We print the shape of the kernel matrix to verify its dimensions, which should match the number of radius bins (i.e., it will be a square matrix).</p>"},{"location":"Examples/Dynamics/Coagulation/Functional/Coagulation_Basic_1_PMF/#creating-a-dataframe","title":"Creating a DataFrame\u00b6","text":"<p>To facilitate analysis, we convert the kernel matrix into a <code>pandas</code> DataFrame. The DataFrame format allows for easy manipulation and visualization of the data. The rows and columns of the DataFrame are indexed by the particle radii, making it straightforward to identify which particle sizes are interacting.</p> <p>We then print the first five rows of the DataFrame to inspect the calculated values. This provides a quick glimpse into the interaction rates between the smallest particles.</p>"},{"location":"Examples/Dynamics/Coagulation/Functional/Coagulation_Basic_1_PMF/#optional-saving-the-kernel-matrix","title":"Optional: Saving the Kernel Matrix\u00b6","text":"<p>For further analysis or to share with others, the kernel matrix can be saved as a CSV file. This step is optional but useful if you need to persist the results for future work.</p>"},{"location":"Examples/Dynamics/Coagulation/Functional/Coagulation_Basic_1_PMF/#plotting-the-brownian-coagulation-kernel","title":"Plotting the Brownian Coagulation Kernel\u00b6","text":"<p>After calculating the Brownian coagulation kernel, the next step is to visualize the results. A plot of the kernel values against the particle radius provides insights into how the coagulation rates vary with particle size.</p>"},{"location":"Examples/Dynamics/Coagulation/Functional/Coagulation_Basic_1_PMF/#visualization-setup","title":"Visualization Setup\u00b6","text":"<p>We use <code>matplotlib</code> to create the plot:</p> <ul> <li>Figure and Axis: We begin by creating a figure and an axis object using <code>plt.subplots()</code>, which provides a flexible framework for plotting.</li> <li>Kernel Plot: The kernel values are plotted on the y-axis, and the particle radii on the x-axis. Since the kernel values can span several orders of magnitude, we plot their logarithm (base 10) to better visualize the data.</li> </ul>"},{"location":"Examples/Dynamics/Coagulation/Functional/Coagulation_Basic_1_PMF/#axes-configuration","title":"Axes Configuration\u00b6","text":"<ul> <li>X-axis: The x-axis represents the particle radius in meters. Given the wide range of particle sizes, we use a logarithmic scale (<code>set_xscale(\"log\")</code>) to evenly distribute the data across the axis.</li> <li>Y-axis: The y-axis represents the logarithm of the kernel values (<code>Log10(Kernel)</code>). This choice makes it easier to observe trends and differences in the coagulation rates across different particle sizes.</li> </ul>"},{"location":"Examples/Dynamics/Coagulation/Functional/Coagulation_Basic_1_PMF/#optional-y-axis-logarithmic-scale","title":"Optional Y-axis Logarithmic Scale\u00b6","text":"<p>If a deeper examination of the kernel's range is required, the y-axis can also be set to a logarithmic scale by uncommenting the <code>ax.set_yscale(\"log\")</code> line. This is useful when the kernel values span several orders of magnitude and need to be visualized more clearly.</p>"},{"location":"Examples/Dynamics/Coagulation/Functional/Coagulation_Basic_1_PMF/#adding-particle-concentrations","title":"Adding Particle Concentrations\u00b6","text":"<p>Now that we have calculated the Brownian coagulation kernel, the next step is to introduce the particle concentrations. While the coagulation kernel itself does not depend on the particle concentration, the concentrations are critical when calculating the actual rate of coagulation, as they determine how many particles are available to interact.</p>"},{"location":"Examples/Dynamics/Coagulation/Functional/Coagulation_Basic_1_PMF/#initial-concentration-setup","title":"Initial Concentration Setup\u00b6","text":"<p>We define an initial particle concentration for each size bin:</p> <ul> <li>Uniform Concentration: In this example, we set a uniform concentration across all size bins. Specifically, we assign a concentration of 100 particles per cubic centimeter (100 cm^-3), which converts to 100 million particles per cubic meter (100 * 1e6 m^-3). This concentration is representative of a typical ambient particle concentration in the atmosphere.</li> </ul>"},{"location":"Examples/Dynamics/Coagulation/Functional/Coagulation_Basic_1_PMF/#visualization-of-the-initial-concentration","title":"Visualization of the Initial Concentration\u00b6","text":"<p>To better understand the initial distribution of particle concentrations, we plot these values against the particle radius:</p> <ul> <li>X-axis: The x-axis represents the particle radius in meters, using a logarithmic scale to cover the wide range of particle sizes.</li> <li>Y-axis: The y-axis shows the particle concentration in particles per cubic meter (m^-3), also plotted on a logarithmic scale. The logarithmic scales on both axes allow us to clearly see the distribution across several orders of magnitude, which is common in aerosol science.</li> </ul>"},{"location":"Examples/Dynamics/Coagulation/Functional/Coagulation_Basic_1_PMF/#importance-of-concentration","title":"Importance of Concentration\u00b6","text":"<p>While the kernel function determines the rate at which particles of different sizes</p>"},{"location":"Examples/Dynamics/Coagulation/Functional/Coagulation_Basic_1_PMF/#coagulation-rate-calculation","title":"Coagulation Rate Calculation\u00b6","text":"<p>With the coagulation kernel and initial concentrations defined, we can now calculate the rates at which particles are gained, lost, and the net change due to coagulation. These rates are essential for understanding how the particle size distribution evolves over time as particles collide and coagulate.</p>"},{"location":"Examples/Dynamics/Coagulation/Functional/Coagulation_Basic_1_PMF/#gain-loss-and-net-rate-calculation","title":"Gain, Loss, and Net Rate Calculation\u00b6","text":"<ul> <li><p>Gain (<code>discrete_gain</code>): This function calculates the rate at which particles are gained in each size bin due to coagulation. Gain occurs when two smaller particles collide to form a larger particle, increasing the concentration in the corresponding size bin.</p> </li> <li><p>Loss (<code>discrete_loss</code>): This function calculates the rate at which particles are lost from each size bin due to coagulation. Loss happens when particles in a particular size bin collide with other particles, thereby decreasing the concentration in that bin.</p> </li> <li><p>Net Rate: The net rate is the difference between the gain and loss for each size bin (<code>net_0 = gain_0 - loss_0</code>). It represents the overall change in concentration for each particle size due to coagulation.</p> </li> </ul>"},{"location":"Examples/Dynamics/Coagulation/Functional/Coagulation_Basic_1_PMF/#displaying-results","title":"Displaying Results\u00b6","text":"<p>We create a <code>pandas</code> DataFrame to organize and display the gain, loss, and net coagulation rates for each particle size bin. The DataFrame is indexed by particle radius, which makes it easy to understand the changes in concentration across different sizes.</p> <ul> <li>Gain: The rate at which particles are added to each bin due to coagulation.</li> <li>Loss: The rate at which particles are removed from each bin due to coagulation.</li> <li>Net: The overall change in concentration for each bin.</li> </ul> <p>Finally, we display the first five rows of the DataFrame to inspect the initial values for gain, loss, and net change. This provides a quick look at how coagulation is expected to alter the particle size distribution in the system.</p> <p>By analyzing these rates, we can predict the dynamic behavior of the aerosol particles over time, as smaller particles merge to form larger ones or disappear from the system.</p>"},{"location":"Examples/Dynamics/Coagulation/Functional/Coagulation_Basic_1_PMF/#plotting-the-coagulation-gain-loss-and-net-rates","title":"Plotting the Coagulation Gain, Loss, and Net Rates\u00b6","text":"<p>After calculating the coagulation rates, it's crucial to visualize how these rates vary across different particle sizes. This plot will show the gain, loss, and net rates of particle concentration as a function of particle radius.</p>"},{"location":"Examples/Dynamics/Coagulation/Functional/Coagulation_Basic_1_PMF/#plot-details","title":"Plot Details\u00b6","text":"<ul> <li>Net Rate: The net rate of change in particle concentration is plotted as a thick gray line. This line highlights the overall effect of coagulation, showing whether the concentration in each size bin is increasing or decreasing.</li> <li>Gain Rate: The gain rate is plotted in dark green. This line shows how particles are being added to each size bin as smaller particles coagulate to form larger ones.</li> <li>Loss Rate: The loss rate is plotted in red. To make it visually distinct and indicate that it's a removal process, the loss rate is plotted as <code>-1 * loss_0</code>. This negative value reflects the decrease in particle concentration due to coagulation.</li> </ul>"},{"location":"Examples/Dynamics/Coagulation/Functional/Coagulation_Basic_1_PMF/#axes-configuration","title":"Axes Configuration\u00b6","text":"<ul> <li><p>X-axis: The x-axis represents the particle radius in meters, plotted on a logarithmic scale. This scale is essential for accurately representing the wide range of particle sizes, from nanometers to micrometers.</p> </li> <li><p>Y-axis: The y-axis shows the rate of change in concentration, with units of <code>m\u207b\u00b3 s\u207b\u00b9</code>, indicating how quickly particles are being gained, lost, or changing net concentration in the system.</p> </li> </ul>"},{"location":"Examples/Dynamics/Coagulation/Functional/Coagulation_Basic_1_PMF/#interpretation","title":"Interpretation\u00b6","text":"<p>By analyzing this plot, you can determine which particle sizes are most affected by coagulation. For instance, sizes where the net rate is positive indicate that coagulation is leading to an increase in concentration, while negative values suggest a decrease. This visualization is crucial for understanding the evolution of the particle size distribution over time.</p>"},{"location":"Examples/Dynamics/Coagulation/Functional/Coagulation_Basic_1_PMF/#simulating-the-coagulation-process-over-time","title":"Simulating the Coagulation Process Over Time\u00b6","text":"<p>In this section, we manually simulate the coagulation process over a few discrete time steps. This manual simulation allows us to observe how particle concentrations evolve as a result of coagulation.</p>"},{"location":"Examples/Dynamics/Coagulation/Functional/Coagulation_Basic_1_PMF/#simulation-setup","title":"Simulation Setup\u00b6","text":"<ul> <li>Time Step: We define a time step of 0.1 seconds (<code>TIME_STEP = 0.1</code>). This value represents the interval at which we update the particle concentrations based on the coagulation rates.</li> </ul>"},{"location":"Examples/Dynamics/Coagulation/Functional/Coagulation_Basic_1_PMF/#time-step-1","title":"Time Step 1\u00b6","text":"<ol> <li>Calculate Gain and Loss: Using the initial concentration (<code>concentration_0</code>), we calculate the gain and loss rates using the coagulation kernel.</li> <li>Net Rate: The net rate of change in concentration is determined by subtracting the loss from the gain.</li> <li>Update Concentration: The concentration is updated by adding the net rate multiplied by the time step to the initial concentration, resulting in <code>concentration_1</code>.</li> </ol>"},{"location":"Examples/Dynamics/Coagulation/Functional/Coagulation_Basic_1_PMF/#time-step-2","title":"Time Step 2\u00b6","text":"<ol> <li>Recalculate Gain and Loss: With the updated concentration from time step 1 (<code>concentration_1</code>), we recalculate the gain and loss rates.</li> <li>Net Rate: Again, we calculate the net rate of change.</li> <li>Update Concentration: The concentration is updated to <code>concentration_2</code> using the same method as in time step 1.</li> </ol>"},{"location":"Examples/Dynamics/Coagulation/Functional/Coagulation_Basic_1_PMF/#time-step-3","title":"Time Step 3\u00b6","text":"<ol> <li>Recalculate Gain and Loss: We perform the same calculations with the concentration from time step 2 (<code>concentration_2</code>).</li> <li>Update Concentration: The concentration is updated to <code>concentration_3</code>.</li> </ol>"},{"location":"Examples/Dynamics/Coagulation/Functional/Coagulation_Basic_1_PMF/#observing-changes","title":"Observing Changes\u00b6","text":"<p>We print the maximum concentration at each time step to observe how the distribution evolves due to coagulation. This can provide insights into how quickly particles are coalescing into larger sizes or being depleted.</p>"},{"location":"Examples/Dynamics/Coagulation/Functional/Coagulation_Basic_1_PMF/#dataframe-creation","title":"DataFrame Creation\u00b6","text":"<p>The concentrations at each time step are combined into a <code>pandas</code> DataFrame, making it easier to compare how the distribution changes over time. We display the first few rows to inspect these changes.</p>"},{"location":"Examples/Dynamics/Coagulation/Functional/Coagulation_Basic_1_PMF/#optional-saving-results","title":"Optional: Saving Results\u00b6","text":"<p>The concentration data can be saved to a CSV file for further analysis or visualization, allowing you to track the evolution of particle concentrations over time.</p>"},{"location":"Examples/Dynamics/Coagulation/Functional/Coagulation_Basic_1_PMF/#interpretation","title":"Interpretation\u00b6","text":"<p>By manually simulating the coagulation process, we can see the step-by-step changes in particle concentrations. This approach highlights the dynamic nature of coagulation and how it impacts particle size distributions in aerosols over time.</p>"},{"location":"Examples/Dynamics/Coagulation/Functional/Coagulation_Basic_1_PMF/#plotting-the-evolution-of-particle-concentration","title":"Plotting the Evolution of Particle Concentration\u00b6","text":"<p>To visualize how particle concentrations evolve over time due to coagulation, we plot the concentration distributions at different time steps. This allows us to observe the changes in particle size distribution as the coagulation process progresses.</p>"},{"location":"Examples/Dynamics/Coagulation/Functional/Coagulation_Basic_1_PMF/#plot-details","title":"Plot Details\u00b6","text":"<ul> <li><p>Time Step 0 (<code>t=0</code>): The initial concentration distribution is plotted as a solid blue line. This serves as the baseline before any coagulation has occurred.</p> </li> <li><p>Time Step 1 (<code>t=1</code>): After the first time step, the concentration distribution is plotted as a dashed green line. This shows the immediate effect of coagulation on the particle distribution.</p> </li> <li><p>Time Step 2 (<code>t=2</code>): The concentration distribution at the second time step is plotted as a dash-dot orange line. By this point, we can begin to see more noticeable changes as particles coagulate.</p> </li> <li><p>Time Step 3 (<code>t=3</code>): Finally, the concentration distribution after the third time step is plotted as a dotted red line, illustrating further evolution of the particle sizes as the coagulation process continues.</p> </li> </ul>"},{"location":"Examples/Dynamics/Coagulation/Functional/Coagulation_Basic_1_PMF/#axes-configuration","title":"Axes Configuration\u00b6","text":"<ul> <li><p>X-axis: The x-axis represents the particle radius in meters, and is plotted on a logarithmic scale to capture the wide range of particle sizes.</p> </li> <li><p>Y-axis: The y-axis shows the concentration in particles per cubic meter (m\u207b\u00b3), also on a logarithmic scale to reflect the changes in concentration across orders of magnitude.</p> </li> </ul>"},{"location":"Examples/Dynamics/Coagulation/Functional/Coagulation_Basic_1_PMF/#interpretation","title":"Interpretation\u00b6","text":"<p>As expected, smaller particles tend to coagulate into larger sizes, leading to changes in the overall distribution. This plot provides a visual representation of the dynamic nature of coagulation, making it easier to understand how particle populations evolve in an aerosol system.</p> <p>The plot provides a visual representation of the dynamic nature of coagulation, making it easier to understand how particle populations evolve in an aerosol system.</p>"},{"location":"Examples/Dynamics/Coagulation/Functional/Coagulation_Basic_1_PMF/#end-member-error","title":"End member Error\u00b6","text":"<p>Due to the underlying numerical integration assumptions, a flat distribution is not treated correctly at the largest sizes. But in real-world cases where the distribution is not flat, this error is not significant.</p>"},{"location":"Examples/Dynamics/Coagulation/Functional/Coagulation_Basic_1_PMF/#lognormal-distribution","title":"Lognormal Distribution\u00b6","text":"<p>In this section, we will implement the coagulation process for a lognormal particle size distribution. A lognormal distribution is more representative of real-world aerosol systems, where particles are not uniformly distributed in size but instead follow a distribution where most particles are centered around a particular size with fewer particles in the smaller and larger size ranges.</p>"},{"location":"Examples/Dynamics/Coagulation/Functional/Coagulation_Basic_1_PMF/#why-lognormal-distribution","title":"Why Lognormal Distribution?\u00b6","text":"<p>A lognormal distribution is often observed in natural aerosol populations due to the multiplicative processes that govern particle formation and growth. This distribution is characterized by a peak (or mode) at the most common particle size, with the number of particles decreasing logarithmically for sizes smaller and larger than the mode. Implementing coagulation for this distribution will provide a more realistic simulation of how aerosol particles behave in the atmosphere.</p> <p>We will proceed by defining the lognormal size distribution, calculating the coagulation kernel, and then simulating the coagulation process over time, similar to what we did for the uniform distribution. This approach will allow us to compare the results between the uniform and lognormal distributions, highlighting the differences in coagulation dynamics based on initial particle size distributions.</p>"},{"location":"Examples/Dynamics/Coagulation/Functional/Coagulation_Basic_1_PMF/#defining-the-radius-and-mass-bins","title":"Defining the Radius and Mass Bins\u00b6","text":"<ul> <li>Radius Bins: We define the particle radius bins on a logarithmic scale ranging from 1 nanometer (1e-9 m) to 10 micrometers (1e-4 m). Using 250 bins ensures a fine resolution across this range, which is important for accurately representing the lognormal distribution.</li> </ul>"},{"location":"Examples/Dynamics/Coagulation/Functional/Coagulation_Basic_1_PMF/#generating-the-lognormal-distribution","title":"Generating the Lognormal Distribution\u00b6","text":"<ul> <li>Lognormal Distribution: We generate the particle concentration using a lognormal distribution, which is characterized by:<ul> <li>A mode (most probable size) of 100 nanometers (100 nm).</li> <li>A geometric standard deviation of 1.4, which controls the spread of the distribution.</li> <li>A total number concentration of 10000 particles per cubic centimeter (10000 cm\u207b\u00b3), converted to particles per cubic meter for consistency with our units.</li> </ul> </li> </ul>"},{"location":"Examples/Dynamics/Coagulation/Functional/Coagulation_Basic_1_PMF/#plotting-the-lognormal-distribution","title":"Plotting the Lognormal Distribution\u00b6","text":"<p>The resulting lognormal distribution is plotted with particle radius on the x-axis (logarithmic scale) and particle concentration on the y-axis. This plot visually demonstrates the lognormal distribution, showing a peak around the mode (100 nm) with concentrations decreasing for both smaller and larger particles.</p> <p>This setup provides a more realistic starting point for simulating the coagulation process in an aerosol system.</p>"},{"location":"Examples/Dynamics/Coagulation/Functional/Coagulation_Basic_1_PMF/#simulating-the-coagulation-process-for-a-lognormal-distribution","title":"Simulating the Coagulation Process for a Lognormal Distribution\u00b6","text":"<p>Having established a lognormal particle size distribution, we now proceed to simulate the coagulation process over time. This simulation will show how the distribution evolves as particles coagulate and form larger particles.</p>"},{"location":"Examples/Dynamics/Coagulation/Functional/Coagulation_Basic_1_PMF/#simulation-setup","title":"Simulation Setup\u00b6","text":"<ul> <li><p>Time Step: We set a time step of 100 seconds (<code>TIME_STEP = 100</code>). This interval determines how frequently the particle concentrations are updated based on the calculated coagulation rates.</p> </li> <li><p>Coagulation Kernel: The coagulation kernel is calculated using the same parameters as before (temperature, pressure, and perfect collision efficiency). The kernel remains constant throughout the simulation as it only depends on the physical properties of the particles and the environment.</p> </li> </ul>"},{"location":"Examples/Dynamics/Coagulation/Functional/Coagulation_Basic_1_PMF/#time-step-calculations","title":"Time Step Calculations\u00b6","text":"<p>For each time step, we calculate the gain, loss, and net change in particle concentration:</p> <ol> <li><p>Time Step 1:</p> <ul> <li>Calculate the gain and loss rates for the initial concentration (<code>concentration_lognormal_0</code>).</li> <li>Update the concentration to <code>concentration_lognormal_1</code> by applying the net rate of change. Any negative concentrations resulting from numerical errors are set to zero.</li> </ul> </li> <li><p>Time Step 2:</p> <ul> <li>Recalculate the gain and loss rates based on <code>concentration_lognormal_1</code>.</li> <li>Update the concentration to <code>concentration_lognormal_2</code> and ensure no negative values.</li> </ul> </li> <li><p>Time Step 3:</p> <ul> <li>Recalculate the rates again based on <code>concentration_lognormal_2</code>.</li> <li>Update the concentration to <code>concentration_lognormal_3</code>, correcting any negative values.</li> </ul> </li> </ol>"},{"location":"Examples/Dynamics/Coagulation/Functional/Coagulation_Basic_1_PMF/#combining-results","title":"Combining Results\u00b6","text":"<p>The concentrations at each time step are combined into a <code>pandas</code> DataFrame. This structure allows for easy comparison of how the particle size distribution changes over time due to coagulation.</p>"},{"location":"Examples/Dynamics/Coagulation/Functional/Coagulation_Basic_1_PMF/#optional-saving-results","title":"Optional: Saving Results\u00b6","text":"<p>The resulting concentration data can be saved to a CSV file for further analysis or visualization. This step is optional but useful for documenting the evolution of the lognormal distribution over time.</p>"},{"location":"Examples/Dynamics/Coagulation/Functional/Coagulation_Basic_1_PMF/#interpretation","title":"Interpretation\u00b6","text":"<p>By simulating the coagulation process for a lognormal distribution, we can observe how initially peaked distributions broaden and shift as particles merge. The correction for negative concentrations ensures that the physical constraints of the system (i.e., non-negative particle counts) are respected throughout the simulation.</p>"},{"location":"Examples/Dynamics/Coagulation/Functional/Coagulation_Basic_1_PMF/#analyzing-concentration-extremes-over-time","title":"Analyzing Concentration Extremes Over Time\u00b6","text":"<p>To gain insights into how the particle concentrations evolve during the coagulation process, it's important to track the maximum and minimum concentrations at each time step. These values can provide valuable information about the stability and dynamics of the particle distribution.</p>"},{"location":"Examples/Dynamics/Coagulation/Functional/Coagulation_Basic_1_PMF/#concentration-extremes","title":"Concentration Extremes\u00b6","text":"<p>We print the maximum and minimum concentrations for each time step:</p> <ul> <li><p>Time Step 0 (<code>t=0</code>):</p> <ul> <li>Max Concentration: This represents the highest concentration of particles at the initial distribution.</li> <li>Min Concentration: This represents the lowest concentration at the initial distribution.</li> </ul> </li> <li><p>Time Step 1 (<code>t=1</code>):</p> <ul> <li>Max Concentration: After the first time step, we observe the highest concentration to see how it compares with the initial state.</li> <li>Min Concentration: Similarly, the lowest concentration is noted, which may indicate the depletion of certain particle sizes.</li> </ul> </li> <li><p>Time Step 2 (<code>t=2</code>):</p> <ul> <li>Max Concentration: As the simulation progresses, the peak concentration may shift due to ongoing coagulation.</li> <li>Min Concentration: Continued tracking of the minimum concentration helps in understanding the impact of coagulation on smaller particle sizes.</li> </ul> </li> <li><p>Time Step 3 (<code>t=3</code>):</p> <ul> <li>Max Concentration: The final maximum concentration provides an overview of how the distribution has evolved.</li> <li>Min Concentration: The minimum concentration may highlight which particle sizes have been most affected by coagulation.</li> </ul> </li> </ul>"},{"location":"Examples/Dynamics/Coagulation/Functional/Coagulation_Basic_1_PMF/#interpretation","title":"Interpretation\u00b6","text":"<p>By examining these extremes, we can infer the following:</p> <ul> <li><p>Max Concentration: Changes in the maximum concentration over time can indicate the formation of larger particles as smaller ones coagulate. A decrease in max concentration suggests that the most abundant particle size at earlier steps is merging with others, leading to a broader or shifted distribution.</p> </li> <li><p>Min Concentration: The minimum concentration helps identify whether certain particle sizes are becoming scarce due to coagulation, which may cause those bins to empty out or reduce significantly.</p> </li> </ul> <p>This analysis is crucial for understanding the dynamic behavior of the particle size distribution under coagulation and for ensuring that the simulation reflects realistic physical constraints.</p>"},{"location":"Examples/Dynamics/Coagulation/Functional/Coagulation_Basic_1_PMF/#plotting-the-coagulation-gain-loss-and-net-rates-for-lognormal-distribution","title":"Plotting the Coagulation Gain, Loss, and Net Rates for Lognormal Distribution\u00b6","text":"<p>To visualize the dynamics of coagulation for a lognormal particle size distribution, we plot the rates of gain, loss, and net change in concentration across the range of particle sizes. This plot provides insights into how particles are interacting during the coagulation process.</p>"},{"location":"Examples/Dynamics/Coagulation/Functional/Coagulation_Basic_1_PMF/#plot-details","title":"Plot Details\u00b6","text":"<ul> <li><p>Net Rate: The net rate of change in particle concentration is plotted as a thick gray line. This line represents the overall effect of coagulation, indicating whether the concentration in each size bin is increasing or decreasing.</p> </li> <li><p>Gain Rate: The gain rate, plotted in dark green, shows how particles are being added to each size bin as smaller particles coagulate to form larger ones. This rate reflects the accumulation of particles in specific size bins.</p> </li> <li><p>Loss Rate: The loss rate is plotted in red, with the values multiplied by -1 to indicate that it represents a reduction in particle concentration. This line shows how particles are being depleted from each size bin due to coagulation.</p> </li> </ul>"},{"location":"Examples/Dynamics/Coagulation/Functional/Coagulation_Basic_1_PMF/#axes-configuration","title":"Axes Configuration\u00b6","text":"<ul> <li><p>X-axis: The x-axis represents the particle radius in meters, plotted on a logarithmic scale to capture the wide range of particle sizes present in the distribution.</p> </li> <li><p>Y-axis: The y-axis shows the rate of change in concentration in units of particles per cubic meter per second ($\\dfrac{1}{m^{3} s^{1}}$), providing a clear view of how rapidly particles are being gained, lost, or changing net concentration in the system.</p> </li> </ul>"},{"location":"Examples/Dynamics/Coagulation/Functional/Coagulation_Basic_1_PMF/#legend-and-interpretation","title":"Legend and Interpretation\u00b6","text":"<p>A legend is included to clearly differentiate between the net, gain, and loss lines on the plot. By analyzing these rates, we can determine the most active particle sizes in the coagulation process:</p> <ul> <li>Positive Net Rate: Indicates that the particle size bin is gaining particles, likely due to the aggregation of smaller particles.</li> <li>Negative Net Rate: Indicates that the particle size bin is losing particles, either because they are merging into larger particles or being depleted through other processes.</li> </ul> <p>This plot is essential for understanding the detailed behavior of the particle size distribution during coagulation, highlighting which sizes are most affected by the process.</p>"},{"location":"Examples/Dynamics/Coagulation/Functional/Coagulation_Basic_1_PMF/#plotting-the-evolution-of-concentration-for-lognormal-distribution","title":"Plotting the Evolution of Concentration for Lognormal Distribution\u00b6","text":"<p>After simulating the coagulation process over several time steps, it is important to visualize how the particle concentration evolves. This plot shows the concentration distribution at different time steps, allowing us to observe the changes in the lognormal distribution as coagulation progresses.</p>"},{"location":"Examples/Dynamics/Coagulation/Functional/Coagulation_Basic_1_PMF/#plot-details","title":"Plot Details\u00b6","text":"<ul> <li><p>Time Step 0 (<code>t=0</code>): The initial concentration distribution is plotted as a solid blue line. This represents the starting point of the simulation, with a lognormal distribution centered around the mode.</p> </li> <li><p>Time Step 1 (<code>t=1</code>): After the first time step, the concentration distribution is plotted as a dashed green line. This line shows the immediate impact of coagulation on the particle sizes.</p> </li> <li><p>Time Step 2 (<code>t=2</code>): The concentration distribution at the second time step is plotted as a dash-dot orange line. By this time, noticeable shifts in the distribution may start to appear as particles coagulate.</p> </li> <li><p>Time Step 3 (<code>t=3</code>): Finally, the concentration distribution after the third time step is plotted as a dotted red line. This line illustrates further evolution of the distribution, highlighting the ongoing effects of coagulation.</p> </li> </ul>"},{"location":"Examples/Dynamics/Coagulation/Functional/Coagulation_Basic_1_PMF/#axes-configuration","title":"Axes Configuration\u00b6","text":"<ul> <li><p>X-axis: The x-axis represents the particle radius in meters, plotted on a logarithmic scale to cover the wide range of particle sizes in the lognormal distribution.</p> </li> <li><p>Y-axis: The y-axis shows the concentration in particles per cubic meter (m\u207b\u00b3), also plotted on a logarithmic scale to reflect the broad range of concentrations.</p> </li> </ul>"},{"location":"Examples/Dynamics/Coagulation/Functional/Coagulation_Basic_1_PMF/#interpretation","title":"Interpretation\u00b6","text":"<p>By comparing the concentration distributions at different time steps, you can observe how the lognormal distribution shifts and broadens as particles coagulate. Typically, the concentration of smaller particles decreases over time as they merge to form larger particles, leading to an increase in the concentration of larger particles. This visualization provides a clear, temporal view of the coagulation process and its effects on the particle size distribution.</p> <p>This plot is crucial for understanding the dynamic evolution of aerosol particles under coagulation, particularly when starting with a realistic lognormal distribution.</p>"},{"location":"Examples/Dynamics/Coagulation/Functional/Coagulation_Basic_1_PMF/#total-concentration-over-time","title":"Total Concentration Over Time\u00b6","text":"<p>To understand the overall impact of coagulation on the particle population, it is essential to track the total concentration of particles over time. This plot shows how the total concentration changes as particles coagulate and form larger sizes.</p>"},{"location":"Examples/Dynamics/Coagulation/Functional/Coagulation_Basic_1_PMF/#summary","title":"Summary\u00b6","text":"<p>In this notebook, we explored the process of particle coagulation in aerosols, focusing on both uniform and lognormal particle size distributions. The notebook provided a step-by-step implementation of the coagulation process, highlighting key concepts and calculations necessary to simulate the dynamic behavior of aerosol particles over time.</p>"},{"location":"Examples/Dynamics/Coagulation/Functional/Coagulation_Basic_1_PMF/#key-steps-and-findings","title":"Key Steps and Findings:\u00b6","text":"<ol> <li><p>Coagulation Basics:</p> <ul> <li>We began with a uniform particle size distribution to introduce the fundamental concepts of coagulation, including the calculation of the Brownian coagulation kernel and the rates of particle gain, loss, and net change.</li> <li>The initial uniform distribution allowed us to understand the basic mechanics of how particles interact and merge over time.</li> </ul> </li> <li><p>Transition to Lognormal Distribution:</p> <ul> <li>We then shifted to a more realistic lognormal particle size distribution, which better represents real-world aerosol systems. This distribution was characterized by a mode (most probable particle size), a geometric standard deviation, and a total number concentration.</li> <li>The coagulation process was simulated for this lognormal distribution, with the particle concentrations updated over several discrete time steps.</li> </ul> </li> <li><p>Simulation and Visualization:</p> <ul> <li>The evolution of the particle size distribution was tracked over time, with plots showing the changes in concentration for different particle sizes. These plots illustrated how smaller particles gradually merge to form larger ones, leading to a shift and broadening of the distribution.</li> <li>The rates of particle gain, loss, and net change were also visualized, providing insights into the most active particle sizes during the coagulation process.</li> </ul> </li> <li><p>Key Insights:</p> <ul> <li>The notebook demonstrated that coagulation leads to a decrease in the number concentration of smaller particles as they coalesce to form larger particles. This results in a broader size distribution with fewer small particles and an increased concentration of larger particles.</li> <li>The lognormal distribution, due to its realistic representation of aerosol particles, showed more complex dynamics compared to the uniform distribution, emphasizing the importance of starting with an appropriate initial distribution in simulations.</li> </ul> </li> </ol>"},{"location":"Examples/Dynamics/Coagulation/Functional/Coagulation_Basic_1_PMF/#conclusion","title":"Conclusion:\u00b6","text":"<p>This notebook provided a guide to simulating the coagulation process in aerosol particles, from basic principles to more advanced applications involving realistic size distributions. By comparing the results from uniform and lognormal distributions, we gained a deeper understanding of how particle populations evolve under coagulation, highlighting the critical role of particle size distribution in aerosol dynamics. The methods and visualizations presented here can be extended to further study and analyze aerosol behavior in various environmental and industrial contexts.</p>"},{"location":"Examples/Dynamics/Coagulation/Functional/Coagulation_Basic_2_PDF/","title":"Coagulation Basics 2: PDF Representation","text":"In\u00a0[\u00a0]: Copied! <pre># In Colab uncomment the following command to install particula:\n#!pip install particula[extra] --quiet\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nfrom scipy.integrate import trapezoid\n\n# particula imports\nimport particula as par\n</pre> # In Colab uncomment the following command to install particula: #!pip install particula[extra] --quiet import numpy as np import matplotlib.pyplot as plt import pandas as pd from scipy.integrate import trapezoid  # particula imports import particula as par In\u00a0[2]: Copied! <pre># Create fine-scale radius bins on a logarithmic scale from 1 nm to 10 \u03bcm\nradius_bins = np.logspace(start=-9, stop=-4, num=500)  # m (1 nm to 10 \u03bcm)\n\n# Calculate the mass for each particle size bin assuming a density of 1 g/cm\u00b3 (1000 kg/m\u00b3)\nmass_bins = 4 / 3 * np.pi * radius_bins**3 * 1e3  # kg\n</pre> # Create fine-scale radius bins on a logarithmic scale from 1 nm to 10 \u03bcm radius_bins = np.logspace(start=-9, stop=-4, num=500)  # m (1 nm to 10 \u03bcm)  # Calculate the mass for each particle size bin assuming a density of 1 g/cm\u00b3 (1000 kg/m\u00b3) mass_bins = 4 / 3 * np.pi * radius_bins**3 * 1e3  # kg In\u00a0[\u00a0]: Copied! <pre># The Brownian coagulation kernel is calculated using the `brownian_coagulation_kernel_via_system_state` function.\n# This function takes into account particle size, mass, temperature, pressure, and collision efficiency\n# to compute the coagulation rates between particles of different sizes.\nkernel = par.dynamics.get_brownian_kernel_via_system_state(\n    particle_radius=radius_bins,\n    particle_mass=mass_bins,\n    temperature=293.15,  # Temperature in Kelvin (20\u00b0C)\n    pressure=101325,  # Pressure in Pascals (1 atm)\n    alpha_collision_efficiency=1.0,  # Assume perfect collision efficiency\n)\n\n# Display the shape of the kernel matrix to confirm its dimensions\nprint(f\"Kernel shape: {kernel.shape}\")\n\n# Create a pandas DataFrame from the kernel matrix\n# The DataFrame allows for easier analysis and visualization of the coagulation kernel.\n# Rows and columns are indexed by the particle radius bins, making it clear which sizes are interacting.\ndf_kernel = pd.DataFrame(kernel, index=radius_bins, columns=radius_bins)\n\n# Print the first 5 rows of the DataFrame to inspect the computed kernel values\ndf_kernel.head(5)\n\n# Optional: Save the kernel matrix to a CSV file for further analysis or sharing\n# df_kernel.to_csv(\"kernel.csv\")\n</pre> # The Brownian coagulation kernel is calculated using the `brownian_coagulation_kernel_via_system_state` function. # This function takes into account particle size, mass, temperature, pressure, and collision efficiency # to compute the coagulation rates between particles of different sizes. kernel = par.dynamics.get_brownian_kernel_via_system_state(     particle_radius=radius_bins,     particle_mass=mass_bins,     temperature=293.15,  # Temperature in Kelvin (20\u00b0C)     pressure=101325,  # Pressure in Pascals (1 atm)     alpha_collision_efficiency=1.0,  # Assume perfect collision efficiency )  # Display the shape of the kernel matrix to confirm its dimensions print(f\"Kernel shape: {kernel.shape}\")  # Create a pandas DataFrame from the kernel matrix # The DataFrame allows for easier analysis and visualization of the coagulation kernel. # Rows and columns are indexed by the particle radius bins, making it clear which sizes are interacting. df_kernel = pd.DataFrame(kernel, index=radius_bins, columns=radius_bins)  # Print the first 5 rows of the DataFrame to inspect the computed kernel values df_kernel.head(5)  # Optional: Save the kernel matrix to a CSV file for further analysis or sharing # df_kernel.to_csv(\"kernel.csv\") <pre>Kernel shape: (500, 500)\n</pre> Out[\u00a0]: 1.000000e-09 1.023340e-09 1.047225e-09 1.071668e-09 1.096681e-09 1.122277e-09 1.148472e-09 1.175277e-09 1.202708e-09 1.230780e-09 ... 8.124930e-05 8.314568e-05 8.508632e-05 8.707225e-05 8.910453e-05 9.118425e-05 9.331251e-05 9.549045e-05 9.771921e-05 1.000000e-04 1.000000e-09 8.812734e-16 8.867456e-16 8.930227e-16 9.001194e-16 9.080509e-16 9.168335e-16 9.264845e-16 9.370220e-16 9.484651e-16 9.608340e-16 ... 1.310366e-09 1.340961e-09 1.372270e-09 1.404310e-09 1.437098e-09 1.470650e-09 1.504986e-09 1.540123e-09 1.576080e-09 1.612876e-09 1.023340e-09 8.867456e-16 8.914801e-16 8.970151e-16 9.033642e-16 9.105423e-16 9.185649e-16 9.274485e-16 9.372104e-16 9.478690e-16 9.594436e-16 ... 1.251439e-09 1.280658e-09 1.310559e-09 1.341157e-09 1.372470e-09 1.404514e-09 1.437305e-09 1.470862e-09 1.505201e-09 1.540342e-09 1.047225e-09 8.930227e-16 8.970151e-16 9.018038e-16 9.074021e-16 9.138240e-16 9.210845e-16 9.291991e-16 9.381847e-16 9.480587e-16 9.588397e-16 ... 1.195165e-09 1.223070e-09 1.251626e-09 1.280848e-09 1.310753e-09 1.341355e-09 1.372672e-09 1.404719e-09 1.437514e-09 1.471075e-09 1.071668e-09 9.001194e-16 9.033642e-16 9.074021e-16 9.122455e-16 9.179079e-16 9.244034e-16 9.317470e-16 9.399548e-16 9.490434e-16 9.590307e-16 ... 1.141425e-09 1.168075e-09 1.195346e-09 1.223255e-09 1.251814e-09 1.281041e-09 1.310949e-09 1.341555e-09 1.372875e-09 1.404926e-09 1.096681e-09 9.080509e-16 9.105423e-16 9.138240e-16 9.179079e-16 9.228066e-16 9.285337e-16 9.351036e-16 9.425313e-16 9.508330e-16 9.600258e-16 ... 1.090104e-09 1.115556e-09 1.141601e-09 1.168254e-09 1.195530e-09 1.223442e-09 1.252005e-09 1.281235e-09 1.311147e-09 1.341756e-09 <p>5 rows \u00d7 500 columns</p> In\u00a0[5]: Copied! <pre># Generate a lognormal particle size distribution\n# This distribution is characterized by a mode (most probable size) of 100 nm,\n# a geometric standard deviation of 1.4, and a total number concentration of 1e6 particles per cm^3.\nconcentration_lognormal_0 = par.particles.get_lognormal_pdf_distribution(\n    x_values=radius_bins,\n    mode=np.array(100e-9),  # Mode of the distribution (100 nm)\n    geometric_standard_deviation=np.array(1.4),  # Geometric standard deviation\n    number_of_particles=np.array(\n        1e6 * 1e6\n    ),  # Total concentration (1e6 cm^-3 converted to m^-3)\n)\n\n# Plot the lognormal concentration distribution\nfig, ax = plt.subplots(figsize=(8, 6))\nax.plot(radius_bins, concentration_lognormal_0)\n\n# Set the x-axis to a logarithmic scale to capture the wide range of particle sizes\nax.set_xlabel(\"Particle radius (m)\")\n\n# Label the y-axis to show the concentration in particles per cubic meter per unit size\nax.set_ylabel(r\"Concentration $\\dfrac{1}{m^3 \\cdot m}$\")\n\n# Use a logarithmic scale for the x-axis to better visualize the distribution across particle sizes\nax.set_xscale(\"log\")\n\n# Set the title of the plot\nax.set_title(\"Lognormal Particle Size Distribution\")\n\n# Display the plot\nplt.show()\n</pre> # Generate a lognormal particle size distribution # This distribution is characterized by a mode (most probable size) of 100 nm, # a geometric standard deviation of 1.4, and a total number concentration of 1e6 particles per cm^3. concentration_lognormal_0 = par.particles.get_lognormal_pdf_distribution(     x_values=radius_bins,     mode=np.array(100e-9),  # Mode of the distribution (100 nm)     geometric_standard_deviation=np.array(1.4),  # Geometric standard deviation     number_of_particles=np.array(         1e6 * 1e6     ),  # Total concentration (1e6 cm^-3 converted to m^-3) )  # Plot the lognormal concentration distribution fig, ax = plt.subplots(figsize=(8, 6)) ax.plot(radius_bins, concentration_lognormal_0)  # Set the x-axis to a logarithmic scale to capture the wide range of particle sizes ax.set_xlabel(\"Particle radius (m)\")  # Label the y-axis to show the concentration in particles per cubic meter per unit size ax.set_ylabel(r\"Concentration $\\dfrac{1}{m^3 \\cdot m}$\")  # Use a logarithmic scale for the x-axis to better visualize the distribution across particle sizes ax.set_xscale(\"log\")  # Set the title of the plot ax.set_title(\"Lognormal Particle Size Distribution\")  # Display the plot plt.show() In\u00a0[\u00a0]: Copied! <pre># Simulating the coagulation process over time for a lognormal distribution\n\n# Define the time step for the simulation\nTIME_STEP = 100  # seconds\n\n# Calculate the coagulation kernel\nkernel = par.dynamics.get_brownian_kernel_via_system_state(\n    particle_radius=radius_bins,\n    particle_mass=mass_bins,\n    temperature=293.15,  # Temperature in Kelvin\n    pressure=101325,  # Pressure in Pascals (1 atm)\n    alpha_collision_efficiency=1.0,  # Assume perfect collision efficiency\n)\n\n# Time step 1: Calculate gain, loss, and update concentration\ngain = par.dynamics.get_coagulation_gain_rate_continuous(\n    radius=radius_bins, concentration=concentration_lognormal_0, kernel=kernel\n)\nloss = par.dynamics.get_coagulation_loss_rate_continuous(\n    radius=radius_bins, concentration=concentration_lognormal_0, kernel=kernel\n)\nnet = gain - loss\nconcentration_lognormal_1 = concentration_lognormal_0 + net * TIME_STEP\nconcentration_lognormal_1[concentration_lognormal_1 &lt; 0] = (\n    0  # Ensure no negative concentrations\n)\n\n# Time step 2: Recalculate rates and update concentration\ngain = par.dynamics.get_coagulation_gain_rate_continuous(\n    radius=radius_bins, concentration=concentration_lognormal_1, kernel=kernel\n)\nloss = par.dynamics.get_coagulation_loss_rate_continuous(\n    radius=radius_bins, concentration=concentration_lognormal_1, kernel=kernel\n)\nnet = gain - loss\nconcentration_lognormal_2 = concentration_lognormal_1 + net * TIME_STEP\nconcentration_lognormal_2[concentration_lognormal_2 &lt; 0] = (\n    0  # Ensure no negative concentrations\n)\n\n# Time step 3: Recalculate rates and update concentration\ngain = par.dynamics.get_coagulation_gain_rate_continuous(\n    radius=radius_bins, concentration=concentration_lognormal_2, kernel=kernel\n)\nloss = par.dynamics.get_coagulation_loss_rate_continuous(\n    radius=radius_bins, concentration=concentration_lognormal_2, kernel=kernel\n)\nnet = gain - loss\nconcentration_lognormal_3 = concentration_lognormal_2 + net * TIME_STEP\nconcentration_lognormal_3[concentration_lognormal_3 &lt; 0] = (\n    0  # Ensure no negative concentrations\n)\n\n# Combine the concentrations at each time step into a DataFrame for easy comparison\ndf_concentration = pd.DataFrame(\n    {\n        \"0\": concentration_lognormal_0,\n        \"1\": concentration_lognormal_1,\n        \"2\": concentration_lognormal_2,\n        \"3\": concentration_lognormal_3,\n    },\n    index=radius_bins,\n)\n\n# Optional: Save the concentration data to a CSV file for further analysis\n# df_concentration.to_csv(\"concentration_lognormal_sim.csv\")\n</pre> # Simulating the coagulation process over time for a lognormal distribution  # Define the time step for the simulation TIME_STEP = 100  # seconds  # Calculate the coagulation kernel kernel = par.dynamics.get_brownian_kernel_via_system_state(     particle_radius=radius_bins,     particle_mass=mass_bins,     temperature=293.15,  # Temperature in Kelvin     pressure=101325,  # Pressure in Pascals (1 atm)     alpha_collision_efficiency=1.0,  # Assume perfect collision efficiency )  # Time step 1: Calculate gain, loss, and update concentration gain = par.dynamics.get_coagulation_gain_rate_continuous(     radius=radius_bins, concentration=concentration_lognormal_0, kernel=kernel ) loss = par.dynamics.get_coagulation_loss_rate_continuous(     radius=radius_bins, concentration=concentration_lognormal_0, kernel=kernel ) net = gain - loss concentration_lognormal_1 = concentration_lognormal_0 + net * TIME_STEP concentration_lognormal_1[concentration_lognormal_1 &lt; 0] = (     0  # Ensure no negative concentrations )  # Time step 2: Recalculate rates and update concentration gain = par.dynamics.get_coagulation_gain_rate_continuous(     radius=radius_bins, concentration=concentration_lognormal_1, kernel=kernel ) loss = par.dynamics.get_coagulation_loss_rate_continuous(     radius=radius_bins, concentration=concentration_lognormal_1, kernel=kernel ) net = gain - loss concentration_lognormal_2 = concentration_lognormal_1 + net * TIME_STEP concentration_lognormal_2[concentration_lognormal_2 &lt; 0] = (     0  # Ensure no negative concentrations )  # Time step 3: Recalculate rates and update concentration gain = par.dynamics.get_coagulation_gain_rate_continuous(     radius=radius_bins, concentration=concentration_lognormal_2, kernel=kernel ) loss = par.dynamics.get_coagulation_loss_rate_continuous(     radius=radius_bins, concentration=concentration_lognormal_2, kernel=kernel ) net = gain - loss concentration_lognormal_3 = concentration_lognormal_2 + net * TIME_STEP concentration_lognormal_3[concentration_lognormal_3 &lt; 0] = (     0  # Ensure no negative concentrations )  # Combine the concentrations at each time step into a DataFrame for easy comparison df_concentration = pd.DataFrame(     {         \"0\": concentration_lognormal_0,         \"1\": concentration_lognormal_1,         \"2\": concentration_lognormal_2,         \"3\": concentration_lognormal_3,     },     index=radius_bins, )  # Optional: Save the concentration data to a CSV file for further analysis # df_concentration.to_csv(\"concentration_lognormal_sim.csv\") In\u00a0[7]: Copied! <pre># Plot the coagulation gain, loss, and net rates for the lognormal distribution\n\n# Create a figure and axis object for the plot\nfig, ax = plt.subplots(figsize=(8, 6))\n\n# Plot the net coagulation rate\n# The net rate is plotted with a thicker gray line for emphasis\nax.plot(radius_bins, net, label=\"Net\", color=\"gray\", linewidth=4)\n\n# Plot the gain rate\n# The gain rate is plotted in dark green\nax.plot(radius_bins, gain, label=\"Gain\", color=\"darkgreen\")\n\n# Plot the loss rate\n# The loss rate is plotted in red, and multiplied by -1 for plotting to indicate that it's a removal process\nax.plot(radius_bins, -1 * loss, label=\"Loss\", color=\"red\")\n\n# Set the x-axis label to indicate the particle radius in meters\nax.set_xlabel(\"Particle radius (m)\")\n\n# Set the y-axis label to indicate the rate of change in concentration, with appropriate units\nax.set_ylabel(r\"Rate $\\dfrac{1}{m^{3} s^{1} \\cdot m}$\")\n\n# Use a logarithmic scale for the x-axis to account for the wide range of particle sizes\nax.set_xscale(\"log\")\n\n# title\nax.set_title(\"PDF: Coagulation Gain, Loss, and Net Rates\")\n\n# Add a legend to identify the gain, loss, and net lines\nplt.legend()\n\n# Display the plot\nplt.show()\n</pre> # Plot the coagulation gain, loss, and net rates for the lognormal distribution  # Create a figure and axis object for the plot fig, ax = plt.subplots(figsize=(8, 6))  # Plot the net coagulation rate # The net rate is plotted with a thicker gray line for emphasis ax.plot(radius_bins, net, label=\"Net\", color=\"gray\", linewidth=4)  # Plot the gain rate # The gain rate is plotted in dark green ax.plot(radius_bins, gain, label=\"Gain\", color=\"darkgreen\")  # Plot the loss rate # The loss rate is plotted in red, and multiplied by -1 for plotting to indicate that it's a removal process ax.plot(radius_bins, -1 * loss, label=\"Loss\", color=\"red\")  # Set the x-axis label to indicate the particle radius in meters ax.set_xlabel(\"Particle radius (m)\")  # Set the y-axis label to indicate the rate of change in concentration, with appropriate units ax.set_ylabel(r\"Rate $\\dfrac{1}{m^{3} s^{1} \\cdot m}$\")  # Use a logarithmic scale for the x-axis to account for the wide range of particle sizes ax.set_xscale(\"log\")  # title ax.set_title(\"PDF: Coagulation Gain, Loss, and Net Rates\")  # Add a legend to identify the gain, loss, and net lines plt.legend()  # Display the plot plt.show() In\u00a0[8]: Copied! <pre># Plot the evolution of particle concentration over time for the lognormal distribution\n\n# Create a figure and axis object for the plot\nfig, ax = plt.subplots(figsize=(8, 6))\n\n# Plot the concentration distribution at each time step\nax.plot(\n    radius_bins,\n    concentration_lognormal_0,\n    label=\"t=0\",\n    linestyle=\"-\",\n    color=\"blue\",\n)\nax.plot(\n    radius_bins,\n    concentration_lognormal_1,\n    label=\"t=1\",\n    linestyle=\"--\",\n    color=\"green\",\n)\nax.plot(\n    radius_bins,\n    concentration_lognormal_2,\n    label=\"t=2\",\n    linestyle=\"-.\",\n    color=\"orange\",\n)\nax.plot(\n    radius_bins,\n    concentration_lognormal_3,\n    label=\"t=3\",\n    linestyle=\":\",\n    color=\"red\",\n)\n\n# Set the x-axis label to indicate the particle radius in meters\nax.set_xlabel(\"Particle radius (m)\")\n\n# Set the y-axis label to indicate the concentration in particles per cubic meter\nax.set_ylabel(r\"Concentration $\\dfrac{1}{m^3 \\cdot m}$\")\n\n# Set the title of the plot to describe the concentration evolution over time\nax.set_title(\"PDF: Particle concentration evolution over time\")\n\n# Use a logarithmic scale for both the x-axis and y-axis\n# This is essential for visualizing the wide range of particle sizes and concentration changes\nax.set_xscale(\"log\")\n# ax.set_yscale(\"log\")\n\n# Add a legend to differentiate between the time steps\nplt.legend()\n\n# Display the plot\nplt.show()\n</pre> # Plot the evolution of particle concentration over time for the lognormal distribution  # Create a figure and axis object for the plot fig, ax = plt.subplots(figsize=(8, 6))  # Plot the concentration distribution at each time step ax.plot(     radius_bins,     concentration_lognormal_0,     label=\"t=0\",     linestyle=\"-\",     color=\"blue\", ) ax.plot(     radius_bins,     concentration_lognormal_1,     label=\"t=1\",     linestyle=\"--\",     color=\"green\", ) ax.plot(     radius_bins,     concentration_lognormal_2,     label=\"t=2\",     linestyle=\"-.\",     color=\"orange\", ) ax.plot(     radius_bins,     concentration_lognormal_3,     label=\"t=3\",     linestyle=\":\",     color=\"red\", )  # Set the x-axis label to indicate the particle radius in meters ax.set_xlabel(\"Particle radius (m)\")  # Set the y-axis label to indicate the concentration in particles per cubic meter ax.set_ylabel(r\"Concentration $\\dfrac{1}{m^3 \\cdot m}$\")  # Set the title of the plot to describe the concentration evolution over time ax.set_title(\"PDF: Particle concentration evolution over time\")  # Use a logarithmic scale for both the x-axis and y-axis # This is essential for visualizing the wide range of particle sizes and concentration changes ax.set_xscale(\"log\") # ax.set_yscale(\"log\")  # Add a legend to differentiate between the time steps plt.legend()  # Display the plot plt.show() In\u00a0[9]: Copied! <pre># Integrate the concentration to calculate the total number of particles at each time step\ntotal_concentration_lognormal_0 = trapezoid(\n    concentration_lognormal_0, x=radius_bins\n)\ntotal_concentration_lognormal_1 = trapezoid(\n    concentration_lognormal_1, x=radius_bins\n)\ntotal_concentration_lognormal_2 = trapezoid(\n    concentration_lognormal_2, x=radius_bins\n)\ntotal_concentration_lognormal_3 = trapezoid(\n    concentration_lognormal_3, x=radius_bins\n)\n\n# Plot the total concentration at each time step for the lognormal distribution\nfig, ax = plt.subplots(figsize=(8, 6))\n\n# Plot the total concentration at each time step\nax.plot(\n    [\n        total_concentration_lognormal_0,\n        total_concentration_lognormal_1,\n        total_concentration_lognormal_2,\n        total_concentration_lognormal_3,\n    ],\n    label=\"Total concentration\",\n    marker=\"o\",  # Add markers to indicate each time step\n    linestyle=\"-\",  # Use a solid line to connect the markers\n    color=\"blue\",  # Set the line color to blue\n)\n\n# Set the x-axis label to indicate the time step\nax.set_xlabel(\"Time step\")\n\n# Set the y-axis label to indicate the total concentration in particles per cubic meter\nax.set_ylabel(r\"Total concentration $\\dfrac{1}{m^3}$\")\nax.set_ylim(bottom=0.84e12)\n\n# Set the title of the plot to describe the total concentration evolution over time\nax.set_title(\"Total concentration at each time step\")\n\n# Display the plot\nplt.show()\n</pre> # Integrate the concentration to calculate the total number of particles at each time step total_concentration_lognormal_0 = trapezoid(     concentration_lognormal_0, x=radius_bins ) total_concentration_lognormal_1 = trapezoid(     concentration_lognormal_1, x=radius_bins ) total_concentration_lognormal_2 = trapezoid(     concentration_lognormal_2, x=radius_bins ) total_concentration_lognormal_3 = trapezoid(     concentration_lognormal_3, x=radius_bins )  # Plot the total concentration at each time step for the lognormal distribution fig, ax = plt.subplots(figsize=(8, 6))  # Plot the total concentration at each time step ax.plot(     [         total_concentration_lognormal_0,         total_concentration_lognormal_1,         total_concentration_lognormal_2,         total_concentration_lognormal_3,     ],     label=\"Total concentration\",     marker=\"o\",  # Add markers to indicate each time step     linestyle=\"-\",  # Use a solid line to connect the markers     color=\"blue\",  # Set the line color to blue )  # Set the x-axis label to indicate the time step ax.set_xlabel(\"Time step\")  # Set the y-axis label to indicate the total concentration in particles per cubic meter ax.set_ylabel(r\"Total concentration $\\dfrac{1}{m^3}$\") ax.set_ylim(bottom=0.84e12)  # Set the title of the plot to describe the total concentration evolution over time ax.set_title(\"Total concentration at each time step\")  # Display the plot plt.show()"},{"location":"Examples/Dynamics/Coagulation/Functional/Coagulation_Basic_2_PDF/#coagulation-basics-2-pdf-representation","title":"Coagulation Basics 2: PDF Representation\u00b6","text":""},{"location":"Examples/Dynamics/Coagulation/Functional/Coagulation_Basic_2_PDF/#continuous-particle-size-distributions","title":"Continuous Particle Size Distributions\u00b6","text":"<p>In this notebook, we implement the coagulation process for continuous particle size distributions, following the methodology outlined in Seinfeld and Pandis (2006). This work builds on concepts from <code>Coagulation Basics 1: PMF Representation</code> by extending the analysis to probability density function (PDF) representations of particle size distributions.</p>"},{"location":"Examples/Dynamics/Coagulation/Functional/Coagulation_Basic_2_PDF/#objective","title":"Objective\u00b6","text":"<p>The primary objective is to demonstrate the calculation of the coagulation kernel and the resulting coagulation rates for a given particle size distribution. We will compare the PDF representation with the probability mass function (PMF) representation, highlighting how the PDF's continuous nature influences the coagulation process.</p>"},{"location":"Examples/Dynamics/Coagulation/Functional/Coagulation_Basic_2_PDF/#approach","title":"Approach\u00b6","text":"<ol> <li><p>Uniform Distribution:</p> <ul> <li>We begin with a uniform particle size distribution to illustrate the fundamental mechanics of coagulation.</li> </ul> </li> <li><p>Lognormal Probability Density Function:</p> <ul> <li><p>After establishing the basics with a uniform distribution, we proceed to a lognormal size distribution, which more accurately reflects real-world aerosol size distributions. The PDF representation is continuous and describes the probability of finding particles within a specific size range. Integrating the PDF across the entire size range yields the total particle concentration.</p> </li> <li><p>Units:</p> <ul> <li>The units of the PDF are particles per unit volume per unit size, typically expressed as $\\dfrac{1}{m^3 \\cdot m}$ or $\\dfrac{1}{m^4}$. Integration of the PDF over the particle size range gives the total number concentration, expressed in $\\dfrac{1}{m^3}$.</li> </ul> </li> </ul> </li> </ol> <p>This step-by-step approach lays the groundwork for more advanced implementations, such as those in the <code>particula</code> library.</p>"},{"location":"Examples/Dynamics/Coagulation/Functional/Coagulation_Basic_2_PDF/#required-libraries","title":"Required Libraries\u00b6","text":"<p>We will use common scientific libraries, including <code>numpy</code> for numerical calculations, <code>matplotlib</code> for visualization, and <code>pandas</code> for data manipulation. Additionally, we will leverage specific functions from the <code>particula</code> library to compute the coagulation kernel and generate size distributions.</p>"},{"location":"Examples/Dynamics/Coagulation/Functional/Coagulation_Basic_2_PDF/#creating-a-size-distribution","title":"Creating a Size Distribution\u00b6","text":"<p>In this section, we define the size distribution for aerosol particles. The particle sizes are distributed across several fine-scale bins, allowing for detailed modeling of particle behavior over a wide size range.</p>"},{"location":"Examples/Dynamics/Coagulation/Functional/Coagulation_Basic_2_PDF/#particle-size-bins","title":"Particle Size Bins\u00b6","text":"<ul> <li><code>radius_bins</code>: These bins represent particle radii, spanning from 1 nanometer (1e-9 m) to 10 micrometers (1e-5 m) on a logarithmic scale. Using fine-scale bins (500 in total) provides a more detailed resolution of the size distribution, which is crucial for accurate coagulation modeling.</li> <li><code>mass_bins</code>: For each radius bin, we calculate the corresponding particle mass, assuming a particle density of 1 g/cm\u00b3 (1000 kg/m\u00b3 in SI units). This mass calculation is essential for understanding how particles interact and coagulate over time.</li> </ul>"},{"location":"Examples/Dynamics/Coagulation/Functional/Coagulation_Basic_2_PDF/#calculating-the-brownian-coagulation-kernel","title":"Calculating the Brownian Coagulation Kernel\u00b6","text":"<p>In this section, we calculate the Brownian coagulation kernel matrix, which quantifies the rate at which particles of different sizes collide and coagulate due to Brownian motion. Understanding the kernel matrix is crucial for analyzing the dynamics of particle coagulation.</p> <p>It's important to note that the kernel matrix itself remains consistent whether we're using a Probability Mass Function (PMF) or a Probability Density Function (PDF) representation. The difference lies in how we apply the kernel matrix\u2014using summations in the PMF case and integrations in the PDF case\u2014to calculate coagulation rates.</p>"},{"location":"Examples/Dynamics/Coagulation/Functional/Coagulation_Basic_2_PDF/#generating-lognormal-pdf-size-distribution","title":"Generating Lognormal PDF Size Distribution\u00b6","text":"<p>In this section, we generate a lognormal particle size distribution and visualize it to understand the particle concentration across different sizes. A lognormal distribution is commonly used to represent aerosol particle size distributions due to its ability to model the skewness observed in real-world data.</p>"},{"location":"Examples/Dynamics/Coagulation/Functional/Coagulation_Basic_2_PDF/#key-parameters","title":"Key Parameters\u00b6","text":"<ul> <li>Mode (Most Probable Size): The mode of the distribution is set at 100 nanometers (100 nm), representing the most common particle size within the distribution.</li> <li>Geometric Standard Deviation: A geometric standard deviation of 1.4 is used, which determines the spread of the distribution. This value reflects how broadly the particle sizes are distributed around the mode.</li> <li>Total Number Concentration: The total particle concentration is set at $1 \\times 10^6$ particles per cubic centimeter (cm\u00b3), which is converted to $1 \\times 10^{12}$ particles per cubic meter (m\u00b3) for the calculation.</li> </ul>"},{"location":"Examples/Dynamics/Coagulation/Functional/Coagulation_Basic_2_PDF/#visualization","title":"Visualization\u00b6","text":"<p>The resulting distribution is plotted with particle radius on the x-axis and particle concentration on the y-axis. The x-axis is scaled logarithmically to effectively display the wide range of particle sizes. This plot helps in visualizing how particle concentration varies with size, providing insights into the distribution characteristics and potential behavior during coagulation processes.</p>"},{"location":"Examples/Dynamics/Coagulation/Functional/Coagulation_Basic_2_PDF/#simulating-the-coagulation-process-for-a-lognormal-distribution","title":"Simulating the Coagulation Process for a Lognormal Distribution\u00b6","text":"<p>After establishing a lognormal particle size distribution, we now simulate the coagulation process over time to observe how the distribution evolves as particles collide and form larger particles.</p>"},{"location":"Examples/Dynamics/Coagulation/Functional/Coagulation_Basic_2_PDF/#simulation-setup","title":"Simulation Setup\u00b6","text":"<ul> <li><p>Time Step: We use a time step of 100 seconds (<code>TIME_STEP = 100</code>). This interval determines the frequency at which particle concentrations are updated based on the calculated coagulation rates.</p> </li> <li><p>Coagulation Kernel: The coagulation kernel is computed using the same environmental parameters (temperature, pressure, and collision efficiency) as before. The kernel remains unchanged throughout the simulation, as it depends solely on the physical properties of the particles and the surrounding environment.</p> </li> </ul>"},{"location":"Examples/Dynamics/Coagulation/Functional/Coagulation_Basic_2_PDF/#time-step-calculations","title":"Time Step Calculations\u00b6","text":"<p>For each time step, we perform the following calculations:</p> <ol> <li><p>Time Step 1:</p> <ul> <li>Gain and Loss Rates: Calculate the gain and loss rates for the initial concentration (<code>concentration_lognormal_0</code>) based on the coagulation kernel.</li> <li>Update Concentration: Apply the net rate of change to update the particle concentration to <code>concentration_lognormal_1</code>. Any negative concentrations, which may result from numerical errors, are set to zero.</li> </ul> </li> <li><p>Time Step 2:</p> <ul> <li>Recalculate Rates: Compute the gain and loss rates using the updated concentration (<code>concentration_lognormal_1</code>).</li> <li>Update Concentration: Update the concentration to <code>concentration_lognormal_2</code>, ensuring no negative values.</li> </ul> </li> <li><p>Time Step 3:</p> <ul> <li>Recalculate Rates: Calculate the rates again based on the most recent concentration (<code>concentration_lognormal_2</code>).</li> <li>Update Concentration: Update the concentration to <code>concentration_lognormal_3</code>, correcting any negative concentrations.</li> </ul> </li> </ol>"},{"location":"Examples/Dynamics/Coagulation/Functional/Coagulation_Basic_2_PDF/#combining-results","title":"Combining Results\u00b6","text":"<p>The concentrations at each time step are combined into a <code>pandas</code> DataFrame. This structure facilitates easy comparison of the particle size distribution changes over time, offering insights into the coagulation process.</p>"},{"location":"Examples/Dynamics/Coagulation/Functional/Coagulation_Basic_2_PDF/#optional-saving-results","title":"Optional: Saving Results\u00b6","text":"<p>For further analysis or documentation, the concentration data can be saved to a CSV file. This step is optional but can be useful for detailed post-simulation analysis.</p>"},{"location":"Examples/Dynamics/Coagulation/Functional/Coagulation_Basic_2_PDF/#plotting-the-coagulation-gain-loss-and-net-rates-for-lognormal-distribution","title":"Plotting the Coagulation Gain, Loss, and Net Rates for Lognormal Distribution\u00b6","text":"<p>To visualize the dynamics of coagulation for a lognormal particle size distribution, we plot the rates of gain, loss, and net change in concentration across the range of particle sizes. This plot provides insights into how particles are interacting during the coagulation process.</p>"},{"location":"Examples/Dynamics/Coagulation/Functional/Coagulation_Basic_2_PDF/#plot-details","title":"Plot Details\u00b6","text":"<ul> <li><p>Net Rate: The net rate of change in particle concentration is plotted as a thick gray line. This line represents the overall effect of coagulation, indicating whether the concentration in each size bin is increasing or decreasing.</p> </li> <li><p>Gain Rate: The gain rate, plotted in dark green, shows how particles are being added to each size bin as smaller particles coagulate to form larger ones. This rate reflects the accumulation of particles in specific size bins.</p> </li> <li><p>Loss Rate: The loss rate is plotted in red, with the values multiplied by -1 to indicate that it represents a reduction in particle concentration. This line shows how particles are being depleted from each size bin due to coagulation.</p> </li> </ul>"},{"location":"Examples/Dynamics/Coagulation/Functional/Coagulation_Basic_2_PDF/#axes-configuration","title":"Axes Configuration\u00b6","text":"<ul> <li><p>X-axis: The x-axis represents the particle radius in meters, plotted on a logarithmic scale to capture the wide range of particle sizes present in the distribution.</p> </li> <li><p>Y-axis: The y-axis shows the rate of change in concentration in units of particles per cubic meter per second ($\\dfrac{1}{m^{3} s^{1} \\cdot m}$), providing a clear view of how rapidly particles are being gained, lost, or changing net concentration in the system.</p> </li> </ul>"},{"location":"Examples/Dynamics/Coagulation/Functional/Coagulation_Basic_2_PDF/#legend-and-interpretation","title":"Legend and Interpretation\u00b6","text":"<p>A legend is included to clearly differentiate between the net, gain, and loss lines on the plot. By analyzing these rates, we can determine the most active particle sizes in the coagulation process:</p> <ul> <li>Positive Net Rate: Indicates that the particle size bin is gaining particles, likely due to the aggregation of smaller particles.</li> <li>Negative Net Rate: Indicates that the particle size bin is losing particles, either because they are merging into larger particles or being depleted through other processes.</li> </ul> <p>This plot is essential for understanding the detailed behavior of the particle size distribution during coagulation, highlighting which sizes are most affected by the process.</p>"},{"location":"Examples/Dynamics/Coagulation/Functional/Coagulation_Basic_2_PDF/#plotting-the-evolution-of-concentration-for-lognormal-distribution","title":"Plotting the Evolution of Concentration for Lognormal Distribution\u00b6","text":"<p>After simulating the coagulation process over several time steps, it is important to visualize how the particle concentration evolves. This plot shows the concentration distribution at different time steps, allowing us to observe the changes in the lognormal distribution as coagulation progresses.</p>"},{"location":"Examples/Dynamics/Coagulation/Functional/Coagulation_Basic_2_PDF/#calculating-and-visualizing-total-particle-concentration-over-time","title":"Calculating and Visualizing Total Particle Concentration Over Time\u00b6","text":"<p>In this section, we calculate the total number of particles at each time step by integrating the particle concentration across the size distribution. This provides a clear view of how the total particle concentration evolves as coagulation progresses.</p>"},{"location":"Examples/Dynamics/Coagulation/Functional/Coagulation_Basic_2_PDF/#integration-of-particle-concentration","title":"Integration of Particle Concentration\u00b6","text":"<p>To determine the total number of particles at each time step, we integrate the concentration across all particle sizes using the trapezoidal rule. This integration gives us the total particle concentration (in particles per cubic meter) at each specific time step.</p>"},{"location":"Examples/Dynamics/Coagulation/Functional/Coagulation_Basic_2_PDF/#plotting-total-concentration-over-time","title":"Plotting Total Concentration Over Time\u00b6","text":"<p>We then plot the total particle concentration for each time step to visualize how the overall concentration decreases as particles coagulate into larger sizes. The x-axis represents the time steps, while the y-axis shows the total particle concentration in particles per cubic meter. Markers are used to highlight the concentration at each time step, connected by a solid line to indicate the trend over time.</p> <p>This plot provides a straightforward representation of the coagulation process's impact on the total number of particles, illustrating the decrease in concentration as particles merge and grow.</p>"},{"location":"Examples/Dynamics/Coagulation/Functional/Coagulation_Basic_2_PDF/#note","title":"Note:\u00b6","text":"<p>You can compare the results obtained from the PDF representation with those from the PMF representation in the previous notebook to observe how similar the results are despite the different representations. They are not exactly equal.</p>"},{"location":"Examples/Dynamics/Coagulation/Functional/Coagulation_Basic_2_PDF/#summary","title":"Summary\u00b6","text":"<p>In this notebook, we explored the process of particle coagulation in aerosols, with a particular focus on probability density function (PDF) representations of lognormal particle size distributions.</p> <p>We began by defining a lognormal distribution, which is commonly used to represent aerosol particle sizes due to its ability to model the skewed distributions observed in real-world scenarios. We then calculated the Brownian coagulation kernel, a crucial element that quantifies the rate at which particles of different sizes collide and coagulate due to Brownian motion.</p> <p>Through a series of simulations, we observed how the particle size distribution evolves over time as coagulation occurs. By applying the coagulation kernel to the initial distribution, we calculated the gain and loss rates for particles and updated the particle concentrations at each time step. This iterative process illustrated the gradual decrease in total particle concentration as smaller particles combined to form larger ones.</p> <p>Finally, we integrated the particle concentrations across the size distribution at each time step to determine the total number of particles present. This allowed us to visualize the overall reduction in particle concentration over time, providing a clear demonstration of the impact of coagulation on aerosol dynamics.</p> <p>This notebook not only highlights the fundamental principles of aerosol coagulation but also provides a practical framework for modeling and analyzing these processes using PDF representations. The methodologies and tools used here, such as the integration of concentration data and the use of a coagulation kernel, are essential for understanding the behavior of aerosols in various environmental and industrial contexts.</p>"},{"location":"Examples/Dynamics/Coagulation/Functional/Coagulation_Basic_3_compared/","title":"Coagulation Basic 3: PMF vs. PDF","text":"In\u00a0[\u00a0]: Copied! <pre># In Colab uncomment the following command to install particula:\n#!pip install particula[extra] --quiet\n# Import necessary libraries\n\nimport numpy as np  # For numerical operations and array manipulations\nimport matplotlib.pyplot as plt  # For plotting graphs and visualizations\nimport pandas as pd  # For data manipulation and analysis\nfrom scipy.integrate import (\n    trapezoid,\n)  # For numerical integration using the trapezoidal rule\n\nimport particula as par\n</pre> # In Colab uncomment the following command to install particula: #!pip install particula[extra] --quiet # Import necessary libraries  import numpy as np  # For numerical operations and array manipulations import matplotlib.pyplot as plt  # For plotting graphs and visualizations import pandas as pd  # For data manipulation and analysis from scipy.integrate import (     trapezoid, )  # For numerical integration using the trapezoidal rule  import particula as par In\u00a0[2]: Copied! <pre># Define distribution parameters\nmode = np.array([200e-9])  # Mode of the distribution (200 nm)\nstd = np.array([1.5])  # Geometric standard deviation\nnumber = np.array([1e6]) * 1e6  # 1e6 particles per cm^3 converted to m^3\n\n# Define radius bins on a logarithmic scale from 1 nm to 10 \u03bcm\nradius_bins = np.logspace(start=-9, stop=-4, num=500)\n\n# Create the lognormal PDF distribution\ndistribution_pdf = par.particles.get_lognormal_pdf_distribution(\n    x_values=radius_bins,\n    mode=mode,\n    geometric_standard_deviation=std,\n    number_of_particles=number,\n)\n\n# Create the lognormal PMF distribution\ndistribution_pmf = par.particles.get_lognormal_pmf_distribution(\n    x_values=radius_bins,\n    mode=mode,\n    geometric_standard_deviation=std,\n    number_of_particles=number,\n)\n\n# Plot the PDF and PMF distributions for comparison\nplt.figure(figsize=(8, 6))\nplt.plot(radius_bins, distribution_pdf, label=\"PDF\")\nplt.plot(radius_bins, distribution_pmf, label=\"PMF\")\nplt.xlabel(\"Particle Radius [m]\")\nplt.ylabel(r\"Concentration $\\dfrac{1}{m^3}$ or $\\dfrac{1}{m^3 \\cdot m}$\")\nplt.xscale(\n    \"log\"\n)  # Logarithmic scale for the x-axis to capture wide size range\nplt.yscale(\n    \"log\"\n)  # Logarithmic scale for the y-axis to highlight distribution differences\nplt.legend()\nplt.show()\n</pre> # Define distribution parameters mode = np.array([200e-9])  # Mode of the distribution (200 nm) std = np.array([1.5])  # Geometric standard deviation number = np.array([1e6]) * 1e6  # 1e6 particles per cm^3 converted to m^3  # Define radius bins on a logarithmic scale from 1 nm to 10 \u03bcm radius_bins = np.logspace(start=-9, stop=-4, num=500)  # Create the lognormal PDF distribution distribution_pdf = par.particles.get_lognormal_pdf_distribution(     x_values=radius_bins,     mode=mode,     geometric_standard_deviation=std,     number_of_particles=number, )  # Create the lognormal PMF distribution distribution_pmf = par.particles.get_lognormal_pmf_distribution(     x_values=radius_bins,     mode=mode,     geometric_standard_deviation=std,     number_of_particles=number, )  # Plot the PDF and PMF distributions for comparison plt.figure(figsize=(8, 6)) plt.plot(radius_bins, distribution_pdf, label=\"PDF\") plt.plot(radius_bins, distribution_pmf, label=\"PMF\") plt.xlabel(\"Particle Radius [m]\") plt.ylabel(r\"Concentration $\\dfrac{1}{m^3}$ or $\\dfrac{1}{m^3 \\cdot m}$\") plt.xscale(     \"log\" )  # Logarithmic scale for the x-axis to capture wide size range plt.yscale(     \"log\" )  # Logarithmic scale for the y-axis to highlight distribution differences plt.legend() plt.show() In\u00a0[3]: Copied! <pre># Rescale the PDF to PMF\ndistribution_pdf_rescaled = par.util.get_pdf_distribution_in_pmf(\n    x_array=radius_bins,\n    distribution=distribution_pdf,\n    to_pdf=False,  # Convert PDF to PMF\n)\n\n# Plot the rescaled PDF and the original PMF for comparison\nplt.figure(figsize=(8, 6))\nplt.plot(radius_bins, distribution_pdf_rescaled, label=\"PDF Rescaled to PMF\")\nplt.plot(radius_bins, distribution_pmf, label=\"PMF\")\nplt.xlabel(\"Particle Radius [m]\")\nplt.ylabel(r\"Concentration $\\dfrac{1}{m^3}$\")\nplt.xscale(\"log\")  # Use a logarithmic scale for the x-axis\n# plt.yscale('log')  # Optionally use a logarithmic scale for the y-axis\nplt.legend()\nplt.show()\n</pre> # Rescale the PDF to PMF distribution_pdf_rescaled = par.util.get_pdf_distribution_in_pmf(     x_array=radius_bins,     distribution=distribution_pdf,     to_pdf=False,  # Convert PDF to PMF )  # Plot the rescaled PDF and the original PMF for comparison plt.figure(figsize=(8, 6)) plt.plot(radius_bins, distribution_pdf_rescaled, label=\"PDF Rescaled to PMF\") plt.plot(radius_bins, distribution_pmf, label=\"PMF\") plt.xlabel(\"Particle Radius [m]\") plt.ylabel(r\"Concentration $\\dfrac{1}{m^3}$\") plt.xscale(\"log\")  # Use a logarithmic scale for the x-axis # plt.yscale('log')  # Optionally use a logarithmic scale for the y-axis plt.legend() plt.show() In\u00a0[4]: Copied! <pre># Rescale the PMF to PDF\ndistribution_pmf_rescaled = par.util.get_pdf_distribution_in_pmf(\n    x_array=radius_bins,\n    distribution=distribution_pmf,\n    to_pdf=True,  # Convert PMF to PDF\n)\n\n# Plot the original PDF and the rescaled PMF for comparison\nplt.figure()\nplt.plot(radius_bins, distribution_pdf, label=\"PDF\")\nplt.plot(radius_bins, distribution_pmf_rescaled, label=\"PMF Rescaled to PDF\")\nplt.xlabel(\"Particle Radius [m]\")\nplt.ylabel(r\"Concentration $\\dfrac{1}{m^3 \\cdot m}$\")\nplt.xscale(\"log\")  # Logarithmic scale for the x-axis to capture size range\nplt.legend()\nplt.show()\n</pre> # Rescale the PMF to PDF distribution_pmf_rescaled = par.util.get_pdf_distribution_in_pmf(     x_array=radius_bins,     distribution=distribution_pmf,     to_pdf=True,  # Convert PMF to PDF )  # Plot the original PDF and the rescaled PMF for comparison plt.figure() plt.plot(radius_bins, distribution_pdf, label=\"PDF\") plt.plot(radius_bins, distribution_pmf_rescaled, label=\"PMF Rescaled to PDF\") plt.xlabel(\"Particle Radius [m]\") plt.ylabel(r\"Concentration $\\dfrac{1}{m^3 \\cdot m}$\") plt.xscale(\"log\")  # Logarithmic scale for the x-axis to capture size range plt.legend() plt.show() In\u00a0[5]: Copied! <pre># Integrate the original PDF to calculate the total number concentration\nnumber_concentration_pdf = trapezoid(distribution_pdf, x=radius_bins)\n\n# Integrate the PMF rescaled to PDF to calculate the total number concentration\nnumber_concentration_pmf_rescaled = trapezoid(\n    distribution_pmf_rescaled, x=radius_bins\n)\n\n# Print the results to compare\nprint(f\"Number concentration from PDF: {number_concentration_pdf}\")\nprint(\n    f\"Number concentration from PMF rescaled to PDF: {number_concentration_pmf_rescaled}\"\n)\n</pre> # Integrate the original PDF to calculate the total number concentration number_concentration_pdf = trapezoid(distribution_pdf, x=radius_bins)  # Integrate the PMF rescaled to PDF to calculate the total number concentration number_concentration_pmf_rescaled = trapezoid(     distribution_pmf_rescaled, x=radius_bins )  # Print the results to compare print(f\"Number concentration from PDF: {number_concentration_pdf}\") print(     f\"Number concentration from PMF rescaled to PDF: {number_concentration_pmf_rescaled}\" ) <pre>Number concentration from PDF: 1000000000000.0\nNumber concentration from PMF rescaled to PDF: 988596064185.8999\n</pre> <p>Verifying Number Concentration for PMF</p> <p>Next, we sum the original PMF distribution and the PDF that has been rescaled to a PMF. Summing these values directly gives the total number concentration, allowing us to verify consistency across the different representations.</p> In\u00a0[6]: Copied! <pre># Sum the original PMF to calculate the total number concentration\nnumber_concentration_pmf = distribution_pmf.sum()\n\n# Sum the PDF rescaled to PMF to calculate the total number concentration\nnumber_concentration_pdf_rescaled = distribution_pdf_rescaled.sum()\n\n# Print the results to compare\nprint(f\"Number concentration from PMF: {number_concentration_pmf}\")\nprint(\n    f\"Number concentration from PDF rescaled to PMF: {number_concentration_pdf_rescaled}\"\n)\n</pre> # Sum the original PMF to calculate the total number concentration number_concentration_pmf = distribution_pmf.sum()  # Sum the PDF rescaled to PMF to calculate the total number concentration number_concentration_pdf_rescaled = distribution_pdf_rescaled.sum()  # Print the results to compare print(f\"Number concentration from PMF: {number_concentration_pmf}\") print(     f\"Number concentration from PDF rescaled to PMF: {number_concentration_pdf_rescaled}\" ) <pre>Number concentration from PMF: 1000000000000.0\nNumber concentration from PDF rescaled to PMF: 1011535485753.2141\n</pre> In\u00a0[\u00a0]: Copied! <pre># Calculate the mass of particles for each size bin\nmass_bins = 4 / 3 * np.pi * radius_bins**3 * 1e3  # kg\n\n# Calculate the Brownian coagulation kernel matrix\nkernel = par.dynamics.get_brownian_kernel_via_system_state(\n    particle_radius=radius_bins,\n    particle_mass=mass_bins,\n    temperature=293.15,  # Temperature in Kelvin (20\u00b0C)\n    pressure=101325,  # Pressure in Pascals (1 atm)\n    alpha_collision_efficiency=1.0,  # Assume perfect collision efficiency\n)\n</pre> # Calculate the mass of particles for each size bin mass_bins = 4 / 3 * np.pi * radius_bins**3 * 1e3  # kg  # Calculate the Brownian coagulation kernel matrix kernel = par.dynamics.get_brownian_kernel_via_system_state(     particle_radius=radius_bins,     particle_mass=mass_bins,     temperature=293.15,  # Temperature in Kelvin (20\u00b0C)     pressure=101325,  # Pressure in Pascals (1 atm)     alpha_collision_efficiency=1.0,  # Assume perfect collision efficiency ) In\u00a0[8]: Copied! <pre>concentration_0 = distribution_pdf\n\n# Calculate gain and loss rates for the PDF\ngain_pdf = par.dynamics.get_coagulation_gain_rate_continuous(\n    radius=radius_bins,\n    concentration=concentration_0,\n    kernel=kernel,\n)\nloss_pdf = par.dynamics.get_coagulation_loss_rate_continuous(\n    radius=radius_bins, concentration=concentration_0, kernel=kernel\n)\nnet_pdf = gain_pdf - loss_pdf\n\n# Convert gain, loss, and net rates to volume distribution\ngain_volume = gain_pdf * 4 / 3 * np.pi * radius_bins**3\nloss_volume = loss_pdf * 4 / 3 * np.pi * radius_bins**3\nnet_volume = net_pdf * 4 / 3 * np.pi * radius_bins**3\n\n# Integrate the gain, loss, and net rates to get the total volume\ngain_total_volume = trapezoid(gain_volume, x=radius_bins)\nloss_total_volume = trapezoid(loss_volume, x=radius_bins)\nnet_total_volume = trapezoid(net_volume, x=radius_bins)\n\n# Print the results to verify volume conservation\nprint(f\"Gain total volume: {gain_total_volume}\")\nprint(f\"Loss total volume: {loss_total_volume}\")\nprint(f\"Net total volume: {net_total_volume}\")\n</pre> concentration_0 = distribution_pdf  # Calculate gain and loss rates for the PDF gain_pdf = par.dynamics.get_coagulation_gain_rate_continuous(     radius=radius_bins,     concentration=concentration_0,     kernel=kernel, ) loss_pdf = par.dynamics.get_coagulation_loss_rate_continuous(     radius=radius_bins, concentration=concentration_0, kernel=kernel ) net_pdf = gain_pdf - loss_pdf  # Convert gain, loss, and net rates to volume distribution gain_volume = gain_pdf * 4 / 3 * np.pi * radius_bins**3 loss_volume = loss_pdf * 4 / 3 * np.pi * radius_bins**3 net_volume = net_pdf * 4 / 3 * np.pi * radius_bins**3  # Integrate the gain, loss, and net rates to get the total volume gain_total_volume = trapezoid(gain_volume, x=radius_bins) loss_total_volume = trapezoid(loss_volume, x=radius_bins) net_total_volume = trapezoid(net_volume, x=radius_bins)  # Print the results to verify volume conservation print(f\"Gain total volume: {gain_total_volume}\") print(f\"Loss total volume: {loss_total_volume}\") print(f\"Net total volume: {net_total_volume}\") <pre>Gain total volume: 6.75165104833036e-11\nLoss total volume: 6.752244952802652e-11\nNet total volume: -5.9390447229141716e-15\n</pre> <p>Ensuring Volume Conservation in Coagulation Rates for PMF</p> <p>Similar to the PDF representation, it is essential to ensure that the total particle volume is conserved in the PMF (Probability Mass Function) representation during the coagulation process. The number of particles may decrease as they coagulate into larger particles, but the total volume of particles should remain constant if no other processes (like condensation or evaporation) are involved.</p> <p>Calculating Coagulation Rates for PMF</p> <p>We calculate the gain, loss, and net coagulation rates for the initial PMF concentration. These rates describe how particle concentrations change in each size bin due to coagulation.</p> In\u00a0[9]: Copied! <pre># Initial concentration for the PMF distribution\nconcentration_0_pmf = distribution_pmf\n\n# Calculate gain and loss rates for the PMF\ngain_pmf = par.dynamics.get_coagulation_gain_rate_discrete(\n    radius=radius_bins,\n    concentration=concentration_0_pmf,\n    kernel=kernel,\n)\nloss_pmf = par.dynamics.get_coagulation_loss_rate_discrete(\n    concentration=concentration_0_pmf, kernel=kernel\n)\nnet_pmf = gain_pmf - loss_pmf\n\n# Convert gain, loss, and net rates to volume distribution\ngain_volume_pmf = gain_pmf * 4 / 3 * np.pi * radius_bins**3\nloss_volume_pmf = loss_pmf * 4 / 3 * np.pi * radius_bins**3\nnet_volume_pmf = net_pmf * 4 / 3 * np.pi * radius_bins**3\n\n# Sum the gain, loss, and net volumes\ngain_total_volume_pmf = gain_volume_pmf.sum()\nloss_total_volume_pmf = loss_volume_pmf.sum()\nnet_total_volume_pmf = net_volume_pmf.sum()\n\n# Print the results to verify volume conservation\nprint(f\"Gain total volume PMF: {gain_total_volume_pmf}\")\nprint(f\"Loss total volume PMF: {loss_total_volume_pmf}\")\nprint(f\"Net total volume PMF: {net_total_volume_pmf}\")\n</pre> # Initial concentration for the PMF distribution concentration_0_pmf = distribution_pmf  # Calculate gain and loss rates for the PMF gain_pmf = par.dynamics.get_coagulation_gain_rate_discrete(     radius=radius_bins,     concentration=concentration_0_pmf,     kernel=kernel, ) loss_pmf = par.dynamics.get_coagulation_loss_rate_discrete(     concentration=concentration_0_pmf, kernel=kernel ) net_pmf = gain_pmf - loss_pmf  # Convert gain, loss, and net rates to volume distribution gain_volume_pmf = gain_pmf * 4 / 3 * np.pi * radius_bins**3 loss_volume_pmf = loss_pmf * 4 / 3 * np.pi * radius_bins**3 net_volume_pmf = net_pmf * 4 / 3 * np.pi * radius_bins**3  # Sum the gain, loss, and net volumes gain_total_volume_pmf = gain_volume_pmf.sum() loss_total_volume_pmf = loss_volume_pmf.sum() net_total_volume_pmf = net_volume_pmf.sum()  # Print the results to verify volume conservation print(f\"Gain total volume PMF: {gain_total_volume_pmf}\") print(f\"Loss total volume PMF: {loss_total_volume_pmf}\") print(f\"Net total volume PMF: {net_total_volume_pmf}\") <pre>Gain total volume PMF: 6.674655653136e-11\nLoss total volume PMF: 6.75224495280265e-11\nNet total volume PMF: -7.758929966665061e-13\n</pre> In\u00a0[10]: Copied! <pre># Convert PMF gain and loss rates to PDF\ngain_pmf_to_pdf = par.util.get_pdf_distribution_in_pmf(\n    x_array=radius_bins, distribution=gain_pmf, to_pdf=True\n)\nloss_pmf_to_pdf = par.util.get_pdf_distribution_in_pmf(\n    x_array=radius_bins, distribution=loss_pmf, to_pdf=True\n)\nnet_pmf_to_pdf = gain_pmf_to_pdf - loss_pmf_to_pdf\n\n# Plot the gain and loss rates for both PDF and converted PMF\nplt.figure()\nplt.plot(radius_bins, gain_pdf, label=\"Gain (PDF)\", linewidth=4)\nplt.plot(radius_bins, -1 * loss_pdf, label=\"Loss (PDF)\", linewidth=4)\nplt.plot(\n    radius_bins, gain_pmf_to_pdf, label=\"Gain (PMF to PDF)\", linestyle=\"--\"\n)\nplt.plot(\n    radius_bins,\n    -1 * loss_pmf_to_pdf,\n    label=\"Loss (PMF to PDF)\",\n    linestyle=\"--\",\n)\nplt.xlabel(\"Particle Radius [m]\")\nplt.ylabel(r\"Rate $\\dfrac{1}{m^3 s \\cdot m}$\")\nplt.xscale(\"log\")\nplt.title(\"PDF: Gain and Loss Comparison\")\nplt.legend()\nplt.show()\n\n# Plot the net gain and loss rates for both PDF and converted PMF\nplt.figure()\nplt.plot(radius_bins, net_pdf, label=\"Net (PDF)\")\nplt.plot(radius_bins, net_pmf_to_pdf, label=\"Net (PMF to PDF)\")\nplt.xlabel(\"Particle Radius [m]\")\nplt.ylabel(r\"Rate $\\dfrac{1}{m^3 s \\cdot m}$\")\nplt.xscale(\"log\")\nplt.title(\"PDF: Net Gain and Loss Comparison\")\nplt.legend()\nplt.show()\n</pre> # Convert PMF gain and loss rates to PDF gain_pmf_to_pdf = par.util.get_pdf_distribution_in_pmf(     x_array=radius_bins, distribution=gain_pmf, to_pdf=True ) loss_pmf_to_pdf = par.util.get_pdf_distribution_in_pmf(     x_array=radius_bins, distribution=loss_pmf, to_pdf=True ) net_pmf_to_pdf = gain_pmf_to_pdf - loss_pmf_to_pdf  # Plot the gain and loss rates for both PDF and converted PMF plt.figure() plt.plot(radius_bins, gain_pdf, label=\"Gain (PDF)\", linewidth=4) plt.plot(radius_bins, -1 * loss_pdf, label=\"Loss (PDF)\", linewidth=4) plt.plot(     radius_bins, gain_pmf_to_pdf, label=\"Gain (PMF to PDF)\", linestyle=\"--\" ) plt.plot(     radius_bins,     -1 * loss_pmf_to_pdf,     label=\"Loss (PMF to PDF)\",     linestyle=\"--\", ) plt.xlabel(\"Particle Radius [m]\") plt.ylabel(r\"Rate $\\dfrac{1}{m^3 s \\cdot m}$\") plt.xscale(\"log\") plt.title(\"PDF: Gain and Loss Comparison\") plt.legend() plt.show()  # Plot the net gain and loss rates for both PDF and converted PMF plt.figure() plt.plot(radius_bins, net_pdf, label=\"Net (PDF)\") plt.plot(radius_bins, net_pmf_to_pdf, label=\"Net (PMF to PDF)\") plt.xlabel(\"Particle Radius [m]\") plt.ylabel(r\"Rate $\\dfrac{1}{m^3 s \\cdot m}$\") plt.xscale(\"log\") plt.title(\"PDF: Net Gain and Loss Comparison\") plt.legend() plt.show() In\u00a0[11]: Copied! <pre># Initial distribution for the simulation\ndistribution_0 = distribution_pdf\ndistribution_i = distribution_0\n\n# Define the time array for the simulation\ntime_array = np.linspace(\n    start=0, stop=1000, num=50\n)  # Time span of 1000 seconds\ntime_interval = (\n    time_array[1] - time_array[0]\n)  # Time interval between each step\n\n# Array to store the distribution at each time step\ndistribution_time = np.zeros([len(time_array), len(distribution_0)])\n\n# Simulate the coagulation process over time\nfor i, dpa in enumerate(time_array):\n    if i &gt; 0:\n        # Calculate coagulation gain and loss at the current time step\n        coag_gain_i = par.dynamics.get_coagulation_gain_rate_continuous(\n            radius=radius_bins,\n            concentration=distribution_i,\n            kernel=kernel,\n        )\n        coag_loss_i = par.dynamics.get_coagulation_loss_rate_continuous(\n            radius=radius_bins, concentration=distribution_i, kernel=kernel\n        )\n\n        # Calculate the net change in distribution due to coagulation\n        net_change = (coag_gain_i - coag_loss_i) * time_interval\n        distribution_i = distribution_i + net_change\n\n        # Ensure no negative concentrations (set to zero if less than zero)\n        distribution_i[distribution_i &lt; 0] = 0\n\n    # Store the updated distribution for the current time step\n    distribution_time[i, :] = distribution_i\n</pre> # Initial distribution for the simulation distribution_0 = distribution_pdf distribution_i = distribution_0  # Define the time array for the simulation time_array = np.linspace(     start=0, stop=1000, num=50 )  # Time span of 1000 seconds time_interval = (     time_array[1] - time_array[0] )  # Time interval between each step  # Array to store the distribution at each time step distribution_time = np.zeros([len(time_array), len(distribution_0)])  # Simulate the coagulation process over time for i, dpa in enumerate(time_array):     if i &gt; 0:         # Calculate coagulation gain and loss at the current time step         coag_gain_i = par.dynamics.get_coagulation_gain_rate_continuous(             radius=radius_bins,             concentration=distribution_i,             kernel=kernel,         )         coag_loss_i = par.dynamics.get_coagulation_loss_rate_continuous(             radius=radius_bins, concentration=distribution_i, kernel=kernel         )          # Calculate the net change in distribution due to coagulation         net_change = (coag_gain_i - coag_loss_i) * time_interval         distribution_i = distribution_i + net_change          # Ensure no negative concentrations (set to zero if less than zero)         distribution_i[distribution_i &lt; 0] = 0      # Store the updated distribution for the current time step     distribution_time[i, :] = distribution_i <p>Visualizing the Evolution of the Particle Size Distribution</p> <p>After simulating the coagulation process over time, we can visualize how the particle size distribution evolves at different time steps. This plot compares the initial distribution with the distribution at a mid-point and at the end of the simulation, highlighting the changes that occur due to coagulation.</p> In\u00a0[12]: Copied! <pre># Set up the plot\nfig, ax = plt.subplots(1, 1, figsize=[9, 6])\n\n# Define the radius bins\nradius = radius_bins\n\n# Plot the initial distribution, mid-point distribution, and final distribution\nax.semilogx(\n    radius, distribution_0, \"-b\", label=\"Initial\"\n)  # Initial distribution\nax.semilogx(\n    radius, distribution_time[25, :], \"--\", label=\"t-step=25\"\n)  # Mid-point\nax.semilogx(\n    radius, distribution_time[-1, :], \"-r\", label=\"t=end\"\n)  # Final distribution\n\n# Set the limits for the x-axis to focus on the relevant size range\nax.set_xlim([2e-8, 1e-6])\n\n# Add legend to distinguish between different time steps\nax.legend()\n\n# Label the y-axis to indicate concentration units\nax.set_ylabel(r\"Concentration $\\dfrac{1}{m^3 \\cdot m}$\")\n\n# Label the x-axis for particle radius\nax.set_xlabel(\"Radius [m]\")\n\n# Add grid lines for better readability\nax.grid(True, alpha=0.5)\n\n# Show the plot\nplt.show()\n</pre> # Set up the plot fig, ax = plt.subplots(1, 1, figsize=[9, 6])  # Define the radius bins radius = radius_bins  # Plot the initial distribution, mid-point distribution, and final distribution ax.semilogx(     radius, distribution_0, \"-b\", label=\"Initial\" )  # Initial distribution ax.semilogx(     radius, distribution_time[25, :], \"--\", label=\"t-step=25\" )  # Mid-point ax.semilogx(     radius, distribution_time[-1, :], \"-r\", label=\"t=end\" )  # Final distribution  # Set the limits for the x-axis to focus on the relevant size range ax.set_xlim([2e-8, 1e-6])  # Add legend to distinguish between different time steps ax.legend()  # Label the y-axis to indicate concentration units ax.set_ylabel(r\"Concentration $\\dfrac{1}{m^3 \\cdot m}$\")  # Label the x-axis for particle radius ax.set_xlabel(\"Radius [m]\")  # Add grid lines for better readability ax.grid(True, alpha=0.5)  # Show the plot plt.show() <p>Visualizing Particle Size Distribution Evolution Over Time</p> <p>To further understand how the particle size distribution evolves during the coagulation process, we can create a 2D image plot. In this plot, time is represented on the x-axis, particle size (radius) on the y-axis, and the concentration is color-coded. This type of plot provides a comprehensive view of how both small and large particles change in concentration over the entire simulation period.</p> In\u00a0[13]: Copied! <pre># Set up the plot\nfig, ax = plt.subplots(figsize=(10, 6))\n\n# Create an image plot (2D histogram) with time on the x-axis, radius on the y-axis, and concentration as color\nc = ax.pcolormesh(\n    time_array,\n    radius_bins,\n    distribution_time.T,\n    shading=\"auto\",\n    cmap=\"viridis\",\n)\n\n# Set the y-axis to a logarithmic scale to capture the wide range of particle sizes\nax.set_ylim([5e-8, 1e-6])\nax.set_yscale(\"log\")\n\n# Label the axes\nax.set_xlabel(\"Time (s)\")\nax.set_ylabel(\"Particle Radius (m)\")\n\n# Add a color bar to indicate the concentration levels\ncbar = fig.colorbar(c, ax=ax)\ncbar.set_label(r\"Concentration $\\dfrac{1}{m^3 \\cdot m}$\")\n\n# Add a title to the plot\nax.set_title(\"Evolution of Particle Size Distribution Over Time\")\n\n# Show the plot\nplt.show()\n</pre> # Set up the plot fig, ax = plt.subplots(figsize=(10, 6))  # Create an image plot (2D histogram) with time on the x-axis, radius on the y-axis, and concentration as color c = ax.pcolormesh(     time_array,     radius_bins,     distribution_time.T,     shading=\"auto\",     cmap=\"viridis\", )  # Set the y-axis to a logarithmic scale to capture the wide range of particle sizes ax.set_ylim([5e-8, 1e-6]) ax.set_yscale(\"log\")  # Label the axes ax.set_xlabel(\"Time (s)\") ax.set_ylabel(\"Particle Radius (m)\")  # Add a color bar to indicate the concentration levels cbar = fig.colorbar(c, ax=ax) cbar.set_label(r\"Concentration $\\dfrac{1}{m^3 \\cdot m}$\")  # Add a title to the plot ax.set_title(\"Evolution of Particle Size Distribution Over Time\")  # Show the plot plt.show() In\u00a0[15]: Copied! <pre>from scipy.integrate import solve_ivp\nimport numpy as np\n\n\n# Define the coagulation ODE system\ndef coagulation_ode(t, distribution, radius_bins, kernel):\n    \"\"\"\n    Compute the derivative of the distribution with respect to time\n    (i.e., the rate of change due to coagulation).\n\n    Arguments:\n        t: Time variable (not used explicitly here, but required by solve_ivp).\n        distribution: The current particle size distribution (array).\n        radius_bins: The bins for the particle radius.\n        kernel: The coagulation kernel.\n\n    Returns:\n        The time derivative of the particle distribution.\n    \"\"\"\n    coag_gain = par.dynamics.get_coagulation_gain_rate_continuous(\n        radius=radius_bins, concentration=distribution, kernel=kernel\n    )\n    coag_loss = par.dynamics.get_coagulation_loss_rate_continuous(\n        radius=radius_bins, concentration=distribution, kernel=kernel\n    )\n\n    # Net change in distribution due to coagulation\n    net_change = coag_gain - coag_loss\n\n    return net_change\n\n\n# Initial distribution for the simulation\ndistribution_0 = distribution_pdf\n\n# Define the time array for the simulation\ntime_array = np.linspace(\n    start=0, stop=1000, num=50\n)  # Time span of 1000 seconds\n\n# Use scipy's solve_ivp to solve the ODE system\nsolution = solve_ivp(\n    fun=coagulation_ode,  # ODE function\n    t_span=(time_array[0], time_array[-1]),  # Time span\n    y0=distribution_0,  # Initial distribution\n    t_eval=time_array,  # Time points to store the solution\n    args=(\n        radius_bins,\n        kernel,\n    ),  # Additional arguments to coagulation_ode\n    method=\"BDF\",  # Integration method (default)\n    max_step=1e2,\n)\n\n# The solution is stored in solution.y (each column is a time step)\ndistribution_solver = solution.y.T  # Transpose to match original format\n</pre> from scipy.integrate import solve_ivp import numpy as np   # Define the coagulation ODE system def coagulation_ode(t, distribution, radius_bins, kernel):     \"\"\"     Compute the derivative of the distribution with respect to time     (i.e., the rate of change due to coagulation).      Arguments:         t: Time variable (not used explicitly here, but required by solve_ivp).         distribution: The current particle size distribution (array).         radius_bins: The bins for the particle radius.         kernel: The coagulation kernel.      Returns:         The time derivative of the particle distribution.     \"\"\"     coag_gain = par.dynamics.get_coagulation_gain_rate_continuous(         radius=radius_bins, concentration=distribution, kernel=kernel     )     coag_loss = par.dynamics.get_coagulation_loss_rate_continuous(         radius=radius_bins, concentration=distribution, kernel=kernel     )      # Net change in distribution due to coagulation     net_change = coag_gain - coag_loss      return net_change   # Initial distribution for the simulation distribution_0 = distribution_pdf  # Define the time array for the simulation time_array = np.linspace(     start=0, stop=1000, num=50 )  # Time span of 1000 seconds  # Use scipy's solve_ivp to solve the ODE system solution = solve_ivp(     fun=coagulation_ode,  # ODE function     t_span=(time_array[0], time_array[-1]),  # Time span     y0=distribution_0,  # Initial distribution     t_eval=time_array,  # Time points to store the solution     args=(         radius_bins,         kernel,     ),  # Additional arguments to coagulation_ode     method=\"BDF\",  # Integration method (default)     max_step=1e2, )  # The solution is stored in solution.y (each column is a time step) distribution_solver = solution.y.T  # Transpose to match original format In\u00a0[16]: Copied! <pre># Set up the plot\nfig, ax = plt.subplots(1, 1, figsize=[9, 6])\n\n# Define the radius bins\nradius = radius_bins\n\n# Plot the initial distribution, mid-point distribution, and final distribution\nax.semilogx(\n    radius, distribution_solver[0, :], \"-b\", label=\"Initial\"\n)  # Initial distribution\nax.semilogx(\n    radius, distribution_solver[25, :], \"--\", label=\"t-step=25\"\n)  # Mid-point\nax.semilogx(\n    radius, distribution_solver[-1, :], \"-r\", label=\"t=end\"\n)  # Final distribution\n\n# Plot the initial distribution, mid-point distribution, and final distribution\nax.semilogx(\n    radius, distribution_0, \"-b\", label=\"Initial-loop\"\n)  # Initial distribution\nax.semilogx(\n    radius, distribution_time[25, :], \"--\", label=\"t-step=25 loop\"\n)  # Mid-point\nax.semilogx(\n    radius, distribution_time[-1, :], \"-r\", label=\"t=end loop\"\n)  # Final distribution\n\n# Set the limits for the x-axis to focus on the relevant size range\nax.set_xlim([2e-8, 1e-6])\n\n# Add legend to distinguish between different time steps\nax.legend()\n\n# Label the y-axis to indicate concentration units\nax.set_ylabel(r\"Concentration $\\dfrac{1}{m^3 \\cdot m}$\")\n\n# Label the x-axis for particle radius\nax.set_xlabel(\"Radius [m]\")\n\n# Add grid lines for better readability\nax.grid(True, alpha=0.5)\n\n# Show the plot\nplt.show()\n</pre> # Set up the plot fig, ax = plt.subplots(1, 1, figsize=[9, 6])  # Define the radius bins radius = radius_bins  # Plot the initial distribution, mid-point distribution, and final distribution ax.semilogx(     radius, distribution_solver[0, :], \"-b\", label=\"Initial\" )  # Initial distribution ax.semilogx(     radius, distribution_solver[25, :], \"--\", label=\"t-step=25\" )  # Mid-point ax.semilogx(     radius, distribution_solver[-1, :], \"-r\", label=\"t=end\" )  # Final distribution  # Plot the initial distribution, mid-point distribution, and final distribution ax.semilogx(     radius, distribution_0, \"-b\", label=\"Initial-loop\" )  # Initial distribution ax.semilogx(     radius, distribution_time[25, :], \"--\", label=\"t-step=25 loop\" )  # Mid-point ax.semilogx(     radius, distribution_time[-1, :], \"-r\", label=\"t=end loop\" )  # Final distribution  # Set the limits for the x-axis to focus on the relevant size range ax.set_xlim([2e-8, 1e-6])  # Add legend to distinguish between different time steps ax.legend()  # Label the y-axis to indicate concentration units ax.set_ylabel(r\"Concentration $\\dfrac{1}{m^3 \\cdot m}$\")  # Label the x-axis for particle radius ax.set_xlabel(\"Radius [m]\")  # Add grid lines for better readability ax.grid(True, alpha=0.5)  # Show the plot plt.show()"},{"location":"Examples/Dynamics/Coagulation/Functional/Coagulation_Basic_3_compared/#coagulation-basic-3-pmf-vs-pdf","title":"Coagulation Basic 3: PMF vs. PDF\u00b6","text":"<p>In this section, we will compare two fundamental approaches to modeling aerosol particle coagulation: the Probability Mass Function (PMF) and the Probability Density Function (PDF) methods. Both methods offer different perspectives on representing particle size distributions and calculating coagulation rates, which are critical for understanding how particles in aerosols interact and evolve over time.</p>"},{"location":"Examples/Dynamics/Coagulation/Functional/Coagulation_Basic_3_compared/#probability-mass-function-pmf-vs-probability-density-function-pdf","title":"Probability Mass Function (PMF) vs. Probability Density Function (PDF)\u00b6","text":"<ul> <li><p>PMF Representation: The PMF method discretizes the particle size distribution into distinct bins, each representing a specific particle size or mass. This approach counts the number of particles within each bin, making it a straightforward method for tracking how particle populations change due to coagulation. PMF is particularly useful when dealing with discrete particle sizes or when particle number concentrations are of primary interest.</p> </li> <li><p>PDF Representation: In contrast, the PDF method provides a continuous representation of the particle size distribution. Instead of counting particles in discrete bins, PDF describes the likelihood of finding particles within a given size range. This approach is well-suited for scenarios where a smooth distribution of particle sizes is expected or when dealing with very fine size resolutions.</p> </li> </ul>"},{"location":"Examples/Dynamics/Coagulation/Functional/Coagulation_Basic_3_compared/#comparison-objectives","title":"Comparison Objectives\u00b6","text":"<p>The objective of this comparison is to demonstrate how the choice between PMF and PDF representations affects the calculation of coagulation rates and the resulting particle size distributions. By applying both methods to a lognormal size distribution, we will analyze the differences in how each method handles the evolution of particle populations during coagulation.</p> <p>To facilitate this comparison, we will:</p> <ol> <li><p>Initialize Lognormal Distributions: Generate lognormal particle size distributions using both PMF and PDF methods, ensuring that both distributions share the same initial parameters (e.g., mode, geometric standard deviation, and total particle concentration).</p> </li> <li><p>Calculate Coagulation Kernel: Compute the Brownian coagulation kernel using identical environmental conditions (e.g., temperature, pressure, collision efficiency) for both methods. This will allow us to isolate the effect of the distribution representation on the coagulation rates.</p> </li> <li><p>Simulate Coagulation: Simulate the coagulation process over several time steps for both PMF and PDF representations, tracking how the particle size distributions evolve and comparing the results.</p> </li> </ol> <p>By the end of this section, we aim to highlight the strengths and limitations of each method, providing insights into when and why one approach might be preferred over the other in aerosol research and modeling.</p>"},{"location":"Examples/Dynamics/Coagulation/Functional/Coagulation_Basic_3_compared/#setting-up-and-visualizing","title":"Setting Up and Visualizing\u00b6","text":"<p>In this section, we define the parameters for a lognormal particle size distribution and generate both Probability Density Function (PDF) and Probability Mass Function (PMF) representations. We then visualize these distributions to compare how each method represents particle concentrations across different size ranges.</p> <p>Distribution Parameters</p> <p>We start by defining the key parameters for the lognormal distribution:</p> <ul> <li>Mode: The most probable particle size is set to 200 nanometers (200 nm or (200 \\times 10^{-9}) meters).</li> <li>Geometric Standard Deviation: The spread of the distribution is controlled by a geometric standard deviation of 1.5.</li> <li>Total Number Concentration: The total concentration of particles is (1 \\times 10^6) particles per cubic centimeter (cm\u00b3), which we convert to (1 \\times 10^{12}) particles per cubic meter (m\u00b3) for our calculations.</li> </ul> <p>We also define the radius bins, which span a wide range from 1 nanometer to 10 micrometers, using a logarithmic scale to capture the distribution across different particle sizes.</p> <p>Explanation</p> <ul> <li>Parameter Definitions: The mode, geometric standard deviation, and number concentration are clearly defined to set up the lognormal distribution.</li> <li>Distribution Creation: We generate both PDF and PMF representations of the distribution using the defined parameters and radius bins. This allows us to see how each method captures the particle concentrations.</li> <li>Visualization: The plot compares the PDF and PMF distributions on a logarithmic scale, which is essential for accurately displaying the wide range of particle sizes and concentrations. The use of log scales on both axes helps to highlight the differences between the two methods.</li> </ul> <p>By visualizing these distributions side by side, we gain a better understanding of how the PDF and PMF methods differ in representing aerosol particle sizes and concentrations.</p>"},{"location":"Examples/Dynamics/Coagulation/Functional/Coagulation_Basic_3_compared/#rescaling-pdf","title":"Rescaling PDF\u00b6","text":"<p>In this section, we convert the previously generated Probability Density Function (PDF) into a Probability Mass Function (PMF) to directly compare it with the original PMF distribution. This rescaling is necessary because PDF and PMF represent the distribution in different ways, and aligning them allows for a more accurate comparison.</p> <p>Rescaling the PDF</p> <p>The conversion from PDF to PMF involves rescaling the distribution so that the integral of the PDF over each bin corresponds to the particle count in that bin, similar to what is represented in the PMF. This is done using the <code>distribution_convert_pdf_pms</code> function.</p>"},{"location":"Examples/Dynamics/Coagulation/Functional/Coagulation_Basic_3_compared/#rescaling-pmf","title":"Rescaling PMF\u00b6","text":"<p>After converting the PDF to a PMF for direct comparison, we now perform the reverse operation: rescaling the PMF to a PDF. This allows us to compare the original PDF with the PMF that has been adjusted to match the continuous representation of particle concentrations.</p> <p>Rescaling the PMF</p> <p>To rescale the PMF to a PDF, we use the <code>distribution_convert_pdf_pms</code> function. This conversion ensures that the PMF, which originally represented discrete particle counts in each bin, is transformed into a continuous probability density function, aligning it with the original PDF format.</p>"},{"location":"Examples/Dynamics/Coagulation/Functional/Coagulation_Basic_3_compared/#verifying-number-concentration","title":"Verifying Number Concentration\u00b6","text":"<p>In this section, we validate the consistency of the number concentration across different representations (PDF and PMF) by performing numerical integrations and summations. This step ensures that the transformations between PDF and PMF maintain the expected total particle concentrations.</p> <p>Integrating Number Concentration for PDF</p> <p>We first integrate the original PDF distribution and the PMF that has been rescaled to a PDF to check if they yield the same total number concentration. The trapezoidal rule is used for this integration.</p>"},{"location":"Examples/Dynamics/Coagulation/Functional/Coagulation_Basic_3_compared/#small-errors","title":"Small Errors\u00b6","text":"<p>When comparing the total number concentrations derived from the PDF and PMF representations, as well as their rescaled versions, we observe small discrepancies between the values.</p> <p>Sources of Error</p> <p>These small differences arise from several factors inherent in the process of transforming and integrating discrete and continuous distributions:</p> <ol> <li><p>Numerical Approximation:</p> <ul> <li>The integration of the PDF and the summation of the PMF involve numerical approximations, which can introduce small errors. The trapezoidal rule, used for integrating the PDF, is an approximation method that may not perfectly capture the area under the curve, especially when dealing with finely spaced bins or distributions that change rapidly in certain regions.</li> </ul> </li> <li><p>Discretization of Continuous Distributions:</p> <ul> <li>When rescaling a PDF to a PMF or vice versa, we are essentially converting a continuous function into a discrete one, or vice versa. This discretization process can lead to slight inconsistencies because the continuous distribution is approximated by a finite number of bins. The exact alignment of these bins with the underlying distribution is rarely perfect, leading to small errors.</li> </ul> </li> <li><p>Cumulative Effect of Small Differences:</p> <ul> <li>Small differences across many bins can accumulate, resulting in a noticeable discrepancy when summing or integrating over the entire distribution. Even if each individual difference is minute, the total error can be more significant when considering the entire size range.</li> </ul> </li> </ol> <p>Significance of the Errors</p> <p>While these errors are small relative to the total number concentration (less than 1% in this case), they are important to acknowledge when performing precision calculations. In practical applications, these discrepancies are often considered acceptable, but they highlight the importance of understanding the limitations of numerical methods and transformations between different types of distributions.</p> <p>Mitigating the Errors</p> <ul> <li>Increasing the Number of Bins: Using a higher resolution (more bins) can help reduce the error by more closely approximating the continuous distribution.</li> <li>Refining the Interpolation Method: More sophisticated interpolation methods may provide better alignment between the PDF and PMF during the rescaling process, further minimizing errors.</li> <li>Error Analysis: Incorporating error analysis into the calculations can help quantify and understand the impact of these discrepancies on the overall results.</li> </ul> <p>Overall, these small errors are a natural consequence of the numerical techniques used and do not significantly detract from the accuracy of the coagulation modeling. However, being aware of their existence is crucial for interpreting results with a full understanding of the underlying processes.</p>"},{"location":"Examples/Dynamics/Coagulation/Functional/Coagulation_Basic_3_compared/#brownian-coagulation-kernel","title":"Brownian Coagulation Kernel\u00b6","text":"<p>Before comparing the coagulation rates between the Probability Mass Function (PMF) and Probability Density Function (PDF) representations, it is essential to calculate the Brownian coagulation kernel. The kernel quantifies the rate at which particles of different sizes collide and coagulate due to Brownian motion. This matrix is a key component in determining how quickly particles in an aerosol system merge to form larger particles.</p> <p>Calculation of Particle Masses</p> <p>To calculate the coagulation kernel, we first need to determine the mass of particles in each size bin. The mass of a particle is calculated using the formula for the volume of a sphere:</p> <p>$$ m = \\frac{4}{3} \\pi r^3 \\times 1000 \\, \\text{kg/m}^3 $$</p> <p>where $r$  is the particle radius and 1000 kg/m\u00b3 is the assumed density of the particles.</p>"},{"location":"Examples/Dynamics/Coagulation/Functional/Coagulation_Basic_3_compared/#volume-conservation","title":"Volume Conservation\u00b6","text":"<p>In aerosol coagulation processes, one check is to ensure that the total particle volume is conserved. While the number of particles decreases as they coagulate to form larger particles, the total volume of material should remain constant (assuming no other processes such as condensation or evaporation are occurring).</p> <p>In this section, we calculate the gain, loss, and net coagulation rates using the PDF representation and verify that the total volume remains consistent.</p> <p>Calculating Coagulation Rates</p> <p>We start by calculating the gain, loss, and net coagulation rates based on the initial PDF concentration. These rates describe how particles in different size bins gain or lose mass due to coagulation.</p> <p>**Converting to Volume Distribution ** To verify volume conservation, we convert the particle concentration rates (gain, loss, and net) into volume rates by multiplying them by the volume of particles in each size bin. The volume of a particle is given by:</p> <p>$$ V = \\frac{4}{3} \\pi r^3 $$</p>"},{"location":"Examples/Dynamics/Coagulation/Functional/Coagulation_Basic_3_compared/#gain-and-loss-rates-comparison","title":"Gain and Loss Rates Comparison\u00b6","text":"<p>To understand the differences and similarities between the PDF and PMF representations in the context of particle coagulation, we convert the PMF gain and loss rates to their corresponding PDF forms. This allows for a direct comparison of how each representation handles particle concentration changes across different size ranges.</p> <p>Converting PMF to PDF</p> <p>The gain and loss rates calculated for the PMF representation are converted to PDF using the <code>distribution_convert_pdf_pms</code> function. This conversion enables us to plot and compare the results on the same scale and with the same units as the original PDF.</p> <p>Explanation</p> <ul> <li><p>Comparison of Gain and Loss Rates: The first plot compares the gain and loss rates between the original PDF and the converted PMF. By plotting these on the same axes, we can observe how closely the PMF (when converted to PDF) matches the behavior of the original PDF. The solid lines represent the PDF results, while the dashed lines represent the PMF converted to PDF.</p> </li> <li><p>Comparison of Net Rates: The second plot focuses on the net gain and loss rates, which are calculated as the difference between the gain and loss rates. This plot helps in understanding whether the differences in the gain and loss rates between the PDF and converted PMF lead to any significant discrepancies in the overall net rate of particle concentration change.</p> </li> </ul> <p>Interpretation</p> <ul> <li><p>Matching Behavior: Ideally, the converted PMF should closely match the original PDF, indicating that both representations handle coagulation rates similarly. Any differences observed in the plots can provide insights into the nuances of each method, such as how they handle small particle sizes or how numerical approximations might affect the results.</p> </li> <li><p>Significance of Differences: While small differences between the PDF and converted PMF may arise due to numerical methods, these differences can highlight the strengths and limitations of each approach in representing particle size distributions and their evolution during coagulation.</p> </li> </ul> <p>PMF Gain Error</p> <p>The PMF gain rate is slightly off, and we are still looking into the issue. We will update this section once we have resolved the discrepancy.</p>"},{"location":"Examples/Dynamics/Coagulation/Functional/Coagulation_Basic_3_compared/#simulating-pdf-coagulation","title":"Simulating PDF Coagulation\u00b6","text":"<p>In this section, we simulate the evolution of a particle size distribution over time as particles undergo coagulation, using the Probability Density Function (PDF) representation. The simulation tracks how the distribution changes at different time steps, providing insight into how the particle population evolves under the influence of Brownian coagulation.</p> <p>Simulation Setup</p> <ul> <li>Initial Distribution: The simulation begins with the initial particle size distribution (<code>distribution_0</code>), which is based on the PDF calculated earlier.</li> <li>Time Array: The simulation runs over a time span from 0 to 1000 seconds, with 50 discrete time steps. The time interval between each step is calculated to update the distribution as coagulation progresses.</li> </ul>"},{"location":"Examples/Dynamics/Coagulation/Functional/Coagulation_Basic_3_compared/#ode-solver","title":"ODE solver\u00b6","text":"<p>In this section, we simulate the coagulation process using an ordinary differential equation (ODE) solver to track the evolution of particle concentrations in different size bins over time.</p>"},{"location":"Examples/Dynamics/Coagulation/Functional/Coagulation_Basic_3_compared/#comparison-of-different-integration-methods","title":"Comparison of Different Integration Methods\u00b6","text":""},{"location":"Examples/Dynamics/Coagulation/Functional/Coagulation_Basic_4_ParticleResolved/","title":"Coagulation Basic 4: Particle Resolved","text":"In\u00a0[\u00a0]: Copied! <pre># In Colab uncomment the following command to install particula:\n#!pip install particula[extra] --quiet\n# %% particle resolved coagulation example\nimport numpy as np  # For numerical operations and array manipulations\nimport matplotlib.pyplot as plt  # For plotting graphs and visualizations\n\nimport particula as par  # Import the particula module\n</pre> # In Colab uncomment the following command to install particula: #!pip install particula[extra] --quiet # %% particle resolved coagulation example import numpy as np  # For numerical operations and array manipulations import matplotlib.pyplot as plt  # For plotting graphs and visualizations  import particula as par  # Import the particula module In\u00a0[18]: Copied! <pre># lognormal spacing\n\nradius_bins = np.logspace(\n    -9, -6, num=20\n)  # Define the radius bins for the distribution\nmass_bins = (\n    4 / 3 * np.pi * radius_bins**3 * 1000\n)  # Calculate the mass of the particles in the bins\n\nkernel = par.dynamics.get_brownian_kernel_via_system_state(\n    particle_radius=radius_bins,\n    particle_mass=mass_bins,\n    temperature=298.15,\n    pressure=101325,\n)  # Calculate the Brownian coagulation kernel for the radius bins\n\nrandom_generator = np.random.default_rng(12345)\n</pre> # lognormal spacing  radius_bins = np.logspace(     -9, -6, num=20 )  # Define the radius bins for the distribution mass_bins = (     4 / 3 * np.pi * radius_bins**3 * 1000 )  # Calculate the mass of the particles in the bins  kernel = par.dynamics.get_brownian_kernel_via_system_state(     particle_radius=radius_bins,     particle_mass=mass_bins,     temperature=298.15,     pressure=101325, )  # Calculate the Brownian coagulation kernel for the radius bins  random_generator = np.random.default_rng(12345) <p>Sampling the Particle Distribution</p> <p>We then sample particles from the lognormal distribution. These particles will be sorted by size to prepare for the coagulation step.</p> In\u00a0[19]: Copied! <pre># %% sample particle distribution\nparticle_radius = par.particles.get_lognormal_sample_distribution(\n    mode=np.array([1e-8, 1e-7]),\n    geometric_standard_deviation=np.array([1.4, 1.4]),\n    number_of_particles=np.array([5000, 1000]),\n    number_of_samples=10_000,\n)\n# particle_radius = np.sort(particle_radius)\nparticles_original = particle_radius.copy()\n</pre> # %% sample particle distribution particle_radius = par.particles.get_lognormal_sample_distribution(     mode=np.array([1e-8, 1e-7]),     geometric_standard_deviation=np.array([1.4, 1.4]),     number_of_particles=np.array([5000, 1000]),     number_of_samples=10_000, ) # particle_radius = np.sort(particle_radius) particles_original = particle_radius.copy() In\u00a0[20]: Copied! <pre># %% Coagulation step\n\ndelta_t = 100  # time step in seconds\ntotal_number_concentration = 1_000_000 * 1e6  # particles per m^3\ntotal_number_tracked = len(particle_radius)\nvolume_sim = total_number_tracked / total_number_concentration\n\nloss_gain_index = par.dynamics.get_particle_resolved_coagulation_step(\n    particle_radius=particle_radius,\n    kernel=kernel,\n    kernel_radius=radius_bins,\n    volume=volume_sim,\n    time_step=delta_t,\n    random_generator=random_generator,\n)\nparticle_radius, gain, loss = par.dynamics.get_particle_resolved_update_step(\n    particle_radius=particle_radius,\n    gain=np.zeros_like(particle_radius),\n    loss=np.zeros_like(particle_radius),\n    small_index=loss_gain_index[:, 0],\n    large_index=loss_gain_index[:, 1],\n)\n\nprint(loss_gain_index.shape)\nprint(loss_gain_index)\n</pre> # %% Coagulation step  delta_t = 100  # time step in seconds total_number_concentration = 1_000_000 * 1e6  # particles per m^3 total_number_tracked = len(particle_radius) volume_sim = total_number_tracked / total_number_concentration  loss_gain_index = par.dynamics.get_particle_resolved_coagulation_step(     particle_radius=particle_radius,     kernel=kernel,     kernel_radius=radius_bins,     volume=volume_sim,     time_step=delta_t,     random_generator=random_generator, ) particle_radius, gain, loss = par.dynamics.get_particle_resolved_update_step(     particle_radius=particle_radius,     gain=np.zeros_like(particle_radius),     loss=np.zeros_like(particle_radius),     small_index=loss_gain_index[:, 0],     large_index=loss_gain_index[:, 1], )  print(loss_gain_index.shape) print(loss_gain_index) <pre>(3201, 2)\n[[3074 9486]\n [3535 9551]\n [2105 3968]\n ...\n [9772 8800]\n [9111 8947]\n [9496 8414]]\n</pre> <p>Plotting the New Distribution</p> <p>Finally, we plot the particle size distribution before and after coagulation. This visualization helps us understand the effect of the coagulation process on the particle size distribution.</p> In\u00a0[21]: Copied! <pre># %% plot new distribution\nfig, ax = plt.subplots()\nax.hist(\n    particles_original, bins=100, histtype=\"step\", color=\"black\", density=True\n)\nax.hist(\n    particle_radius[particle_radius &gt; 0],\n    bins=100,\n    histtype=\"step\",\n    color=\"blue\",\n    density=True,\n)\nax.set_xscale(\"log\")\nax.set_yscale(\"log\")\nax.set_xlabel(\"Particle radius (m)\")\nax.set_ylabel(\"Frequency\")\nplt.show()\n</pre> # %% plot new distribution fig, ax = plt.subplots() ax.hist(     particles_original, bins=100, histtype=\"step\", color=\"black\", density=True ) ax.hist(     particle_radius[particle_radius &gt; 0],     bins=100,     histtype=\"step\",     color=\"blue\",     density=True, ) ax.set_xscale(\"log\") ax.set_yscale(\"log\") ax.set_xlabel(\"Particle radius (m)\") ax.set_ylabel(\"Frequency\") plt.show() <p>Plotting the Loss and Gain of Particles</p> <p>We also plot the loss and gain of particles due to coagulation. This visualization provides insights into the coagulation process and how it affects the particle population.</p> In\u00a0[22]: Copied! <pre>fig, ax = plt.subplots()\nax.hist(loss[loss &gt; 0], bins=100, histtype=\"step\", color=\"red\", density=True)\nax.hist(gain[gain &gt; 0], bins=100, histtype=\"step\", color=\"green\", density=True)\nax.set_xscale(\"log\")\n# ax.set_yscale(\"log\")\nax.set_xlabel(\"Particle radius (m)\")\nax.set_ylabel(\"Frequency\")\nplt.show()\n</pre> fig, ax = plt.subplots() ax.hist(loss[loss &gt; 0], bins=100, histtype=\"step\", color=\"red\", density=True) ax.hist(gain[gain &gt; 0], bins=100, histtype=\"step\", color=\"green\", density=True) ax.set_xscale(\"log\") # ax.set_yscale(\"log\") ax.set_xlabel(\"Particle radius (m)\") ax.set_ylabel(\"Frequency\") plt.show() In\u00a0[23]: Copied! <pre># Initial distribution for the simulation\nparticles_0 = particles_original\nparticles_i = particles_0\n\n# Define the time array for the simulation\ntime_array = np.linspace(\n    start=0, stop=1000, num=100\n)  # Time span of 1000 seconds\ntime_interval = (\n    time_array[1] - time_array[0]\n)  # Time interval between each step\n\n# Array to store the distribution at each time step\nparticles_matrix = np.zeros([len(time_array), len(particles_0)])\n\n# Simulate the coagulation process over time\nfor i, dpa in enumerate(time_array):\n    if i &gt; 0:\n\n        loss_gain_index = par.dynamics.get_particle_resolved_coagulation_step(\n            particle_radius=particles_i,\n            kernel=kernel,\n            kernel_radius=radius_bins,\n            volume=volume_sim,\n            time_step=time_interval,\n            random_generator=random_generator,\n        )\n        particles_i, _, _ = par.dynamics.get_particle_resolved_update_step(\n            particle_radius=particles_i,\n            gain=np.zeros_like(particles_i),\n            loss=np.zeros_like(particles_i),\n            small_index=loss_gain_index[:, 0],\n            large_index=loss_gain_index[:, 1],\n        )\n\n        # Ensure no negative concentrations (set to zero if less than zero)\n        particles_i[particles_i &lt; 0] = 0\n\n    # Store the updated distribution for the current time step\n    particles_matrix[i, :] = particles_i\n</pre> # Initial distribution for the simulation particles_0 = particles_original particles_i = particles_0  # Define the time array for the simulation time_array = np.linspace(     start=0, stop=1000, num=100 )  # Time span of 1000 seconds time_interval = (     time_array[1] - time_array[0] )  # Time interval between each step  # Array to store the distribution at each time step particles_matrix = np.zeros([len(time_array), len(particles_0)])  # Simulate the coagulation process over time for i, dpa in enumerate(time_array):     if i &gt; 0:          loss_gain_index = par.dynamics.get_particle_resolved_coagulation_step(             particle_radius=particles_i,             kernel=kernel,             kernel_radius=radius_bins,             volume=volume_sim,             time_step=time_interval,             random_generator=random_generator,         )         particles_i, _, _ = par.dynamics.get_particle_resolved_update_step(             particle_radius=particles_i,             gain=np.zeros_like(particles_i),             loss=np.zeros_like(particles_i),             small_index=loss_gain_index[:, 0],             large_index=loss_gain_index[:, 1],         )          # Ensure no negative concentrations (set to zero if less than zero)         particles_i[particles_i &lt; 0] = 0      # Store the updated distribution for the current time step     particles_matrix[i, :] = particles_i <p>Plotting the Final Distribution</p> <p>Finally, we plot the final particle size distribution after multiple coagulation steps. This visualization shows how the particle size distribution evolves over time due to coagulation.</p> In\u00a0[24]: Copied! <pre>filtered = particles_matrix[-1, :] &gt; 0\n\nfig, ax = plt.subplots()\nax.hist(\n    particles_original, bins=100, histtype=\"step\", color=\"black\", density=True\n)\nax.hist(\n    particles_matrix[-1, filtered],\n    bins=100,\n    histtype=\"step\",\n    color=\"blue\",\n    density=True,\n)\nax.set_xscale(\"log\")\nax.set_yscale(\"log\")\nax.set_xlabel(\"Particle radius (m)\")\nax.set_ylabel(\"Frequency\")\nplt.show()\n</pre> filtered = particles_matrix[-1, :] &gt; 0  fig, ax = plt.subplots() ax.hist(     particles_original, bins=100, histtype=\"step\", color=\"black\", density=True ) ax.hist(     particles_matrix[-1, filtered],     bins=100,     histtype=\"step\",     color=\"blue\",     density=True, ) ax.set_xscale(\"log\") ax.set_yscale(\"log\") ax.set_xlabel(\"Particle radius (m)\") ax.set_ylabel(\"Frequency\") plt.show() In\u00a0[25]: Copied! <pre># plot total number of particles\ntotal_number = np.sum(particles_matrix &gt; 0, axis=1)\n\nfig, ax = plt.subplots()\nax.plot(time_array, total_number)\nax.set_xlabel(\"Time (s)\")\nax.set_ylabel(\"Number of particles\")\nplt.show()\n</pre> # plot total number of particles total_number = np.sum(particles_matrix &gt; 0, axis=1)  fig, ax = plt.subplots() ax.plot(time_array, total_number) ax.set_xlabel(\"Time (s)\") ax.set_ylabel(\"Number of particles\") plt.show() In\u00a0[26]: Copied! <pre># convert to concentration\ntotal_concentration = total_number / volume_sim\n\nfig, ax = plt.subplots()\nax.plot(time_array, total_concentration)\nax.set_xlabel(\"Time (s)\")\nax.set_ylabel(r\"Concentration $(m^{-3})$\")\nplt.show()\n</pre> # convert to concentration total_concentration = total_number / volume_sim  fig, ax = plt.subplots() ax.plot(time_array, total_concentration) ax.set_xlabel(\"Time (s)\") ax.set_ylabel(r\"Concentration $(m^{-3})$\") plt.show()"},{"location":"Examples/Dynamics/Coagulation/Functional/Coagulation_Basic_4_ParticleResolved/#coagulation-basic-4-particle-resolved","title":"Coagulation Basic 4: Particle Resolved\u00b6","text":"<p>Introduction</p> <p>In aerosol science, understanding particle-particle interactions is crucial for predicting the evolution of particle size distributions. One such interaction is coagulation, where two particles collide and merge into a larger particle. Accurately modeling coagulation at the level of individual particles is known as the particle-resolved method.</p> <p>The particle-resolved method tracks each particle individually, considering its unique properties and interactions. This method provides the most detailed representation of aerosol dynamics, making it ideal for cases where precision is paramount, such as in cloud microphysics or laboratory-scale studies.</p> <p>However, this approach is computationally intensive because it requires simulating every individual particle and its interactions. Unlike the super droplet method, which uses statistical representations to reduce computational load, the direct particle-resolved method does not aggregate particles into larger groups. Instead, every particle is treated independently, ensuring that every interaction is explicitly modeled.</p> <p>This notebook provides a step-by-step guide to simulating coagulation using a pure particle-resolved approach, demonstrating how individual particles evolve over time without any simplifications or approximations in particle grouping.</p> <p>Setup and Imports</p> <p>We'll start by importing the necessary libraries and setting up the environment.</p>"},{"location":"Examples/Dynamics/Coagulation/Functional/Coagulation_Basic_4_ParticleResolved/#generating-distribution","title":"Generating Distribution\u00b6","text":"<p>In this section, we generate a sample particle size distribution following a lognormal distribution. The lognormal distribution is commonly used in aerosol science to describe particle size distributions.</p> <p>Coagulation Kernel</p> <p>We also calculate the Brownian coagulation kernel for these particles, which quantifies the probability of coagulation between particles of different sizes.</p> <p>Random seed</p> <p>We set a random seed to ensure reproducibility of the results.</p>"},{"location":"Examples/Dynamics/Coagulation/Functional/Coagulation_Basic_4_ParticleResolved/#coagulation-step","title":"Coagulation Step\u00b6","text":"<p>In the coagulation step, particles collide and merge over a given time step. The super droplet method efficiently simulates this process by adjusting the particle sizes and concentrations based on the calculated kernel and the specified volume and time step.</p>"},{"location":"Examples/Dynamics/Coagulation/Functional/Coagulation_Basic_4_ParticleResolved/#direct-time-stepping","title":"Direct Time Stepping\u00b6","text":"<p>With the first coagulation step completed, we can now proceed to the next time step. We repeat the coagulation process for the new particle distribution, updating the particle sizes and concentrations accordingly. This iterative approach allows us to simulate the evolution of the particle size distribution over time.</p> <p>Here we use a simple for loop to perform multiple coagulation steps. In practice, more sophisticated time-stepping methods may be used to improve efficiency and accuracy.</p>"},{"location":"Examples/Dynamics/Coagulation/Functional/Coagulation_Basic_4_ParticleResolved/#conclusion","title":"Conclusion\u00b6","text":"<p>This notebook demonstrated the use of the particle resolved coagulation method to simulate particle coagulation.</p>"},{"location":"Examples/Dynamics/Condensation/Condensation_1_Bin/","title":"Condensation Tutorial: Radius Bin","text":"In\u00a0[\u00a0]: Copied! <pre># In Colab uncomment the following command to install particula:\n#!pip install particula[extra] --quiet\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# particula imports\nimport particula as par\n</pre> # In Colab uncomment the following command to install particula: #!pip install particula[extra] --quiet import numpy as np import matplotlib.pyplot as plt  # particula imports import particula as par In\u00a0[3]: Copied! <pre># Glycerol gas\nmolar_mass_glycerol = 92.09382e-3  # kg/mol\nparameters_clausius = {\n    \"latent_heat\": 71.5 * molar_mass_glycerol,\n    \"latent_heat_units\": \"kJ/mol\",\n    \"temperature_initial\": 125.5,\n    \"temperature_initial_units\": \"degC\",\n    \"pressure_initial\": 1,\n    \"pressure_initial_units\": \"mmHg\",\n}\nvapor_pressure_strategy = par.gas.VaporPressureFactory().get_strategy(\n    \"clausius_clapeyron\", parameters_clausius\n)\n\nsat_concentration = vapor_pressure_strategy.saturation_concentration(\n    molar_mass_glycerol, 298.15\n)\nprint(f\"Saturation concentration: {sat_concentration:.2e} kg/m^3\")\n\nsat_factor = 0.01  # 50% of saturation concentration\nglycerol_gas = (\n    par.gas.GasSpeciesBuilder()\n    .set_molar_mass(molar_mass_glycerol, \"kg/mol\")\n    .set_vapor_pressure_strategy(vapor_pressure_strategy)\n    .set_concentration(sat_concentration * sat_factor, \"kg/m^3\")\n    .set_name(\"Glycerol\")\n    .set_partitioning(True)\n    .build()\n)\n\natmosphere = (\n    par.gas.AtmosphereBuilder()\n    .set_more_partitioning_species(glycerol_gas)\n    .set_temperature(25, temperature_units=\"degC\")\n    .set_pressure(1, pressure_units=\"atm\")\n    .build()\n)\n\n# Glycerol particle distribution\nbins = np.logspace(-8, -5, 500)\nlognormal_rep = (\n    par.particles.PresetParticleRadiusBuilder()\n    .set_mode(np.array([100]), \"nm\")\n    .set_geometric_standard_deviation(np.array([1.3]))\n    .set_number_concentration(np.array([1e4]), \"1/cm^3\")\n    .set_density(1.26, \"g/cm^3\")\n    .set_distribution_type(\"pmf\")\n    .set_radius_bins(bins, \"m\")\n    .build()\n)\n\naerosol = par.Aerosol(atmosphere=atmosphere, particles=lognormal_rep)\n\nprint(aerosol)\n</pre> # Glycerol gas molar_mass_glycerol = 92.09382e-3  # kg/mol parameters_clausius = {     \"latent_heat\": 71.5 * molar_mass_glycerol,     \"latent_heat_units\": \"kJ/mol\",     \"temperature_initial\": 125.5,     \"temperature_initial_units\": \"degC\",     \"pressure_initial\": 1,     \"pressure_initial_units\": \"mmHg\", } vapor_pressure_strategy = par.gas.VaporPressureFactory().get_strategy(     \"clausius_clapeyron\", parameters_clausius )  sat_concentration = vapor_pressure_strategy.saturation_concentration(     molar_mass_glycerol, 298.15 ) print(f\"Saturation concentration: {sat_concentration:.2e} kg/m^3\")  sat_factor = 0.01  # 50% of saturation concentration glycerol_gas = (     par.gas.GasSpeciesBuilder()     .set_molar_mass(molar_mass_glycerol, \"kg/mol\")     .set_vapor_pressure_strategy(vapor_pressure_strategy)     .set_concentration(sat_concentration * sat_factor, \"kg/m^3\")     .set_name(\"Glycerol\")     .set_partitioning(True)     .build() )  atmosphere = (     par.gas.AtmosphereBuilder()     .set_more_partitioning_species(glycerol_gas)     .set_temperature(25, temperature_units=\"degC\")     .set_pressure(1, pressure_units=\"atm\")     .build() )  # Glycerol particle distribution bins = np.logspace(-8, -5, 500) lognormal_rep = (     par.particles.PresetParticleRadiusBuilder()     .set_mode(np.array([100]), \"nm\")     .set_geometric_standard_deviation(np.array([1.3]))     .set_number_concentration(np.array([1e4]), \"1/cm^3\")     .set_density(1.26, \"g/cm^3\")     .set_distribution_type(\"pmf\")     .set_radius_bins(bins, \"m\")     .build() )  aerosol = par.Aerosol(atmosphere=atmosphere, particles=lognormal_rep)  print(aerosol) <pre>Saturation concentration: 2.54e-03 kg/m^3\nGas mixture at 298.15 K, 101325.0 Pa, partitioning=Glycerol, gas_only_species=None\nParticle Representation:\n\tStrategy: RadiiBasedMovingBin\n\tActivity: ActivityIdealMass\n\tSurface: SurfaceStrategyVolume\n\tMass Concentration: 7.194e-08 [kg/m^3]\n\tNumber Concentration: 1.000e+10 [#/m^3]\n</pre> In\u00a0[\u00a0]: Copied! <pre># define the condensation process\ncondensation_isothermal = par.dynamics.CondensationIsothermal(\n    molar_mass=molar_mass_glycerol,\n    diffusion_coefficient=2e-5,\n    accommodation_coefficient=0.1,  # makes things go slower/faster\n)\ncondensation_process = par.dynamics.MassCondensation(\n    condensation_strategy=condensation_isothermal\n)\n\n# define the time array in seconds\ntime_step = 0.5\ntime_array = np.arange(0, 10, time_step)\ntotal_mass = np.zeros_like(time_array)\n\n# output arrays\naerosol_sim = []\n\nrate = condensation_process.rate(aerosol)\n\n# print(f\"Inital rate: {rate[:5]}...\")\n# print(f\"Initial rate shape: {rate.shape}\")\n\nfig, ax = plt.subplots(figsize=(8, 6))\nax.semilogx(\n    aerosol.particles.get_radius() * 1e9,\n    aerosol.particles.concentration,\n    label=\"Initial\",\n)\n# singe step\naerosol = condensation_process.execute(aerosol, time_step)\nax.semilogx(\n    aerosol.particles.get_radius() * 1e9,\n    aerosol.particles.concentration,\n    label=\"After 1 step\",\n)\n# second step\naerosol = condensation_process.execute(aerosol, time_step)\nax.semilogx(\n    aerosol.particles.get_radius() * 1e9,\n    aerosol.particles.concentration,\n    label=\"After 2 steps\",\n)\n# 5th step\naerosol = condensation_process.execute(aerosol, time_step)\naerosol = condensation_process.execute(aerosol, time_step)\naerosol = condensation_process.execute(aerosol, time_step)\nax.semilogx(\n    aerosol.particles.get_radius() * 1e9,\n    aerosol.particles.concentration,\n    label=\"After 5 steps\",\n)\nplt.legend()\nax.set_xlabel(\"Radius (nm)\")\nax.set_ylabel(\"Concentration (1/m^3)\")\nplt.show()\n</pre> # define the condensation process condensation_isothermal = par.dynamics.CondensationIsothermal(     molar_mass=molar_mass_glycerol,     diffusion_coefficient=2e-5,     accommodation_coefficient=0.1,  # makes things go slower/faster ) condensation_process = par.dynamics.MassCondensation(     condensation_strategy=condensation_isothermal )  # define the time array in seconds time_step = 0.5 time_array = np.arange(0, 10, time_step) total_mass = np.zeros_like(time_array)  # output arrays aerosol_sim = []  rate = condensation_process.rate(aerosol)  # print(f\"Inital rate: {rate[:5]}...\") # print(f\"Initial rate shape: {rate.shape}\")  fig, ax = plt.subplots(figsize=(8, 6)) ax.semilogx(     aerosol.particles.get_radius() * 1e9,     aerosol.particles.concentration,     label=\"Initial\", ) # singe step aerosol = condensation_process.execute(aerosol, time_step) ax.semilogx(     aerosol.particles.get_radius() * 1e9,     aerosol.particles.concentration,     label=\"After 1 step\", ) # second step aerosol = condensation_process.execute(aerosol, time_step) ax.semilogx(     aerosol.particles.get_radius() * 1e9,     aerosol.particles.concentration,     label=\"After 2 steps\", ) # 5th step aerosol = condensation_process.execute(aerosol, time_step) aerosol = condensation_process.execute(aerosol, time_step) aerosol = condensation_process.execute(aerosol, time_step) ax.semilogx(     aerosol.particles.get_radius() * 1e9,     aerosol.particles.concentration,     label=\"After 5 steps\", ) plt.legend() ax.set_xlabel(\"Radius (nm)\") ax.set_ylabel(\"Concentration (1/m^3)\") plt.show()"},{"location":"Examples/Dynamics/Condensation/Condensation_1_Bin/#condensation-tutorial-radius-bin","title":"Condensation Tutorial: Radius Bin\u00b6","text":"<p>Work in progress, probably split into multiple notebooks, need to find a model system to test this on</p> <p>Condensation, is the first process where this framework we have been building up is applied. Here we need to account for the gas phase, and the particle phase. Then ensure that the partial pressures of species at the surface of the particle are equal to the partial pressure in the gas.</p> <p>Core Concepts:</p> <ul> <li>Runnable: An abstract base class defining the interface for aerosol transformation processes.<ul> <li>Here and aerosol object is passed to the process, and the process is expected to modify the aerosol object in place, returning the modified object.</li> </ul> </li> <li>MassCondensation: A concrete class implementing the RunnableProcess interface for the condensation process. Is an implementation of a <code>Runnable</code> process that adds mass to the aerosol object based on the partial pressures of the gas phase and the particle phase. Then removes the mass from the gas phase.</li> </ul>"},{"location":"Examples/Dynamics/Condensation/Condensation_1_Bin/#setup-aerosol","title":"Setup Aerosol\u00b6","text":"<p>First we will repeat the aerosol object that we have been using in the previous notebooks. This object will be passed to the <code>Runnable</code> processes <code>MassCondensation</code>, and modified in place.</p>"},{"location":"Examples/Dynamics/Condensation/Condensation_1_Bin/#condensation-process-isothermal","title":"Condensation Process (Isothermal)\u00b6","text":"<p>In code this process is implemented as a <code>Runnable</code> process. This means that the process is expected to modify the aerosol object in place, returning the modified aerosol object. This is defined in <code>Particle_processes.py</code> as the <code>MassCondensation</code> class.</p> <p>The <code>MassCondensation</code> class takes a <code>CondensationStrategy</code> object as an input. This object defines and evaluates the $dm_{i}/dt$ equation for the condensation process. More strategies can be added into the <code>condensation.py</code> file.</p> <p>For now, let's just run it for a few time steps and see what happens.</p> <p>Note: We have a moving bin particle representation, so we would expect all the bins to move.</p>"},{"location":"Examples/Dynamics/Condensation/Condensation_1_Bin/#summary","title":"Summary\u00b6","text":"<p>We built out the condensation process, and the equations that define the process. We also defined the inputs and outputs of the process. Next we will build out coagulation and nucleation processes, to complete the aerosol dynamics framework.</p>"},{"location":"Examples/Dynamics/Condensation/Condensation_2_MassBin/","title":"Condensation Tutorial: Mass Binned","text":"In\u00a0[\u00a0]: Copied! <pre># In Colab uncomment the following command to install particula:\n#!pip install particula[extra] --quiet\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nimport particula as par\n</pre> # In Colab uncomment the following command to install particula: #!pip install particula[extra] --quiet import numpy as np import matplotlib.pyplot as plt  import particula as par In\u00a0[2]: Copied! <pre># Ammonium sulfate and water vapor pressure\nmolar_mass_ammonium_sulfate = 132.14e-3  # kg/mol\nmolar_mass_water = 18.015e-3  # kg/mol\nparameters_vapor = {\n    \"vapor_pressure\": 1e-20,\n    \"vapor_pressure_units\": \"Pa\",\n}\nvapor_pressure_ammonium = par.gas.VaporPressureFactory().get_strategy(\n    \"constant\", parameters_vapor\n)\nvapor_pressure_water = par.gas.VaporPressureFactory().get_strategy(\n    \"water_buck\"\n)\n\nwater_sat = vapor_pressure_water.saturation_concentration(\n    molar_mass=molar_mass_water, temperature=298.15\n)\nwater_concentration = 0.8 * water_sat\n\ncombo_gas = (\n    par.gas.GasSpeciesBuilder()\n    .set_molar_mass(\n        np.array([molar_mass_water, molar_mass_ammonium_sulfate]), \"kg/mol\"\n    )\n    .set_vapor_pressure_strategy(\n        [vapor_pressure_water, vapor_pressure_ammonium]\n    )\n    .set_concentration(np.array([water_concentration, 0.0]), \"kg/m^3\")\n    .set_name([\"H2O\", \"NH4HSO4\"])\n    .set_partitioning(True)\n    .build()\n)\n\natmosphere = (\n    par.gas.AtmosphereBuilder()\n    .set_more_partitioning_species(combo_gas)\n    .set_temperature(25, temperature_units=\"degC\")\n    .set_pressure(1, pressure_units=\"atm\")\n    .build()\n)\n</pre> # Ammonium sulfate and water vapor pressure molar_mass_ammonium_sulfate = 132.14e-3  # kg/mol molar_mass_water = 18.015e-3  # kg/mol parameters_vapor = {     \"vapor_pressure\": 1e-20,     \"vapor_pressure_units\": \"Pa\", } vapor_pressure_ammonium = par.gas.VaporPressureFactory().get_strategy(     \"constant\", parameters_vapor ) vapor_pressure_water = par.gas.VaporPressureFactory().get_strategy(     \"water_buck\" )  water_sat = vapor_pressure_water.saturation_concentration(     molar_mass=molar_mass_water, temperature=298.15 ) water_concentration = 0.8 * water_sat  combo_gas = (     par.gas.GasSpeciesBuilder()     .set_molar_mass(         np.array([molar_mass_water, molar_mass_ammonium_sulfate]), \"kg/mol\"     )     .set_vapor_pressure_strategy(         [vapor_pressure_water, vapor_pressure_ammonium]     )     .set_concentration(np.array([water_concentration, 0.0]), \"kg/m^3\")     .set_name([\"H2O\", \"NH4HSO4\"])     .set_partitioning(True)     .build() )  atmosphere = (     par.gas.AtmosphereBuilder()     .set_more_partitioning_species(combo_gas)     .set_temperature(25, temperature_units=\"degC\")     .set_pressure(1, pressure_units=\"atm\")     .build() ) <p>Sample Distribution</p> <p>Next we'll sample the distribution to get a set of particles. We'll then build an aerosol object to represent the aerosol population.</p> In\u00a0[3]: Copied! <pre># sample\nparticles_sample = par.particles.get_lognormal_sample_distribution(\n    mode=np.array([100, 1000]) * 1e-9,\n    geometric_standard_deviation=np.array([1.3, 1.5]),\n    number_of_particles=np.array([1e3, 1e2]),\n    number_of_samples=1000,\n)\n\n# histogram lognormal\nbins_lognormal = np.logspace(-8, -4, 100)\nbins, edges = np.histogram(particles_sample, bins=bins_lognormal, density=True)\n# plot\nfig, ax = plt.subplots(figsize=(8, 6))\nax.bar(edges[:-1], bins, width=np.diff(edges), align=\"edge\")\nax.set_xscale(\"log\")\nax.set_xlabel(\"Diameter (m)\")\nax.set_ylabel(\"Count\")\nplt.show()\n</pre> # sample particles_sample = par.particles.get_lognormal_sample_distribution(     mode=np.array([100, 1000]) * 1e-9,     geometric_standard_deviation=np.array([1.3, 1.5]),     number_of_particles=np.array([1e3, 1e2]),     number_of_samples=1000, )  # histogram lognormal bins_lognormal = np.logspace(-8, -4, 100) bins, edges = np.histogram(particles_sample, bins=bins_lognormal, density=True) # plot fig, ax = plt.subplots(figsize=(8, 6)) ax.bar(edges[:-1], bins, width=np.diff(edges), align=\"edge\") ax.set_xscale(\"log\") ax.set_xlabel(\"Diameter (m)\") ax.set_ylabel(\"Count\") plt.show() In\u00a0[4]: Copied! <pre># particle radis to mass\ndensity = 1.26e3  # kg/m^3\nparticle_mass = density * 4 / 3 * np.pi * particles_sample**3\nmass_speciation = np.array(\n    [particle_mass * 0, particle_mass]\n).T  # water, ammonium sulfate\nconcentration = np.ones_like(particles_sample) * 1e1\ndensities = np.array([1000, 1.26e3])  # kg/m^3\n\nprint(mass_speciation.shape)\n\nactivity_strat = (\n    par.particles.ActivityKappaParameterBuilder()\n    .set_density(densities, \"kg/m^3\")\n    .set_kappa(np.array([0.0, 0.61]))\n    .set_molar_mass(\n        np.array([molar_mass_water, molar_mass_ammonium_sulfate]), \"kg/mol\"\n    )\n    .set_water_index(0)\n    .build()\n)\n\nsurface_strat = (\n    par.particles.SurfaceStrategyVolumeBuilder()\n    .set_density(densities, \"kg/m^3\")\n    .set_surface_tension(np.array([0.072, 0.092]), \"N/m\")\n    .build()\n)\n\nparitcle_rep = (\n    par.particles.ParticleMassRepresentationBuilder()\n    .set_distribution_strategy(\n        par.particles.SpeciatedMassMovingBinBuilder().build()\n    )\n    .set_surface_strategy(surface_strat)\n    .set_activity_strategy(activity_strat)\n    .set_density(densities, \"kg/m^3\")\n    .set_charge(0.0)\n    .set_mass(mass_speciation, \"kg\")\n    .set_concentration(concentration, \"1/cm^3\")\n    .build()\n)\n\naerosol = par.Aerosol(atmosphere=atmosphere, particles=paritcle_rep)\n\nprint(aerosol)\n</pre> # particle radis to mass density = 1.26e3  # kg/m^3 particle_mass = density * 4 / 3 * np.pi * particles_sample**3 mass_speciation = np.array(     [particle_mass * 0, particle_mass] ).T  # water, ammonium sulfate concentration = np.ones_like(particles_sample) * 1e1 densities = np.array([1000, 1.26e3])  # kg/m^3  print(mass_speciation.shape)  activity_strat = (     par.particles.ActivityKappaParameterBuilder()     .set_density(densities, \"kg/m^3\")     .set_kappa(np.array([0.0, 0.61]))     .set_molar_mass(         np.array([molar_mass_water, molar_mass_ammonium_sulfate]), \"kg/mol\"     )     .set_water_index(0)     .build() )  surface_strat = (     par.particles.SurfaceStrategyVolumeBuilder()     .set_density(densities, \"kg/m^3\")     .set_surface_tension(np.array([0.072, 0.092]), \"N/m\")     .build() )  paritcle_rep = (     par.particles.ParticleMassRepresentationBuilder()     .set_distribution_strategy(         par.particles.SpeciatedMassMovingBinBuilder().build()     )     .set_surface_strategy(surface_strat)     .set_activity_strategy(activity_strat)     .set_density(densities, \"kg/m^3\")     .set_charge(0.0)     .set_mass(mass_speciation, \"kg\")     .set_concentration(concentration, \"1/cm^3\")     .build() )  aerosol = par.Aerosol(atmosphere=atmosphere, particles=paritcle_rep)  print(aerosol) <pre>(1000, 2)\nGas mixture at 298.15 K, 101325.0 Pa, partitioning=['H2O', 'NH4HSO4'], gas_only_species=None\nParticle Representation:\n\tStrategy: SpeciatedMassMovingBin\n\tActivity: ActivityKappaParameter\n\tSurface: SurfaceStrategyVolume\n\tMass Concentration: 9.686e-06 [kg/m^3]\n\tNumber Concentration: 1.000e+10 [#/m^3]\n</pre> In\u00a0[5]: Copied! <pre># define the condensation process\ncondensation_isothermal = par.dynamics.CondensationIsothermal(\n    molar_mass=np.array(\n        [molar_mass_water, molar_mass_ammonium_sulfate]\n    ),  # kg/mol\n    accommodation_coefficient=0.1,  # makes things go slower/faster\n    update_gases=False,\n)\ncondensation_process = par.dynamics.MassCondensation(\n    condensation_strategy=condensation_isothermal\n)\n\n# define the time array in seconds\ntime_step = 11\nsub_steps = 10000\ntime_array = np.arange(0, 5, time_step)\ntotal_mass = np.zeros_like(time_array)\n\n# output arrays\naerosol_sim = []\n\n\nfig, ax = plt.subplots(figsize=(8, 6))\nbins, edges = np.histogram(\n    aerosol.particles.get_radius(), bins=bins_lognormal\n)\nax.bar(edges[:-1], bins, width=np.diff(edges), align=\"edge\", label=\"Initial\")\n\nprint(aerosol)\n# one step\naerosol = condensation_process.execute(aerosol, time_step, sub_steps)\nbins, edges = np.histogram(\n    aerosol.particles.get_radius(), bins=bins_lognormal\n)\nax.bar(\n    edges[:-1],\n    bins,\n    width=np.diff(edges),\n    align=\"edge\",\n    label=\"After 1 step\",\n    alpha=0.8,\n)\n\nprint(aerosol)\n# 10 seconds\naerosol = condensation_process.execute(aerosol, time_step, sub_steps)\nbins, edges = np.histogram(\n    aerosol.particles.get_radius(), bins=bins_lognormal\n)\nax.bar(\n    edges[:-1],\n    bins,\n    width=np.diff(edges),\n    align=\"edge\",\n    label=\"After 2 steps\",\n    alpha=0.7,\n)\nprint(aerosol)\n\nax.set_xscale(\"log\")\n# ax.set_yscale(\"log\")\nplt.legend()\nax.set_xlabel(\"Radius (m)\")\nax.set_ylabel(\"Concentration (1/m^3)\")\nplt.show()\n</pre> # define the condensation process condensation_isothermal = par.dynamics.CondensationIsothermal(     molar_mass=np.array(         [molar_mass_water, molar_mass_ammonium_sulfate]     ),  # kg/mol     accommodation_coefficient=0.1,  # makes things go slower/faster     update_gases=False, ) condensation_process = par.dynamics.MassCondensation(     condensation_strategy=condensation_isothermal )  # define the time array in seconds time_step = 11 sub_steps = 10000 time_array = np.arange(0, 5, time_step) total_mass = np.zeros_like(time_array)  # output arrays aerosol_sim = []   fig, ax = plt.subplots(figsize=(8, 6)) bins, edges = np.histogram(     aerosol.particles.get_radius(), bins=bins_lognormal ) ax.bar(edges[:-1], bins, width=np.diff(edges), align=\"edge\", label=\"Initial\")  print(aerosol) # one step aerosol = condensation_process.execute(aerosol, time_step, sub_steps) bins, edges = np.histogram(     aerosol.particles.get_radius(), bins=bins_lognormal ) ax.bar(     edges[:-1],     bins,     width=np.diff(edges),     align=\"edge\",     label=\"After 1 step\",     alpha=0.8, )  print(aerosol) # 10 seconds aerosol = condensation_process.execute(aerosol, time_step, sub_steps) bins, edges = np.histogram(     aerosol.particles.get_radius(), bins=bins_lognormal ) ax.bar(     edges[:-1],     bins,     width=np.diff(edges),     align=\"edge\",     label=\"After 2 steps\",     alpha=0.7, ) print(aerosol)  ax.set_xscale(\"log\") # ax.set_yscale(\"log\") plt.legend() ax.set_xlabel(\"Radius (m)\") ax.set_ylabel(\"Concentration (1/m^3)\") plt.show() <pre>Gas mixture at 298.15 K, 101325.0 Pa, partitioning=['H2O', 'NH4HSO4'], gas_only_species=None\nParticle Representation:\n\tStrategy: SpeciatedMassMovingBin\n\tActivity: ActivityKappaParameter\n\tSurface: SurfaceStrategyVolume\n\tMass Concentration: 9.686e-06 [kg/m^3]\n\tNumber Concentration: 1.000e+10 [#/m^3]\nGas mixture at 298.15 K, 101325.0 Pa, partitioning=['H2O', 'NH4HSO4'], gas_only_species=None\nParticle Representation:\n\tStrategy: SpeciatedMassMovingBin\n\tActivity: ActivityKappaParameter\n\tSurface: SurfaceStrategyVolume\n\tMass Concentration: 2.838e-05 [kg/m^3]\n\tNumber Concentration: 1.000e+10 [#/m^3]\nGas mixture at 298.15 K, 101325.0 Pa, partitioning=['H2O', 'NH4HSO4'], gas_only_species=None\nParticle Representation:\n\tStrategy: SpeciatedMassMovingBin\n\tActivity: ActivityKappaParameter\n\tSurface: SurfaceStrategyVolume\n\tMass Concentration: 2.838e-05 [kg/m^3]\n\tNumber Concentration: 1.000e+10 [#/m^3]\n</pre>"},{"location":"Examples/Dynamics/Condensation/Condensation_2_MassBin/#condensation-tutorial-mass-binned","title":"Condensation Tutorial: Mass Binned\u00b6","text":"<p>NEEDS REVISION: integration unstable</p> <p>A mass binned model is relaxes the assumption of a single composition for all particles in a given bin. Instead, it allows for a distribution of compositions within each bin. This is useful when the composition of particles is separated by masses. This does not account for the same sized particles having different compositions, but rather different sized particles having different compositions.</p>"},{"location":"Examples/Dynamics/Condensation/Condensation_2_MassBin/#aerosol-setup","title":"Aerosol Setup\u00b6","text":"<p>First we'll draw from a lognormal distribution to create a set of particles. We'll will then build an aerosol object to represent the aerosol population.</p>"},{"location":"Examples/Dynamics/Condensation/Condensation_2_MassBin/#condensation-process","title":"Condensation Process\u00b6","text":"<p>Using the same iso thermal condensation process as in the bulk model, we'll update the properties of the particles in the aerosol object. In this cas we will change the water saturation ratio to be 80% and simulate the condensation process.</p>"},{"location":"Examples/Dynamics/Condensation/Condensation_2_MassBin/#summary","title":"Summary\u00b6","text":"<p>We built out the condensation process, and the equations that define the process. We also defined the inputs and outputs of the process. Next we will build out coagulation and nucleation processes, to complete the aerosol dynamics framework.</p>"},{"location":"Examples/Dynamics/Condensation/Condensation_3_MassResolved/","title":"Condensation Tutorial: Particle Resolved","text":"In\u00a0[\u00a0]: Copied! <pre># In Colab uncomment the following command to install particula:\n#!pip install particula[extra] --quiet\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nimport particula as par\n</pre> # In Colab uncomment the following command to install particula: #!pip install particula[extra] --quiet import numpy as np import matplotlib.pyplot as plt  import particula as par In\u00a0[2]: Copied! <pre>initial_water_vapor_activity = 1.025  # Relative humidity/100\n\n# Ammonium sulfate and water vapor pressure\nmolar_mass_ammonium_sulfate = 132.14e-3  # kg/mol\nmolar_mass_water = 18.015e-3  # kg/mol\nparameters_vapor = {\n    \"vapor_pressure\": 1e-24,\n    \"vapor_pressure_units\": \"Pa\",\n}\nvapor_pressure_ammonium = par.gas.VaporPressureFactory().get_strategy(\n    \"constant\", parameters_vapor\n)\nvapor_pressure_water = par.gas.VaporPressureFactory().get_strategy(\n    \"water_buck\"\n)\n\nwater_sat = vapor_pressure_water.saturation_concentration(\n    molar_mass=molar_mass_water, temperature=298.15\n)\nwater_concentration = water_sat * initial_water_vapor_activity\n\ngas_phase = (\n    par.gas.GasSpeciesBuilder()\n    .set_molar_mass(\n        np.array([molar_mass_water, molar_mass_ammonium_sulfate]), \"kg/mol\"\n    )\n    .set_vapor_pressure_strategy(\n        [vapor_pressure_water, vapor_pressure_ammonium]\n    )\n    .set_concentration(np.array([water_concentration, 1e-30]), \"kg/m^3\")\n    .set_name([\"H2O\", \"NH4HSO4\"])\n    .set_partitioning(True)\n    .build()\n)\n\natmosphere = (\n    par.gas.AtmosphereBuilder()\n    .set_more_partitioning_species(gas_phase)\n    .set_temperature(25, temperature_units=\"degC\")\n    .set_pressure(1, pressure_units=\"atm\")\n    .build()\n)\n</pre> initial_water_vapor_activity = 1.025  # Relative humidity/100  # Ammonium sulfate and water vapor pressure molar_mass_ammonium_sulfate = 132.14e-3  # kg/mol molar_mass_water = 18.015e-3  # kg/mol parameters_vapor = {     \"vapor_pressure\": 1e-24,     \"vapor_pressure_units\": \"Pa\", } vapor_pressure_ammonium = par.gas.VaporPressureFactory().get_strategy(     \"constant\", parameters_vapor ) vapor_pressure_water = par.gas.VaporPressureFactory().get_strategy(     \"water_buck\" )  water_sat = vapor_pressure_water.saturation_concentration(     molar_mass=molar_mass_water, temperature=298.15 ) water_concentration = water_sat * initial_water_vapor_activity  gas_phase = (     par.gas.GasSpeciesBuilder()     .set_molar_mass(         np.array([molar_mass_water, molar_mass_ammonium_sulfate]), \"kg/mol\"     )     .set_vapor_pressure_strategy(         [vapor_pressure_water, vapor_pressure_ammonium]     )     .set_concentration(np.array([water_concentration, 1e-30]), \"kg/m^3\")     .set_name([\"H2O\", \"NH4HSO4\"])     .set_partitioning(True)     .build() )  atmosphere = (     par.gas.AtmosphereBuilder()     .set_more_partitioning_species(gas_phase)     .set_temperature(25, temperature_units=\"degC\")     .set_pressure(1, pressure_units=\"atm\")     .build() ) <p>Sample Distribution</p> <p>Next we'll sample the distribution to get a set of particles. We'll then build an aerosol object to represent the aerosol population.</p> In\u00a0[3]: Copied! <pre>density = 1.77e3  # kg/m^3\nvolume_sim = 1 * par.util.get_unit_conversion(\"cm^3\", \"m^3\")  # m^3\nnumber_of_samples = 10_000\n\n# Generate a particle distribution using a lognormal sample distribution\n# This distribution has a mean particle diameter (mode) and geometric standard deviation (GSD)\nparticle_sample = par.particles.get_lognormal_sample_distribution(\n    mode=np.array([100, 400]) * 1e-9,\n    geometric_standard_deviation=np.array([1.3, 1.4]),\n    number_of_particles=np.array([1, 0.5]),  # relative to each mode\n    number_of_samples=number_of_samples,  # Number of samples for particle distribution\n)\n\n# Calculate the mass of each particle in the sample, assuming density of 1500 kg/m^3\nparticle_mass = (\n    4 / 3 * np.pi * particle_sample**3 * density\n)  # Particle mass in kg\n\nmass_speciation = np.column_stack(\n    [particle_mass * 0, particle_mass]\n)  # water, ammonium sulfate\ndensities = np.array([1000, density])  # kg/m^3\n\n# kappa activity\nactivity_strat = (\n    par.particles.ActivityKappaParameterBuilder()\n    .set_density(densities, \"kg/m^3\")\n    .set_kappa(np.array([0.0, 0.61]))\n    .set_molar_mass(\n        np.array([molar_mass_water, molar_mass_ammonium_sulfate]), \"kg/mol\"\n    )\n    .set_water_index(0)\n    .build()\n)\n\nsurface_strat = (\n    par.particles.SurfaceStrategyVolumeBuilder()\n    .set_density(densities, \"kg/m^3\")\n    .set_surface_tension(np.array([0.072, 0.092]), \"N/m\")\n    .build()\n)\n\n\n# Build a resolved mass representation for each particle\n# This defines how particle mass, activity, and surface are represented\nresolved_masses = (\n    par.particles.ResolvedParticleMassRepresentationBuilder()\n    .set_distribution_strategy(\n        par.particles.ParticleResolvedSpeciatedMass()\n    )  # Use speciated mass distribution\n    .set_activity_strategy(\n        activity_strat\n    )  # Define activity based on ideal mass\n    .set_surface_strategy(\n        surface_strat\n    )  # Define surface area based on particle volume\n    .set_mass(mass_speciation, \"kg\")  # Assign mass of particles (in kg)\n    .set_density(densities, \"kg/m^3\")  # Set particle density to 1500 kg/m^3\n    .set_charge(0)  # Assume neutral particles with no charge\n    .set_volume(volume_sim, \"m^3\")  # Set volume of particle distribution\n    .build()  # Finalize the resolved mass representation\n)\n\n# Create an aerosol object with the defined atmosphere and resolved particles\naerosol_resolved = par.Aerosol(\n    atmosphere=atmosphere, particles=resolved_masses\n)\n\n# Print the properties of the atmosphere\nprint(aerosol_resolved)\n</pre> density = 1.77e3  # kg/m^3 volume_sim = 1 * par.util.get_unit_conversion(\"cm^3\", \"m^3\")  # m^3 number_of_samples = 10_000  # Generate a particle distribution using a lognormal sample distribution # This distribution has a mean particle diameter (mode) and geometric standard deviation (GSD) particle_sample = par.particles.get_lognormal_sample_distribution(     mode=np.array([100, 400]) * 1e-9,     geometric_standard_deviation=np.array([1.3, 1.4]),     number_of_particles=np.array([1, 0.5]),  # relative to each mode     number_of_samples=number_of_samples,  # Number of samples for particle distribution )  # Calculate the mass of each particle in the sample, assuming density of 1500 kg/m^3 particle_mass = (     4 / 3 * np.pi * particle_sample**3 * density )  # Particle mass in kg  mass_speciation = np.column_stack(     [particle_mass * 0, particle_mass] )  # water, ammonium sulfate densities = np.array([1000, density])  # kg/m^3  # kappa activity activity_strat = (     par.particles.ActivityKappaParameterBuilder()     .set_density(densities, \"kg/m^3\")     .set_kappa(np.array([0.0, 0.61]))     .set_molar_mass(         np.array([molar_mass_water, molar_mass_ammonium_sulfate]), \"kg/mol\"     )     .set_water_index(0)     .build() )  surface_strat = (     par.particles.SurfaceStrategyVolumeBuilder()     .set_density(densities, \"kg/m^3\")     .set_surface_tension(np.array([0.072, 0.092]), \"N/m\")     .build() )   # Build a resolved mass representation for each particle # This defines how particle mass, activity, and surface are represented resolved_masses = (     par.particles.ResolvedParticleMassRepresentationBuilder()     .set_distribution_strategy(         par.particles.ParticleResolvedSpeciatedMass()     )  # Use speciated mass distribution     .set_activity_strategy(         activity_strat     )  # Define activity based on ideal mass     .set_surface_strategy(         surface_strat     )  # Define surface area based on particle volume     .set_mass(mass_speciation, \"kg\")  # Assign mass of particles (in kg)     .set_density(densities, \"kg/m^3\")  # Set particle density to 1500 kg/m^3     .set_charge(0)  # Assume neutral particles with no charge     .set_volume(volume_sim, \"m^3\")  # Set volume of particle distribution     .build()  # Finalize the resolved mass representation )  # Create an aerosol object with the defined atmosphere and resolved particles aerosol_resolved = par.Aerosol(     atmosphere=atmosphere, particles=resolved_masses )  # Print the properties of the atmosphere print(aerosol_resolved) <pre>Gas mixture at 298.15 K, 101325.0 Pa, partitioning=['H2O', 'NH4HSO4'], gas_only_species=None\nParticle Representation:\n\tStrategy: ParticleResolvedSpeciatedMass\n\tActivity: ActivityKappaParameter\n\tSurface: SurfaceStrategyVolume\n\tMass Concentration: 2.676e-06 [kg/m^3]\n\tNumber Concentration: 1.000e+10 [#/m^3]\n</pre> In\u00a0[4]: Copied! <pre># define the condensation process\ncondensation_isothermal = par.dynamics.CondensationIsothermal(\n    molar_mass=np.array(\n        [molar_mass_water, molar_mass_ammonium_sulfate]\n    ),  # kg/mol\n    diffusion_coefficient=2e-5,  # m^2/s\n    accommodation_coefficient=1,  # makes things go slower/faster\n    update_gases=True,\n)\ncondensation_process = par.dynamics.MassCondensation(\n    condensation_strategy=condensation_isothermal\n)\n\n# Set up time and sub-steps for the coagulation process\ntotal_time = 10\ntime_step = 0.01\nsub_steps = 10\n\n# bins\nbins_lognormal = np.logspace(-8, -4, 200)\n\n\n# output arrays\ntime = np.arange(0, total_time, time_step)\ntotal_mass_resolved = np.ones_like(time, dtype=np.float64)\nnumber_distribution_resolved = np.zeros((len(time), number_of_samples))\nnumber_distribution_binned = np.zeros((len(time), len(bins_lognormal) - 1))\ntotal_number_resolved = np.ones_like(time, dtype=np.float64)\nwater_saturation_in_time = np.ones_like(time, dtype=np.float64)\n\nprint(f\"Total iterations to do: {len(time)*sub_steps}\")\n</pre> # define the condensation process condensation_isothermal = par.dynamics.CondensationIsothermal(     molar_mass=np.array(         [molar_mass_water, molar_mass_ammonium_sulfate]     ),  # kg/mol     diffusion_coefficient=2e-5,  # m^2/s     accommodation_coefficient=1,  # makes things go slower/faster     update_gases=True, ) condensation_process = par.dynamics.MassCondensation(     condensation_strategy=condensation_isothermal )  # Set up time and sub-steps for the coagulation process total_time = 10 time_step = 0.01 sub_steps = 10  # bins bins_lognormal = np.logspace(-8, -4, 200)   # output arrays time = np.arange(0, total_time, time_step) total_mass_resolved = np.ones_like(time, dtype=np.float64) number_distribution_resolved = np.zeros((len(time), number_of_samples)) number_distribution_binned = np.zeros((len(time), len(bins_lognormal) - 1)) total_number_resolved = np.ones_like(time, dtype=np.float64) water_saturation_in_time = np.ones_like(time, dtype=np.float64)  print(f\"Total iterations to do: {len(time)*sub_steps}\") <pre>Total iterations to do: 10000\n</pre> In\u00a0[7]: Copied! <pre># Simulation loop\nfor i, t in enumerate(time):\n    if i &gt; 0:\n        # Perform condensation for the resolved aerosol\n        aerosol_resolved = condensation_process.execute(\n            aerosol_resolved, time_step, sub_steps\n        )\n\n    total_mass_resolved[i] = aerosol_resolved.particles.get_mass_concentration()\n    number_distribution_resolved[i, :] = aerosol_resolved.particles.get_radius(clone=True)\n    number_distribution_binned[i, :], edges = np.histogram(\n        number_distribution_resolved[i, :], bins=bins_lognormal\n    )\n    total_number_resolved[i] = np.sum(number_distribution_resolved[i, :] &gt; 0)\n    water_saturation_in_time[i] = aerosol_resolved.atmosphere.partitioning_species.get_saturation_ratio(temperature=298.15)[0]\n\n\nnumber_distribution_binned = number_distribution_binned / volume_sim\n\nprint(aerosol_resolved)\n</pre> # Simulation loop for i, t in enumerate(time):     if i &gt; 0:         # Perform condensation for the resolved aerosol         aerosol_resolved = condensation_process.execute(             aerosol_resolved, time_step, sub_steps         )      total_mass_resolved[i] = aerosol_resolved.particles.get_mass_concentration()     number_distribution_resolved[i, :] = aerosol_resolved.particles.get_radius(clone=True)     number_distribution_binned[i, :], edges = np.histogram(         number_distribution_resolved[i, :], bins=bins_lognormal     )     total_number_resolved[i] = np.sum(number_distribution_resolved[i, :] &gt; 0)     water_saturation_in_time[i] = aerosol_resolved.atmosphere.partitioning_species.get_saturation_ratio(temperature=298.15)[0]   number_distribution_binned = number_distribution_binned / volume_sim  print(aerosol_resolved) <pre>Gas mixture at 298.15 K, 101325.0 Pa, partitioning=['H2O', 'NH4HSO4'], gas_only_species=None\nParticle Representation:\n\tStrategy: ParticleResolvedSpeciatedMass\n\tActivity: ActivityKappaParameter\n\tSurface: SurfaceStrategyVolume\n\tMass Concentration: 6.033e-04 [kg/m^3]\n\tNumber Concentration: 1.000e+10 [#/m^3]\n</pre> In\u00a0[\u00a0]: Copied! <pre># plot the initial and final distributions\nfig, ax = plt.subplots(figsize=(8, 5))\n\nax.bar(\n    edges[:-1],\n    number_distribution_binned[0, :],\n    width=np.diff(edges),\n    align=\"edge\",\n    label=\"Resolved initial\",\n    color=\"red\",\n    alpha=0.7,\n)\nplot_index = 100\nax.bar(\n    edges[:-1],\n    number_distribution_binned[plot_index, :],\n    width=np.diff(edges),\n    align=\"edge\",\n    label=\"CCN overshoot time: {:.1f} s\".format(time[plot_index]),\n    color=\"purple\",\n    alpha=0.5,\n)\nax.bar(\n    edges[:-1],\n    number_distribution_binned[-1, :],\n    width=np.diff(edges),\n    align=\"edge\",\n    label=\"Resolved final\",\n    color=\"blue\",\n    alpha=0.7,\n)\nax.set_yscale(\"log\")\nax.set_xscale(\"log\")\nax.set_xlabel(\"Particle radius (m)\")\nax.set_ylabel(\"Number concentration (m^-3)\")\nax.legend()\nplt.show()\n</pre> # plot the initial and final distributions fig, ax = plt.subplots(figsize=(8, 5))  ax.bar(     edges[:-1],     number_distribution_binned[0, :],     width=np.diff(edges),     align=\"edge\",     label=\"Resolved initial\",     color=\"red\",     alpha=0.7, ) plot_index = 100 ax.bar(     edges[:-1],     number_distribution_binned[plot_index, :],     width=np.diff(edges),     align=\"edge\",     label=\"CCN overshoot time: {:.1f} s\".format(time[plot_index]),     color=\"purple\",     alpha=0.5, ) ax.bar(     edges[:-1],     number_distribution_binned[-1, :],     width=np.diff(edges),     align=\"edge\",     label=\"Resolved final\",     color=\"blue\",     alpha=0.7, ) ax.set_yscale(\"log\") ax.set_xscale(\"log\") ax.set_xlabel(\"Particle radius (m)\") ax.set_ylabel(\"Number concentration (m^-3)\") ax.legend() plt.show() In\u00a0[\u00a0]: Copied! <pre>fig, ax = plt.subplots(figsize=(8, 5))\n\n# Swap X and Y to reverse axes\nX, Y = np.meshgrid(\n    time, edges[:-1]\n)  # Now time is on the x-axis and edges on the y-axis\n\n# Plot the contour with updated X and Y\nlog_of_number_distribution_binned = np.log10(\n    number_distribution_binned,\n    out=np.nan * np.ones_like(number_distribution_binned),\n    where=number_distribution_binned &gt; 0,\n)\ncontour = ax.contourf(\n    X,\n    Y,\n    log_of_number_distribution_binned.T,\n    cmap=\"viridis\",\n    vmin=5,\n)\n\n# Add the color bar\ncbar = fig.colorbar(contour)\ncbar.set_label(\"Log10 of Number concentration (m^-3)\")\n\nax.set_ylim([1e-8, 1e-5])  # Set limits for y-axis\n\n# Set axis labels\nax.set_yscale(\"log\")  # Log scale for particle radius on y-axis\nax.set_xlabel(\"Time (s)\")\nax.set_ylabel(\"Particle radius (m)\")\nfig.tight_layout()\nplt.show()\n</pre> fig, ax = plt.subplots(figsize=(8, 5))  # Swap X and Y to reverse axes X, Y = np.meshgrid(     time, edges[:-1] )  # Now time is on the x-axis and edges on the y-axis  # Plot the contour with updated X and Y log_of_number_distribution_binned = np.log10(     number_distribution_binned,     out=np.nan * np.ones_like(number_distribution_binned),     where=number_distribution_binned &gt; 0, ) contour = ax.contourf(     X,     Y,     log_of_number_distribution_binned.T,     cmap=\"viridis\",     vmin=5, )  # Add the color bar cbar = fig.colorbar(contour) cbar.set_label(\"Log10 of Number concentration (m^-3)\")  ax.set_ylim([1e-8, 1e-5])  # Set limits for y-axis  # Set axis labels ax.set_yscale(\"log\")  # Log scale for particle radius on y-axis ax.set_xlabel(\"Time (s)\") ax.set_ylabel(\"Particle radius (m)\") fig.tight_layout() plt.show() In\u00a0[\u00a0]: Copied! <pre># plot the total mass and water saturation on twin y-axis\nfig, ax1 = plt.subplots(figsize=(8, 5))\n\nax1.plot(time, total_mass_resolved, label=\"Total mass\", color=\"blue\")\nax1.set_xlabel(\"Time (s)\")\nax1.set_ylabel(\"Total Particle mass (kg/m^3)\", color=\"blue\")\nax1.tick_params(axis=\"y\", labelcolor=\"blue\")\n\nax2 = ax1.twinx()\nax2.plot(time, water_saturation_in_time, label=\"Water saturation\", color=\"red\")\nax2.set_ylabel(\"Water saturation\", color=\"red\")\nax2.tick_params(axis=\"y\", labelcolor=\"red\")\n\nfig.tight_layout()\nplt.show()\n</pre> # plot the total mass and water saturation on twin y-axis fig, ax1 = plt.subplots(figsize=(8, 5))  ax1.plot(time, total_mass_resolved, label=\"Total mass\", color=\"blue\") ax1.set_xlabel(\"Time (s)\") ax1.set_ylabel(\"Total Particle mass (kg/m^3)\", color=\"blue\") ax1.tick_params(axis=\"y\", labelcolor=\"blue\")  ax2 = ax1.twinx() ax2.plot(time, water_saturation_in_time, label=\"Water saturation\", color=\"red\") ax2.set_ylabel(\"Water saturation\", color=\"red\") ax2.tick_params(axis=\"y\", labelcolor=\"red\")  fig.tight_layout() plt.show()"},{"location":"Examples/Dynamics/Condensation/Condensation_3_MassResolved/#condensation-tutorial-particle-resolved","title":"Condensation Tutorial: Particle Resolved\u00b6","text":"<p>A particle resolved model is a model that tracks the properties of individual particles or collection of particles (e.g., super droplets). This is in contrast to a bulk model, which tracks the properties of the entire aerosol population. The particle resolved model can be more computationally expensive, but can provide more detailed information about the aerosol population.</p> <p>To run this type of model we will need to use a speciated distribution representation. This is so that we can track the properties of individual particles.</p>"},{"location":"Examples/Dynamics/Condensation/Condensation_3_MassResolved/#setup-aerosol","title":"Setup Aerosol\u00b6","text":"<p>First we'll draw from a lognormal distribution to create a set of particles. We'll will then build an aerosol object to represent the aerosol population.</p>"},{"location":"Examples/Dynamics/Condensation/Condensation_3_MassResolved/#condensation-process","title":"Condensation Process\u00b6","text":"<p>Using the same iso thermal condensation process we now setup the particle resolved simulation. We'll track the properties of each particle as they grow.</p>"},{"location":"Examples/Dynamics/Condensation/Condensation_3_MassResolved/#visualization","title":"Visualization\u00b6","text":"<p>Finally we'll visualize the results of the simulation. The first plot is a histogram of the particle size distribution. The second plot is 2D distribution plot vs time. Third is our limiting varible of water vapor saturation ratio, and the mass transferred to the particles.</p>"},{"location":"Examples/Dynamics/Condensation/Condensation_3_MassResolved/#summary","title":"Summary\u00b6","text":"<p>This tutorial demonstrates how to run a particle resolved model. We performed a cloud condensation simulation and visualized the results. We can see once the aerosol particles activate there is a redistribution of water vapor to the larger particles as the smaller ones are out of equilibrium and evaporate.</p>"},{"location":"Examples/Dynamics/Customization/Adding_Particles_During_Simulation/","title":"Adding Particles During Simulation","text":"In\u00a0[\u00a0]: Copied! <pre># In Colab uncomment the following command to install particula:\n#!pip install particula[extra] --quiet\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# particula imports\nimport particula as par\n</pre> # In Colab uncomment the following command to install particula: #!pip install particula[extra] --quiet import numpy as np import matplotlib.pyplot as plt  # particula imports import particula as par In\u00a0[6]: Copied! <pre># Preset gas species that does not condense in the atmosphere\n# AtmosphereBuilder constructs the atmosphere with predefined species\natmosphere = (\n    par.gas.AtmosphereBuilder()\n    .set_temperature(25, temperature_units=\"degC\")  # Set temperature to 25\u00b0C\n    .set_pressure(1, pressure_units=\"atm\")  # Set pressure to 1 atmosphere\n    .build()  # Finalize the atmosphere object\n)\n\n# Generate a particle distribution using a lognormal sample distribution\n# This distribution has a mean particle diameter (mode) and geometric standard deviation (GSD)\nparticle_sample = par.particles.get_lognormal_sample_distribution(\n    mode=np.array([100e-9]),  # Mean particle diameter of 100 nm\n    geometric_standard_deviation=np.array([1.3]),  # GSD of 1.3\n    number_of_particles=np.array([1e4]),  # Total number of particles\n    number_of_samples=100_000,  # Number of samples for particle distribution\n)\n\n# Calculate the mass of each particle in the sample, assuming density of 1500 kg/m^3\nparticle_mass_sample = (\n    4 / 3 * np.pi * particle_sample**3 * 1500\n)  # Particle mass in kg\n\n# Build a resolved mass representation for each particle\n# This defines how particle mass, activity, and surface are represented\nresolved_masses = (\n    par.particles.ResolvedParticleMassRepresentationBuilder()\n    .set_distribution_strategy(\n        par.particles.ParticleResolvedSpeciatedMass()\n    )  # Use speciated mass distribution\n    .set_activity_strategy(\n        par.particles.ActivityIdealMass()\n    )  # Define activity based on ideal mass\n    .set_surface_strategy(\n        par.particles.SurfaceStrategyVolume()\n    )  # Define surface area based on particle volume\n    .set_mass(particle_mass_sample, \"kg\")  # Assign mass of particles (in kg)\n    .set_density(1500, \"kg/m^3\")  # Set particle density to 1500 kg/m^3\n    .set_charge(0)  # Assume neutral particles with no charge\n    .set_volume(1, \"cm^3\")  # Set volume of particle distribution\n    .build()  # Finalize the resolved mass representation\n)\n\n# Create an aerosol object with the defined atmosphere and resolved particles\naerosol = par.Aerosol(atmosphere=atmosphere, particles=resolved_masses)\n\n# Print the properties of the atmosphere\nprint(aerosol)\n</pre> # Preset gas species that does not condense in the atmosphere # AtmosphereBuilder constructs the atmosphere with predefined species atmosphere = (     par.gas.AtmosphereBuilder()     .set_temperature(25, temperature_units=\"degC\")  # Set temperature to 25\u00b0C     .set_pressure(1, pressure_units=\"atm\")  # Set pressure to 1 atmosphere     .build()  # Finalize the atmosphere object )  # Generate a particle distribution using a lognormal sample distribution # This distribution has a mean particle diameter (mode) and geometric standard deviation (GSD) particle_sample = par.particles.get_lognormal_sample_distribution(     mode=np.array([100e-9]),  # Mean particle diameter of 100 nm     geometric_standard_deviation=np.array([1.3]),  # GSD of 1.3     number_of_particles=np.array([1e4]),  # Total number of particles     number_of_samples=100_000,  # Number of samples for particle distribution )  # Calculate the mass of each particle in the sample, assuming density of 1500 kg/m^3 particle_mass_sample = (     4 / 3 * np.pi * particle_sample**3 * 1500 )  # Particle mass in kg  # Build a resolved mass representation for each particle # This defines how particle mass, activity, and surface are represented resolved_masses = (     par.particles.ResolvedParticleMassRepresentationBuilder()     .set_distribution_strategy(         par.particles.ParticleResolvedSpeciatedMass()     )  # Use speciated mass distribution     .set_activity_strategy(         par.particles.ActivityIdealMass()     )  # Define activity based on ideal mass     .set_surface_strategy(         par.particles.SurfaceStrategyVolume()     )  # Define surface area based on particle volume     .set_mass(particle_mass_sample, \"kg\")  # Assign mass of particles (in kg)     .set_density(1500, \"kg/m^3\")  # Set particle density to 1500 kg/m^3     .set_charge(0)  # Assume neutral particles with no charge     .set_volume(1, \"cm^3\")  # Set volume of particle distribution     .build()  # Finalize the resolved mass representation )  # Create an aerosol object with the defined atmosphere and resolved particles aerosol = par.Aerosol(atmosphere=atmosphere, particles=resolved_masses)  # Print the properties of the atmosphere print(aerosol) <pre>Gas mixture at 298.15 K, 101325.0 Pa, partitioning=None, gas_only_species=None\nParticle Representation:\n\tStrategy: ParticleResolvedSpeciatedMass\n\tActivity: ActivityIdealMass\n\tSurface: SurfaceStrategyVolume\n\tMass Concentration: 8.570e-07 [kg/m^3]\n\tNumber Concentration: 1.000e+11 [#/m^3]\n</pre> In\u00a0[7]: Copied! <pre># particles to add\n\n# Generate a particle distribution using a lognormal sample distribution\n# This distribution has a mean particle diameter (mode) and geometric standard deviation (GSD)\nparticles_to_add = par.particles.get_lognormal_sample_distribution(\n    mode=np.array([1e-9]),  # Mean particle diameter of 100 nm\n    geometric_standard_deviation=np.array([1.1]),  # GSD of 1.3\n    number_of_particles=np.array([1e4]),  # Total number of particles\n    number_of_samples=10_000,  # Number of samples for particle distribution\n)\n\n# Calculate the mass of each particle in the sample, assuming density of 1500 kg/m^3\nparticle_mass_add = (\n    4 / 3 * np.pi * particles_to_add**3 * 1500\n)  # Particle mass in kg\nconcentration_add = np.ones_like(particle_mass_add)\n\n\n# print shapes\nprint(f\"Particles to add: {particle_mass_add.shape}\")\n</pre> # particles to add  # Generate a particle distribution using a lognormal sample distribution # This distribution has a mean particle diameter (mode) and geometric standard deviation (GSD) particles_to_add = par.particles.get_lognormal_sample_distribution(     mode=np.array([1e-9]),  # Mean particle diameter of 100 nm     geometric_standard_deviation=np.array([1.1]),  # GSD of 1.3     number_of_particles=np.array([1e4]),  # Total number of particles     number_of_samples=10_000,  # Number of samples for particle distribution )  # Calculate the mass of each particle in the sample, assuming density of 1500 kg/m^3 particle_mass_add = (     4 / 3 * np.pi * particles_to_add**3 * 1500 )  # Particle mass in kg concentration_add = np.ones_like(particle_mass_add)   # print shapes print(f\"Particles to add: {particle_mass_add.shape}\") <pre>Particles to add: (10000,)\n</pre> In\u00a0[8]: Copied! <pre># Get initial particle radii before adding particle\ninitial_radii = aerosol.particles.get_radius(clone=True)\nprint(\n    f\"Initial concentration: {aerosol.particles.get_total_concentration()}\"\n)\n\n# Perform the add process\naerosol.particles.add_concentration(  # select the particle representation and call add_concentration\n    added_concentration=concentration_add,\n    added_distribution=particle_mass_add,\n)\nradii_after_step_1 = aerosol.particles.get_radius(clone=True)\nprint(\n    f\"Concentration after step 1: {aerosol.particles.get_total_concentration()}\"\n)\n\n# Perform the add process\naerosol.particles.add_concentration(\n    added_concentration=concentration_add,\n    added_distribution=particle_mass_add,\n)\nradii_after_step_2 = aerosol.particles.get_radius(clone=True)\n\nprint(\n    f\"Concentration after step 2: {aerosol.particles.get_total_concentration()}\"\n)\nconcentration_value = aerosol.particles.concentration\n</pre> # Get initial particle radii before adding particle initial_radii = aerosol.particles.get_radius(clone=True) print(     f\"Initial concentration: {aerosol.particles.get_total_concentration()}\" )  # Perform the add process aerosol.particles.add_concentration(  # select the particle representation and call add_concentration     added_concentration=concentration_add,     added_distribution=particle_mass_add, ) radii_after_step_1 = aerosol.particles.get_radius(clone=True) print(     f\"Concentration after step 1: {aerosol.particles.get_total_concentration()}\" )  # Perform the add process aerosol.particles.add_concentration(     added_concentration=concentration_add,     added_distribution=particle_mass_add, ) radii_after_step_2 = aerosol.particles.get_radius(clone=True)  print(     f\"Concentration after step 2: {aerosol.particles.get_total_concentration()}\" ) concentration_value = aerosol.particles.concentration <pre>Initial concentration: 99999999999.99998\nConcentration after step 1: 109999999999.99998\nConcentration after step 2: 119999999999.99998\n</pre> In\u00a0[9]: Copied! <pre># Define lognormal bins for particle radius histogram\nbins_lognormal = np.logspace(-10, -6, 100)\n\n# Create figure for visualizing the histogram of particle radii\nfig, ax = plt.subplots(figsize=(8, 6))\n\n# Plot radii distribution after step 2\nbins, edges = np.histogram(radii_after_step_2, bins=bins_lognormal)\nax.bar(\n    edges[:-1],\n    bins,\n    width=np.diff(edges),\n    align=\"edge\",\n    label=\"After 2 steps\",\n    alpha=0.6,\n)\n# Plot radii distribution after step 1\n\nbins, edges = np.histogram(radii_after_step_1, bins=bins_lognormal)\nax.bar(\n    edges[:-1],\n    bins,\n    width=np.diff(edges),\n    align=\"edge\",\n    label=\"After 1 step\",\n    alpha=0.5,\n)\n\n# Plot initial radii distribution\nbins, edges = np.histogram(initial_radii, bins=bins_lognormal)\nax.bar(\n    edges[:-1],\n    bins,\n    width=np.diff(edges),\n    align=\"edge\",\n    label=\"Initial\",\n    alpha=0.4,\n    edgecolor=\"black\",\n)\n\n# Set axes to logarithmic scale for x-axis (particle radius)\nax.set_xscale(\"log\")\nax.set_yscale(\"log\")\n\n# Add labels and legend\nax.set_xlabel(\"Radius (m)\")\nax.set_ylabel(\"Number of particles\")\nplt.legend()\n\n# Show the plot\nplt.show()\n</pre> # Define lognormal bins for particle radius histogram bins_lognormal = np.logspace(-10, -6, 100)  # Create figure for visualizing the histogram of particle radii fig, ax = plt.subplots(figsize=(8, 6))  # Plot radii distribution after step 2 bins, edges = np.histogram(radii_after_step_2, bins=bins_lognormal) ax.bar(     edges[:-1],     bins,     width=np.diff(edges),     align=\"edge\",     label=\"After 2 steps\",     alpha=0.6, ) # Plot radii distribution after step 1  bins, edges = np.histogram(radii_after_step_1, bins=bins_lognormal) ax.bar(     edges[:-1],     bins,     width=np.diff(edges),     align=\"edge\",     label=\"After 1 step\",     alpha=0.5, )  # Plot initial radii distribution bins, edges = np.histogram(initial_radii, bins=bins_lognormal) ax.bar(     edges[:-1],     bins,     width=np.diff(edges),     align=\"edge\",     label=\"Initial\",     alpha=0.4,     edgecolor=\"black\", )  # Set axes to logarithmic scale for x-axis (particle radius) ax.set_xscale(\"log\") ax.set_yscale(\"log\")  # Add labels and legend ax.set_xlabel(\"Radius (m)\") ax.set_ylabel(\"Number of particles\") plt.legend()  # Show the plot plt.show()"},{"location":"Examples/Dynamics/Customization/Adding_Particles_During_Simulation/#adding-particles-during-simulation","title":"Adding Particles During Simulation\u00b6","text":"<p>In this tutorial, we demonstrate how add particles to an aerosol object. This is useful when you want to modify a custom aerosol process during a simulation.</p> <p>The example is for a particle resolved simulation, the same approach can be used for the other types of particle representations (but it has not been tested yet).</p> <p>Imports</p>"},{"location":"Examples/Dynamics/Customization/Adding_Particles_During_Simulation/#aerosol-setup","title":"Aerosol Setup\u00b6","text":"<p>We need to first make the aerosol object. Details on this can be found in the Aerosol Tutorial.</p>"},{"location":"Examples/Dynamics/Customization/Adding_Particles_During_Simulation/#particles-to-add","title":"Particles to Add\u00b6","text":"<p>For the particle resolved representation, the particles to add must be the provide an array of new particle masses and the concentrations.</p> <p>Currently the concentrations should all be one, as this is the particle resolved representation.</p> <p>If you have multiple species, then the shape of the <code>added_distribution</code> should be <code>(number of particles, number of species)</code>. But <code>added_concentration</code> is still <code>(number of particles,)</code>.</p>"},{"location":"Examples/Dynamics/Customization/Adding_Particles_During_Simulation/#graphing","title":"Graphing\u00b6","text":"<p>We now visualize the two particle add steps</p>"},{"location":"Examples/Dynamics/Customization/Adding_Particles_During_Simulation/#conclusion","title":"Conclusion\u00b6","text":"<p>We have demonstrated how to add particles to an aerosol object. This is useful when you want to modify a aerosol object with a custom process during a simulation.</p>"},{"location":"Examples/Equilibria/","title":"Index Equilibria","text":""},{"location":"Examples/Equilibria/#notebooks","title":"Notebooks","text":"<ul> <li>Activity Coefficients</li> <li>Liquid-Liquid Equilibrium</li> </ul>"},{"location":"Examples/Equilibria/#what-is-equilibria","title":"What is Equilibria?","text":"<p>Equilibria, a fundamental concept in physical chemistry, refers to the state where the concentrations of reactants and products in a chemical reaction remain constant over time. In the context of aerosol science, equilibria are essential in understanding how aerosol particles interact with their environment, particularly with respect to liquid and vapor phases. This balance is crucial in predicting how aerosols behave under different atmospheric conditions.</p>"},{"location":"Examples/Equilibria/#why-is-equilibria-important","title":"Why is Equilibria Important?","text":"<p>Studying equilibria in aerosol systems is vital for several reasons:</p> <ol> <li> <p>Environmental Impact: Aerosols play a significant role in air quality and climate change. Understanding their equilibrium behavior helps in assessing their environmental impact, such as their role in cloud formation and solar radiation scattering.</p> </li> <li> <p>Health Implications: Aerosols affect human health, especially in terms of respiratory issues. Knowledge of equilibrium states helps in evaluating exposure risks and designing mitigation strategies.</p> </li> <li> <p>Atmospheric Chemistry: Equilibria studies contribute to our understanding of atmospheric chemistry, particularly in the formation and transformation of aerosols.</p> </li> </ol>"},{"location":"Examples/Equilibria/#how-does-equilibria-relate-to-these-notebooks","title":"How Does Equilibria Relate to These Notebooks?","text":"<p>The notebooks presented here are dedicated to exploring various aspects of equilibria in aerosol science:</p> <ol> <li> <p>Activity Coefficients and Phase Behavior: By calculating activity coefficients, we can predict how different components of aerosols partition between liquid and vapor phases. This is crucial in understanding the composition and concentration of aerosols under varying atmospheric conditions.</p> </li> <li> <p>Liquid-Vapor Equilibrium: The notebook delves into the equilibrium compositions of liquid-vapor mixtures, highlighting the role of relative humidity (RH) in shaping aerosol behavior.</p> </li> <li> <p>Practical Applications: Through examples and simulations, these notebooks provide practical insights into real-world scenarios, enhancing our understanding of aerosols in environmental and health contexts.</p> </li> </ol> <p>Overall, the notebooks serve as an interactive platform to explore and understand the complex yet fascinating world of equilibria in aerosol science. Whether you're a student, researcher, or enthusiast, these materials offer valuable insights into the dynamic equilibrium processes that govern aerosol behavior in our atmosphere.</p>"},{"location":"Examples/Equilibria/Notebooks/activity_part1/","title":"Activity Example","text":"In\u00a0[\u00a0]: Copied! <pre># In Colab uncomment the following command to install particula:\n#!pip install particula[extra] --quiet\nimport numpy as np  # For numerical operations\nimport matplotlib.pyplot as plt  # For plotting graphs\n\n# Specific functions from the particula package for activity calculations\nfrom particula.activity import (\n    water_activity,\n    phase_separation,\n    species_density,\n    activity_coefficients,\n)\n</pre> # In Colab uncomment the following command to install particula: #!pip install particula[extra] --quiet import numpy as np  # For numerical operations import matplotlib.pyplot as plt  # For plotting graphs  # Specific functions from the particula package for activity calculations from particula.activity import (     water_activity,     phase_separation,     species_density,     activity_coefficients, ) In\u00a0[2]: Copied! <pre># Define a range of organic mole fractions for the calculation\norganic_mole_fraction = np.linspace(0.001, 1, 1000)\n\n# Define other necessary parameters\noxygen2carbon = 0.225  # Oxygen to carbon ratio\nmolar_mass_ratio = 18.016 / 100  # Water to organic molecular weight ratio\ndensity = species_density.organic_density_estimate(\n    18.016 / molar_mass_ratio, oxygen2carbon\n)  # Estimate of organic compound density\n\n# Calculate activity coefficients using the binary_activity function\n(\n    activity_water,\n    activity_organic,\n    mass_water,\n    mass_organic,\n    gamma_water,\n    gamma_organic,\n) = activity_coefficients.bat_activity_coefficients(\n    molar_mass_ratio,\n    organic_mole_fraction,\n    oxygen2carbon,\n    density,\n    functional_group=None,\n)\n</pre> # Define a range of organic mole fractions for the calculation organic_mole_fraction = np.linspace(0.001, 1, 1000)  # Define other necessary parameters oxygen2carbon = 0.225  # Oxygen to carbon ratio molar_mass_ratio = 18.016 / 100  # Water to organic molecular weight ratio density = species_density.organic_density_estimate(     18.016 / molar_mass_ratio, oxygen2carbon )  # Estimate of organic compound density  # Calculate activity coefficients using the binary_activity function (     activity_water,     activity_organic,     mass_water,     mass_organic,     gamma_water,     gamma_organic, ) = activity_coefficients.bat_activity_coefficients(     molar_mass_ratio,     organic_mole_fraction,     oxygen2carbon,     density,     functional_group=None, ) In\u00a0[3]: Copied! <pre>fig, ax = plt.subplots()\nax.plot(\n    1 - organic_mole_fraction,\n    activity_water,\n    label=\"water\",\n    linestyle=\"dashed\",\n)\nax.plot(\n    1 - organic_mole_fraction,\n    activity_organic,\n    label=\"organic\",\n)\nax.set_ylim()\nax.set_xlabel(\"water mole fraction\")\nax.set_ylabel(\"activity\")\nax.legend()\nplt.show()\n\nfig, ax = plt.subplots()\nax.plot(\n    1 - organic_mole_fraction, gamma_water, label=\"water\", linestyle=\"dashed\"\n)\nax.plot(\n    1 - organic_mole_fraction,\n    gamma_organic,\n    label=\"organic\",\n)\nax.set_ylim()\nax.set_xlabel(\"water mole fraction\")\nax.set_ylabel(\"activity coefficient\")\nax.legend()\nplt.show()\n</pre> fig, ax = plt.subplots() ax.plot(     1 - organic_mole_fraction,     activity_water,     label=\"water\",     linestyle=\"dashed\", ) ax.plot(     1 - organic_mole_fraction,     activity_organic,     label=\"organic\", ) ax.set_ylim() ax.set_xlabel(\"water mole fraction\") ax.set_ylabel(\"activity\") ax.legend() plt.show()  fig, ax = plt.subplots() ax.plot(     1 - organic_mole_fraction, gamma_water, label=\"water\", linestyle=\"dashed\" ) ax.plot(     1 - organic_mole_fraction,     gamma_organic,     label=\"organic\", ) ax.set_ylim() ax.set_xlabel(\"water mole fraction\") ax.set_ylabel(\"activity coefficient\") ax.legend() plt.show() In\u00a0[4]: Copied! <pre># Finding phase separation points and calculating q_alpha\nphase_sep_aw = phase_separation.find_phase_separation(\n    activity_water, activity_organic\n)\nq_alpha = phase_separation.q_alpha(\n    seperation_activity=phase_sep_aw[\"upper_seperation\"],\n    activities=activity_water,\n)\n\n# Plotting q_alpha\nfig, ax = plt.subplots()\nplt.plot(activity_water, q_alpha)\nplt.xlabel(\"Water Activity\")\nplt.ylabel(\"$q^{\\\\alpha}$ [Organic Rich to Water Rich]\")\nplt.show()\n</pre> # Finding phase separation points and calculating q_alpha phase_sep_aw = phase_separation.find_phase_separation(     activity_water, activity_organic ) q_alpha = phase_separation.q_alpha(     seperation_activity=phase_sep_aw[\"upper_seperation\"],     activities=activity_water, )  # Plotting q_alpha fig, ax = plt.subplots() plt.plot(activity_water, q_alpha) plt.xlabel(\"Water Activity\") plt.ylabel(\"$q^{\\\\alpha}$ [Organic Rich to Water Rich]\") plt.show() In\u00a0[7]: Copied! <pre># select the water activity desired\nwater_activity_desired = np.linspace(0.5, 1, 100)\noxygen2carbon = 0.25\n\n# calculate the mass fraction of water in the alpha and beta phases\n# for each water activity\nalpha, beta, q_alpha = water_activity.fixed_water_activity(\n    water_activity=water_activity_desired,\n    molar_mass_ratio=molar_mass_ratio,\n    oxygen2carbon=oxygen2carbon,\n    density=density,\n)\n\n# plot the results vs water activity\nfig, ax = plt.subplots()\nax.plot(\n    water_activity_desired,\n    alpha[2],\n    label=\"alpha phase mass fraction water\",\n)\nax.plot(\n    water_activity_desired,\n    q_alpha,\n    label=\"q_alpha\",\n)\nif beta is not None:\n    ax.plot(\n        water_activity_desired,\n        beta[2],\n        label=\"beta phase mass fraction water\",\n    )\nax.set_ylim()\nax.set_xlabel(\"water activity (Relative Humidity/100)\")\nax.set_ylabel(\"mass fraction of water\")\nplt.legend()\nplt.show()\n</pre> # select the water activity desired water_activity_desired = np.linspace(0.5, 1, 100) oxygen2carbon = 0.25  # calculate the mass fraction of water in the alpha and beta phases # for each water activity alpha, beta, q_alpha = water_activity.fixed_water_activity(     water_activity=water_activity_desired,     molar_mass_ratio=molar_mass_ratio,     oxygen2carbon=oxygen2carbon,     density=density, )  # plot the results vs water activity fig, ax = plt.subplots() ax.plot(     water_activity_desired,     alpha[2],     label=\"alpha phase mass fraction water\", ) ax.plot(     water_activity_desired,     q_alpha,     label=\"q_alpha\", ) if beta is not None:     ax.plot(         water_activity_desired,         beta[2],         label=\"beta phase mass fraction water\",     ) ax.set_ylim() ax.set_xlabel(\"water activity (Relative Humidity/100)\") ax.set_ylabel(\"mass fraction of water\") plt.legend() plt.show() In\u00a0[9]: Copied! <pre># select the water activity desired\nwater_activity_desired = np.linspace(0.5, 1, 100)\n# select the oxygen to carbon ratio\noxygen2carbon = 0.6\n\n# calculate the mass fraction of water in the alpha and beta phases\n# for each water activity\nalpha, beta, q_alpha = water_activity.fixed_water_activity(\n    water_activity=water_activity_desired,\n    molar_mass_ratio=molar_mass_ratio,\n    oxygen2carbon=oxygen2carbon,\n    density=density,\n)\n\n# plot the results vs water activity\nfig, ax = plt.subplots()\nax.plot(\n    water_activity_desired,\n    alpha[2],\n    label=\"alpha phase mass fraction water\",\n)\nax.plot(\n    water_activity_desired,\n    q_alpha,\n    label=\"q_alpha\",\n)\nif beta is not None:\n    ax.plot(\n        water_activity_desired,\n        beta[2],\n        label=\"beta phase mass fraction water\",\n    )\nax.set_ylim()\nax.set_xlabel(\"water activity (Relative Humidity/100)\")\nax.set_ylabel(\"mass fraction of water\")\nplt.legend()\nplt.show()\n</pre> # select the water activity desired water_activity_desired = np.linspace(0.5, 1, 100) # select the oxygen to carbon ratio oxygen2carbon = 0.6  # calculate the mass fraction of water in the alpha and beta phases # for each water activity alpha, beta, q_alpha = water_activity.fixed_water_activity(     water_activity=water_activity_desired,     molar_mass_ratio=molar_mass_ratio,     oxygen2carbon=oxygen2carbon,     density=density, )  # plot the results vs water activity fig, ax = plt.subplots() ax.plot(     water_activity_desired,     alpha[2],     label=\"alpha phase mass fraction water\", ) ax.plot(     water_activity_desired,     q_alpha,     label=\"q_alpha\", ) if beta is not None:     ax.plot(         water_activity_desired,         beta[2],         label=\"beta phase mass fraction water\",     ) ax.set_ylim() ax.set_xlabel(\"water activity (Relative Humidity/100)\") ax.set_ylabel(\"mass fraction of water\") plt.legend() plt.show()"},{"location":"Examples/Equilibria/Notebooks/activity_part1/#activity-example","title":"Activity Example\u00b6","text":"<p>This notebook demonstrates the Binary Activity Theory (BAT) model application, crucial for calculating the activity of water and organic compounds in mixtures and understanding phase separation. This model, as detailed in Gorkowski, K., Preston, T. C., &amp; Zuend, A. (2019), provides critical insights into aerosol particle behavior, essential in environmental and climate change research.</p> <p>Reference: Gorkowski, K., Preston, T. C., &amp; Zuend, A. (2019). Relative-humidity-dependent organic aerosol thermodynamics Via an efficient reduced-complexity model. Atmospheric Chemistry and Physics https://doi.org/10.5194/acp-19-13383-2019</p>"},{"location":"Examples/Equilibria/Notebooks/activity_part1/#activity-calculation","title":"Activity Calculation\u00b6","text":"<p>Define the parameters required by the activity module to calculate the activity of water and organic compounds in a mixture, as well as phase separation. These parameters include organic mole fraction, density, molecular weight ratio [water/organic], and the density of the organic compound. Using these parameters helps in accurately modeling the behavior of aerosol particles in various environmental conditions.</p>"},{"location":"Examples/Equilibria/Notebooks/activity_part1/#plotting-the-activity-and-phase-separation","title":"Plotting the Activity and Phase Separation\u00b6","text":"<p>Here we plot the activity of water and the organic compound as a function of the organic mole fraction. Visualizing these activities helps in identifying phase separation or miscibility gaps, crucial for understanding the behavior of aerosols under different environmental conditions. Phase separation is indicated by activities greater than 1.0 or non-monotonic behavior in the activity curve, as shown below.</p>"},{"location":"Examples/Equilibria/Notebooks/activity_part1/#qalpha","title":"$ q^\\alpha $\u00b6","text":"<p>The $q^\\alpha$ parameter signifies the transition from an organic-rich phase to a water-rich phase. This transition is crucial for understanding the phase behavior of aerosol particles. It can be calculated using the <code>particula.activity.phase_separation</code> function. The plot below illustrates $q^\\alpha$ based on the activity calculations performed earlier.</p>"},{"location":"Examples/Equilibria/Notebooks/activity_part1/#water-activity-focus","title":"Water Activity Focus\u00b6","text":"<p>In atmospheric aerosol modeling, water activity is often a more critical parameter than mole fraction. This is because water activity is typically a controllable or known variable in atmospheric conditions, unlike the exact mole fractions in a solution. To correlate water activity with the mole fraction required to achieve it, we utilize functions from the <code>particula.activity</code> module.</p>"},{"location":"Examples/Equilibria/Notebooks/activity_part1/#higher-oxygen-to-carbon-ratios","title":"Higher Oxygen to Carbon Ratios\u00b6","text":"<p>Higher oxygen to carbon ratios in the mixture tend to inhibit phase separation. The following analysis demonstrates this effect. This observation is crucial in predicting the behavior of aerosol particles under varying chemical compositions (more or less 'aged').</p>"},{"location":"Examples/Equilibria/Notebooks/activity_part1/#summary","title":"Summary\u00b6","text":"<p>This notebook demonstrates how to use the activity module for calculating the activity of water and organic compounds in a mixture and assessing phase separation. The insights gained are vital for applications in aerosol thermodynamics, cloud condensation nuclei, and cloud microphysics.</p> <p>This is an implementation of the Binary Activity Theory (BAT) model developed in Gorkowski, K., Preston, T. C., &amp; Zuend, A. (2019).</p>"},{"location":"Examples/Equilibria/Notebooks/equilibria_part1/","title":"Liquid Vapor Equilibrium","text":"In\u00a0[\u00a0]: Copied! <pre># In Colab uncomment the following command to install particula:\n#!pip install particula[extra] --quiet\n# Importing necessary libraries\nimport matplotlib.pyplot as plt  # For creating plots and visualizations\nimport numpy as np  # For numerical operations\nfrom particula.activity import (\n    species_density,\n)  # For calculating species density\n\n# For partitioning calculations in liquid-vapor equilibrium\nfrom particula.equilibria import partitioning\n</pre> # In Colab uncomment the following command to install particula: #!pip install particula[extra] --quiet # Importing necessary libraries import matplotlib.pyplot as plt  # For creating plots and visualizations import numpy as np  # For numerical operations from particula.activity import (     species_density, )  # For calculating species density  # For partitioning calculations in liquid-vapor equilibrium from particula.equilibria import partitioning In\u00a0[2]: Copied! <pre># Defining system parameters\nc_star_j_dry = [1e-6, 1e-4, 1e-1, 1e2, 1e4]  # Volatility distribution in ug/m3\n# Total concentration in ug/m3\nconcentration_organic_matter = [1, 5, 10, 15, 10]\noxygen2carbon = np.array([0.2, 0.3, 0.5, 0.4, 0.4])  # Oxygen to carbon ratios\n\nmolar_mass = np.array([200, 200, 200, 200, 200])  # Molar mass in g/mol\nwater_activity_desired = np.array([0.8])  # Desired water activity\nmolar_mass_ratio = 18.015 / np.array(molar_mass)  # Molar mass ratio\n\n# Calculate the density of organic compounds\ndensity = species_density.organic_array(\n    molar_mass, oxygen2carbon, hydrogen2carbon=None, nitrogen2carbon=None\n)\n</pre> # Defining system parameters c_star_j_dry = [1e-6, 1e-4, 1e-1, 1e2, 1e4]  # Volatility distribution in ug/m3 # Total concentration in ug/m3 concentration_organic_matter = [1, 5, 10, 15, 10] oxygen2carbon = np.array([0.2, 0.3, 0.5, 0.4, 0.4])  # Oxygen to carbon ratios  molar_mass = np.array([200, 200, 200, 200, 200])  # Molar mass in g/mol water_activity_desired = np.array([0.8])  # Desired water activity molar_mass_ratio = 18.015 / np.array(molar_mass)  # Molar mass ratio  # Calculate the density of organic compounds density = species_density.organic_array(     molar_mass, oxygen2carbon, hydrogen2carbon=None, nitrogen2carbon=None ) In\u00a0[3]: Copied! <pre># Calculate the properties needed for liquid-vapor partitioning\ngamma_organic_ab, mass_fraction_water_ab, q_ab = (\n    partitioning.get_properties_for_liquid_vapor_partitioning(\n        water_activity_desired=water_activity_desired,\n        molar_mass=molar_mass,\n        oxygen2carbon=oxygen2carbon,\n        density=density,\n    )\n)\n\n# The optimization the partition coefficients, i.e. the partitioning calculation\nalpha_opt, beta_opt, system_opt, fit_result = (\n    partitioning.liquid_vapor_partitioning(\n        c_star_j_dry=c_star_j_dry,\n        concentration_organic_matter=concentration_organic_matter,\n        molar_mass=molar_mass,\n        gamma_organic_ab=gamma_organic_ab,\n        mass_fraction_water_ab=mass_fraction_water_ab,\n        q_ab=q_ab,\n        partition_coefficient_guess=None,\n    )\n)\n\nprint(f\"mass in organic aerosol [ug/m3]: {system_opt[0]}\")\nprint(f\"mass in water [ug/3]: {system_opt[1]}\")\n</pre> # Calculate the properties needed for liquid-vapor partitioning gamma_organic_ab, mass_fraction_water_ab, q_ab = (     partitioning.get_properties_for_liquid_vapor_partitioning(         water_activity_desired=water_activity_desired,         molar_mass=molar_mass,         oxygen2carbon=oxygen2carbon,         density=density,     ) )  # The optimization the partition coefficients, i.e. the partitioning calculation alpha_opt, beta_opt, system_opt, fit_result = (     partitioning.liquid_vapor_partitioning(         c_star_j_dry=c_star_j_dry,         concentration_organic_matter=concentration_organic_matter,         molar_mass=molar_mass,         gamma_organic_ab=gamma_organic_ab,         mass_fraction_water_ab=mass_fraction_water_ab,         q_ab=q_ab,         partition_coefficient_guess=None,     ) )  print(f\"mass in organic aerosol [ug/m3]: {system_opt[0]}\") print(f\"mass in water [ug/3]: {system_opt[1]}\") <pre>mass in organic aerosol [ug/m3]: 23.96066277089358\nmass in water [ug/3]: 1.76895852033799e+16\n</pre> <pre>C:\\GitHub\\particula\\particula\\activity\\gibbs_mixing.py:85: RuntimeWarning: invalid value encountered in divide\n  phi2 / organic_mole_fraction\n</pre> In\u00a0[4]: Copied! <pre># Calculating activity coefficients across a range of RH values\n# Range of water activity (RH/100)\nwater_activity_curve = np.linspace(0.01, 0.99, 50)\ntotal_oa_concentration = np.empty([len(water_activity_curve), 1], dtype=float)\nwater_concentration = np.empty([len(water_activity_curve), 1], dtype=float)\n\nfor i, water_activity in enumerate(water_activity_curve):\n    # Get properties for liquid-vapor partitioning at each RH value\n    gamma_organic_ab, mass_fraction_water_ab, q_ab = (\n        partitioning.get_properties_for_liquid_vapor_partitioning(\n            water_activity_desired=water_activity,\n            molar_mass=molar_mass,\n            oxygen2carbon=oxygen2carbon,\n            density=density,\n        )\n    )\n\n    # Optimize the partition coefficients for each RH value\n    alpha_opt, beta_opt, system_opt, fit_result = (\n        partitioning.liquid_vapor_partitioning(\n            c_star_j_dry=c_star_j_dry,\n            concentration_organic_matter=concentration_organic_matter,\n            molar_mass=molar_mass,\n            gamma_organic_ab=gamma_organic_ab,\n            mass_fraction_water_ab=mass_fraction_water_ab,\n            q_ab=q_ab,\n            partition_coefficient_guess=None,\n        )\n    )\n\n    # Record the total organic and water concentration\n    total_oa_concentration[i] = system_opt[0]\n    water_concentration[i] = system_opt[1]\n\nprint(\"Calculation complete\")\n</pre> # Calculating activity coefficients across a range of RH values # Range of water activity (RH/100) water_activity_curve = np.linspace(0.01, 0.99, 50) total_oa_concentration = np.empty([len(water_activity_curve), 1], dtype=float) water_concentration = np.empty([len(water_activity_curve), 1], dtype=float)  for i, water_activity in enumerate(water_activity_curve):     # Get properties for liquid-vapor partitioning at each RH value     gamma_organic_ab, mass_fraction_water_ab, q_ab = (         partitioning.get_properties_for_liquid_vapor_partitioning(             water_activity_desired=water_activity,             molar_mass=molar_mass,             oxygen2carbon=oxygen2carbon,             density=density,         )     )      # Optimize the partition coefficients for each RH value     alpha_opt, beta_opt, system_opt, fit_result = (         partitioning.liquid_vapor_partitioning(             c_star_j_dry=c_star_j_dry,             concentration_organic_matter=concentration_organic_matter,             molar_mass=molar_mass,             gamma_organic_ab=gamma_organic_ab,             mass_fraction_water_ab=mass_fraction_water_ab,             q_ab=q_ab,             partition_coefficient_guess=None,         )     )      # Record the total organic and water concentration     total_oa_concentration[i] = system_opt[0]     water_concentration[i] = system_opt[1]  print(\"Calculation complete\") <pre>Calculation complete\n</pre> In\u00a0[5]: Copied! <pre>fig, ax = plt.subplots()\nax.plot(\n    water_activity_curve,\n    total_oa_concentration,\n    label=\"total organic concentration\",\n    color=\"green\",\n)\naw = ax.twinx()\naw.plot(\n    water_activity_curve,\n    water_concentration,\n    label=\"water concentration\",\n    color=\"blue\",\n)\nplt.legend(loc=\"upper left\")\nax.set_xlabel(\"water activity (a_w is RH/100)\")\n\nhandles, labels = ax.get_legend_handles_labels()\naw_handles, aw_labels = aw.get_legend_handles_labels()\nhandles.extend(aw_handles)\nlabels.extend(aw_labels)\nplt.legend(handles, labels, loc=\"upper left\")\n\nax.set_ylabel(\"organic aerosol concentration [ug/m3]\")\naw.set_ylabel(\"aerosol water concentration [ug/m3]\")\nplt.show()\n</pre> fig, ax = plt.subplots() ax.plot(     water_activity_curve,     total_oa_concentration,     label=\"total organic concentration\",     color=\"green\", ) aw = ax.twinx() aw.plot(     water_activity_curve,     water_concentration,     label=\"water concentration\",     color=\"blue\", ) plt.legend(loc=\"upper left\") ax.set_xlabel(\"water activity (a_w is RH/100)\")  handles, labels = ax.get_legend_handles_labels() aw_handles, aw_labels = aw.get_legend_handles_labels() handles.extend(aw_handles) labels.extend(aw_labels) plt.legend(handles, labels, loc=\"upper left\")  ax.set_ylabel(\"organic aerosol concentration [ug/m3]\") aw.set_ylabel(\"aerosol water concentration [ug/m3]\") plt.show()"},{"location":"Examples/Equilibria/Notebooks/equilibria_part1/#liquid-vapor-equilibrium","title":"Liquid Vapor Equilibrium\u00b6","text":"<p>This notebook explores the calculation of equilibrium composition in liquid-vapor mixtures, a crucial concept in aerosol science and environmental studies. We utilize an activity coefficient model to understand how different volatile organic compounds distribute between the liquid and vapor phases. This analysis is particularly important for predicting aerosol behavior and understanding atmospheric processes.</p>"},{"location":"Examples/Equilibria/Notebooks/equilibria_part1/#setup-the-system","title":"Setup the System\u00b6","text":"<p>To simulate the liquid-vapor equilibrium, we define several key parameters:</p> <ul> <li><code>c_star_j_dry</code>: Represents the volatility distribution of organic compounds in dry air, calculable from vapor pressure.</li> <li><code>concentration_organic_matter</code>: The combined concentration of vapor and liquid organic matter in the system.</li> <li><code>oxygen2carbon</code>: The ratio of oxygen to carbon in the organic compounds, crucial for characterizing their chemical nature.</li> <li><code>molar_mass</code>: The molar mass of the organic compounds.</li> </ul> <p>These parameters help us determine the density of organics in the system, a vital step in understanding their distribution between phases.</p>"},{"location":"Examples/Equilibria/Notebooks/equilibria_part1/#calculate-the-activity-coefficients","title":"Calculate the Activity Coefficients\u00b6","text":"<p>The next step involves calculating the activity coefficients, which are pivotal in determining how the organic compounds distribute between the liquid and vapor phases. We use the <code>partitioning.get_properties_for_liquid_vapor_equilibrium</code> function, a specialized tool that simplifies the process by returning only the essential properties: activity coefficients, mass fractions, and the two-phase q values for the alpha-beta equilibrium.</p>"},{"location":"Examples/Equilibria/Notebooks/equilibria_part1/#activity-coefficients-as-a-function-of-relative-humidity-frh","title":"Activity Coefficients as a Function of Relative Humidity (f(RH))\u00b6","text":"<p>The binary activity model's key feature is its interaction with water, particularly through relative humidity (RH). Here, we will calculate how the activity coefficients vary as a function of RH. This is done by iterating over a range of RH values and computing the corresponding activity coefficients, providing insights into how atmospheric humidity influences the equilibrium behavior of the system.</p>"},{"location":"Examples/Equilibria/Notebooks/equilibria_part1/#plotting-the-equilibrium-composition-vs-relative-humidity","title":"Plotting the Equilibrium Composition vs. Relative Humidity\u00b6","text":"<p>(To be updated, current bug in q-alpha transfer)</p> <p>Now that we have calculated the equilibrium composition for a range of RH values, we will visualize these results. The plot will show how the total organic aerosol concentration and the water concentration in the aerosol vary with changing RH. This visualization is crucial for understanding the dynamic behavior of aerosols in different atmospheric humidity conditions.</p>"},{"location":"Examples/Equilibria/Notebooks/equilibria_part1/#summary","title":"Summary\u00b6","text":"<p>In this notebook, we have journeyed through the process of defining a liquid-vapor equilibrium system and employing the binary activity model to calculate activity coefficients as a function of relative humidity (RH). We then used these coefficients to determine the equilibrium composition of the liquid and vapor phases. Finally, the results were visualized to demonstrate the impact of RH on aerosol behavior, which is essential for understanding atmospheric aerosol dynamics and their environmental implications.</p>"},{"location":"Examples/Gas_Phase/","title":"Gas Phase","text":""},{"location":"Examples/Gas_Phase/#notebooks","title":"Notebooks","text":"<ul> <li>Vapor Pressure Tutorial</li> <li>Gas Species Tutorial</li> <li>Atmosphere Tutorial</li> </ul>"},{"location":"Examples/Gas_Phase/Notebooks/AtmosphereTutorial/","title":"Atmosphere Tutorial","text":"In\u00a0[\u00a0]: Copied! <pre># In Colab uncomment the following command to install particula:\n#!pip install particula[extra] --quiet\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# import particula\nimport particula as par\n</pre> # In Colab uncomment the following command to install particula: #!pip install particula[extra] --quiet import numpy as np import matplotlib.pyplot as plt  # import particula import particula as par In\u00a0[17]: Copied! <pre># Define the coefficients for Butanol using the Antoine equation.\nbutanol_coefficients = {\"a\": 7.838, \"b\": 1558.19, \"c\": 196.881}\nbutanol_antione = par.gas.VaporPressureFactory().get_strategy(\n    \"antoine\", butanol_coefficients\n)\nstyrene_coefficients = {\"a\": 6.924, \"b\": 1420, \"c\": 226}\nstyrene_antione = par.gas.VaporPressureFactory().get_strategy(\n    \"antoine\", styrene_coefficients\n)\n\n# Water uses a different model for vapor pressure calculation called the Buck equation.\nwater_buck = par.gas.VaporPressureFactory().get_strategy(\"water_buck\")\n\n# Create the GasSpecies using the GasSpeciesBuilder\n# water species\nwater_species = (\n    par.gas.GasSpeciesBuilder()\n    .set_name(\"water\")\n    .set_molar_mass(18.01528e-3, \"kg/mol\")\n    .set_vapor_pressure_strategy(water_buck)\n    .set_partitioning(True)\n    .set_concentration(1e-3, \"kg/m^3\")\n    .build()\n)\n\n# organic species\norganic_molar_mass = np.array([0.074121, 104.15e-3])\norganic_vapor_pressure = [butanol_antione, styrene_antione]\norganic_concentration = np.array([2e-6, 1e-9])\norganic_names = np.array([\"butanol\", \"styrene\"])\norganic_species = (\n    par.gas.GasSpeciesBuilder()\n    .set_name(organic_names)\n    .set_molar_mass(organic_molar_mass, \"kg/mol\")\n    .set_vapor_pressure_strategy(organic_vapor_pressure)\n    .set_partitioning(True)\n    .set_concentration(organic_concentration, \"kg/m^3\")\n    .build()\n)\n\n# Print the species\nprint(water_species)\nprint(organic_species)\n</pre> # Define the coefficients for Butanol using the Antoine equation. butanol_coefficients = {\"a\": 7.838, \"b\": 1558.19, \"c\": 196.881} butanol_antione = par.gas.VaporPressureFactory().get_strategy(     \"antoine\", butanol_coefficients ) styrene_coefficients = {\"a\": 6.924, \"b\": 1420, \"c\": 226} styrene_antione = par.gas.VaporPressureFactory().get_strategy(     \"antoine\", styrene_coefficients )  # Water uses a different model for vapor pressure calculation called the Buck equation. water_buck = par.gas.VaporPressureFactory().get_strategy(\"water_buck\")  # Create the GasSpecies using the GasSpeciesBuilder # water species water_species = (     par.gas.GasSpeciesBuilder()     .set_name(\"water\")     .set_molar_mass(18.01528e-3, \"kg/mol\")     .set_vapor_pressure_strategy(water_buck)     .set_partitioning(True)     .set_concentration(1e-3, \"kg/m^3\")     .build() )  # organic species organic_molar_mass = np.array([0.074121, 104.15e-3]) organic_vapor_pressure = [butanol_antione, styrene_antione] organic_concentration = np.array([2e-6, 1e-9]) organic_names = np.array([\"butanol\", \"styrene\"]) organic_species = (     par.gas.GasSpeciesBuilder()     .set_name(organic_names)     .set_molar_mass(organic_molar_mass, \"kg/mol\")     .set_vapor_pressure_strategy(organic_vapor_pressure)     .set_partitioning(True)     .set_concentration(organic_concentration, \"kg/m^3\")     .build() )  # Print the species print(water_species) print(organic_species) <pre>water\n['butanol' 'styrene']\n</pre> In\u00a0[18]: Copied! <pre>gas_mixture = (\n    par.gas.AtmosphereBuilder()\n    .set_more_partitioning_species(water_species)\n    .set_more_partitioning_species(organic_species)\n    .set_temperature(25, temperature_units=\"degC\")\n    .set_pressure(1, pressure_units=\"atm\")\n    .build()\n)\n\nprint(\"Notice the units conversion to base SI:\")\nprint(gas_mixture)\n</pre> gas_mixture = (     par.gas.AtmosphereBuilder()     .set_more_partitioning_species(water_species)     .set_more_partitioning_species(organic_species)     .set_temperature(25, temperature_units=\"degC\")     .set_pressure(1, pressure_units=\"atm\")     .build() )  print(\"Notice the units conversion to base SI:\") print(gas_mixture) <pre>Notice the units conversion to base SI:\nGas mixture at 298.15 K, 101325.0 Pa, partitioning=['water' 'butanol' 'styrene'], gas_only_species=None\n</pre> In\u00a0[19]: Copied! <pre># Constants for calculations\nsea_level_pressure = 101325  # Reference pressure at sea level (Pa)\nsea_level_temperature = 288.15  # Reference temperature at sea level (K)\ngravity = 9.80665  # Acceleration due to gravity (m/s^2)\nmolar_mass_air = 0.0289644  # Molar mass of Earth's air (kg/mol)\nuniversal_gas_constant = 8.314  # Universal gas constant (J/(mol\u00b7K))\ntemperature_lapse_rate = 0.0065  # Standard temperature lapse rate (K/m)\n\n# Generate an array of altitudes from sea level (0 meters) to 10 km (10000 meters), divided into 100 intervals\naltitude_range = np.linspace(0, 10000, 100)\n\n# Calculate the temperature at each altitude based on the linear temperature lapse rate\ntemperature_at_altitudes = (\n    sea_level_temperature - temperature_lapse_rate * altitude_range\n)\n\n# Calculate the pressure at each altitude using the barometric formula\npressure_at_altitudes = sea_level_pressure * (\n    (1 - temperature_lapse_rate * altitude_range / sea_level_temperature)\n    ** (\n        gravity\n        * molar_mass_air\n        / (universal_gas_constant * temperature_lapse_rate)\n    )\n)\n\n\n# Initialize a matrix to hold saturation ratios for each species at each\n# altitude\nsaturation_ratio = np.zeros(len(altitude_range))\n\n# Loop over each altitude's temperature and pressure\nfor index, (temperature, pressure) in enumerate(\n    zip(temperature_at_altitudes, pressure_at_altitudes)\n):\n    # Set the current temperature and pressure of the gas mixture\n    gas_mixture.temperature = temperature\n    gas_mixture.total_pressure = pressure\n\n    # Loop over water\n    saturation_ratio[index] = gas_mixture.partitioning_species.get_saturation_ratio(\n        gas_mixture.temperature\n    )[0]\n\n\n# Plot the saturation ratio of water vapor at each altitude\nfig, ax = plt.subplots()\nax.plot(saturation_ratio, altitude_range, label=\"Water\")\nax.set_xscale(\"log\")\nax.set_ylabel(\"Altitude (m)\")\nax.set_xlabel(\"Water Saturation Ratio\")\nax.set_title(\"Saturation Ratio of Water Vapor at Different Altitudes\")\nax.legend()\nplt.show()\n</pre> # Constants for calculations sea_level_pressure = 101325  # Reference pressure at sea level (Pa) sea_level_temperature = 288.15  # Reference temperature at sea level (K) gravity = 9.80665  # Acceleration due to gravity (m/s^2) molar_mass_air = 0.0289644  # Molar mass of Earth's air (kg/mol) universal_gas_constant = 8.314  # Universal gas constant (J/(mol\u00b7K)) temperature_lapse_rate = 0.0065  # Standard temperature lapse rate (K/m)  # Generate an array of altitudes from sea level (0 meters) to 10 km (10000 meters), divided into 100 intervals altitude_range = np.linspace(0, 10000, 100)  # Calculate the temperature at each altitude based on the linear temperature lapse rate temperature_at_altitudes = (     sea_level_temperature - temperature_lapse_rate * altitude_range )  # Calculate the pressure at each altitude using the barometric formula pressure_at_altitudes = sea_level_pressure * (     (1 - temperature_lapse_rate * altitude_range / sea_level_temperature)     ** (         gravity         * molar_mass_air         / (universal_gas_constant * temperature_lapse_rate)     ) )   # Initialize a matrix to hold saturation ratios for each species at each # altitude saturation_ratio = np.zeros(len(altitude_range))  # Loop over each altitude's temperature and pressure for index, (temperature, pressure) in enumerate(     zip(temperature_at_altitudes, pressure_at_altitudes) ):     # Set the current temperature and pressure of the gas mixture     gas_mixture.temperature = temperature     gas_mixture.total_pressure = pressure      # Loop over water     saturation_ratio[index] = gas_mixture.partitioning_species.get_saturation_ratio(         gas_mixture.temperature     )[0]   # Plot the saturation ratio of water vapor at each altitude fig, ax = plt.subplots() ax.plot(saturation_ratio, altitude_range, label=\"Water\") ax.set_xscale(\"log\") ax.set_ylabel(\"Altitude (m)\") ax.set_xlabel(\"Water Saturation Ratio\") ax.set_title(\"Saturation Ratio of Water Vapor at Different Altitudes\") ax.legend() plt.show()"},{"location":"Examples/Gas_Phase/Notebooks/AtmosphereTutorial/#atmosphere-tutorial","title":"Atmosphere Tutorial\u00b6","text":"<p>Gases, alongside particles, constitute the essential components of an aerosol system. In their natural state, gases are collections of molecules that move freely, not bound to one another. We introduce the <code>Atmosphere</code> class, a composite that encapsulates <code>GasSpecies</code>, with additional parameters for the atmospheric state.</p> <ul> <li><code>Atmosphere</code>: This class represents the atmospheric environment by detailing properties such as temperature and pressure, alongside a dynamic list of gas species present.</li> <li><code>AtmosphericBuilder</code>: A builder class that simplifies the creation of <code>Atmosphere</code> objects.</li> </ul> <p>We'll continue with our organics and water example, combining the two into a single <code>Atmosphere</code> object.</p>"},{"location":"Examples/Gas_Phase/Notebooks/AtmosphereTutorial/#build-gas-species","title":"Build Gas Species\u00b6","text":"<p>First we will build the, <code>GasSpecies</code> objects for the organics and water. Following the same procedure from previously in <code>Gas Species</code>.</p>"},{"location":"Examples/Gas_Phase/Notebooks/AtmosphereTutorial/#atmosphere-builder","title":"Atmosphere Builder\u00b6","text":"<p>The <code>AtmosphereBuilder</code> class is a builder class that simplifies the creation of <code>Atmosphere</code> objects. It provides a fluent interface for adding <code>GasSpecies</code> objects to the <code>Atmosphere</code> object. We will use it to build the <code>Atmosphere</code> object for the organics and water. The builder requries the following parameters:</p> <ul> <li><code>pressure</code>: The total pressure of the gas mixture, in Pascals, or provided pressure_units string for conversion.</li> <li><code>temperature</code>: The temperature of the gas mixture, in Kelvin, or provided temperature_units string for conversion.</li> <li><code>species</code>: A list of <code>GasSpecies</code> objects, representing the gases in the mixture. This can be added one by one using the <code>add_species</code> method.</li> </ul>"},{"location":"Examples/Gas_Phase/Notebooks/AtmosphereTutorial/#air","title":"Air\u00b6","text":"<p>Air is assumed to be the non-specified component of the gas mixture, making up the remainder of the gas mixture. We do not explicitly add air to the gas mixture, but it is implicitly included in most calculations.</p>"},{"location":"Examples/Gas_Phase/Notebooks/AtmosphereTutorial/#iterating-over-gas-species","title":"Iterating Over Gas Species\u00b6","text":"<p>Once the <code>Gas</code> object has been established, it enables us to iterate over each <code>GasSpecies</code> within the mixture. This functionality is particularly valuable for evaluating and adjusting properties dynamically, such as when changes in temperature and pressure occur due to environmental alterations.</p>"},{"location":"Examples/Gas_Phase/Notebooks/AtmosphereTutorial/#practical-example-altitude-impact","title":"Practical Example: Altitude Impact\u00b6","text":"<p>Consider a scenario where our gas mixture is transported from sea level to an altitude of 10 kilometers. Such a change in altitude significantly impacts both temperature and pressure, which in turn affects the behavior of each gas species in the mixture.</p>"},{"location":"Examples/Gas_Phase/Notebooks/AtmosphereTutorial/#geopotential-height-equation","title":"Geopotential Height Equation\u00b6","text":"<p>The pressure and temperature changes with altitude can be approximated by using the geopotential height equation. Here's how you can calculate these changes:</p> <ol> <li>Pressure Change: The pressure at a given altitude can be estimated by:</li> </ol> <p>$$    P = P_0 \\left(1 - \\frac{L \\cdot h}{T_0}\\right)^{\\frac{g \\cdot M}{R \\cdot L}} $$</p> <p>where:</p> <ul> <li>$ P $ is the pressure at altitude $ h $,</li> <li>$ P_0 $ is the reference pressure at sea level (101325 Pa),</li> <li>$ L $ is the standard temperature lapse rate (approximately 0.0065 K/m),</li> <li>$ h $ is the altitude in meters (10000 m for 10 km),</li> <li>$ T_0 $ is the reference temperature at sea level (288.15 K),</li> <li>$ g $ is the acceleration due to gravity (9.80665 m/s\u00b2),</li> <li>$ M $ is the molar mass of Earth's air (0.0289644 kg/mol),</li> <li>$ R $ is the universal gas constant (8.314 J/(mol\u00b7K)).</li> </ul> <ol> <li><p>Temperature Change: The temperature decreases linearly with altitude at the lapse rate $ L $:</p> <p>$$ T = T_0 - L h $$</p> <p>Using this formula, we can estimate the temperature at an altitude of 10 km:</p> <ul> <li>$T$ = 223.15 K</li> <li>$L$ = 0.0065 K/m</li> <li>$h$ = 10000 m</li> </ul> </li> </ol>"},{"location":"Examples/Gas_Phase/Notebooks/AtmosphereTutorial/#application","title":"Application\u00b6","text":"<p>By iterating through each <code>GasSpecies</code>, we can apply these formulas to adjust their properties based on the calculated pressure and temperature at 10 km altitude, aiding in simulations or real-world applications where altitude plays a crucial role in gas behavior.</p>"},{"location":"Examples/Gas_Phase/Notebooks/AtmosphereTutorial/#summary","title":"Summary\u00b6","text":"<p>In this notebook, we learned how to create an <code>Atmosphere</code> object using the <code>AtmosphereBuilder</code> class. We also explored how to iterate over each <code>GasSpecies</code> within the mixture, enabling us to adjust properties dynamically based on environmental changes. This functionality is particularly useful for simulating real-world scenarios where temperature and pressure variations significantly impact gas behavior.</p> <p>We now need to build the particle representation, so that combined with the <code>Atmosphere</code>, we can create an aerosol system.</p>"},{"location":"Examples/Gas_Phase/Notebooks/Gas_Species/","title":"Gas Species Tutorial","text":"In\u00a0[\u00a0]: Copied! <pre># In Colab uncomment the following command to install particula:\n#!pip install particula[extra] --quiet\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Particula imports\nimport particula as par\n</pre> # In Colab uncomment the following command to install particula: #!pip install particula[extra] --quiet import numpy as np import matplotlib.pyplot as plt  # Particula imports import particula as par In\u00a0[6]: Copied! <pre># Define the coefficients for Butanol using the Antoine equation.\n# 'a', 'b', and 'c' are coefficients specific to the Antoine equation used to calculate vapor pressure.\nbutanol_coefficients = {\"a\": 7.838, \"b\": 1558.19, \"c\": 196.881}\n# Create a vapor pressure strategy for Butanol using the Antoine equation.\nbutanol_antione = par.gas.VaporPressureFactory().get_strategy(\n    strategy_type=\"antoine\", parameters=butanol_coefficients\n)\n\n# Define the coefficients for Styrene, similar to Butanol, using the\n# Antoine equation.\nstyrene_coefficients = {\"a\": 6.924, \"b\": 1420, \"c\": 226}\n# Create a vapor pressure strategy for Styrene using the Antoine equation.\nstyrene_antione = par.gas.VaporPressureFactory().get_strategy(\n    strategy_type=\"antoine\", parameters=styrene_coefficients\n)\n\n# Water uses a different model for vapor pressure calculation called the Buck equation.\n# The Buck equation is particularly suited for water vapor calculations.\n# No additional parameters are required to be passed for the Buck equation\n# in this instance.\nwater_buck = par.gas.VaporPressureFactory().get_strategy(\n    strategy_type=\"water_buck\"\n)\n</pre> # Define the coefficients for Butanol using the Antoine equation. # 'a', 'b', and 'c' are coefficients specific to the Antoine equation used to calculate vapor pressure. butanol_coefficients = {\"a\": 7.838, \"b\": 1558.19, \"c\": 196.881} # Create a vapor pressure strategy for Butanol using the Antoine equation. butanol_antione = par.gas.VaporPressureFactory().get_strategy(     strategy_type=\"antoine\", parameters=butanol_coefficients )  # Define the coefficients for Styrene, similar to Butanol, using the # Antoine equation. styrene_coefficients = {\"a\": 6.924, \"b\": 1420, \"c\": 226} # Create a vapor pressure strategy for Styrene using the Antoine equation. styrene_antione = par.gas.VaporPressureFactory().get_strategy(     strategy_type=\"antoine\", parameters=styrene_coefficients )  # Water uses a different model for vapor pressure calculation called the Buck equation. # The Buck equation is particularly suited for water vapor calculations. # No additional parameters are required to be passed for the Buck equation # in this instance. water_buck = par.gas.VaporPressureFactory().get_strategy(     strategy_type=\"water_buck\" ) In\u00a0[7]: Copied! <pre># Configure the builder with the necessary properties\nwater_species = (\n    par.gas.GasSpeciesBuilder()\n    .set_name(\"Water\")\n    .set_molar_mass(18.01528, molar_mass_units=\"g/mol\")\n    .set_vapor_pressure_strategy(water_buck)\n    .set_partitioning(True)\n    .set_concentration(1e2, concentration_units=\"ug/m^3\")\n    .build()\n)\n\n\n# molar mass in kg/mol, concentration in kg/m3\n\nprint(water_species)\nprint(\n    f\"Notice the units of the concentration are now in kg/m^3: {water_species.concentration}\"\n)\nprint(\n    f\"Also the units of the molar mass are now in kg/mol: {water_species.molar_mass}\"\n)\n</pre> # Configure the builder with the necessary properties water_species = (     par.gas.GasSpeciesBuilder()     .set_name(\"Water\")     .set_molar_mass(18.01528, molar_mass_units=\"g/mol\")     .set_vapor_pressure_strategy(water_buck)     .set_partitioning(True)     .set_concentration(1e2, concentration_units=\"ug/m^3\")     .build() )   # molar mass in kg/mol, concentration in kg/m3  print(water_species) print(     f\"Notice the units of the concentration are now in kg/m^3: {water_species.concentration}\" ) print(     f\"Also the units of the molar mass are now in kg/mol: {water_species.molar_mass}\" ) <pre>Water\nNotice the units of the concentration are now in kg/m^3: 1.0000000000000001e-07\nAlso the units of the molar mass are now in kg/mol: 0.01801528\n</pre> In\u00a0[8]: Copied! <pre># Define molar masses for organic species (Butanol and Styrene) in kilograms per mole (kg/mol).\norganic_molar_mass = np.array(\n    [0.074121, 104.15e-3]\n)  # Molar mass for Butanol and Styrene respectively.\n\n# List of vapor pressure strategies assigned to each organic species.\norganic_vapor_pressure = [\n    butanol_antione,\n    styrene_antione,\n]  # Using Antoine's equation for both.\n\n# Define concentrations for each organic species in the mixture, in kilograms per cubic meter (kg/m^3).\norganic_concentration = np.array(\n    [2e-6, 1e-9]\n)  # Concentration values for Butanol and Styrene respectively.\n\n# Names of the organic species.\norganic_names = np.array([\"butanol\", \"styrene\"])\n\n# Using GasSpeciesBuilder to construct a GasSpecies object for organics.\n# Notice how we can directly use arrays to set properties for multiple species.\norganic_species = (\n    par.gas.GasSpeciesBuilder()\n    .set_name(organic_names)\n    .set_molar_mass(organic_molar_mass, \"kg/mol\")\n    .set_vapor_pressure_strategy(organic_vapor_pressure)\n    .set_partitioning(True)\n    .set_concentration(organic_concentration, \"kg/m^3\")\n    .build()\n)\n\n# The `build()` method validates all the properties are set and returns the constructed GasSpecies object(s).\n# Here, organic_species will contain the built GasSpecies instances for Butanol and Styrene.\nprint(organic_species)\n</pre> # Define molar masses for organic species (Butanol and Styrene) in kilograms per mole (kg/mol). organic_molar_mass = np.array(     [0.074121, 104.15e-3] )  # Molar mass for Butanol and Styrene respectively.  # List of vapor pressure strategies assigned to each organic species. organic_vapor_pressure = [     butanol_antione,     styrene_antione, ]  # Using Antoine's equation for both.  # Define concentrations for each organic species in the mixture, in kilograms per cubic meter (kg/m^3). organic_concentration = np.array(     [2e-6, 1e-9] )  # Concentration values for Butanol and Styrene respectively.  # Names of the organic species. organic_names = np.array([\"butanol\", \"styrene\"])  # Using GasSpeciesBuilder to construct a GasSpecies object for organics. # Notice how we can directly use arrays to set properties for multiple species. organic_species = (     par.gas.GasSpeciesBuilder()     .set_name(organic_names)     .set_molar_mass(organic_molar_mass, \"kg/mol\")     .set_vapor_pressure_strategy(organic_vapor_pressure)     .set_partitioning(True)     .set_concentration(organic_concentration, \"kg/m^3\")     .build() )  # The `build()` method validates all the properties are set and returns the constructed GasSpecies object(s). # Here, organic_species will contain the built GasSpecies instances for Butanol and Styrene. print(organic_species) <pre>['butanol' 'styrene']\n</pre> In\u00a0[9]: Copied! <pre>temperature_range = np.linspace(\n    273.15, 373.15, 100\n)  # Temperature range from 0 to 100 degrees Celsius.\n\norganic_pure_vapor_pressure = organic_species.get_pure_vapor_pressure(\n    temperature_range\n)\nwater_pure_vapor_pressure = water_species.get_pure_vapor_pressure(\n    temperature_range\n)\n\n# Plotting the vapor pressure curves for the organic species.\nfig, ax = plt.subplots(figsize=(8, 6))\nfor i in range(len(organic_names)):\n    ax.plot(\n        temperature_range,\n        organic_pure_vapor_pressure[i],\n        label=organic_names[i],\n    )\nax.plot(temperature_range, water_pure_vapor_pressure, label=\"Water\")\nax.set_xlabel(\"Temperature (K)\")\nax.set_ylabel(\"Vapor Pressure (Pa)\")\nax.set_yscale(\"log\")\nax.legend()\nplt.show()\n</pre> temperature_range = np.linspace(     273.15, 373.15, 100 )  # Temperature range from 0 to 100 degrees Celsius.  organic_pure_vapor_pressure = organic_species.get_pure_vapor_pressure(     temperature_range ) water_pure_vapor_pressure = water_species.get_pure_vapor_pressure(     temperature_range )  # Plotting the vapor pressure curves for the organic species. fig, ax = plt.subplots(figsize=(8, 6)) for i in range(len(organic_names)):     ax.plot(         temperature_range,         organic_pure_vapor_pressure[i],         label=organic_names[i],     ) ax.plot(temperature_range, water_pure_vapor_pressure, label=\"Water\") ax.set_xlabel(\"Temperature (K)\") ax.set_ylabel(\"Vapor Pressure (Pa)\") ax.set_yscale(\"log\") ax.legend() plt.show() In\u00a0[10]: Copied! <pre># Saturation ratio calculation\norganic_saturation_ratio = organic_species.get_saturation_ratio(\n    temperature_range\n)\nwater_saturation_ratio = water_species.get_saturation_ratio(temperature_range)\n\n# Plotting the saturation ratio curves for the organic species.\nfig, ax = plt.subplots(figsize=(8, 6))\nfor i in range(len(organic_names)):\n    ax.plot(\n        temperature_range, organic_saturation_ratio[i], label=organic_names[i]\n    )\nax.plot(temperature_range, water_saturation_ratio, label=\"Water\")\nax.set_ylim(0, 5)\nax.set_xlabel(\"Temperature (K)\")\nax.set_ylabel(\"Saturation Ratio\")\nax.legend()\nplt.show()\n</pre> # Saturation ratio calculation organic_saturation_ratio = organic_species.get_saturation_ratio(     temperature_range ) water_saturation_ratio = water_species.get_saturation_ratio(temperature_range)  # Plotting the saturation ratio curves for the organic species. fig, ax = plt.subplots(figsize=(8, 6)) for i in range(len(organic_names)):     ax.plot(         temperature_range, organic_saturation_ratio[i], label=organic_names[i]     ) ax.plot(temperature_range, water_saturation_ratio, label=\"Water\") ax.set_ylim(0, 5) ax.set_xlabel(\"Temperature (K)\") ax.set_ylabel(\"Saturation Ratio\") ax.legend() plt.show()"},{"location":"Examples/Gas_Phase/Notebooks/Gas_Species/#gas-species-tutorial","title":"Gas Species Tutorial\u00b6","text":"<p>The <code>GasSpecies</code> is a class that represents a gas species in a simulation or calculation. It includes properties such as the species' name, molar mass, vapor pressure, and whether it is condensable. The class provides methods to set and retrieve these properties, ensuring that each species is fully defined and manageable within simulations.</p> <p>In this notebook, we will demonstrate how to use the <code>GasSpecies</code> class to create and manage gas species. This includes creating new species, setting their properties, and retrieving vapor pressure, concentration, and other properties.</p>"},{"location":"Examples/Gas_Phase/Notebooks/Gas_Species/#key-classes","title":"Key Classes\u00b6","text":"<ul> <li><code>GasSpecies</code>: Represents a gas species in a simulation or calculation.</li> <li><code>GasSpeciesBuilder</code>: A builder class that constructs instances of <code>GasSpecies</code> with well-defined properties.</li> </ul>"},{"location":"Examples/Gas_Phase/Notebooks/Gas_Species/#define-vapor-pressure-strategies","title":"Define Vapor Pressure Strategies\u00b6","text":"<p>In this section, we'll focus on defining vapor pressure strategies for gas species, specifically Butanol, Styrene, and Water, which were used in our previous examples. To streamline our analysis, we will group Butanol and Styrene into a single organic category, and consider Water separately.</p>"},{"location":"Examples/Gas_Phase/Notebooks/Gas_Species/#strategy-assignment","title":"Strategy Assignment\u00b6","text":"<p>For calculating vapor pressures:</p> <ul> <li>Organics (Butanol and Styrene): We will utilize the Antoine equation, a widely recognized method for estimating the vapor pressure of organic compounds based on temperature.</li> <li>Water: We will apply the Buck equation, which is specifically tailored to accurately calculate the vapor pressure of water across a range of temperatures.</li> </ul>"},{"location":"Examples/Gas_Phase/Notebooks/Gas_Species/#using-gasspeciesbuilder-to-construct-gas-species","title":"Using <code>GasSpeciesBuilder</code> to Construct Gas Species\u00b6","text":"<p>Now that we have defined the appropriate vapor pressure strategies for our gas species, we can proceed to construct the individual species using the <code>GasSpeciesBuilder</code>. This builder simplifies the process of defining and validating the properties of each gas species before their creation. We'll begin with Water, as it involves a straightforward application of the Buck equation.</p>"},{"location":"Examples/Gas_Phase/Notebooks/Gas_Species/#building-the-water-gas-species","title":"Building the Water Gas Species\u00b6","text":"<p>The <code>GasSpeciesBuilder</code> facilitates a structured approach to setting up a gas species. To build a Water gas species, the builder requires the following properties to be set:</p> <ol> <li>Name: Identifies the species, which in this case is \"Water\".</li> <li>Molar Mass: The molar mass of water, essential for calculations involving mass and moles.</li> <li>Vapor Pressure Strategy: The specific strategy used to calculate vapor pressure; for Water, we use the Buck equation.</li> <li>Condensability: Indicates whether the species can condense under certain atmospheric conditions. For Water, this is typically true.</li> <li>Concentration: The initial concentration of Water in the mixture, which could vary based on the scenario.</li> </ol> <p>Here is how you can use the <code>GasSpeciesBuilder</code> to set up Water:</p>"},{"location":"Examples/Gas_Phase/Notebooks/Gas_Species/#building-gas-species-for-organics","title":"Building Gas Species for Organics\u00b6","text":"<p>Following Water, you can apply a similar process to build gas species for Organics like Butanol and Styrene. Each will have its set of properties based on the chemical's nature and the desired simulation context.</p> <p>When calling <code>.build()</code>, it checks that all required properties are set correctly, raising an error if any essential attribute is missing or improperly configured. This ensures that each <code>GasSpecies</code> instance is valid and ready usage.</p>"},{"location":"Examples/Gas_Phase/Notebooks/Gas_Species/#pure-vapor-pressures","title":"Pure Vapor Pressures\u00b6","text":"<p>With the gas species defined, we can now calculate the pure vapor pressures of Butanol, Styrene, and Water using the respective strategies we assigned earlier. This will help us understand the vapor pressure behavior of each species individually, which is crucial for predicting their behavior in mixtures and under varying conditions.</p>"},{"location":"Examples/Gas_Phase/Notebooks/Gas_Species/#saturation-ratios","title":"Saturation Ratios\u00b6","text":"<p>Now that we have established the concentration of each gas species within the mixture, we can proceed to calculate the saturation ratio for each species. The saturation ratio is an essential parameter in determining the condensation behavior of gas species within a mixture.</p> <ul> <li>Above 1: A saturation ratio greater than 1 indicates that the species is supersaturated and is likely to condense.</li> <li>Below 1: Conversely, a saturation ratio below 1 suggests that the species will likely remain in the gas phase.</li> </ul>"},{"location":"Examples/Gas_Phase/Notebooks/Gas_Species/#future-exploration","title":"Future Exploration\u00b6","text":"<p>In subsequent sections of this notebook series, we will delve deeper into how these saturation ratios reach equilibrium with a liquid phase, enhancing our understanding of the phase behavior under different conditions.</p>"},{"location":"Examples/Gas_Phase/Notebooks/Gas_Species/#summary","title":"Summary\u00b6","text":"<p>The <code>GasSpecies</code> module, along with the <code>GasSpeciesBuilder</code>, provides a robust framework for defining and managing gas species within a mixture. By assigning specific vapor pressure strategies and other essential properties, we can accurately model the behavior of individual species and their interactions in various scenarios. This module serves as a foundational component for more advanced simulations and analyses involving gas mixtures, condensation, and phase equilibrium.</p> <p>The next section is one more layer of abstraction, where we will define the <code>GasMixture</code> class to manage multiple gas species within a single mixture. This class will enable us to handle complex gas mixtures effectively and efficiently, paving the way particle to gas interactions.</p>"},{"location":"Examples/Gas_Phase/Notebooks/Vapor_Pressure/","title":"Vapor Pressure Tutorial","text":"In\u00a0[\u00a0]: Copied! <pre># In Colab uncomment the following command to install particula:\n#!pip install particula[extra] --quiet\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nimport particula as par\n</pre> # In Colab uncomment the following command to install particula: #!pip install particula[extra] --quiet import numpy as np import matplotlib.pyplot as plt  import particula as par In\u00a0[18]: Copied! <pre># Direct instantiation of an AntoineVaporPressureStrategy for butanol.\n# This approach directly sets the coefficients 'a', 'b', and 'c' specific\n# to butanol for calculating its vapor pressure.\nbutanol_antione = par.gas.AntoineVaporPressureStrategy(\n    a=7.838, b=1558.19, c=196.881\n)\n\n# Use the Builder pattern to create a vapor pressure strategy for styrene.\n# The Builder pattern allows for more flexible object creation by setting properties step-by-step.\n# This approach, also validates the input parameters and ensures the object is fully defined.\n# Here, coefficients are set individually using setter methods provided by\n# the AntoineBuilder.\nstyrene_coefficients = {\"a\": 6.924, \"b\": 1420, \"c\": 226}\nstyrene_antione = (\n    par.gas.AntoineVaporPressureBuilder()\n    .set_a(styrene_coefficients[\"a\"])\n    .set_b(styrene_coefficients[\"b\"])\n    .set_c(styrene_coefficients[\"c\"])\n    .build()\n)\n\n# Initialize a vapor pressure strategy for water using the factory method.\n# The factory method abstracts the creation logic of the builder and can instantiate different builder strategies based on the input strategy.\n# This approach ensures that object creation is centralized and consistent across the application.\n# Note: The strategy name provided to the factory method is case-insensitive.\nwater_coefficients = {\"a\": 7.949017, \"b\": 1657.462, \"c\": 227.02}\nwater_antione = par.gas.VaporPressureFactory().get_strategy(\n    strategy_type=\"Antoine\", parameters=water_coefficients\n)\n\n\n# Calculate and print the vapor pressures at 300 Kelvin for each substance using the initialized strategies.\n# The function 'pure_vapor_pressure' is used here, which calculates the\n# vapor pressure based on the provided temperature.\n\nprint(\n    f\"Butanol Antoine vapor pressure at 300 K: {butanol_antione.pure_vapor_pressure(300)} Pa\"\n)\nprint(\n    f\"Styrene Antoine vapor pressure at 300 K: {styrene_antione.pure_vapor_pressure(300)} Pa\"\n)\nprint(\n    f\"Water Antoine vapor pressure at 300 K: {water_antione.pure_vapor_pressure(300)} Pa\"\n)\n</pre> # Direct instantiation of an AntoineVaporPressureStrategy for butanol. # This approach directly sets the coefficients 'a', 'b', and 'c' specific # to butanol for calculating its vapor pressure. butanol_antione = par.gas.AntoineVaporPressureStrategy(     a=7.838, b=1558.19, c=196.881 )  # Use the Builder pattern to create a vapor pressure strategy for styrene. # The Builder pattern allows for more flexible object creation by setting properties step-by-step. # This approach, also validates the input parameters and ensures the object is fully defined. # Here, coefficients are set individually using setter methods provided by # the AntoineBuilder. styrene_coefficients = {\"a\": 6.924, \"b\": 1420, \"c\": 226} styrene_antione = (     par.gas.AntoineVaporPressureBuilder()     .set_a(styrene_coefficients[\"a\"])     .set_b(styrene_coefficients[\"b\"])     .set_c(styrene_coefficients[\"c\"])     .build() )  # Initialize a vapor pressure strategy for water using the factory method. # The factory method abstracts the creation logic of the builder and can instantiate different builder strategies based on the input strategy. # This approach ensures that object creation is centralized and consistent across the application. # Note: The strategy name provided to the factory method is case-insensitive. water_coefficients = {\"a\": 7.949017, \"b\": 1657.462, \"c\": 227.02} water_antione = par.gas.VaporPressureFactory().get_strategy(     strategy_type=\"Antoine\", parameters=water_coefficients )   # Calculate and print the vapor pressures at 300 Kelvin for each substance using the initialized strategies. # The function 'pure_vapor_pressure' is used here, which calculates the # vapor pressure based on the provided temperature.  print(     f\"Butanol Antoine vapor pressure at 300 K: {butanol_antione.pure_vapor_pressure(300)} Pa\" ) print(     f\"Styrene Antoine vapor pressure at 300 K: {styrene_antione.pure_vapor_pressure(300)} Pa\" ) print(     f\"Water Antoine vapor pressure at 300 K: {water_antione.pure_vapor_pressure(300)} Pa\" ) <pre>Butanol Antoine vapor pressure at 300 K: 7.1170940952359955e-06 Pa\nStyrene Antoine vapor pressure at 300 K: 7.239588688753633e-11 Pa\nWater Antoine vapor pressure at 300 K: 2.305360971329159e-13 Pa\n</pre> In\u00a0[19]: Copied! <pre># failed build due to missing parameters\ntry:\n    styrene_fail = (\n        par.gas.AntoineVaporPressureBuilder().set_a(styrene_coefficients[\"a\"]).build()\n    )\nexcept ValueError as e:\n    print(e)  # prints error message\n</pre> # failed build due to missing parameters try:     styrene_fail = (         par.gas.AntoineVaporPressureBuilder().set_a(styrene_coefficients[\"a\"]).build()     ) except ValueError as e:     print(e)  # prints error message <pre>[ERROR|abc_builder|L157]: Required parameter(s) not set: b, c\n</pre> <pre>Required parameter(s) not set: b, c\n</pre> In\u00a0[20]: Copied! <pre># create a range of temperatures from 200 to 400 Kelvin\ntemperatures = np.linspace(300, 500, 100)\n\n# Calculate the vapor pressures for each substance at the range of temperatures.\nbutanol_vapor_pressure = butanol_antione.pure_vapor_pressure(temperatures)\nstyrene_vapor_pressure = styrene_antione.pure_vapor_pressure(temperatures)\nwater_vapor_pressure = water_antione.pure_vapor_pressure(temperatures)\n\n# Plot the vapor pressures for each substance.\nfig, ax = plt.subplots(figsize=(8, 6))\nax.plot(temperatures, butanol_vapor_pressure, label=\"Butanol\")\nax.plot(temperatures, styrene_vapor_pressure, label=\"Styrene\", linestyle=\"--\")\nax.plot(temperatures, water_vapor_pressure, label=\"Water\", linestyle=\"-.\")\nax.set_yscale(\"log\")\nax.set_xlabel(\"Temperature (K)\")\nax.set_ylabel(\"Pure Vapor Pressure (Pa)\")\nax.set_title(\"Pure Vapor Pressure vs Temperature\")\nax.legend()\nplt.show()\n</pre> # create a range of temperatures from 200 to 400 Kelvin temperatures = np.linspace(300, 500, 100)  # Calculate the vapor pressures for each substance at the range of temperatures. butanol_vapor_pressure = butanol_antione.pure_vapor_pressure(temperatures) styrene_vapor_pressure = styrene_antione.pure_vapor_pressure(temperatures) water_vapor_pressure = water_antione.pure_vapor_pressure(temperatures)  # Plot the vapor pressures for each substance. fig, ax = plt.subplots(figsize=(8, 6)) ax.plot(temperatures, butanol_vapor_pressure, label=\"Butanol\") ax.plot(temperatures, styrene_vapor_pressure, label=\"Styrene\", linestyle=\"--\") ax.plot(temperatures, water_vapor_pressure, label=\"Water\", linestyle=\"-.\") ax.set_yscale(\"log\") ax.set_xlabel(\"Temperature (K)\") ax.set_ylabel(\"Pure Vapor Pressure (Pa)\") ax.set_title(\"Pure Vapor Pressure vs Temperature\") ax.legend() plt.show() In\u00a0[21]: Copied! <pre># Define the molar mass of each substance in kg/mol\nbutanol_molar_mass = 74.12e-3\nstyrene_molar_mass = 104.15e-3\nwater_molar_mass = 18.015e-3\n\n# calculate the concentration pressure vs temperature\nbutanol_saturation_concentration = butanol_antione.saturation_concentration(\n    molar_mass=butanol_molar_mass, temperature=temperatures\n)\nstyrene_saturation_concentration = styrene_antione.saturation_concentration(\n    molar_mass=styrene_molar_mass, temperature=temperatures\n)\nwater_saturation_concentration = water_antione.saturation_concentration(\n    molar_mass=water_molar_mass, temperature=temperatures\n)\n\n# Plot the saturation concentrations for each substance.\nfig, ax = plt.subplots(figsize=(8, 6))\nax.plot(temperatures, butanol_saturation_concentration, label=\"Butanol\")\nax.plot(\n    temperatures,\n    styrene_saturation_concentration,\n    label=\"Styrene\",\n    linestyle=\"--\",\n)\nax.plot(\n    temperatures, water_saturation_concentration, label=\"Water\", linestyle=\"-.\"\n)\nax.set_yscale(\"log\")\nax.set_xlabel(\"Temperature (K)\")\nax.set_ylabel(\"Saturation Concentration (kg/m^3)\")\nax.set_title(\"Saturation Concentration vs Temperature\")\nax.legend()\nplt.show()\n</pre> # Define the molar mass of each substance in kg/mol butanol_molar_mass = 74.12e-3 styrene_molar_mass = 104.15e-3 water_molar_mass = 18.015e-3  # calculate the concentration pressure vs temperature butanol_saturation_concentration = butanol_antione.saturation_concentration(     molar_mass=butanol_molar_mass, temperature=temperatures ) styrene_saturation_concentration = styrene_antione.saturation_concentration(     molar_mass=styrene_molar_mass, temperature=temperatures ) water_saturation_concentration = water_antione.saturation_concentration(     molar_mass=water_molar_mass, temperature=temperatures )  # Plot the saturation concentrations for each substance. fig, ax = plt.subplots(figsize=(8, 6)) ax.plot(temperatures, butanol_saturation_concentration, label=\"Butanol\") ax.plot(     temperatures,     styrene_saturation_concentration,     label=\"Styrene\",     linestyle=\"--\", ) ax.plot(     temperatures, water_saturation_concentration, label=\"Water\", linestyle=\"-.\" ) ax.set_yscale(\"log\") ax.set_xlabel(\"Temperature (K)\") ax.set_ylabel(\"Saturation Concentration (kg/m^3)\") ax.set_title(\"Saturation Concentration vs Temperature\") ax.legend() plt.show() In\u00a0[22]: Copied! <pre># saturation concentration at 300 K\nbutanol_300K_concentration = butanol_saturation_concentration[0]\nstyrene_300K_concentration = styrene_saturation_concentration[0]\nwater_300K_concentration = water_saturation_concentration[0]\n\n# caculate the partial pressure of each substance at 300 K\nbutanol_partial_pressure = butanol_antione.partial_pressure(\n    concentration=butanol_300K_concentration,\n    molar_mass=butanol_molar_mass,\n    temperature=temperatures,\n)\nstyrene_partial_pressure = styrene_antione.partial_pressure(\n    concentration=styrene_300K_concentration,\n    molar_mass=styrene_molar_mass,\n    temperature=temperatures,\n)\nwater_partial_pressure = water_antione.partial_pressure(\n    concentration=water_300K_concentration,\n    molar_mass=water_molar_mass,\n    temperature=temperatures,\n)\n\n# Plot the partial pressures for each substance.\nfig, ax = plt.subplots(figsize=(8, 6))\nax.plot(temperatures, butanol_partial_pressure, label=\"Butanol\")\nax.plot(\n    temperatures, styrene_partial_pressure, label=\"Styrene\", linestyle=\"--\"\n)\nax.plot(temperatures, water_partial_pressure, label=\"Water\", linestyle=\"-.\")\nax.set_yscale(\"log\")\nax.set_xlabel(\"Temperature (K)\")\nax.set_ylabel(\"Partial Pressure (Pa)\")\nax.set_title(\"Partial Pressure vs Temperature\")\nax.legend()\nplt.show()\n</pre> # saturation concentration at 300 K butanol_300K_concentration = butanol_saturation_concentration[0] styrene_300K_concentration = styrene_saturation_concentration[0] water_300K_concentration = water_saturation_concentration[0]  # caculate the partial pressure of each substance at 300 K butanol_partial_pressure = butanol_antione.partial_pressure(     concentration=butanol_300K_concentration,     molar_mass=butanol_molar_mass,     temperature=temperatures, ) styrene_partial_pressure = styrene_antione.partial_pressure(     concentration=styrene_300K_concentration,     molar_mass=styrene_molar_mass,     temperature=temperatures, ) water_partial_pressure = water_antione.partial_pressure(     concentration=water_300K_concentration,     molar_mass=water_molar_mass,     temperature=temperatures, )  # Plot the partial pressures for each substance. fig, ax = plt.subplots(figsize=(8, 6)) ax.plot(temperatures, butanol_partial_pressure, label=\"Butanol\") ax.plot(     temperatures, styrene_partial_pressure, label=\"Styrene\", linestyle=\"--\" ) ax.plot(temperatures, water_partial_pressure, label=\"Water\", linestyle=\"-.\") ax.set_yscale(\"log\") ax.set_xlabel(\"Temperature (K)\") ax.set_ylabel(\"Partial Pressure (Pa)\") ax.set_title(\"Partial Pressure vs Temperature\") ax.legend() plt.show() In\u00a0[23]: Copied! <pre># caculate the saturation ratio\nbutanol_saturation_ratio = butanol_antione.saturation_ratio(\n    concentration=butanol_300K_concentration,\n    molar_mass=butanol_molar_mass,\n    temperature=temperatures,\n)\nstyrene_saturation_ratio = styrene_antione.saturation_ratio(\n    concentration=styrene_300K_concentration,\n    molar_mass=styrene_molar_mass,\n    temperature=temperatures,\n)\nwater_saturation_ratio = water_antione.saturation_ratio(\n    concentration=water_300K_concentration,\n    molar_mass=water_molar_mass,\n    temperature=temperatures,\n)\n\n# Plot the saturation ratios for each substance.\nfig, ax = plt.subplots(figsize=(8, 6))\nax.plot(temperatures, butanol_saturation_ratio, label=\"Butanol\")\nax.plot(\n    temperatures, styrene_saturation_ratio, label=\"Styrene\", linestyle=\"--\"\n)\nax.plot(temperatures, water_saturation_ratio, label=\"Water\", linestyle=\"-.\")\nax.set_xlabel(\"Temperature (K)\")\nax.set_ylabel(\"Saturation Ratio\")\nax.set_title(\"Saturation Ratio vs Temperature\")\nax.legend()\nplt.show()\n</pre> # caculate the saturation ratio butanol_saturation_ratio = butanol_antione.saturation_ratio(     concentration=butanol_300K_concentration,     molar_mass=butanol_molar_mass,     temperature=temperatures, ) styrene_saturation_ratio = styrene_antione.saturation_ratio(     concentration=styrene_300K_concentration,     molar_mass=styrene_molar_mass,     temperature=temperatures, ) water_saturation_ratio = water_antione.saturation_ratio(     concentration=water_300K_concentration,     molar_mass=water_molar_mass,     temperature=temperatures, )  # Plot the saturation ratios for each substance. fig, ax = plt.subplots(figsize=(8, 6)) ax.plot(temperatures, butanol_saturation_ratio, label=\"Butanol\") ax.plot(     temperatures, styrene_saturation_ratio, label=\"Styrene\", linestyle=\"--\" ) ax.plot(temperatures, water_saturation_ratio, label=\"Water\", linestyle=\"-.\") ax.set_xlabel(\"Temperature (K)\") ax.set_ylabel(\"Saturation Ratio\") ax.set_title(\"Saturation Ratio vs Temperature\") ax.legend() plt.show() In\u00a0[24]: Copied! <pre># Setting a constant vapor pressure at 300 K for water\nwater_pure_at_300K = {\"vapor_pressure\": 1234.56, \"vapor_pressure_units\": \"Pa\"}  # in Pascals (Pa)\nwater_constant_strategy = par.gas.VaporPressureFactory().get_strategy(\n    strategy_type=\"constant\", parameters=water_pure_at_300K\n)\n\n# Setting parameters for the Clausius-Clapeyron equation for water\nwater_clausius_clapeyron_parameters = {\n    \"latent_heat\": 40.7e3,  # specific latent heat J/mol\n    \"latent_heat_units\": \"J/mol\",\n    \"temperature_initial\": 300,  # Initial temperature in Kelvin\n    \"temperature_initial_units\": \"K\",\n    \"pressure_initial\": 1234.56,  # Initial pressure in Pascals\n    \"pressure_initial_units\": \"Pa\",\n}\nwater_clausius_clapeyron_strategy = (\n    par.gas.VaporPressureFactory().get_strategy(\n        strategy_type=\"clausius_clapeyron\",\n        parameters=water_clausius_clapeyron_parameters,\n    )\n)\n\n# Using the Water Buck strategy, no additional parameters needed\nwater_buck_strategy = par.gas.VaporPressureFactory().get_strategy(\n    strategy_type=\"water_buck\"\n)\n\n# Define a range of temperatures for which to calculate vapor pressures\ntemperatures = range(250, 500)  # From 280 K to 320 K\n\n# Calculate the pure vapor pressure at different temperatures using\n# various strategies\nwater_pure_constant = [\n    water_constant_strategy.pure_vapor_pressure(temp) for temp in temperatures\n]\nwater_pure_antione = [\n    water_antione.pure_vapor_pressure(temp) for temp in temperatures\n]\nwater_pure_clausius_clapeyron = [\n    water_clausius_clapeyron_strategy.pure_vapor_pressure(temp)\n    for temp in temperatures\n]\nwater_pure_buck = [\n    water_buck_strategy.pure_vapor_pressure(temp) for temp in temperatures\n]\n\n# Plotting the results using Matplotlib\nfig, ax = plt.subplots(figsize=(8, 6))\nax.plot(temperatures, water_pure_constant, label=\"Constant\", linestyle=\"-\")\nax.plot(temperatures, water_pure_antione, label=\"Antoine\", linestyle=\"--\")\nax.plot(\n    temperatures,\n    water_pure_clausius_clapeyron,\n    label=\"Clausius-Clapeyron\",\n    linestyle=\"-.\",\n)\nax.plot(temperatures, water_pure_buck, label=\"Buck\", linestyle=\":\")\nax.set_yscale(\"log\")\nax.set_ylim(bottom=1e-10)\nax.set_xlabel(\"Temperature (K)\")\nax.set_ylabel(\"Pure Vapor Pressure (Pa)\")\nax.set_title(\"Comparison of Water Vapor Pressure Calculations\")\nax.legend(loc=\"lower right\")\nplt.show()\n</pre> # Setting a constant vapor pressure at 300 K for water water_pure_at_300K = {\"vapor_pressure\": 1234.56, \"vapor_pressure_units\": \"Pa\"}  # in Pascals (Pa) water_constant_strategy = par.gas.VaporPressureFactory().get_strategy(     strategy_type=\"constant\", parameters=water_pure_at_300K )  # Setting parameters for the Clausius-Clapeyron equation for water water_clausius_clapeyron_parameters = {     \"latent_heat\": 40.7e3,  # specific latent heat J/mol     \"latent_heat_units\": \"J/mol\",     \"temperature_initial\": 300,  # Initial temperature in Kelvin     \"temperature_initial_units\": \"K\",     \"pressure_initial\": 1234.56,  # Initial pressure in Pascals     \"pressure_initial_units\": \"Pa\", } water_clausius_clapeyron_strategy = (     par.gas.VaporPressureFactory().get_strategy(         strategy_type=\"clausius_clapeyron\",         parameters=water_clausius_clapeyron_parameters,     ) )  # Using the Water Buck strategy, no additional parameters needed water_buck_strategy = par.gas.VaporPressureFactory().get_strategy(     strategy_type=\"water_buck\" )  # Define a range of temperatures for which to calculate vapor pressures temperatures = range(250, 500)  # From 280 K to 320 K  # Calculate the pure vapor pressure at different temperatures using # various strategies water_pure_constant = [     water_constant_strategy.pure_vapor_pressure(temp) for temp in temperatures ] water_pure_antione = [     water_antione.pure_vapor_pressure(temp) for temp in temperatures ] water_pure_clausius_clapeyron = [     water_clausius_clapeyron_strategy.pure_vapor_pressure(temp)     for temp in temperatures ] water_pure_buck = [     water_buck_strategy.pure_vapor_pressure(temp) for temp in temperatures ]  # Plotting the results using Matplotlib fig, ax = plt.subplots(figsize=(8, 6)) ax.plot(temperatures, water_pure_constant, label=\"Constant\", linestyle=\"-\") ax.plot(temperatures, water_pure_antione, label=\"Antoine\", linestyle=\"--\") ax.plot(     temperatures,     water_pure_clausius_clapeyron,     label=\"Clausius-Clapeyron\",     linestyle=\"-.\", ) ax.plot(temperatures, water_pure_buck, label=\"Buck\", linestyle=\":\") ax.set_yscale(\"log\") ax.set_ylim(bottom=1e-10) ax.set_xlabel(\"Temperature (K)\") ax.set_ylabel(\"Pure Vapor Pressure (Pa)\") ax.set_title(\"Comparison of Water Vapor Pressure Calculations\") ax.legend(loc=\"lower right\") plt.show()"},{"location":"Examples/Gas_Phase/Notebooks/Vapor_Pressure/#vapor-pressure-tutorial","title":"Vapor Pressure Tutorial\u00b6","text":"<p>Vapor pressure is defined as the pressure exerted by a vapor in equilibrium with its liquid or solid phase. It is a crucial measure for understanding the tendency of molecules to transition from the liquid phase to the gas phase. This property is particularly important in systems where an aerosol (gas phase + particle phase) is in equilibrium with both phases.</p> <p>The vapor pressure varies with temperature, and this variation can manifest in several forms. Understanding these changes is key to predicting how substances will behave under different temperature conditions.</p> <p>In this notebook, we will explore the strategies for calculating vapor pressure as implemented in the <code>vapor_pressure</code> module. These strategies are essential for accurately modeling and understanding the behavior of aerosols in equilibrium with a liquid phase.</p> <p>Wikipedia: Vapor Pressure</p>"},{"location":"Examples/Gas_Phase/Notebooks/Vapor_Pressure/#units","title":"Units\u00b6","text":"<p>All measurements and calculations in this module adhere to the base SI units:</p> <ul> <li>Molar mass is in kilograms per mole (kg/mol).</li> <li>Concentration is in kilograms per cubic meter (kg/m^3).</li> <li>Temperature is in Kelvin (K).</li> <li>Pressure is in Pascals (Pa).</li> </ul>"},{"location":"Examples/Gas_Phase/Notebooks/Vapor_Pressure/#strategies-for-vapor-pressure-calculations","title":"Strategies for Vapor Pressure Calculations\u00b6","text":"<p>In our framework, all strategies for calculating vapor pressure are encapsulated within classes that inherit from the <code>VaporPressureStrategy</code> abstract base class. This design ensures that each strategy conforms to a standardized interface, making them interchangeable and simplifying integration with other components of our modular framework.</p>"},{"location":"Examples/Gas_Phase/Notebooks/Vapor_Pressure/#core-functions","title":"Core Functions\u00b6","text":"<p>We define two primary functions that form the backbone of our vapor pressure calculations:</p> <ul> <li><p><code>calculate_partial_pressure</code>: This function computes the partial pressure of a gas given its concentration, molar mass, and temperature. It applies the ideal gas law to derive the partial pressure in Pascals (Pa).</p> </li> <li><p><code>calculate_concentration</code>: This function inversely calculates the concentration of a gas from its partial pressure, molar mass, and temperature, also using the ideal gas law.</p> </li> </ul> <p>These functions can be reused for different strategies.</p>"},{"location":"Examples/Gas_Phase/Notebooks/Vapor_Pressure/#abstract-base-class","title":"Abstract Base Class\u00b6","text":"<p>The <code>VaporPressureStrategy</code> class serves as an abstract base class that outlines the necessary methods for vapor pressure calculations:</p> <ul> <li><p><code>partial_pressure</code>: Calculates the partial pressure of a gas based on its concentration, molar mass, and temperature.</p> </li> <li><p><code>concentration</code>: Calculates the concentration of a gas based on its partial pressure, temperature, and molar mass.</p> </li> <li><p><code>saturation_ratio</code>: Computes the ratio of the current vapor pressure to the saturation vapor pressure, which indicates how \"saturated\" the gas is with respect to a given temperature.</p> </li> <li><p><code>saturation_concentration</code>: Determines the maximum concentration of a gas at saturation at a given temperature.</p> </li> <li><p><code>pure_vapor_pressure</code>: This abstract method must be implemented by each subclass to calculate the pure (saturation) vapor pressure of a gas at specific temperatures.</p> </li> </ul> <p>By structuring our vapor pressure strategies around this abstract base class, we maintain high flexibility and robustness in our approach. Each subclass can implement specific behaviors for different gases or conditions, while relying on a common set of tools and interfaces provided by the base class.</p>"},{"location":"Examples/Gas_Phase/Notebooks/Vapor_Pressure/#example-antoine-equation-vapor-pressure-strategy","title":"Example: Antoine Equation Vapor Pressure Strategy\u00b6","text":"<p>The Antoine equation is a widely used empirical formula for estimating the vapor pressure of a substance over a range of temperatures. It takes the form:</p> <p>$$ \\log_{10}(P) = A - \\frac{B}{T - C} $$</p> <p>where:</p> <ul> <li>$P$ is the vapor pressure in mmHg,</li> <li>$T$ is the temperature in Kelvin,</li> <li>$A$, $B$, and $C$ are substance-specific constants.<ul> <li>These constants are typically determined experimentally and can vary for different substances.</li> <li>The Antoine equation is often used for organic compounds and provides a good approximation of vapor pressure behavior, over a limited temperature range.</li> </ul> </li> </ul> <p>We will implement this for the following substances, using constants from link:</p> <ul> <li><p>n-Butanol: \"Formula\": \"C4H10O\", \"A\": 7.838, \"B\": 1558.190, \"C\": 196.881</p> </li> <li><p>Styrene: \"Formula\": \"C8H8\", \"A\": 6.92409, \"B\": 1420, \"C\": 226</p> </li> <li><p>Water: \"Formula\": \"H2O\", \"A\": 7.94917, \"B\": 1657.462, \"C\": 227.02</p> </li> </ul>"},{"location":"Examples/Gas_Phase/Notebooks/Vapor_Pressure/#direct-strategy-builder-and-factory-patterns","title":"Direct Strategy, Builder, and Factory Patterns\u00b6","text":"<p>We will demonstrate the use of the direct, builder, and factory patterns to create instances of the <code>AntoineVaporPressure</code> strategy. These patterns provide different levels of abstraction and flexibility in object creation, catering to various use cases and design requirements.</p> <ul> <li>Direct Strategy: This involves directly creating instances of the <code>AntoineVaporPressure</code> class with the required parameters. It is straightforward but may be less flexible when dealing with complex object creation or configuration.</li> <li>Builder Pattern: The builder pattern separates the construction of a complex object from its representation, allowing for more flexible and readable object creation. We will use a <code>VaporPressureBuilder</code> class to construct instances of the <code>AntoineVaporPressure</code> strategy with different parameters. The parameters can be set in any order, and the builder provides a clear and intuitive way to create objects.</li> <li>Factory Pattern: The factory pattern provides an interface for creating objects without specifying the exact class of the object to be created. We will use a <code>VaporPressureFactory</code> class to create instances of the <code>AntoineVaporPressure</code> strategy based on the substance name. This pattern allows for dynamic object creation based on input parameters, enhancing flexibility and extensibility.</li> </ul>"},{"location":"Examples/Gas_Phase/Notebooks/Vapor_Pressure/#builder-validation","title":"Builder Validation\u00b6","text":"<p>Here we call the <code>AntoineBuilder</code> pattern, with incomplete parameters, to demonstrate the error handling mechanism.</p>"},{"location":"Examples/Gas_Phase/Notebooks/Vapor_Pressure/#temperature-variation","title":"Temperature Variation\u00b6","text":"<p>With the vapor pressure strategy implemented, we can now explore how the vapor pressure of these substances varies with temperature. We will plot the vapor pressure curves for n-Butanol, Styrene, and Water over a range of temperatures to observe their behavior.</p>"},{"location":"Examples/Gas_Phase/Notebooks/Vapor_Pressure/#saturation-concentration","title":"Saturation Concentration\u00b6","text":"<p>We will also calculate the concentration of these substances at different temperatures. The saturation concentration represents the maximum amount of a substance that can be in a gas at a given temperature. By examining how the saturation concentration changes with temperature, we can gain insights into the solubility and volatility of these substances.</p> <p>$$ C = \\frac{P_{pure}M}{RT} $$</p> <p>where:</p> <ul> <li>$C$ is the concentration in kg/m^3,</li> <li>$P_{pure}$ is the pure vapor pressure in Pa, (also known as $P_{sat}$, or $P_{0}$),</li> <li>$M$ is the molar mass in kg/mol,</li> <li>$R$ is the ideal gas constant (8.314 J/(mol K)),</li> <li>$T$ is the temperature in Kelvin.</li> </ul> <p>In the case of water, the saturation ratio can be used to determine the relative humidity of the air, as it is a key factor in weather and climate models.</p> <p>We can do this calculation from the directly from the vapor pressure strategy, as it is a common in the abstract base class. So even if we change how the vapor pressure is calculated, we can still use the same method to calculate the saturation concentration.</p>"},{"location":"Examples/Gas_Phase/Notebooks/Vapor_Pressure/#partial-pressure","title":"Partial Pressure\u00b6","text":"<p>The partial pressure of a gas is the pressure that the gas would exert if it occupied the entire volume alone. It is a key concept in understanding gas mixtures and the behavior of gases in equilibrium. The partial pressure of a gas is proportional to its concentration and temperature, as described by the ideal gas law.</p> <p>$$ P_{partial} = \\frac{C R T}{M} $$</p> <p>where:</p> <ul> <li>$P_{partial}$ is the partial pressure in Pascals (Pa),</li> <li>$C$ is the concentration of the gas in kg/m^3,</li> <li>$R$ is the ideal gas constant (8.314 J/(mol K)),</li> <li>$T$ is the temperature in Kelvin,</li> <li>$M$ is the molar mass of the gas in kg/mol.</li> </ul> <p>We can use the <code>calculate_partial_pressure</code> method from the vapor pressure strategy to calculate the partial pressure of a gas given its concentration, molar mass, and temperature. This calculation is essential for understanding the behavior of gas mixtures and the distribution of gases in a system.</p> <p>We will use the partial pressure at 300 K and calculate how it changes with temperature for the three substances.</p>"},{"location":"Examples/Gas_Phase/Notebooks/Vapor_Pressure/#saturation-ratio","title":"Saturation Ratio\u00b6","text":"<p>The saturation ratio is the ratio of a gas's current vapor pressure to its saturation vapor pressure at a specific temperature. This ratio helps determine how \"saturated\" the gas is with respect to the substance it is in equilibrium with. A saturation ratio of 1 implies that the gas is at equilibrium with the liquid phase. Values less than 1 indicate that the gas is sub-saturated (less than equilibrium), and values greater than 1 indicate supersaturation (more than equilibrium).</p> <p>$$ SR = \\frac{P}{P_{sat}} $$</p> <p>where:</p> <ul> <li>$SR$ is the saturation ratio,</li> <li>$P$ is the partial pressure of the gas,</li> <li>$P_{sat}$ is the saturation vapor pressure of the gas at the given temperature.</li> </ul> <p>To calculate the saturation ratio, we use the concentration of the gas and compare it to the saturation concentration. We calculate the partial pressure from the concentration and the saturation concentration, and then calculate the saturation ratio.</p> <p>We will start with the gas's initial concentration at 300K and calculate the saturation ratio at various temperatures while keeping the concentration constant.</p> <p>This method simulates the behavior of a gas that is initially at equilibrium with its liquid phase at 300K. If the temperature changes but the concentration remains constant, the saturation ratio will begin at 1 and typically decrease as the temperature increases. This decrease reflects the gas moving from a state of equilibrium to a state of sub-saturation as it becomes less capable of remaining in the liquid phase at higher temperatures.</p>"},{"location":"Examples/Gas_Phase/Notebooks/Vapor_Pressure/#other-strategies","title":"Other Strategies\u00b6","text":"<p>In addition to the common methods shared across all vapor pressure strategies, we have several specialized strategies that can be employed to calculate vapor pressure based on different principles:</p> <ul> <li>Constant: This strategy applies a fixed value for the vapor pressure, regardless of external conditions.</li> <li>Antoine: Utilizes the Antoine equation to determine the vapor pressure of a substance, adjusting based on temperature changes.</li> <li>Clausius_Clapeyron: Employs the Clausius-Clapeyron equation to estimate changes in vapor pressure in response to temperature variations.</li> <li>Water_Buck: Specifically designed for water, this strategy uses the Buck equation to calculate vapor pressure accurately.</li> </ul> <p>We will apply these different strategies to calculate the pure vapor pressure of water and observe how the values vary with temperature.</p>"},{"location":"Examples/Gas_Phase/Notebooks/Vapor_Pressure/#consistency-across-methods","title":"Consistency Across Methods\u00b6","text":"<p>Despite using different calculation strategies, the method calls remain consistent. This uniformity allows for straightforward substitutions between methods without altering the structure of the code.</p>"},{"location":"Examples/Gas_Phase/Notebooks/Vapor_Pressure/#summary","title":"Summary\u00b6","text":"<p>In this notebook, we covered how the strategies for vapor pressure calculations are implemented in our system. By using an abstract base class and common core functions, we ensure that each strategy adheres to a standardized interface and can be easily integrated into our framework. We explored the Antoine equation vapor pressure strategy for n-Butanol, Styrene, and Water, examining how their vapor pressures and saturation concentrations change with temperature. We calculated the partial pressure, saturation ratio, and saturation concentration for these substances, providing insights into their behavior in gas-phase systems. Finally, we demonstrated the consistency and flexibility of our approach by applying different vapor pressure strategies to calculate the vapor pressure of water and observing how the values vary with temperature.</p> <p>This modular and extensible design allows us to incorporate various vapor pressure calculation methods while maintaining a consistent interface and ensuring robustness and flexibility in our system.</p>"},{"location":"Examples/Nucleation/","title":"Nucleation","text":"<p>How to implement a custom nucleation model, and manually add particles to the simulation.</p>"},{"location":"Examples/Nucleation/#notebooks","title":"Notebooks","text":"<ul> <li>Single Species</li> </ul>"},{"location":"Examples/Nucleation/Notebooks/Custom_Nucleation_Single_Species/","title":"Custom Nucleation: Single Species","text":"In\u00a0[\u00a0]: Copied! <pre># In Colab uncomment the following command to install particula:\n#!pip install particula[extra] --quiet\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# particula\nimport particula as par\n</pre> # In Colab uncomment the following command to install particula: #!pip install particula[extra] --quiet import numpy as np import matplotlib.pyplot as plt  # particula import particula as par In\u00a0[21]: Copied! <pre># Build the sulfate gas species\n\n# Ammonium sulfate properties\nmolar_mass_ammonium_sulfate = 132.14e-3  # kg/mol\ndensity_ammonium_sulfate = 1.77e3  # kg/m^3\n\n# Define vapor pressure parameters for ammonium sulfate\nparameters_vapor = {\n    \"vapor_pressure\": 4e-12,  # pascal\n    \"vapor_pressure_units\": \"atm\",  # units\n}\n\n# Create a constant vapor pressure strategy using the VaporPressureFactory\nvapor_pressure_sulfate = par.gas.VaporPressureFactory().get_strategy(\n    \"constant\", parameters_vapor\n)\n\n# Calculate the saturation concentration at a given temperature\nsulfate_saturation = vapor_pressure_sulfate.saturation_concentration(\n    molar_mass=molar_mass_ammonium_sulfate,\n    temperature=298.15,  # Kelvin\n)\n\n# Set initial sulfate concentration as a fraction of saturation concentration\ninitial_sulfate_concentration = 0.5 * sulfate_saturation  # kg/m^3\n\n# Build the sulfate gas species using the GasSpeciesBuilder\ngas_sulfate = (\n    par.gas.GasSpeciesBuilder()\n    .set_name(\"sulfate\")\n    .set_molar_mass(molar_mass_ammonium_sulfate, \"kg/mol\")\n    .set_partitioning(True)\n    .set_vapor_pressure_strategy(vapor_pressure_sulfate)\n    .set_concentration(initial_sulfate_concentration, \"kg/m^3\")\n    .build()\n)\n\n# Build the atmosphere with the sulfate species and environmental conditions\natmosphere = (\n    par.gas.AtmosphereBuilder()\n    .set_more_partitioning_species(gas_sulfate)  # Add sulfate to the atmosphere\n    .set_temperature(25, temperature_units=\"degC\")  # Set temperature to 25\u00b0C\n    .set_pressure(1, pressure_units=\"atm\")  # Set pressure to 1 atm\n    .build()\n)\n\n# Generate a lognormal particle size distribution\nparticle_sample = par.particles.get_lognormal_sample_distribution(\n    mode=np.array([400e-9]),  # Mean particle diameter of 400 nm\n    geometric_standard_deviation=np.array([1.4]),  # GSD of 1.4\n    number_of_particles=np.array(\n        [1e4]\n    ),  # Number of particles in the distribution\n    number_of_samples=100,  # Number of particle samples\n)\n\n# Calculate the mass of each particle based on its size and ammonium sulfate density\nparticle_mass_sample = (\n    4 / 3 * np.pi * particle_sample**3 * density_ammonium_sulfate  # kg\n)\n\nvolume_sim = 0.1 * par.util.get_unit_conversion(\"cm^3\", \"m^3\")  # m^3\n# Build the resolved particle mass representation for the aerosol particles\nresolved_masses = (\n    par.particles.ResolvedParticleMassRepresentationBuilder()\n    .set_distribution_strategy(par.particles.ParticleResolvedSpeciatedMass())\n    .set_activity_strategy(par.particles.ActivityIdealMass())\n    .set_surface_strategy(par.particles.SurfaceStrategyVolume())\n    .set_mass(particle_mass_sample, \"kg\")\n    .set_density(density_ammonium_sulfate, \"kg/m^3\")\n    .set_charge(0)\n    .set_volume(volume_sim, \"m^3\")\n    .build()\n)\n\n# Create the aerosol object with the atmosphere and particles\naerosol = par.Aerosol(atmosphere=atmosphere, particles=resolved_masses)\n\n# Print the properties of the created aerosol system\nprint(aerosol)\n</pre> # Build the sulfate gas species  # Ammonium sulfate properties molar_mass_ammonium_sulfate = 132.14e-3  # kg/mol density_ammonium_sulfate = 1.77e3  # kg/m^3  # Define vapor pressure parameters for ammonium sulfate parameters_vapor = {     \"vapor_pressure\": 4e-12,  # pascal     \"vapor_pressure_units\": \"atm\",  # units }  # Create a constant vapor pressure strategy using the VaporPressureFactory vapor_pressure_sulfate = par.gas.VaporPressureFactory().get_strategy(     \"constant\", parameters_vapor )  # Calculate the saturation concentration at a given temperature sulfate_saturation = vapor_pressure_sulfate.saturation_concentration(     molar_mass=molar_mass_ammonium_sulfate,     temperature=298.15,  # Kelvin )  # Set initial sulfate concentration as a fraction of saturation concentration initial_sulfate_concentration = 0.5 * sulfate_saturation  # kg/m^3  # Build the sulfate gas species using the GasSpeciesBuilder gas_sulfate = (     par.gas.GasSpeciesBuilder()     .set_name(\"sulfate\")     .set_molar_mass(molar_mass_ammonium_sulfate, \"kg/mol\")     .set_partitioning(True)     .set_vapor_pressure_strategy(vapor_pressure_sulfate)     .set_concentration(initial_sulfate_concentration, \"kg/m^3\")     .build() )  # Build the atmosphere with the sulfate species and environmental conditions atmosphere = (     par.gas.AtmosphereBuilder()     .set_more_partitioning_species(gas_sulfate)  # Add sulfate to the atmosphere     .set_temperature(25, temperature_units=\"degC\")  # Set temperature to 25\u00b0C     .set_pressure(1, pressure_units=\"atm\")  # Set pressure to 1 atm     .build() )  # Generate a lognormal particle size distribution particle_sample = par.particles.get_lognormal_sample_distribution(     mode=np.array([400e-9]),  # Mean particle diameter of 400 nm     geometric_standard_deviation=np.array([1.4]),  # GSD of 1.4     number_of_particles=np.array(         [1e4]     ),  # Number of particles in the distribution     number_of_samples=100,  # Number of particle samples )  # Calculate the mass of each particle based on its size and ammonium sulfate density particle_mass_sample = (     4 / 3 * np.pi * particle_sample**3 * density_ammonium_sulfate  # kg )  volume_sim = 0.1 * par.util.get_unit_conversion(\"cm^3\", \"m^3\")  # m^3 # Build the resolved particle mass representation for the aerosol particles resolved_masses = (     par.particles.ResolvedParticleMassRepresentationBuilder()     .set_distribution_strategy(par.particles.ParticleResolvedSpeciatedMass())     .set_activity_strategy(par.particles.ActivityIdealMass())     .set_surface_strategy(par.particles.SurfaceStrategyVolume())     .set_mass(particle_mass_sample, \"kg\")     .set_density(density_ammonium_sulfate, \"kg/m^3\")     .set_charge(0)     .set_volume(volume_sim, \"m^3\")     .build() )  # Create the aerosol object with the atmosphere and particles aerosol = par.Aerosol(atmosphere=atmosphere, particles=resolved_masses)  # Print the properties of the created aerosol system print(aerosol) <pre>Gas mixture at 298.15 K, 101325.0 Pa, partitioning=sulfate, gas_only_species=None\nParticle Representation:\n\tStrategy: ParticleResolvedSpeciatedMass\n\tActivity: ActivityIdealMass\n\tSurface: SurfaceStrategyVolume\n\tMass Concentration: 7.221e-07 [kg/m^3]\n\tNumber Concentration: 1.000e+09 [#/m^3]\n</pre> In\u00a0[22]: Copied! <pre># Build the sulfate gas species\n\n# Ammonium sulfate and water vapor pressure\nmolar_mass_ammonium_sulfate = 132.14e-3  # kg/mol\ndensity_ammonium_sulfate = 1.77e3  # kg/m^3\nparameters_vapor = {\n    \"vapor_pressure\": 4e-12,  # pascal\n    \"vapor_pressure_units\": \"atm\",\n}\nvapor_pressure_sulfate = par.gas.VaporPressureFactory().get_strategy(\n    \"constant\", parameters_vapor\n)\n\n# get initial vapor concentration\nsulfate_saturation = vapor_pressure_sulfate.saturation_concentration(\n    molar_mass=molar_mass_ammonium_sulfate,\n    temperature=298.15,\n)\n\ninitial_sulfate_concentration = 0.5 * sulfate_saturation\n\n\n# Create the gas species\ngas_sulfate = (\n    par.gas.GasSpeciesBuilder()\n    .set_name(\"sulfate\")\n    .set_molar_mass(molar_mass_ammonium_sulfate, \"kg/mol\")\n    .set_partitioning(True)\n    .set_vapor_pressure_strategy(vapor_pressure_sulfate)\n    .set_concentration(initial_sulfate_concentration, \"kg/m^3\")\n    .build()\n)\n\n# AtmosphereBuilder constructs the atmosphere with predefined species\natmosphere = (\n    par.gas.AtmosphereBuilder()\n    .set_more_partitioning_species(gas_sulfate)  # Add the sulfate gas species to the atmosphere\n    .set_temperature(25, temperature_units=\"degC\")  # Set temperature to 25\u00b0C\n    .set_pressure(1, pressure_units=\"atm\")  # Set pressure to 1 atmosphere\n    .build()  # Finalize the atmosphere object\n)\n\n# Generate a particle distribution using a lognormal sample distribution\n# This distribution has a mean particle diameter (mode) and geometric standard deviation (GSD)\nparticle_sample = par.particles.get_lognormal_sample_distribution(\n    mode=np.array([400e-9]),  # Mean particle diameter of 100 nm\n    geometric_standard_deviation=np.array([1.4]),  # GSD of 1.3\n    number_of_particles=np.array([1e4]),  # Total number of particles\n    number_of_samples=100,  # Number of samples for particle distribution\n)\n\n\n# Calculate the mass of each particle in the sample\nparticle_mass_sample = (\n    4 / 3 * np.pi * particle_sample**3 * density_ammonium_sulfate\n)  # Particle mass in kg\n\n\n# Build a resolved mass representation for each particle\n# This defines how particle mass, activity, and surface are represented\nresolved_masses = (\n    par.particles.ResolvedParticleMassRepresentationBuilder()\n    .set_distribution_strategy(par.particles.ParticleResolvedSpeciatedMass())\n    .set_activity_strategy(par.particles.ActivityIdealMass())\n    .set_surface_strategy(par.particles.SurfaceStrategyVolume())\n    .set_mass(particle_mass_sample, \"kg\")\n    .set_density(density_ammonium_sulfate, \"kg/m^3\")\n    .set_charge(0)\n    .set_volume(0.1, \"cm^3\")\n    .build()\n)\n\n# # Create an aerosol object with the defined atmosphere and resolved particles\naerosol = par.Aerosol(atmosphere=atmosphere, particles=resolved_masses)\n\n\n# Print the properties of the atmosphere\nprint(aerosol)\n</pre> # Build the sulfate gas species  # Ammonium sulfate and water vapor pressure molar_mass_ammonium_sulfate = 132.14e-3  # kg/mol density_ammonium_sulfate = 1.77e3  # kg/m^3 parameters_vapor = {     \"vapor_pressure\": 4e-12,  # pascal     \"vapor_pressure_units\": \"atm\", } vapor_pressure_sulfate = par.gas.VaporPressureFactory().get_strategy(     \"constant\", parameters_vapor )  # get initial vapor concentration sulfate_saturation = vapor_pressure_sulfate.saturation_concentration(     molar_mass=molar_mass_ammonium_sulfate,     temperature=298.15, )  initial_sulfate_concentration = 0.5 * sulfate_saturation   # Create the gas species gas_sulfate = (     par.gas.GasSpeciesBuilder()     .set_name(\"sulfate\")     .set_molar_mass(molar_mass_ammonium_sulfate, \"kg/mol\")     .set_partitioning(True)     .set_vapor_pressure_strategy(vapor_pressure_sulfate)     .set_concentration(initial_sulfate_concentration, \"kg/m^3\")     .build() )  # AtmosphereBuilder constructs the atmosphere with predefined species atmosphere = (     par.gas.AtmosphereBuilder()     .set_more_partitioning_species(gas_sulfate)  # Add the sulfate gas species to the atmosphere     .set_temperature(25, temperature_units=\"degC\")  # Set temperature to 25\u00b0C     .set_pressure(1, pressure_units=\"atm\")  # Set pressure to 1 atmosphere     .build()  # Finalize the atmosphere object )  # Generate a particle distribution using a lognormal sample distribution # This distribution has a mean particle diameter (mode) and geometric standard deviation (GSD) particle_sample = par.particles.get_lognormal_sample_distribution(     mode=np.array([400e-9]),  # Mean particle diameter of 100 nm     geometric_standard_deviation=np.array([1.4]),  # GSD of 1.3     number_of_particles=np.array([1e4]),  # Total number of particles     number_of_samples=100,  # Number of samples for particle distribution )   # Calculate the mass of each particle in the sample particle_mass_sample = (     4 / 3 * np.pi * particle_sample**3 * density_ammonium_sulfate )  # Particle mass in kg   # Build a resolved mass representation for each particle # This defines how particle mass, activity, and surface are represented resolved_masses = (     par.particles.ResolvedParticleMassRepresentationBuilder()     .set_distribution_strategy(par.particles.ParticleResolvedSpeciatedMass())     .set_activity_strategy(par.particles.ActivityIdealMass())     .set_surface_strategy(par.particles.SurfaceStrategyVolume())     .set_mass(particle_mass_sample, \"kg\")     .set_density(density_ammonium_sulfate, \"kg/m^3\")     .set_charge(0)     .set_volume(0.1, \"cm^3\")     .build() )  # # Create an aerosol object with the defined atmosphere and resolved particles aerosol = par.Aerosol(atmosphere=atmosphere, particles=resolved_masses)   # Print the properties of the atmosphere print(aerosol) <pre>Gas mixture at 298.15 K, 101325.0 Pa, partitioning=sulfate, gas_only_species=None\nParticle Representation:\n\tStrategy: ParticleResolvedSpeciatedMass\n\tActivity: ActivityIdealMass\n\tSurface: SurfaceStrategyVolume\n\tMass Concentration: 8.956e-07 [kg/m^3]\n\tNumber Concentration: 1.000e+09 [#/m^3]\n</pre> In\u00a0[23]: Copied! <pre># setup dynamics for condensation\ncondensation_method = par.dynamics.CondensationIsothermal(\n    molar_mass=molar_mass_ammonium_sulfate,\n    accommodation_coefficient=1,\n    diffusion_coefficient=2e-5,\n)\ncondensation_runnable = par.dynamics.MassCondensation(\n    condensation_strategy=condensation_method\n)\n# setup dynamics for coagulation\ncoagulation_strategy = (\n    par.dynamics.BrownianCoagulationBuilder()\n    .set_distribution_type(\"particle_resolved\")\n    .build()\n)\ncoagulation_runnable = par.dynamics.Coagulation(\n    coagulation_strategy=coagulation_strategy\n)\n\nstep_count = 0\n</pre> # setup dynamics for condensation condensation_method = par.dynamics.CondensationIsothermal(     molar_mass=molar_mass_ammonium_sulfate,     accommodation_coefficient=1,     diffusion_coefficient=2e-5, ) condensation_runnable = par.dynamics.MassCondensation(     condensation_strategy=condensation_method ) # setup dynamics for coagulation coagulation_strategy = (     par.dynamics.BrownianCoagulationBuilder()     .set_distribution_type(\"particle_resolved\")     .build() ) coagulation_runnable = par.dynamics.Coagulation(     coagulation_strategy=coagulation_strategy )  step_count = 0 <p>You can repeatedly run the next cell to see the evolution of the aerosol system.</p> In\u00a0[24]: Copied! <pre># Initialize or increment step counter\nstep_count += 1\nprint(f\"Step {step_count}\")\n\n# Define key parameters\nvapor_production = (\n    sulfate_saturation * 0.2\n)  # Adding 20% of saturation concentration per second\nbase_nucleation_rate = (\n    1e-8 * density_ammonium_sulfate\n)  # Base nucleation rate in kg/m^3/s\nmass_nucleated_particle = (\n    4 / 3 * np.pi * (2e-9) ** 3 * density_ammonium_sulfate\n)  # Mass of a 10 nm particle in kg\nexponent_nucleation = 2  # Nucleation rate exponent (empirical)\ntime_step = 1  # Time step in seconds\n\n# 1. Add more vapor to the gas phase (e.g., by external sources)\nprint(\n    \"Current sulfate concentration: \",\n    aerosol.atmosphere.partitioning_species.get_concentration(),\n)\naerosol.atmosphere.partitioning_species.add_concentration(vapor_production * time_step)\nprint(\n    \"New sulfate concentration: \",\n    aerosol.atmosphere.partitioning_species.get_concentration(),\n)\n\n# 2. Calculate the new saturation ratio for sulfate in the atmosphere\nsaturation_ratio = aerosol.atmosphere.partitioning_species.get_saturation_ratio(\n    temperature=298.15\n)\nprint(f\"Saturation ratio: {saturation_ratio}\")\n\n# 3. Calculate the nucleation rate based on the saturation ratio\n# Ensure the saturation ratio is above 1, nucleation only occurs above saturation\nsaturation_difference = np.maximum(\n    saturation_ratio - 1, 0\n)  # No nucleation if S \u2264 1\n# Calculate the nucleation rate using the exponential form (custom)\n# note this is mass based, if you have a volume based nucleation rate, you need to convert it\n# to mass, as the resolved particles are mass based\nnucleation_rate = (\n    base_nucleation_rate * (saturation_difference / 500) ** exponent_nucleation\n)\nprint(\n    f\"Nucleation rate [mass concentration per sec, kg/m^3/s]: {nucleation_rate}\"\n)\n\n# 4. Calculate the number of new particles nucleated\n# Floor division ensures we only get whole particles\nnumber_of_new_particles = (\n    time_step * nucleation_rate // mass_nucleated_particle\n)\nprint(f\"Number of new particles nucleated: {number_of_new_particles}\")\n\n# 5. Determine the number of resolved particles to create (based on simulation volume)\nsingle_resolved_particle = aerosol.particles.get_concentration().max()\nnumber_of_new_resolved_particles = int(\n    number_of_new_particles // single_resolved_particle\n)\nprint(\n    f\"Number of new resolved particles to be created: {number_of_new_resolved_particles}\"\n)\n\n# 6. If new particles are nucleated, proceed to add them to the aerosol\nif number_of_new_resolved_particles &gt; 0:\n    # Remove nucleated mass from the gas phase to conserve mass\n    aerosol.atmosphere.partitioning_species.add_concentration(\n        -number_of_new_resolved_particles * mass_nucleated_particle\n    )\n\n    # Create arrays to store the properties of the newly resolved particles\n    new_resolved_particle_masses = np.full(\n        number_of_new_resolved_particles, mass_nucleated_particle\n    )\n    new_resolved_particle_concentrations = np.ones_like(\n        new_resolved_particle_masses\n    )  # Concentration of 1 per particle\n\n    # Add the new resolved particles to the aerosol\n    aerosol.particles.add_concentration(\n        added_concentration=new_resolved_particle_concentrations,\n        added_distribution=new_resolved_particle_masses,\n    )\n\n# Print the total particle concentration before dynamics (for monitoring)\ntotal_particle_concentration = aerosol.particles.get_total_concentration()\nprint(\n    f\"Total particle concentration before dynamics [#/m^3]: {total_particle_concentration}\"\n)\n\n# 7. Perform the condensation step\ncondensation_runnable.execute(aerosol, time_step)\n\n# 8. Perform the coagulation step\ncoagulation_runnable.execute(aerosol, time_step)\n\n# Print the total particle concentration and mass after running the dynamics\ntotal_particle_concentration_after_process = aerosol.particles.get_total_concentration()\nprint(\n    f\"Total particle concentration after dynamics [#/m^3]: {total_particle_concentration_after_process}\"\n)\n\ntotal_particle_mass_after_process = aerosol.particles.get_mass_concentration()\nprint(\n    f\"Total particle mass after dynamics [kg/m^3]: {total_particle_mass_after_process}\"\n)\n\n# Retrieve and print the total number of resolved particles simulated\ntotal_resolved_particles_in_simulation = aerosol.particles.concentration.sum()\nprint(\n    f\"Total resolved particles in simulation: {total_resolved_particles_in_simulation}\"\n)\n</pre> # Initialize or increment step counter step_count += 1 print(f\"Step {step_count}\")  # Define key parameters vapor_production = (     sulfate_saturation * 0.2 )  # Adding 20% of saturation concentration per second base_nucleation_rate = (     1e-8 * density_ammonium_sulfate )  # Base nucleation rate in kg/m^3/s mass_nucleated_particle = (     4 / 3 * np.pi * (2e-9) ** 3 * density_ammonium_sulfate )  # Mass of a 10 nm particle in kg exponent_nucleation = 2  # Nucleation rate exponent (empirical) time_step = 1  # Time step in seconds  # 1. Add more vapor to the gas phase (e.g., by external sources) print(     \"Current sulfate concentration: \",     aerosol.atmosphere.partitioning_species.get_concentration(), ) aerosol.atmosphere.partitioning_species.add_concentration(vapor_production * time_step) print(     \"New sulfate concentration: \",     aerosol.atmosphere.partitioning_species.get_concentration(), )  # 2. Calculate the new saturation ratio for sulfate in the atmosphere saturation_ratio = aerosol.atmosphere.partitioning_species.get_saturation_ratio(     temperature=298.15 ) print(f\"Saturation ratio: {saturation_ratio}\")  # 3. Calculate the nucleation rate based on the saturation ratio # Ensure the saturation ratio is above 1, nucleation only occurs above saturation saturation_difference = np.maximum(     saturation_ratio - 1, 0 )  # No nucleation if S \u2264 1 # Calculate the nucleation rate using the exponential form (custom) # note this is mass based, if you have a volume based nucleation rate, you need to convert it # to mass, as the resolved particles are mass based nucleation_rate = (     base_nucleation_rate * (saturation_difference / 500) ** exponent_nucleation ) print(     f\"Nucleation rate [mass concentration per sec, kg/m^3/s]: {nucleation_rate}\" )  # 4. Calculate the number of new particles nucleated # Floor division ensures we only get whole particles number_of_new_particles = (     time_step * nucleation_rate // mass_nucleated_particle ) print(f\"Number of new particles nucleated: {number_of_new_particles}\")  # 5. Determine the number of resolved particles to create (based on simulation volume) single_resolved_particle = aerosol.particles.get_concentration().max() number_of_new_resolved_particles = int(     number_of_new_particles // single_resolved_particle ) print(     f\"Number of new resolved particles to be created: {number_of_new_resolved_particles}\" )  # 6. If new particles are nucleated, proceed to add them to the aerosol if number_of_new_resolved_particles &gt; 0:     # Remove nucleated mass from the gas phase to conserve mass     aerosol.atmosphere.partitioning_species.add_concentration(         -number_of_new_resolved_particles * mass_nucleated_particle     )      # Create arrays to store the properties of the newly resolved particles     new_resolved_particle_masses = np.full(         number_of_new_resolved_particles, mass_nucleated_particle     )     new_resolved_particle_concentrations = np.ones_like(         new_resolved_particle_masses     )  # Concentration of 1 per particle      # Add the new resolved particles to the aerosol     aerosol.particles.add_concentration(         added_concentration=new_resolved_particle_concentrations,         added_distribution=new_resolved_particle_masses,     )  # Print the total particle concentration before dynamics (for monitoring) total_particle_concentration = aerosol.particles.get_total_concentration() print(     f\"Total particle concentration before dynamics [#/m^3]: {total_particle_concentration}\" )  # 7. Perform the condensation step condensation_runnable.execute(aerosol, time_step)  # 8. Perform the coagulation step coagulation_runnable.execute(aerosol, time_step)  # Print the total particle concentration and mass after running the dynamics total_particle_concentration_after_process = aerosol.particles.get_total_concentration() print(     f\"Total particle concentration after dynamics [#/m^3]: {total_particle_concentration_after_process}\" )  total_particle_mass_after_process = aerosol.particles.get_mass_concentration() print(     f\"Total particle mass after dynamics [kg/m^3]: {total_particle_mass_after_process}\" )  # Retrieve and print the total number of resolved particles simulated total_resolved_particles_in_simulation = aerosol.particles.concentration.sum() print(     f\"Total resolved particles in simulation: {total_resolved_particles_in_simulation}\" ) <pre>Step 1\nCurrent sulfate concentration:  1.0802192486690696e-11\nNew sulfate concentration:  1.5123069481366975e-11\nSaturation ratio: 0.7\nNucleation rate [mass concentration per sec, kg/m^3/s]: 0.0\nNumber of new particles nucleated: 0.0\nNumber of new resolved particles to be created: 0\nTotal particle concentration before dynamics [#/m^3]: 999999999.9999999\nTotal particle concentration after dynamics [#/m^3]: 999999999.9999999\nTotal particle mass after dynamics [kg/m^3]: 8.956465989717756e-07\nTotal resolved particles in simulation: 100.0\n</pre> In\u00a0[27]: Copied! <pre># Build the sulfate gas species using the GasSpeciesBuilder\ngas_sulfate = (\n    par.gas.GasSpeciesBuilder()\n    .set_name(\"sulfate\")\n    .set_molar_mass(molar_mass_ammonium_sulfate, \"kg/mol\")\n    .set_partitioning(True)\n    .set_vapor_pressure_strategy(vapor_pressure_sulfate)\n    .set_concentration(initial_sulfate_concentration, \"kg/m^3\")\n    .build()\n)\n\n# AtmosphereBuilder constructs the atmosphere with predefined species\natmosphere = (\n    par.gas.AtmosphereBuilder()\n    .set_more_partitioning_species(gas_sulfate)  # Add the sulfate gas species to the atmosphere\n    .set_temperature(25, temperature_units=\"degC\")  # Set temperature to 25\u00b0C\n    .set_pressure(1, pressure_units=\"atm\")  # Set pressure to 1 atmosphere\n    .build()  # Finalize the atmosphere object\n)\n# Build the resolved particle mass representation for the aerosol particles\nresolved_masses = (\n    par.particles.ResolvedParticleMassRepresentationBuilder()\n    .set_distribution_strategy(par.particles.ParticleResolvedSpeciatedMass())\n    .set_activity_strategy(par.particles.ActivityIdealMass())\n    .set_surface_strategy(par.particles.SurfaceStrategyVolume())\n    .set_mass(particle_mass_sample, \"kg\")\n    .set_density(density_ammonium_sulfate, \"kg/m^3\")\n    .set_charge(0)\n    .set_volume(0.1, \"cm^3\")\n    .build()\n)\n\n# Create the aerosol object with the atmosphere and particles\naerosol = par.Aerosol(atmosphere=atmosphere, particles=resolved_masses)\n\n# Print the properties of the created aerosol system\nprint(aerosol)\n\n\n# Set up time and sub-steps for the coagulation process\ntotal_time = 200\ntime_step = 1\nsub_steps = 2\n\n# bins\nbins_lognormal = np.logspace(-9, -7, 200)\n\n# output arrays\ntime = np.arange(0, total_time, time_step)\ntotal_mass_resolved = np.ones_like(time, dtype=np.float64)\nnumber_distribution_binned = np.zeros((len(time), len(bins_lognormal) - 1))\ntotal_number_resolved = np.ones_like(time, dtype=np.float64)\nsaturation_ratio_output = np.ones_like(time, dtype=np.float64)\n\nprint(f\"Total iterations to do: {len(time)*sub_steps}\")\n</pre> # Build the sulfate gas species using the GasSpeciesBuilder gas_sulfate = (     par.gas.GasSpeciesBuilder()     .set_name(\"sulfate\")     .set_molar_mass(molar_mass_ammonium_sulfate, \"kg/mol\")     .set_partitioning(True)     .set_vapor_pressure_strategy(vapor_pressure_sulfate)     .set_concentration(initial_sulfate_concentration, \"kg/m^3\")     .build() )  # AtmosphereBuilder constructs the atmosphere with predefined species atmosphere = (     par.gas.AtmosphereBuilder()     .set_more_partitioning_species(gas_sulfate)  # Add the sulfate gas species to the atmosphere     .set_temperature(25, temperature_units=\"degC\")  # Set temperature to 25\u00b0C     .set_pressure(1, pressure_units=\"atm\")  # Set pressure to 1 atmosphere     .build()  # Finalize the atmosphere object ) # Build the resolved particle mass representation for the aerosol particles resolved_masses = (     par.particles.ResolvedParticleMassRepresentationBuilder()     .set_distribution_strategy(par.particles.ParticleResolvedSpeciatedMass())     .set_activity_strategy(par.particles.ActivityIdealMass())     .set_surface_strategy(par.particles.SurfaceStrategyVolume())     .set_mass(particle_mass_sample, \"kg\")     .set_density(density_ammonium_sulfate, \"kg/m^3\")     .set_charge(0)     .set_volume(0.1, \"cm^3\")     .build() )  # Create the aerosol object with the atmosphere and particles aerosol = par.Aerosol(atmosphere=atmosphere, particles=resolved_masses)  # Print the properties of the created aerosol system print(aerosol)   # Set up time and sub-steps for the coagulation process total_time = 200 time_step = 1 sub_steps = 2  # bins bins_lognormal = np.logspace(-9, -7, 200)  # output arrays time = np.arange(0, total_time, time_step) total_mass_resolved = np.ones_like(time, dtype=np.float64) number_distribution_binned = np.zeros((len(time), len(bins_lognormal) - 1)) total_number_resolved = np.ones_like(time, dtype=np.float64) saturation_ratio_output = np.ones_like(time, dtype=np.float64)  print(f\"Total iterations to do: {len(time)*sub_steps}\") <pre>Gas mixture at 298.15 K, 101325.0 Pa, partitioning=sulfate, gas_only_species=None\nParticle Representation:\n\tStrategy: ParticleResolvedSpeciatedMass\n\tActivity: ActivityIdealMass\n\tSurface: SurfaceStrategyVolume\n\tMass Concentration: 8.956e-07 [kg/m^3]\n\tNumber Concentration: 1.000e+09 [#/m^3]\nTotal iterations to do: 400\n</pre> In\u00a0[28]: Copied! <pre># Define key parameters\nvapor_production = (\n    sulfate_saturation * 0.2\n)  # Adding 20% of saturation concentration per second\nbase_nucleation_rate = (\n    1e-8 * density_ammonium_sulfate\n)  # Base nucleation rate in kg/m^3/s\nmass_nucleated_particle = (\n    4 / 3 * np.pi * (2e-9) ** 3 * density_ammonium_sulfate\n)  # Mass of a 10 nm particle in kg\nexponent_nucleation = 2  # Nucleation rate exponent (empirical)\n\n\nfor i, t in enumerate(time):\n    if i &gt; 0:\n        # 1. Add more vapor to the gas phase (e.g., by external sources)\n        aerosol.atmosphere.partitioning_species.add_concentration(\n            vapor_production * time_step\n        )\n\n        # 2. Calculate the new saturation ratio for sulfate in the atmosphere\n        saturation_ratio = aerosol.atmosphere.partitioning_species.get_saturation_ratio(\n            temperature=298.15\n        )\n\n        # 3. Calculate the nucleation rate based on the saturation ratio\n        # Ensure the saturation ratio is above 1, nucleation only occurs above saturation\n        saturation_difference = np.maximum(\n            saturation_ratio - 1, 0\n        )  # No nucleation if S \u2264 1\n        # Calculate the nucleation rate using the exponential form (custom)\n        # note this is mass based, if you have a volume based nucleation rate, you need to convert it\n        # to mass, as the resolved particles are mass based\n        nucleation_rate = (\n            base_nucleation_rate\n            * (saturation_difference / 500) ** exponent_nucleation\n        )\n\n        # 4. Calculate the number of new particles nucleated\n        # Floor division ensures we only get whole particles\n        number_of_new_particles = (\n            time_step * nucleation_rate // mass_nucleated_particle\n        )\n\n        # 5. Determine the number of resolved particles to create (based on simulation volume)\n        single_resolved_particle = (\n            aerosol.particles.get_concentration().max()\n        )\n        number_of_new_resolved_particles = int(\n            number_of_new_particles // single_resolved_particle\n        )\n\n        # 6. If new particles are nucleated, proceed to add them to the aerosol\n        if number_of_new_resolved_particles &gt; 0:\n            # Remove nucleated mass from the gas phase to conserve mass\n            aerosol.atmosphere.partitioning_species.add_concentration(\n                -number_of_new_resolved_particles * mass_nucleated_particle\n            )\n\n            # Create arrays to store the properties of the newly resolved particles\n            new_resolved_particle_masses = np.full(\n                number_of_new_resolved_particles, mass_nucleated_particle\n            )\n            new_resolved_particle_concentrations = np.ones_like(\n                new_resolved_particle_masses\n            )  # Concentration of 1 per particle\n\n            # Add the new resolved particles to the aerosol\n            aerosol.particles.add_concentration(\n                added_concentration=new_resolved_particle_concentrations,\n                added_distribution=new_resolved_particle_masses,\n            )\n\n        # 7. Perform the condensation step\n        condensation_runnable.execute(aerosol, time_step, sub_steps)\n        # 8. Perform the coagulation step\n        coagulation_runnable.execute(aerosol, time_step, sub_steps)\n\n    total_mass_resolved[i] = aerosol.particles.get_mass_concentration()\n    number_distribution = aerosol.particles.get_radius(clone=True)\n    number_distribution_binned[i, :], edges = np.histogram(\n        number_distribution, bins=bins_lognormal\n    )\n    total_number_resolved[i] = np.sum(number_distribution[i] &gt; 0)\n    saturation_ratio_output[i] = aerosol.atmosphere.partitioning_species.get_saturation_ratio(temperature=298.15)\n\n    if i % 20 == 0:\n        # Retrieve and print the total number of resolved particles simulated\n        total_resolved_particles_in_simulation = aerosol.particles.get_concentration().sum()\n        print(\n            f\"Index {i}: Total resolved particles in simulation: {total_resolved_particles_in_simulation}\"\n        )\n\n\nnumber_distribution_binned = number_distribution_binned / volume_sim\n</pre> # Define key parameters vapor_production = (     sulfate_saturation * 0.2 )  # Adding 20% of saturation concentration per second base_nucleation_rate = (     1e-8 * density_ammonium_sulfate )  # Base nucleation rate in kg/m^3/s mass_nucleated_particle = (     4 / 3 * np.pi * (2e-9) ** 3 * density_ammonium_sulfate )  # Mass of a 10 nm particle in kg exponent_nucleation = 2  # Nucleation rate exponent (empirical)   for i, t in enumerate(time):     if i &gt; 0:         # 1. Add more vapor to the gas phase (e.g., by external sources)         aerosol.atmosphere.partitioning_species.add_concentration(             vapor_production * time_step         )          # 2. Calculate the new saturation ratio for sulfate in the atmosphere         saturation_ratio = aerosol.atmosphere.partitioning_species.get_saturation_ratio(             temperature=298.15         )          # 3. Calculate the nucleation rate based on the saturation ratio         # Ensure the saturation ratio is above 1, nucleation only occurs above saturation         saturation_difference = np.maximum(             saturation_ratio - 1, 0         )  # No nucleation if S \u2264 1         # Calculate the nucleation rate using the exponential form (custom)         # note this is mass based, if you have a volume based nucleation rate, you need to convert it         # to mass, as the resolved particles are mass based         nucleation_rate = (             base_nucleation_rate             * (saturation_difference / 500) ** exponent_nucleation         )          # 4. Calculate the number of new particles nucleated         # Floor division ensures we only get whole particles         number_of_new_particles = (             time_step * nucleation_rate // mass_nucleated_particle         )          # 5. Determine the number of resolved particles to create (based on simulation volume)         single_resolved_particle = (             aerosol.particles.get_concentration().max()         )         number_of_new_resolved_particles = int(             number_of_new_particles // single_resolved_particle         )          # 6. If new particles are nucleated, proceed to add them to the aerosol         if number_of_new_resolved_particles &gt; 0:             # Remove nucleated mass from the gas phase to conserve mass             aerosol.atmosphere.partitioning_species.add_concentration(                 -number_of_new_resolved_particles * mass_nucleated_particle             )              # Create arrays to store the properties of the newly resolved particles             new_resolved_particle_masses = np.full(                 number_of_new_resolved_particles, mass_nucleated_particle             )             new_resolved_particle_concentrations = np.ones_like(                 new_resolved_particle_masses             )  # Concentration of 1 per particle              # Add the new resolved particles to the aerosol             aerosol.particles.add_concentration(                 added_concentration=new_resolved_particle_concentrations,                 added_distribution=new_resolved_particle_masses,             )          # 7. Perform the condensation step         condensation_runnable.execute(aerosol, time_step, sub_steps)         # 8. Perform the coagulation step         coagulation_runnable.execute(aerosol, time_step, sub_steps)      total_mass_resolved[i] = aerosol.particles.get_mass_concentration()     number_distribution = aerosol.particles.get_radius(clone=True)     number_distribution_binned[i, :], edges = np.histogram(         number_distribution, bins=bins_lognormal     )     total_number_resolved[i] = np.sum(number_distribution[i] &gt; 0)     saturation_ratio_output[i] = aerosol.atmosphere.partitioning_species.get_saturation_ratio(temperature=298.15)      if i % 20 == 0:         # Retrieve and print the total number of resolved particles simulated         total_resolved_particles_in_simulation = aerosol.particles.get_concentration().sum()         print(             f\"Index {i}: Total resolved particles in simulation: {total_resolved_particles_in_simulation}\"         )   number_distribution_binned = number_distribution_binned / volume_sim <pre>Index 0: Total resolved particles in simulation: 999999999.9999999\nIndex 20: Total resolved particles in simulation: 2958949999999.9995\nIndex 40: Total resolved particles in simulation: 3360559999999.9995\nIndex 60: Total resolved particles in simulation: 3201369999999.9995\nIndex 80: Total resolved particles in simulation: 3026179999999.9995\nIndex 100: Total resolved particles in simulation: 2867979999999.9995\nIndex 120: Total resolved particles in simulation: 2725539999999.9995\nIndex 140: Total resolved particles in simulation: 2596449999999.9995\nIndex 160: Total resolved particles in simulation: 2479179999999.9995\nIndex 180: Total resolved particles in simulation: 2370949999999.9995\n</pre> In\u00a0[\u00a0]: Copied! <pre>fig, ax = plt.subplots(figsize=(8, 5))\n\n# Swap X and Y to reverse axes\nX, Y = np.meshgrid(\n    time, edges[:-1]\n)  # Now time is on the x-axis and edges on the y-axis\n\n# Plot the contour with updated X and Y\nlog_of_number_distribution_binned = np.log10(\n    number_distribution_binned,\n    out=np.nan * np.ones_like(number_distribution_binned),\n    where=number_distribution_binned &gt; 0,\n)\ncontour = ax.contourf(\n    X,\n    Y,\n    log_of_number_distribution_binned.T,\n    cmap=\"viridis\",\n    vmin=5,\n)\n\n# Add the color bar\ncbar = fig.colorbar(contour)\ncbar.set_label(\"Log10 of Number concentration (m^-3)\")\n\nax.set_ylim([1e-9, 1e-7])  # Set limits for y-axis\n\n# Set axis labels\nax.set_yscale(\"log\")  # Log scale for particle radius on y-axis\nax.set_xlabel(\"Time (s)\")\nax.set_ylabel(\"Particle radius (m)\")\nfig.tight_layout()\nplt.show()\n</pre> fig, ax = plt.subplots(figsize=(8, 5))  # Swap X and Y to reverse axes X, Y = np.meshgrid(     time, edges[:-1] )  # Now time is on the x-axis and edges on the y-axis  # Plot the contour with updated X and Y log_of_number_distribution_binned = np.log10(     number_distribution_binned,     out=np.nan * np.ones_like(number_distribution_binned),     where=number_distribution_binned &gt; 0, ) contour = ax.contourf(     X,     Y,     log_of_number_distribution_binned.T,     cmap=\"viridis\",     vmin=5, )  # Add the color bar cbar = fig.colorbar(contour) cbar.set_label(\"Log10 of Number concentration (m^-3)\")  ax.set_ylim([1e-9, 1e-7])  # Set limits for y-axis  # Set axis labels ax.set_yscale(\"log\")  # Log scale for particle radius on y-axis ax.set_xlabel(\"Time (s)\") ax.set_ylabel(\"Particle radius (m)\") fig.tight_layout() plt.show() In\u00a0[\u00a0]: Copied! <pre># plot the total mass and water saturation on twin y-axis\nfig, ax1 = plt.subplots(figsize=(8, 5))\n\nax1.plot(time, total_mass_resolved, label=\"Total mass\", color=\"blue\")\nax1.set_xlabel(\"Time (s)\")\nax1.set_ylabel(\"Total Particle mass (kg/m^3)\", color=\"blue\")\nax1.tick_params(axis=\"y\", labelcolor=\"blue\")\n\nax2 = ax1.twinx()\nax2.plot(time, saturation_ratio_output, label=\"Satruation Ratio\", color=\"red\")\nax2.set_ylabel(\"Saturation Ratio\", color=\"red\")\nax2.tick_params(axis=\"y\", labelcolor=\"red\")\n\nfig.tight_layout()\nplt.show()\n</pre> # plot the total mass and water saturation on twin y-axis fig, ax1 = plt.subplots(figsize=(8, 5))  ax1.plot(time, total_mass_resolved, label=\"Total mass\", color=\"blue\") ax1.set_xlabel(\"Time (s)\") ax1.set_ylabel(\"Total Particle mass (kg/m^3)\", color=\"blue\") ax1.tick_params(axis=\"y\", labelcolor=\"blue\")  ax2 = ax1.twinx() ax2.plot(time, saturation_ratio_output, label=\"Satruation Ratio\", color=\"red\") ax2.set_ylabel(\"Saturation Ratio\", color=\"red\") ax2.tick_params(axis=\"y\", labelcolor=\"red\")  fig.tight_layout() plt.show()"},{"location":"Examples/Nucleation/Notebooks/Custom_Nucleation_Single_Species/#custom-nucleation-single-species","title":"Custom Nucleation: Single Species\u00b6","text":"<p>In this How-to Guide, we will demonstrate how to create a custom nucleation model for a single-species aerosol system. We will use fixed nucleation rates for demonstration purposes. This approach highlights the flexibility of adding new processes to your aerosol simulation before full integration into the main codebase.</p> <p>This guide is based on the Dynamics Customization tutorial.</p> <p>Imports</p>"},{"location":"Examples/Nucleation/Notebooks/Custom_Nucleation_Single_Species/#aerosol-setup","title":"Aerosol Setup\u00b6","text":"<p>We will begin by setting up ammonium sulfate vapor alongside a few pre-existing particles. The vapor phase will include a constant vapor pressure for ammonium sulfate, and a lognormal distribution will be used to represent the initial particle population.</p> <p>The pre-existing particles are also necessary as, the zero particle case is not supported in the current version of the model.</p>"},{"location":"Examples/Nucleation/Notebooks/Custom_Nucleation_Single_Species/#simulation","title":"Simulation\u00b6","text":"<p>This section performs a step in the simulation using a manual stepping method. The steps include:</p> <ol> <li>Adding more vapors to the gas phase.</li> <li>Calculating the new saturation ratio.</li> <li>Calculating the nucleation rate based on the saturation difference.</li> <li>Determining the number of new particles nucleated.</li> <li>Determining the number of resolved particles to be added to the aerosol.</li> <li>Creating and adding the new particles to the aerosol.</li> <li>Performing a condensation step to account for gas-phase condensation onto existing particles.</li> <li>Performing a coagulation step to account for particle-particle interactions.</li> </ol> <p>And before we start, we also need to initialize the condensation and coagulation runnables.</p>"},{"location":"Examples/Nucleation/Notebooks/Custom_Nucleation_Single_Species/#time-loop","title":"Time Loop\u00b6","text":"<p>Now that we see the simulation is working, we can put that into a loop and save out the distribution of particles at each time step.</p> <p>We'll first reset the aerosol system to its initial state, create a output matrix, then run the previous simulation in a for loop.</p>"},{"location":"Examples/Nucleation/Notebooks/Custom_Nucleation_Single_Species/#graphing","title":"Graphing\u00b6","text":"<p>In this section, we will visualize the nucleation events over time. The initial particles will be displayed, followed by their coagulated pairs. As the simulation progresses, particle growth results from both coagulation and condensation processes.</p>"},{"location":"Examples/Nucleation/Notebooks/Custom_Nucleation_Single_Species/#conclusion","title":"Conclusion\u00b6","text":"<p>In this guide, we demonstrated how to integrate custom nucleation processes into the aerosol simulation. This shows the flexibility of the aerosol model, allowing for the addition of new processes before they are fully integrated into the core framework.</p> <p>Note: Custom nucleation, particularly at high rates, can significantly increase the number of particles simulated, potentially slowing down the computation. A rescaling mechanism to adjust the simulation volume and control the number of resolved particles is planned for future enhancements to address this issue.</p>"},{"location":"Examples/Particle_Phase/","title":"Index: Particle Phase","text":""},{"location":"Examples/Particle_Phase/#notebooks","title":"Notebooks","text":"<ul> <li>Aerosol Surface Tutorial</li> <li>Activity Tutorial</li> <li>Distribution Tutorial</li> <li>Types of Distributions Tutorial</li> <li>Particle Representation Tutorial</li> </ul>"},{"location":"Examples/Particle_Phase/#functional-representation","title":"Functional Representation","text":"<ul> <li>Activity Functions</li> </ul>"},{"location":"Examples/Particle_Phase/Notebooks/Activity_Tutorial/","title":"Activity Tutorial","text":"In\u00a0[\u00a0]: Copied! <pre># In Colab uncomment the following command to install particula:\n#!pip install particula[extra] --quiet\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nimport particula as par\n</pre> # In Colab uncomment the following command to install particula: #!pip install particula[extra] --quiet import numpy as np import matplotlib.pyplot as plt  import particula as par In\u00a0[2]: Copied! <pre>activity_mass = par.particles.ActivityIdealMass()  # no parameters needed\n\n# mixture\nmass_mixture = np.array([0.2, 0.8])  # water, sucrose\n\nactivities = activity_mass.activity(mass_concentration=mass_mixture)\nprint(f\"Activities: {activities}\")\n\n# partial pressures\npure_pressure = np.array([100, 10])  # water, sucrose\npartial_pressures = activity_mass.partial_pressure(\n    pure_vapor_pressure=pure_pressure, mass_concentration=mass_mixture\n)\n\nprint(f\"Partial pressures: {partial_pressures}\")\n</pre> activity_mass = par.particles.ActivityIdealMass()  # no parameters needed  # mixture mass_mixture = np.array([0.2, 0.8])  # water, sucrose  activities = activity_mass.activity(mass_concentration=mass_mixture) print(f\"Activities: {activities}\")  # partial pressures pure_pressure = np.array([100, 10])  # water, sucrose partial_pressures = activity_mass.partial_pressure(     pure_vapor_pressure=pure_pressure, mass_concentration=mass_mixture )  print(f\"Partial pressures: {partial_pressures}\") <pre>Activities: [0.2 0.8]\nPartial pressures: [20.  8.]\n</pre> In\u00a0[3]: Copied! <pre>activity_molar = (\n    par.particles.ActivityIdealMolarBuilder()\n    .set_molar_mass(\n        np.array([18.01528, 342.29648]) * 1e-3, \"kg/mol\"\n    )  # water, sucrose\n    .build()\n)\n\n# mixture\nactivities = activity_molar.activity(mass_concentration=mass_mixture)\nprint(f\"Activities: {activities}\")\n\n# partial pressures\npure_pressure = np.array([100, 10])  # water, sucrose\npartial_pressures = activity_molar.partial_pressure(\n    pure_vapor_pressure=pure_pressure, mass_concentration=mass_mixture\n)\n\nprint(f\"Partial pressures: {partial_pressures}\")\n</pre> activity_molar = (     par.particles.ActivityIdealMolarBuilder()     .set_molar_mass(         np.array([18.01528, 342.29648]) * 1e-3, \"kg/mol\"     )  # water, sucrose     .build() )  # mixture activities = activity_molar.activity(mass_concentration=mass_mixture) print(f\"Activities: {activities}\")  # partial pressures pure_pressure = np.array([100, 10])  # water, sucrose partial_pressures = activity_molar.partial_pressure(     pure_vapor_pressure=pure_pressure, mass_concentration=mass_mixture )  print(f\"Partial pressures: {partial_pressures}\") <pre>Activities: [0.82608954 0.17391046]\nPartial pressures: [82.6089542   1.73910458]\n</pre> In\u00a0[4]: Copied! <pre>parameters_input = {\n    \"density\": np.array(\n        [1000, 1500]\n    ),  # water, sucrose, kg/m^3 are the base SI default units\n    \"density_units\": \"kg/m^3\",  # this tells the factory what the input units are so it can convert to kg/m^3\n    \"molar_mass\": np.array([18.01528, 342.29648]),  # water, sucrose\n    \"molar_mass_units\": \"g/mol\",  # this tells the factory what the input units are so it can convert to kg/mol\n    \"kappa\": np.array([0, 0.3]),  # water, sucrose\n    \"water_index\": 0,  # water is the first component\n}\n\nactivity_kappa = par.particles.ActivityFactory().get_strategy(\n    strategy_type=\"kappa\", parameters=parameters_input\n)\n\n# mixture\nactivities = activity_kappa.activity(mass_concentration=mass_mixture)\nprint(f\"Activities: {activities}\")\n\n# partial pressures\npure_pressure = np.array([100, 10])  # water, sucrose\npartial_pressures = activity_kappa.partial_pressure(\n    pure_vapor_pressure=pure_pressure, mass_concentration=mass_mixture\n)\n\nprint(f\"Partial pressures: {partial_pressures}\")\n</pre> parameters_input = {     \"density\": np.array(         [1000, 1500]     ),  # water, sucrose, kg/m^3 are the base SI default units     \"density_units\": \"kg/m^3\",  # this tells the factory what the input units are so it can convert to kg/m^3     \"molar_mass\": np.array([18.01528, 342.29648]),  # water, sucrose     \"molar_mass_units\": \"g/mol\",  # this tells the factory what the input units are so it can convert to kg/mol     \"kappa\": np.array([0, 0.3]),  # water, sucrose     \"water_index\": 0,  # water is the first component }  activity_kappa = par.particles.ActivityFactory().get_strategy(     strategy_type=\"kappa\", parameters=parameters_input )  # mixture activities = activity_kappa.activity(mass_concentration=mass_mixture) print(f\"Activities: {activities}\")  # partial pressures pure_pressure = np.array([100, 10])  # water, sucrose partial_pressures = activity_kappa.partial_pressure(     pure_vapor_pressure=pure_pressure, mass_concentration=mass_mixture )  print(f\"Partial pressures: {partial_pressures}\") <pre>Activities: [0.55555556 0.17391046]\nPartial pressures: [55.55555556  1.73910458]\n</pre> In\u00a0[5]: Copied! <pre>mass_water = np.linspace(0.001, 0.9999, 100)\nmass_sucrose = 1 - mass_water\nmass_mixture = np.array([mass_water, mass_sucrose]).T\n\nactivities_mass = np.zeros_like(mass_mixture)\nactivities_molar = np.zeros_like(mass_mixture)\nactivities_kappa = np.zeros_like(mass_mixture)\n\n\nfor i, mass in enumerate(mass_mixture):\n    activities_mass[i] = activity_mass.activity(mass_concentration=mass)\n    activities_molar[i] = activity_molar.activity(mass_concentration=mass)\n    activities_kappa[i] = activity_kappa.activity(mass_concentration=mass)\n\nfig, ax = plt.subplots(figsize=(8, 6))\nax.plot(mass_water, activities_mass[:, 0], label=\"Mass: Water\")\nax.plot(\n    mass_water, activities_mass[:, 1], label=\"Mass: Sucrose\", linestyle=\"--\"\n)\nax.plot(mass_water, activities_molar[:, 0], label=\"Molar: Water\")\nax.plot(\n    mass_water,\n    activities_molar[:, 1],\n    label=\"Molar: Sucrose\",\n    linestyle=\"--\",\n    linewidth=3,\n    alpha=0.85,\n)\nax.plot(mass_water, activities_kappa[:, 0], label=\"Kappa: Water\")\nax.plot(\n    mass_water, activities_kappa[:, 1], label=\"Kappa: Sucrose\", linestyle=\"--\"\n)\nax.set_xlabel(\"Mass fraction water\")\nax.set_ylabel(\"Activity\")\nax.legend()\nplt.show()\n</pre> mass_water = np.linspace(0.001, 0.9999, 100) mass_sucrose = 1 - mass_water mass_mixture = np.array([mass_water, mass_sucrose]).T  activities_mass = np.zeros_like(mass_mixture) activities_molar = np.zeros_like(mass_mixture) activities_kappa = np.zeros_like(mass_mixture)   for i, mass in enumerate(mass_mixture):     activities_mass[i] = activity_mass.activity(mass_concentration=mass)     activities_molar[i] = activity_molar.activity(mass_concentration=mass)     activities_kappa[i] = activity_kappa.activity(mass_concentration=mass)  fig, ax = plt.subplots(figsize=(8, 6)) ax.plot(mass_water, activities_mass[:, 0], label=\"Mass: Water\") ax.plot(     mass_water, activities_mass[:, 1], label=\"Mass: Sucrose\", linestyle=\"--\" ) ax.plot(mass_water, activities_molar[:, 0], label=\"Molar: Water\") ax.plot(     mass_water,     activities_molar[:, 1],     label=\"Molar: Sucrose\",     linestyle=\"--\",     linewidth=3,     alpha=0.85, ) ax.plot(mass_water, activities_kappa[:, 0], label=\"Kappa: Water\") ax.plot(     mass_water, activities_kappa[:, 1], label=\"Kappa: Sucrose\", linestyle=\"--\" ) ax.set_xlabel(\"Mass fraction water\") ax.set_ylabel(\"Activity\") ax.legend() plt.show()"},{"location":"Examples/Particle_Phase/Notebooks/Activity_Tutorial/#activity-tutorial","title":"Activity Tutorial\u00b6","text":"<p>This Jupyter notebook is designed to deepen your understanding of mixing behaviors in solutions, focusing on both theoretical models and practical applications. We will explore ideal and non-ideal mixing rules, differentiate between mass-based and molar-based approaches, and introduce the kappa value parameterization for predicting water activity.</p>"},{"location":"Examples/Particle_Phase/Notebooks/Activity_Tutorial/#introduction-to-mixing-rules","title":"Introduction to Mixing Rules\u00b6","text":"<p>Mixing rules are essential for predicting the properties of solutions, including their thermodynamic behavior and phase equilibria. In this notebook, we will:</p> <ul> <li>Define and compare different mixing rules: Understand how various rules apply to different types of solutions.</li> <li>Mass-Based vs. Molar-Based Mixing: Discuss the implications of choosing mass-based or molar-based calculations for different applications.</li> <li>Kappa Value based Activity: Learn about the kappa value parameterization and its role in modeling water activity in non-ideal solutions.</li> </ul>"},{"location":"Examples/Particle_Phase/Notebooks/Activity_Tutorial/#structure-of-the-notebook","title":"Structure of the Notebook\u00b6","text":"<ol> <li><p>Mass-Based vs. Molar-Based Mixing</p> <ul> <li>Definitions and when to use each method</li> <li>Examples and comparative analysis</li> </ul> </li> <li><p>Kappa Value Parameterization</p> <ul> <li>Theory behind kappa values</li> <li>Practical exercises on calculating water activity</li> </ul> </li> </ol>"},{"location":"Examples/Particle_Phase/Notebooks/Activity_Tutorial/#strategies-builders-and-factories","title":"Strategies, Builders, and Factories\u00b6","text":"<p>We'll show examples for getting the strategy directly, form a builder, and from a factory.</p>"},{"location":"Examples/Particle_Phase/Notebooks/Activity_Tutorial/#strategy-ideal-activity-mass-based-mixing","title":"Strategy: Ideal Activity Mass-Based Mixing\u00b6","text":"<p>The ideal in this context refers to all the activity coefficients being equal to 1. This is the simplest case and is often used as a reference point for more complex models. In this case, then we are just mixing based on mass fractions in the solution. Let's start witha mixture of water and sucrose.</p> <p>With an Ideal mass based mixing rule, the activity and partial pressure reduction is just the mass fraction of the component in the mixture.</p>"},{"location":"Examples/Particle_Phase/Notebooks/Activity_Tutorial/#builder-molar-based-mixing","title":"Builder: Molar-Based Mixing\u00b6","text":"<p>All strategies have a builder method that can be used to create a new strategy with different parameters. In this case, we will create a molar-based mixing rule using the builder method.</p> <p>Using the same mixture of water and sucrose, we will now calculate the activity and partial pressure reduction based on molar fractions in the solution. We should see a large effect due to the difference in molecular weight between water and sucrose.</p>"},{"location":"Examples/Particle_Phase/Notebooks/Activity_Tutorial/#factory-kappa-value-parameterization","title":"Factory: Kappa Value Parameterization\u00b6","text":"<p>Lastly, we will use the factory method to create a kappa value parameterization for predicting water activity in non-ideal solutions. This method is more complex and requires additional parameters to be defined. We will use the same water-sucrose mixture to demonstrate the kappa value approach.</p>"},{"location":"Examples/Particle_Phase/Notebooks/Activity_Tutorial/#plotting-mixing-rules","title":"Plotting Mixing Rules\u00b6","text":"<p>We will plot the activity and partial pressure reduction for the water-sucrose mixture using the ideal mass-based mixing rule, molar-based mixing rule, and kappa value parameterization. This will help us visualize the differences between the three methods and understand how they affect the prediction of water activity in the solution.</p> <p>Note: Only water is treated non-ideally in the kappa value parameterization. The other species are treated in a molar-based ideal mixing rule.</p>"},{"location":"Examples/Particle_Phase/Notebooks/Activity_Tutorial/#summary","title":"Summary\u00b6","text":"<p>By the end of this notebook, you should have a better understanding of mixing rules, mass-based vs. molar-based calculations, and the kappa value parameterization for predicting water activity in non-ideal solutions. You will also have learned how to apply these concepts to practical examples and visualize the results using plots.</p> <p>You saw how different mixing rules can be used to predict the properties of solutions and how they can affect the accuracy of the predictions. You also learned about the kappa value parameterization and how it can be used to model water activity in non-ideal solutions. These concepts are essential for condensation and phase equilibrium calculations when aerosol particles are present in the atmosphere.</p>"},{"location":"Examples/Particle_Phase/Notebooks/Aerosol_Distributions/","title":"Size Distributions Tutorial","text":"In\u00a0[\u00a0]: Copied! <pre># In Colab uncomment the following command to install particula:\n#!pip install particula[extra] --quiet\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nimport particula as par\n</pre> # In Colab uncomment the following command to install particula: #!pip install particula[extra] --quiet import numpy as np import matplotlib.pyplot as plt  import particula as par In\u00a0[16]: Copied! <pre># Define the x_values as a range of particle diameters\nx_values = np.logspace(-3, 1, 2000)  # From 0.001 to 10 microns\n</pre> # Define the x_values as a range of particle diameters x_values = np.logspace(-3, 1, 2000)  # From 0.001 to 10 microns In\u00a0[17]: Copied! <pre># %%\n# Single mode distribution\nsingle_mode_gsd = np.array([1.4])\nsingle_mode = np.array([0.02])\nsingle_mode_nparticles = np.array([1e3])\n\nsingle_mode_distribution = par.particles.get_lognormal_pdf_distribution(\n    x_values, single_mode, single_mode_gsd, single_mode_nparticles\n)\n</pre> # %% # Single mode distribution single_mode_gsd = np.array([1.4]) single_mode = np.array([0.02]) single_mode_nparticles = np.array([1e3])  single_mode_distribution = par.particles.get_lognormal_pdf_distribution(     x_values, single_mode, single_mode_gsd, single_mode_nparticles ) In\u00a0[18]: Copied! <pre># %%\n# Multi-mode distribution\nmulti_mode_gsd = np.array([1.4, 1.8])\nmulti_mode = np.array([0.02, 1.0])\nmulti_mode_nparticles = np.array([1e3, 1e3])\n\nmulti_mode_distribution = par.particles.get_lognormal_pdf_distribution(\n    x_values, multi_mode, multi_mode_gsd, multi_mode_nparticles\n)\n</pre> # %% # Multi-mode distribution multi_mode_gsd = np.array([1.4, 1.8]) multi_mode = np.array([0.02, 1.0]) multi_mode_nparticles = np.array([1e3, 1e3])  multi_mode_distribution = par.particles.get_lognormal_pdf_distribution(     x_values, multi_mode, multi_mode_gsd, multi_mode_nparticles ) In\u00a0[19]: Copied! <pre># %%\nplt.figure(figsize=(10, 6))\nplt.plot(x_values, single_mode_distribution, label=\"Single Mode\", linewidth=4)\nplt.plot(x_values, multi_mode_distribution, label=\"Multi Mode\")\nplt.title(\"Lognormal Particle Size Distribution\")\nplt.xlabel(\"Particle Diameter (\u03bcm)\")\nplt.ylabel(\"Frequency\")\nplt.xscale(\"log\")\nplt.legend()\nplt.grid(True)\nplt.show()\n</pre> # %% plt.figure(figsize=(10, 6)) plt.plot(x_values, single_mode_distribution, label=\"Single Mode\", linewidth=4) plt.plot(x_values, multi_mode_distribution, label=\"Multi Mode\") plt.title(\"Lognormal Particle Size Distribution\") plt.xlabel(\"Particle Diameter (\u03bcm)\") plt.ylabel(\"Frequency\") plt.xscale(\"log\") plt.legend() plt.grid(True) plt.show() In\u00a0[20]: Copied! <pre># %%\nsingle_mode_total_concentration = np.trapezoid(\n    single_mode_distribution, x_values\n)\nmulti_mode_total_concentration = np.trapezoid(\n    multi_mode_distribution, x_values\n)\n\nprint(\n    f\"Total Concentration for Single Mode: {single_mode_total_concentration}\"\n)\nprint(f\"Total Concentration for Multi Mode: {multi_mode_total_concentration}\")\n</pre> # %% single_mode_total_concentration = np.trapezoid(     single_mode_distribution, x_values ) multi_mode_total_concentration = np.trapezoid(     multi_mode_distribution, x_values )  print(     f\"Total Concentration for Single Mode: {single_mode_total_concentration}\" ) print(f\"Total Concentration for Multi Mode: {multi_mode_total_concentration}\") <pre>Total Concentration for Single Mode: 1000.0\nTotal Concentration for Multi Mode: 2000.000000000001\n</pre> In\u00a0[21]: Copied! <pre>single_pmf_distribution = par.particles.get_lognormal_pmf_distribution(\n    x_values, single_mode, single_mode_gsd, single_mode_nparticles\n)\nmulti_pmf_distribution = par.particles.get_lognormal_pmf_distribution(\n    x_values, multi_mode, multi_mode_gsd, multi_mode_nparticles\n)\n</pre> single_pmf_distribution = par.particles.get_lognormal_pmf_distribution(     x_values, single_mode, single_mode_gsd, single_mode_nparticles ) multi_pmf_distribution = par.particles.get_lognormal_pmf_distribution(     x_values, multi_mode, multi_mode_gsd, multi_mode_nparticles ) In\u00a0[22]: Copied! <pre>plt.figure(figsize=(10, 6))\nplt.plot(x_values, single_pmf_distribution, label=\"Single Mode\", linewidth=4)\nplt.plot(x_values, multi_pmf_distribution, label=\"Multi Mode\")\nplt.title(\"Lognormal PMF Particle Size Distribution\")\nplt.xlabel(\"Particle Diameter (\u03bcm)\")\nplt.ylabel(\"Number of Particles\")\nplt.xscale(\"log\")\nplt.legend()\nplt.grid(True)\nplt.show()\n</pre> plt.figure(figsize=(10, 6)) plt.plot(x_values, single_pmf_distribution, label=\"Single Mode\", linewidth=4) plt.plot(x_values, multi_pmf_distribution, label=\"Multi Mode\") plt.title(\"Lognormal PMF Particle Size Distribution\") plt.xlabel(\"Particle Diameter (\u03bcm)\") plt.ylabel(\"Number of Particles\") plt.xscale(\"log\") plt.legend() plt.grid(True) plt.show() In\u00a0[23]: Copied! <pre># %%\nsingle_mode_total_concentration = single_pmf_distribution.sum()\nmulti_mode_total_concentration = multi_pmf_distribution.sum()\n\nprint(\n    f\"Total Concentration for Single Mode: {single_mode_total_concentration}\"\n)\nprint(f\"Total Concentration for Multi Mode: {multi_mode_total_concentration}\")\n</pre> # %% single_mode_total_concentration = single_pmf_distribution.sum() multi_mode_total_concentration = multi_pmf_distribution.sum()  print(     f\"Total Concentration for Single Mode: {single_mode_total_concentration}\" ) print(f\"Total Concentration for Multi Mode: {multi_mode_total_concentration}\") <pre>Total Concentration for Single Mode: 1000.0000000000001\nTotal Concentration for Multi Mode: 2000.0\n</pre>"},{"location":"Examples/Particle_Phase/Notebooks/Aerosol_Distributions/#size-distributions-tutorial","title":"Size Distributions Tutorial\u00b6","text":"<p>In this tutorial, we will explore how to calculate and plot lognormal distributions for aerosol particles. This is commonly used in aerosol science to model the size distribution of particles in different environmental or experimental conditions.</p>"},{"location":"Examples/Particle_Phase/Notebooks/Aerosol_Distributions/#probability-density-function","title":"Probability Density Function\u00b6","text":"<p>(fix this, more details for aerosol science)</p> <p>The probability density function (PDF) of a lognormal distribution is given by:</p> <p>$$ f(x, s) = \\frac{1}{s x \\sqrt{2\\pi}} \\exp\\left(-\\frac{\\log^2(x)}{2s^2}\\right)  $$</p> <p>where $x$ is the particle diameter, and $s$ is the standard deviation of the distribution. $$ for x &gt; 0, s &gt; 0 $$</p> <p>The <code>scale</code> parameter is defined as the mode of the distribution.</p> <p>The probability density above is defined in the \u201cstandardized\u201d form. To shift and/or scale the distribution use the loc and scale parameters. Specifically, <code>lognorm.pdf(x, s, loc, scale)</code> is identically equivalent to <code>lognorm.pdf(y, s) / scale</code> with <code>y = (x - loc) / scale</code>. Note that shifting the location of a distribution does not make it a \u201cnoncentral\u201d distribution; noncentral generalizations of some distributions are available in separate classes.</p> <ul> <li>PDF Wikipedia</li> <li>Log-normal Wikipedia</li> <li>Log-normal Scipy</li> </ul>"},{"location":"Examples/Particle_Phase/Notebooks/Aerosol_Distributions/#define-particle-size-ranges","title":"Define Particle Size Ranges\u00b6","text":"<p>We use logarithmic spacing for particle diameters to cover a broad size range typically observed in aerosol particles.</p>"},{"location":"Examples/Particle_Phase/Notebooks/Aerosol_Distributions/#single-mode-pdf-particle-size-distribution","title":"Single Mode PDF Particle Size Distribution\u00b6","text":"<p>In this section, we explore modeling a distribution with a single mode, typical for scenarios where particle populations are relatively uniform. The single mode represents a common characteristic size (mode) and spread (geometric standard deviation) of aerosol particles. We utilize parameters for the geometric standard deviation and the modal particle diameter to define this distribution. The distribution is scaled such that the area under the probability density function (PDF) equals the total number of particles, ensuring that it accurately reflects the particle count in terms of probability across different sizes. This method is particularly useful for representing aerosol populations where a single predominant size class exists, making it easier to analyze and predict aerosol behavior in environmental or laboratory settings.</p>"},{"location":"Examples/Particle_Phase/Notebooks/Aerosol_Distributions/#multi-mode-pdf-particle-distribution","title":"Multi-Mode PDF Particle Distribution\u00b6","text":"<p>For more complex scenarios, such as urban air samples, we often observe multiple modes. Here we define and calculate distributions for a two-mode system.</p>"},{"location":"Examples/Particle_Phase/Notebooks/Aerosol_Distributions/#plotting-the-pdfs-of-particle-size-distributions","title":"Plotting the PDFs of Particle Size Distributions\u00b6","text":"<p>Visualizing the probability density functions (PDFs) helps in understanding the frequency of different particle sizes.</p>"},{"location":"Examples/Particle_Phase/Notebooks/Aerosol_Distributions/#calculate-and-display-total-concentration-from-pdfs","title":"Calculate and Display Total Concentration from PDFs\u00b6","text":"<p>Total concentration is important for understanding the overall particle load in a sample.</p>"},{"location":"Examples/Particle_Phase/Notebooks/Aerosol_Distributions/#probability-mass-function-pmf-for-aerosol-distributions","title":"Probability Mass Function (PMF) for Aerosol Distributions\u00b6","text":"<p>The Probability Mass Function (PMF) of aerosol distributions provides a distinct perspective compared to the Probability Density Function (PDF). While the PDF represents the probability of particle sizes occurring within a continuous range, ensuring that the integral over all sizes equals the total number of particles, the PMF deals directly with discrete particle counts.</p> <p>In PMF, each value represents the actual number of particles expected at a specific size interval, rather than the probability density. This approach is particularly advantageous when quantifying and visualizing the actual particle counts across various size classes, making it ideal for detailed statistical analysis and practical applications like filter testing or health impact studies.</p> <p>Unlike the PDF, where the area under the curve corresponds to the total number of particles (when scaled appropriately), the PMF sums directly to the total number of particles without needing any integral calculation. Each point on the PMF curve directly indicates the number of particles in that particular size class, thus providing a more intuitive grasp of the size distribution's impact, especially in contexts where the exact count of particles is more relevant than their probability density.</p> <p>PMF Wikipedia</p>"},{"location":"Examples/Particle_Phase/Notebooks/Aerosol_Distributions/#plotting-the-pmfs-of-particle-size-distributions","title":"Plotting the PMFs of Particle Size Distributions\u00b6","text":"<p>Particle mass functions (PMFs) tell us about the actual number of particles at different sizes.</p>"},{"location":"Examples/Particle_Phase/Notebooks/Aerosol_Distributions/#calculate-and-display-total-number-of-particles-from-pmfs","title":"Calculate and Display Total Number of Particles from PMFs\u00b6","text":"<p>This helps quantify the actual particle count in different modes.</p>"},{"location":"Examples/Particle_Phase/Notebooks/Aerosol_Distributions/#summary-of-pdf-vs-pmf-in-aerosol-distributions","title":"Summary of PDF vs. PMF in Aerosol Distributions\u00b6","text":"<p>In this tutorial, we explored two fundamental representations of aerosol size distributions: the Probability Density Function (PDF) and the Particle Mass Function (PMF). Both offer valuable insights into aerosol characteristics but serve different analytical purposes:</p> <ul> <li><p>Probability Density Function (PDF): The PDF provides a normalized view of particle size distribution where the area under the curve represents the total number of particles. It is ideal for understanding the relative frequency of different particle sizes within a continuous range and for conducting probability-based analyses. The PDF is particularly useful in theoretical studies and simulations where understanding the likelihood of particle sizes is crucial.</p> </li> <li><p>Particle Mass Function (PMF): Conversely, the PMF directly quantifies the actual number of particles in each size interval. This discrete representation is especially useful for practical applications such as air quality monitoring and aerosol delivery systems where knowing the exact count of particles at different sizes is necessary. The PMF is straightforward as it adds up to the total particle count directly, providing a more tangible grasp of particle distribution without requiring integration.</p> </li> </ul> <p>Both methods play critical roles in aerosol science, each complementing the other by offering different perspectives on particle size distributions. Understanding when to use each can significantly enhance the accuracy and relevance of aerosol studies.</p>"},{"location":"Examples/Particle_Phase/Notebooks/Distribution_Tutorial/","title":"Distribution Strategy Tutorial","text":"In\u00a0[\u00a0]: Copied! <pre># In Colab uncomment the following command to install particula:\n#!pip install particula[extra] --quiet\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nimport particula as par\n</pre> # In Colab uncomment the following command to install particula: #!pip install particula[extra] --quiet import numpy as np import matplotlib.pyplot as plt  import particula as par In\u00a0[2]: Copied! <pre>mass_distribution = np.linspace(0, 10, 5)  # kg\ndensity = 1000  # kg/m^3\n\nradius = par.particles.MassBasedMovingBin().get_radius(\n    mass_distribution, density\n)\nprint(f\"Radius of the particles: {radius} m\")\n\ntotal_mass = par.particles.MassBasedMovingBin().get_total_mass(\n    mass_distribution,\n    concentration=np.ones_like(mass_distribution),\n    density=density,\n)\nprint(f\"Total mass of the particles: {total_mass} kg\")\nprint(f\"Same as the sum*concentration: {np.sum(mass_distribution)} kg\")\n</pre> mass_distribution = np.linspace(0, 10, 5)  # kg density = 1000  # kg/m^3  radius = par.particles.MassBasedMovingBin().get_radius(     mass_distribution, density ) print(f\"Radius of the particles: {radius} m\")  total_mass = par.particles.MassBasedMovingBin().get_total_mass(     mass_distribution,     concentration=np.ones_like(mass_distribution),     density=density, ) print(f\"Total mass of the particles: {total_mass} kg\") print(f\"Same as the sum*concentration: {np.sum(mass_distribution)} kg\") <pre>Radius of the particles: [0.         0.08419452 0.10607844 0.1214295  0.13365046] m\nTotal mass of the particles: 25.0 kg\nSame as the sum*concentration: 25.0 kg\n</pre> In\u00a0[3]: Copied! <pre>radii_distribution = np.linspace(0, 0.1, 5)  # m\ndensity = 1000  # kg/m^3\n\nradii_strategy = par.particles.RadiiBasedMovingBinBuilder().build()\n\nmass_distribution = radii_strategy.get_mass(radii_distribution, density)\nprint(f\"Mass of the particles: {mass_distribution} kg\")\n\ntotal_mass = radii_strategy.get_total_mass(\n    radii_distribution,\n    concentration=np.ones_like(radii_distribution),\n    density=density,\n)\nprint(f\"Total mass of the particles: {total_mass} kg\")\n</pre> radii_distribution = np.linspace(0, 0.1, 5)  # m density = 1000  # kg/m^3  radii_strategy = par.particles.RadiiBasedMovingBinBuilder().build()  mass_distribution = radii_strategy.get_mass(radii_distribution, density) print(f\"Mass of the particles: {mass_distribution} kg\")  total_mass = radii_strategy.get_total_mass(     radii_distribution,     concentration=np.ones_like(radii_distribution),     density=density, ) print(f\"Total mass of the particles: {total_mass} kg\") <pre>Mass of the particles: [0.         0.06544985 0.52359878 1.76714587 4.1887902 ] kg\nTotal mass of the particles: 6.544984694978737 kg\n</pre> In\u00a0[4]: Copied! <pre>mass_distribution1 = np.linspace(0, 10, 5)  # kg\nmass_distribution2 = np.linspace(0, 10, 5)  # kg\nmasses_combined = np.vstack((mass_distribution1, mass_distribution2)).T\ndensity = np.array([1000.0, 2000.0])  # kg/m^3\n\nspeciated_mass = par.particles.DistributionFactory().get_strategy(\n    \"speciated_mass_moving_bin\"\n)\n\nradius = speciated_mass.get_radius(masses_combined, density)\n\nprint(f\"Radius of the particles: {radius} m\")\n\ntotal_mass = speciated_mass.get_total_mass(\n    masses_combined,\n    concentration=np.ones_like(mass_distribution1),\n    density=density,\n)\nprint(f\"Total mass of the particles: {total_mass} kg\")\n</pre> mass_distribution1 = np.linspace(0, 10, 5)  # kg mass_distribution2 = np.linspace(0, 10, 5)  # kg masses_combined = np.vstack((mass_distribution1, mass_distribution2)).T density = np.array([1000.0, 2000.0])  # kg/m^3  speciated_mass = par.particles.DistributionFactory().get_strategy(     \"speciated_mass_moving_bin\" )  radius = speciated_mass.get_radius(masses_combined, density)  print(f\"Radius of the particles: {radius} m\")  total_mass = speciated_mass.get_total_mass(     masses_combined,     concentration=np.ones_like(mass_distribution1),     density=density, ) print(f\"Total mass of the particles: {total_mass} kg\") <pre>Radius of the particles: [0.         0.09637866 0.1214295  0.13900208 0.15299159] m\nTotal mass of the particles: 50.0 kg\n</pre>"},{"location":"Examples/Particle_Phase/Notebooks/Distribution_Tutorial/#distribution-strategy-tutorial","title":"Distribution Strategy Tutorial\u00b6","text":"<p>The representation of particle distributions is core to the simulation, but it can vary depending on what you are trying to achieve. In this tutorial, we will cover the  distribution strategies currently implemented.</p> <p>The distribution strategies, define how to calculate properties derived from the particle distribution. These include particle mass, radius, and total mass. All of which can have different methods depending if the distribution is mass-based, radius-based, or speciated-mass based.</p> <p>We will cover the following distribution strategies:</p> <ul> <li><code>MassBasedMovingBin</code></li> <li><code>RadiiBasedMovingBin</code></li> <li><code>SpeciatedMassMovingBin</code></li> </ul> <p>As they are just operational strategies, they do not have any specific parameters to be set. They are just used to calculate the properties of the particles.</p>"},{"location":"Examples/Particle_Phase/Notebooks/Distribution_Tutorial/#strategy-massbasedmovingbin","title":"Strategy: MassBasedMovingBin\u00b6","text":"<p>The <code>MassBasedMovingBin</code> strategy is used when the distribution is mass-based. This means that the mass of the particles is known and the radius is calculated from the mass. The <code>MassBasedMovingBin</code> strategy calculates the radius of the particles using the following equation:</p> <p>$$ r = \\left(\\frac{3m}{4\\pi\\rho}\\right)^{1/3} $$</p> <p>where $r$ is the radius of the particle, $m$ is the mass of the particle, and $\\rho$ is the density of the particle.</p>"},{"location":"Examples/Particle_Phase/Notebooks/Distribution_Tutorial/#builder-radiibasedmovingbin","title":"Builder: RadiiBasedMovingBin\u00b6","text":"<p>The <code>RadiiBasedMovingBin</code> strategy is used when the distribution is radius-based. This means that the radius of the particles is known and the mass is calculated from the radius. The <code>RadiiBasedMovingBin</code> strategy calculates the mass of the particles using the following equation:</p> <p>$$ m = \\frac{4\\pi\\rho r^3}{3} $$</p> <p>where $m$ is the mass of the particle, $r$ is the radius of the particle, and $\\rho$ is the density of the particle.</p> <p>The builder does nothing in this case, as we just have no parameters to set. We use the builder pattern here to keep the code consistent with the other strategies.</p>"},{"location":"Examples/Particle_Phase/Notebooks/Distribution_Tutorial/#factory-speciatedmassmovingbin","title":"Factory: SpeciatedMassMovingBin\u00b6","text":"<p>The <code>SpeciatedMassMovingBin</code> strategy is used when the distribution is speciated-mass based. This means that the mass of the particles is known and the radius is calculated from the mass. The <code>SpeciatedMassMovingBin</code> has multiple species, and the mass of each species is known for that given bin or particle.</p>"},{"location":"Examples/Particle_Phase/Notebooks/Distribution_Tutorial/#summary","title":"Summary\u00b6","text":"<p>In this tutorial, we covered the distribution strategies implemented in the simulation. We covered the <code>MassBasedMovingBin</code>, <code>RadiiBasedMovingBin</code>, and <code>SpeciatedMassMovingBin</code> strategies. These strategies are used to calculate the properties of the particles based on the distribution type.</p>"},{"location":"Examples/Particle_Phase/Notebooks/Particle_Representation_Tutorial/","title":"Particle Representation","text":"In\u00a0[\u00a0]: Copied! <pre># In Colab uncomment the following command to install particula:\n#!pip install particula[extra] --quiet\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nimport particula as par\n</pre> # In Colab uncomment the following command to install particula: #!pip install particula[extra] --quiet import numpy as np import matplotlib.pyplot as plt  import particula as par In\u00a0[9]: Copied! <pre># Creating particle distribution examples\nradius = np.array([100, 200, 300], dtype=np.float64)  # in nm\ndensity = 2.5\nconcentration = np.array([1e2, 1e3, 1e4], dtype=np.float64)\n\n# parameters\nsufrace_tension_strategy = (\n    par.particles.SurfaceStrategyMassBuilder()\n    .set_surface_tension(0.072, \"N/m\")\n    .set_density(2.5, \"g/cm^3\")\n)\n\n# Create a Particle instance using the RadiusParticleRepresentationBuilder\nparticle_rep_mass = (\n    par.particles.ParticleRadiusRepresentationBuilder()\n    .set_distribution_strategy(par.particles.RadiiBasedMovingBin())\n    .set_activity_strategy(par.particles.ActivityIdealMass())\n    .set_surface_strategy(sufrace_tension_strategy)\n    .set_concentration(\n        concentration=concentration, concentration_units=\"1/cm^3\"\n    )\n    .set_density(density=density, density_units=\"g/cm^3\")\n    .set_radius(radius=radius, radius_units=\"nm\")\n    .set_charge(charge=0)\n    .build()\n)\n\n# Accessing calculated properties\nprint(\"Mass of particles:\", particle_rep_mass.get_mass())\nprint(\"Radius of particles:\", particle_rep_mass.get_radius())\nprint(\n    \"Total mass of the particle distribution:\",\n    particle_rep_mass.get_mass_concentration(),\n)\n</pre> # Creating particle distribution examples radius = np.array([100, 200, 300], dtype=np.float64)  # in nm density = 2.5 concentration = np.array([1e2, 1e3, 1e4], dtype=np.float64)  # parameters sufrace_tension_strategy = (     par.particles.SurfaceStrategyMassBuilder()     .set_surface_tension(0.072, \"N/m\")     .set_density(2.5, \"g/cm^3\") )  # Create a Particle instance using the RadiusParticleRepresentationBuilder particle_rep_mass = (     par.particles.ParticleRadiusRepresentationBuilder()     .set_distribution_strategy(par.particles.RadiiBasedMovingBin())     .set_activity_strategy(par.particles.ActivityIdealMass())     .set_surface_strategy(sufrace_tension_strategy)     .set_concentration(         concentration=concentration, concentration_units=\"1/cm^3\"     )     .set_density(density=density, density_units=\"g/cm^3\")     .set_radius(radius=radius, radius_units=\"nm\")     .set_charge(charge=0)     .build() )  # Accessing calculated properties print(\"Mass of particles:\", particle_rep_mass.get_mass()) print(\"Radius of particles:\", particle_rep_mass.get_radius()) print(     \"Total mass of the particle distribution:\",     particle_rep_mass.get_mass_concentration(), ) <pre>Mass of particles: [1.04719755e-17 8.37758041e-17 2.82743339e-16]\nRadius of particles: [1.e-07 2.e-07 3.e-07]\nTotal mass of the particle distribution: 2.912256389877738e-06\n</pre> In\u00a0[10]: Copied! <pre># Generating random properties for speciated particles\nmass_distribution = np.random.rand(500, 3).astype(np.float64)\nconcentration = np.random.rand(500, 1).astype(np.float64) * 1e3\n\n# Defining surface tension parameters\nsurface_tension_parameter = {\n    \"surface_tension\": 0.072,  # in N/m\n    \"surface_tension_units\": \"N/m\",\n    \"density\": 2.5,  # Density in g/cm^3\n    \"density_units\": \"g/cm^3\",\n}\nsurface_strategy = par.particles.SurfaceFactory().get_strategy(\n    \"mass\", surface_tension_parameter\n)\ndistribution_strategy = par.particles.DistributionFactory().get_strategy(\n    \"speciated_mass_moving_bin\"\n)\nactivity_strategy = par.particles.ActivityFactory().get_strategy(\"mass_ideal\")\n\n# Setting up parameters for the particle representation factory\nparameters = {\n    \"distribution_strategy\": distribution_strategy,\n    \"activity_strategy\": activity_strategy,\n    \"surface_strategy\": surface_strategy,\n    \"density\": 2.5,\n    \"density_units\": \"g/cm^3\",\n    \"concentration\": concentration,\n    \"concentration_units\": \"1/cm^3\",\n    \"mass\": mass_distribution,\n    \"mass_units\": \"pg\",  # picograms\n    \"charge\": 0,\n}\n\n# Using the factory to create a speciated particle representation\nspeciated_mass_rep = (\n    par.particles.ParticleRepresentationFactory().get_strategy(\n        \"mass\", parameters\n    )\n)\n\n# Outputting the total mass of the particle distribution\nprint(\n    f\"Total mass of the particle distribution: {speciated_mass_rep.get_mass_concentration()}\"\n)\n\n# Plot histogram of the mass distribution and number distribution vs radius\nradius = speciated_mass_rep.get_radius()\nmasses = speciated_mass_rep.get_mass()\nconcentration = speciated_mass_rep.get_concentration(clone=True)\n\n\nfig, ax = plt.subplots(figsize=(8, 6))\nax.hist(masses * 1e6, bins=20, color=\"blue\", alpha=0.7)\nax.set_xlabel(\"Mass (ug)\")\nax.set_ylabel(\"Number of Particles (Droplets)\")\nax.set_title(\"Mass Distribution Particles\")\nplt.show()\n\nfig, ax2 = plt.subplots(figsize=(8, 6))\nax2.hist(radius * 1e9, bins=20, color=\"red\", alpha=0.7)\nax2.set_ylabel(\"Concentration (1/m^3)\")\nax2.set_xlabel(\"Radius (nm)\")\nax2.set_title(\"Number Distribution Particles\")\nplt.show()\n</pre> # Generating random properties for speciated particles mass_distribution = np.random.rand(500, 3).astype(np.float64) concentration = np.random.rand(500, 1).astype(np.float64) * 1e3  # Defining surface tension parameters surface_tension_parameter = {     \"surface_tension\": 0.072,  # in N/m     \"surface_tension_units\": \"N/m\",     \"density\": 2.5,  # Density in g/cm^3     \"density_units\": \"g/cm^3\", } surface_strategy = par.particles.SurfaceFactory().get_strategy(     \"mass\", surface_tension_parameter ) distribution_strategy = par.particles.DistributionFactory().get_strategy(     \"speciated_mass_moving_bin\" ) activity_strategy = par.particles.ActivityFactory().get_strategy(\"mass_ideal\")  # Setting up parameters for the particle representation factory parameters = {     \"distribution_strategy\": distribution_strategy,     \"activity_strategy\": activity_strategy,     \"surface_strategy\": surface_strategy,     \"density\": 2.5,     \"density_units\": \"g/cm^3\",     \"concentration\": concentration,     \"concentration_units\": \"1/cm^3\",     \"mass\": mass_distribution,     \"mass_units\": \"pg\",  # picograms     \"charge\": 0, }  # Using the factory to create a speciated particle representation speciated_mass_rep = (     par.particles.ParticleRepresentationFactory().get_strategy(         \"mass\", parameters     ) )  # Outputting the total mass of the particle distribution print(     f\"Total mass of the particle distribution: {speciated_mass_rep.get_mass_concentration()}\" )  # Plot histogram of the mass distribution and number distribution vs radius radius = speciated_mass_rep.get_radius() masses = speciated_mass_rep.get_mass() concentration = speciated_mass_rep.get_concentration(clone=True)   fig, ax = plt.subplots(figsize=(8, 6)) ax.hist(masses * 1e6, bins=20, color=\"blue\", alpha=0.7) ax.set_xlabel(\"Mass (ug)\") ax.set_ylabel(\"Number of Particles (Droplets)\") ax.set_title(\"Mass Distribution Particles\") plt.show()  fig, ax2 = plt.subplots(figsize=(8, 6)) ax2.hist(radius * 1e9, bins=20, color=\"red\", alpha=0.7) ax2.set_ylabel(\"Concentration (1/m^3)\") ax2.set_xlabel(\"Radius (nm)\") ax2.set_title(\"Number Distribution Particles\") plt.show() <pre>Total mass of the particle distribution: 0.1952955162888737\n</pre> In\u00a0[11]: Copied! <pre>lognormal_rep = (\n    par.particles.PresetParticleRadiusBuilder()\n    .set_mode(np.array([100, 2000]), \"nm\")\n    .set_geometric_standard_deviation(np.array([1.5, 2.0]))\n    .set_number_concentration(np.array([1e4, 1e4]), \"1/cm^3\")\n    .set_distribution_type(\"pmf\")\n    .build()\n)\n\n# plot\nfig, ax = plt.subplots(figsize=(8, 6))\nax.semilogx(\n    lognormal_rep.get_radius(),\n    lognormal_rep.get_concentration(),\n    label=\"Number Distribution\",\n    color=\"blue\",\n)\nax.set_xlabel(\"Radius (m)\")\nax.set_ylabel(\"Concentration (1/m^3)\")\nax.set_title(\"Number Distribution of Particles\")\nplt.legend()\nplt.show()\n</pre> lognormal_rep = (     par.particles.PresetParticleRadiusBuilder()     .set_mode(np.array([100, 2000]), \"nm\")     .set_geometric_standard_deviation(np.array([1.5, 2.0]))     .set_number_concentration(np.array([1e4, 1e4]), \"1/cm^3\")     .set_distribution_type(\"pmf\")     .build() )  # plot fig, ax = plt.subplots(figsize=(8, 6)) ax.semilogx(     lognormal_rep.get_radius(),     lognormal_rep.get_concentration(),     label=\"Number Distribution\",     color=\"blue\", ) ax.set_xlabel(\"Radius (m)\") ax.set_ylabel(\"Concentration (1/m^3)\") ax.set_title(\"Number Distribution of Particles\") plt.legend() plt.show()"},{"location":"Examples/Particle_Phase/Notebooks/Particle_Representation_Tutorial/#particle-representation","title":"Particle Representation\u00b6","text":"<p>With the different aspects of particles laid out in the previous sections, we can now focus on how to represent them in a simulation. The representation of particles is crucial for having a unified way to handle particles in a system. This section will discuss building a particle representation that can be used in simulations and analyses.</p>"},{"location":"Examples/Particle_Phase/Notebooks/Particle_Representation_Tutorial/#builder-particle-representation","title":"Builder: Particle Representation\u00b6","text":"<p>In this section, we will demonstrate how to create a particle distribution using specific particle properties such as radius, density, and concentration. This example will help illustrate the practical application of object-oriented programming in simulating and analyzing particle systems in scientific research. We'll utilize a builder pattern to construct an instance of a Particle class, allowing for flexible configuration of particle characteristics and behaviors.</p> <p>Key Components:</p> <ul> <li>Radius and Concentration: Define the size and number of particles in nanometers and their concentration per cubic centimeter, respectively. Density and Surface Tension: Specify the material's density and the surface tension for the particles, which are critical for calculating various physical and chemical properties.</li> <li>Builder Pattern: Use a builder pattern for creating a particle representation, which facilitates the step-by-step configuration of different strategies for distribution, activity, and surface approximations.</li> </ul> <p>The code snippet below sets up a particle distribution with defined properties using multiple factory methods to specify behavior strategies for distribution, activity, and surface interactions. The use of a builder pattern enhances readability and maintainability of the code by separating the construction of a complex object from its representation.</p>"},{"location":"Examples/Particle_Phase/Notebooks/Particle_Representation_Tutorial/#factory-particle-representation-implementation","title":"Factory: Particle Representation Implementation\u00b6","text":"<p>The factory pattern plays a crucial role in the flexibility and extensibility of particle property computations, such as mass, radius, and total mass, within different computational models. It allows for dynamic selection of computational strategies based on the scenario, facilitating accurate and tailored simulations of real-world conditions.</p> <p>In this section, we'll demonstrate how to use a factory to construct speciated particles characterized by varied properties, enhancing our ability to simulate diverse environmental scenarios. Initially, it's beneficial to directly manipulate builders to familiarize yourself with various strategies. Subsequently, parameters can be saved in JSON format. In future iterations, these saved configurations can be rapidly deployed through the factory, streamlining particle creation and modification.</p>"},{"location":"Examples/Particle_Phase/Notebooks/Particle_Representation_Tutorial/#limited-representation-builder","title":"Limited Representation Builder\u00b6","text":"<p>The last representation, is a modification of the radii builder, where we can specify a lognomal distribution parameters. This is useful when we want a to start a simulation quick and are not trying to explicitly reproduce a specific system.</p>"},{"location":"Examples/Particle_Phase/Notebooks/Particle_Representation_Tutorial/#summary","title":"Summary\u00b6","text":"<p>In this notebook, we have discussed the importance of particle representation in simulations and analyses. We have demonstrated how to create a particle distribution using specific particle properties such as radius, density, and concentration. We have also shown how to use a builder pattern to construct an instance of a Particle class, allowing for flexible configuration of particle characteristics and behaviors. Finally, we have discussed the factory pattern and how it can be used to construct speciated particles characterized by varied properties.</p>"},{"location":"Examples/Particle_Phase/Notebooks/Particle_Surface_Tutorial/","title":"Particle Surface Tutorial","text":"In\u00a0[\u00a0]: Copied! <pre># In Colab uncomment the following command to install particula:\n#!pip install particula[extra] --quiet\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nimport particula as par\n</pre> # In Colab uncomment the following command to install particula: #!pip install particula[extra] --quiet import numpy as np import matplotlib.pyplot as plt  import particula as par In\u00a0[14]: Copied! <pre>glycerol_molar_mass = 0.092093  # kg/mol\nglycerol_density = 1261  # kg/m^3\nglycerol_surface_tension = 0.063  # N/m\n\n# Create a surface strategy\nglycerol_surface_strategy = par.particles.SurfaceStrategyMolar(\n    glycerol_molar_mass, glycerol_density, glycerol_surface_tension\n)\n\nglycerol_kelvin_radius = glycerol_surface_strategy.kelvin_radius(\n    molar_mass=glycerol_molar_mass,\n    mass_concentration=0.1,  # not this doesn't not matter for a single species mixture\n    temperature=300,\n)\n\nprint(f\"kelvin radius of glycerol {glycerol_kelvin_radius} m\")\n</pre> glycerol_molar_mass = 0.092093  # kg/mol glycerol_density = 1261  # kg/m^3 glycerol_surface_tension = 0.063  # N/m  # Create a surface strategy glycerol_surface_strategy = par.particles.SurfaceStrategyMolar(     glycerol_molar_mass, glycerol_density, glycerol_surface_tension )  glycerol_kelvin_radius = glycerol_surface_strategy.kelvin_radius(     molar_mass=glycerol_molar_mass,     mass_concentration=0.1,  # not this doesn't not matter for a single species mixture     temperature=300, )  print(f\"kelvin radius of glycerol {glycerol_kelvin_radius} m\") <pre>kelvin radius of glycerol 5.392780089118282e-09 m\n</pre> In\u00a0[15]: Copied! <pre>radii = np.logspace(-10, -6, 100)\n\nglycerol_kevlin_term = glycerol_surface_strategy.kelvin_term(\n    radius=radii,\n    molar_mass=glycerol_molar_mass,\n    mass_concentration=0.1,\n    temperature=300,\n)\n\nfig, ax = plt.subplots(figsize=(8, 6))\nax.plot(radii, glycerol_kevlin_term)\nax.plot(\n    [glycerol_kelvin_radius, glycerol_kelvin_radius],\n    [min(glycerol_kevlin_term), max(glycerol_kevlin_term)],\n    color=\"red\",\n    linestyle=\"--\",\n)\nax.set_yscale(\"log\")\nax.set_xscale(\"log\")\nax.set_title(\"Kelvin term of glycerol\")\nax.set_xlabel(\"radius (m)\")\nax.set_ylabel(\"Kelvin term\")\nax.legend([\"Kelvin term\", \"Kelvin radius\"])\nplt.show()\n</pre> radii = np.logspace(-10, -6, 100)  glycerol_kevlin_term = glycerol_surface_strategy.kelvin_term(     radius=radii,     molar_mass=glycerol_molar_mass,     mass_concentration=0.1,     temperature=300, )  fig, ax = plt.subplots(figsize=(8, 6)) ax.plot(radii, glycerol_kevlin_term) ax.plot(     [glycerol_kelvin_radius, glycerol_kelvin_radius],     [min(glycerol_kevlin_term), max(glycerol_kevlin_term)],     color=\"red\",     linestyle=\"--\", ) ax.set_yscale(\"log\") ax.set_xscale(\"log\") ax.set_title(\"Kelvin term of glycerol\") ax.set_xlabel(\"radius (m)\") ax.set_ylabel(\"Kelvin term\") ax.legend([\"Kelvin term\", \"Kelvin radius\"]) plt.show() In\u00a0[16]: Copied! <pre>squalane_surface = (\n    par.particles.SurfaceStrategyMassBuilder()\n    .set_density(0.81, density_units=\"g/cm^3\")  # call with parameter name\n    .set_surface_tension(28, \"mN/m\")  # call without parameter name\n    .build()\n)\n\n# create plot\nsqualane_kelvin_radius = squalane_surface.kelvin_radius(\n    molar_mass=0.422, mass_concentration=0.1, temperature=300\n)\nsqualane_kelvin_term = squalane_surface.kelvin_term(\n    radius=radii, molar_mass=0.422, mass_concentration=0.1, temperature=300\n)\n\nfig, ax = plt.subplots(figsize=(8, 6))\nax.plot(radii, squalane_kelvin_term)\nax.plot(\n    [squalane_kelvin_radius, squalane_kelvin_radius],\n    [min(squalane_kelvin_term), max(squalane_kelvin_term)],\n    color=\"red\",\n    linestyle=\"--\",\n)\nax.set_yscale(\"log\")\nax.set_xscale(\"log\")\nax.set_title(\"Kelvin term of squalane\")\nax.set_xlabel(\"radius (m)\")\nax.set_ylabel(\"Kelvin term\")\nax.legend([\"Kelvin term\", \"Kelvin radius\"])\nplt.show()\n</pre> squalane_surface = (     par.particles.SurfaceStrategyMassBuilder()     .set_density(0.81, density_units=\"g/cm^3\")  # call with parameter name     .set_surface_tension(28, \"mN/m\")  # call without parameter name     .build() )  # create plot squalane_kelvin_radius = squalane_surface.kelvin_radius(     molar_mass=0.422, mass_concentration=0.1, temperature=300 ) squalane_kelvin_term = squalane_surface.kelvin_term(     radius=radii, molar_mass=0.422, mass_concentration=0.1, temperature=300 )  fig, ax = plt.subplots(figsize=(8, 6)) ax.plot(radii, squalane_kelvin_term) ax.plot(     [squalane_kelvin_radius, squalane_kelvin_radius],     [min(squalane_kelvin_term), max(squalane_kelvin_term)],     color=\"red\",     linestyle=\"--\", ) ax.set_yscale(\"log\") ax.set_xscale(\"log\") ax.set_title(\"Kelvin term of squalane\") ax.set_xlabel(\"radius (m)\") ax.set_ylabel(\"Kelvin term\") ax.legend([\"Kelvin term\", \"Kelvin radius\"]) plt.show() In\u00a0[17]: Copied! <pre>parameters = {  # glycerol, squalane\n    \"density\": np.array([1261, 810]),  # kg/m^3\n    \"density_units\": \"kg/m^3\",\n    \"surface_tension\": np.array([0.063, 0.028]),  # N/m\n    \"surface_tension_units\": \"N/m\",\n}\n\nmixture_surface = par.particles.SurfaceFactory().get_strategy(\n    strategy_type=\"volume\",\n    parameters=parameters,\n)\n\nmixture_kelvin_radius = mixture_surface.kelvin_radius(\n    molar_mass=0.092093,\n    mass_concentration=np.array([0.1, 0.1]),\n    temperature=300,\n)\nprint(f\"kelvin radius of mixture {mixture_kelvin_radius} m\")\n\nmixture_kelvin_term = mixture_surface.kelvin_term(\n    radius=radii,\n    molar_mass=0.092093,\n    mass_concentration=np.array([0.1, 0.1]),\n    temperature=300,\n)\n\nfig, ax = plt.subplots(figsize=(8, 6))\nax.plot(radii, mixture_kelvin_term, label=\"Mixure\")\nax.plot(\n    [mixture_kelvin_radius, mixture_kelvin_radius],\n    [min(mixture_kelvin_term), max(mixture_kelvin_term)],\n    color=\"red\",\n    linestyle=\"--\",\n)\nax.plot(radii, glycerol_kevlin_term, label=\"Glycerol\")\nax.plot(\n    [glycerol_kelvin_radius, glycerol_kelvin_radius],\n    [min(glycerol_kevlin_term), max(glycerol_kevlin_term)],\n    color=\"red\",\n    linestyle=\"--\",\n)\nax.plot(radii, squalane_kelvin_term, label=\"Squalane\")\nax.plot(\n    [squalane_kelvin_radius, squalane_kelvin_radius],\n    [min(squalane_kelvin_term), max(squalane_kelvin_term)],\n    color=\"red\",\n    linestyle=\"--\",\n)\nax.set_yscale(\"log\")\nax.set_xscale(\"log\")\nax.set_title(\"Kelvin term of mixture\")\nax.set_xlabel(\"radius (m)\")\nax.set_ylabel(\"Kelvin term\")\nax.legend()\nplt.show()\n</pre> parameters = {  # glycerol, squalane     \"density\": np.array([1261, 810]),  # kg/m^3     \"density_units\": \"kg/m^3\",     \"surface_tension\": np.array([0.063, 0.028]),  # N/m     \"surface_tension_units\": \"N/m\", }  mixture_surface = par.particles.SurfaceFactory().get_strategy(     strategy_type=\"volume\",     parameters=parameters, )  mixture_kelvin_radius = mixture_surface.kelvin_radius(     molar_mass=0.092093,     mass_concentration=np.array([0.1, 0.1]),     temperature=300, ) print(f\"kelvin radius of mixture {mixture_kelvin_radius} m\")  mixture_kelvin_term = mixture_surface.kelvin_term(     radius=radii,     molar_mass=0.092093,     mass_concentration=np.array([0.1, 0.1]),     temperature=300, )  fig, ax = plt.subplots(figsize=(8, 6)) ax.plot(radii, mixture_kelvin_term, label=\"Mixure\") ax.plot(     [mixture_kelvin_radius, mixture_kelvin_radius],     [min(mixture_kelvin_term), max(mixture_kelvin_term)],     color=\"red\",     linestyle=\"--\", ) ax.plot(radii, glycerol_kevlin_term, label=\"Glycerol\") ax.plot(     [glycerol_kelvin_radius, glycerol_kelvin_radius],     [min(glycerol_kevlin_term), max(glycerol_kevlin_term)],     color=\"red\",     linestyle=\"--\", ) ax.plot(radii, squalane_kelvin_term, label=\"Squalane\") ax.plot(     [squalane_kelvin_radius, squalane_kelvin_radius],     [min(squalane_kelvin_term), max(squalane_kelvin_term)],     color=\"red\",     linestyle=\"--\", ) ax.set_yscale(\"log\") ax.set_xscale(\"log\") ax.set_title(\"Kelvin term of mixture\") ax.set_xlabel(\"radius (m)\") ax.set_ylabel(\"Kelvin term\") ax.legend() plt.show() <pre>kelvin radius of mixture 3.1208511801897936e-09 m\n</pre>"},{"location":"Examples/Particle_Phase/Notebooks/Particle_Surface_Tutorial/#particle-surface-tutorial","title":"Particle Surface Tutorial\u00b6","text":"<p>Understanding how particle surfaces are represented is crucial in the study of condensation processes involving water and organic molecules. This is primarily influenced by the Kelvin curvature effect, which describes how the saturation vapor pressure of a liquid droplet varies with its size. This tutorial will introduce the fundamental approaches to modeling the particle surface in aerosol particle simulations.</p> <p>Kelvin Curvature Effect</p>"},{"location":"Examples/Particle_Phase/Notebooks/Particle_Surface_Tutorial/#strategies-for-surface-representation","title":"Strategies for Surface Representation\u00b6","text":"<p>To accurately simulate particle surfaces, one must adhere to the <code>SurfaceStrategy</code> abstract base class. This class outlines common methods required for all surface representation strategies:</p> <ul> <li><code>kelvin_radius</code>: Calculates the particle radius that corresponds to the Kelvin curvature effect.</li> <li><code>kelvin_term</code>: Computes the Kelvin term, defined as exp(kelvin_radius / particle_radius).</li> </ul> <p>Specifically, the strategies differ in how they calculate:</p> <ul> <li><code>effective_surface_tension</code>: Determines the effective surface tension of species based on their concentration.</li> <li><code>effective_density</code>: Computes the effective density of species based on their concentration.</li> </ul> <p>While each strategy may require additional parameters, defining surface tension is essential for all. The primary strategies include:</p> <ul> <li><code>SurfaceStrategyMolar</code>: Uses mole fraction weighted values to determine surface tension and density.</li> <li><code>SurfaceStrategyMass</code>: Uses mass fraction weighted values to determine surface tension and density.</li> <li><code>SurfaceStrategyVolume</code>: Uses volume fraction weighted values to determine surface tension and density.</li> </ul> <p>Each strategy is interchangeable and suitable for use in aerosol particle simulations. The choice of strategy should be guided by the available data and the level of detail required for the simulation.</p> <p>In this tutorial, we will demonstrate how to create and use these strategies, employing builders and factories to instantiate them and calculate both the Kelvin radius and term.</p>"},{"location":"Examples/Particle_Phase/Notebooks/Particle_Surface_Tutorial/#direct-strategy-creation","title":"Direct Strategy Creation\u00b6","text":"<p>The following code demonstrates how directly create and instance of a molar surface strategy and calculate the Kelvin radius and term.</p> <p>Note this approach assumes base SI units, if you want conversions on the inputs and data validation checks then use the subsequent builder and factory methods.</p>"},{"location":"Examples/Particle_Phase/Notebooks/Particle_Surface_Tutorial/#kelvin-term","title":"Kelvin term\u00b6","text":"<p>To see the Kelvin term in action, we will calculate the Kelvin term for an array of glycerol particles. The Kelvin term is a dimensionless quantity that describes the effect of the Kelvin curvature on the saturation vapor pressure of a liquid droplet. It is defined as exp(kelvin_radius / particle_radius).</p> <p>So values of the Kelvin term greater than 1 indicate that the saturation vapor pressure required to maintain the particle's size is higher than the saturation vapor pressure of the bulk liquid (flat surface). This is due to the increased in curvature of the particle surface.</p>"},{"location":"Examples/Particle_Phase/Notebooks/Particle_Surface_Tutorial/#builder-for-squalane","title":"Builder for Squalane\u00b6","text":"<p>The following code demonstrates how to use the builder to create a surface strategy for squalane particles. The builder allows for the specification of the surface tension and density of the species, as well as the concentration of the species in the particle.</p> <p>Squalane is a larger molecule with a lower surface tension than glycerol, so the Kelvin term will be lower for the same particle size.</p>"},{"location":"Examples/Particle_Phase/Notebooks/Particle_Surface_Tutorial/#factory-approach","title":"Factory Approach\u00b6","text":"<p>Next example is the creation using a factory method, which is more flexible and allows for the use of different units and conversions. The factory method also performs data validation checks to ensure the input values are within the expected range. As the factory is just a wrapper around the builder, the same parameters can/must be used.</p> <p>Here we'll create a mixture of glycerol and squalane particles, and calculate the Kelvin term for a range of particle sizes for a volume fraction of 0.5 for each species. And assume glycerol is the condensing species.</p> <p>[double check the graph output, if the mixture should be lower than the pure or not]</p>"},{"location":"Examples/Particle_Phase/Notebooks/Particle_Surface_Tutorial/#summary","title":"Summary\u00b6","text":"<p>This tutorial has demonstrated the fundamental approaches to modeling particle surfaces in aerosol particle simulations. By using the <code>SurfaceStrategy</code> abstract base class, we can create and use different strategies to calculate the Kelvin radius and term. The choice of strategy should be guided by the available data and the level of detail required for the simulation.</p> <p>The <code>SurfaceStrategyMolar</code>, <code>SurfaceStrategyMass</code>, and <code>SurfaceStrategyVolume</code> strategies provide flexibility in determining the effective surface tension and density of species based on their concentration. By using builders and factories, we can create surface strategies with the necessary parameters and perform data validation checks to ensure the input values are within the expected range.</p>"},{"location":"Examples/Particle_Phase/Notebooks/Functional/Activity_Functions/","title":"Activity Tutorial","text":"In\u00a0[\u00a0]: Copied! <pre># In Colab uncomment the following command to install particula:\n#!pip install particula[extra] --quiet\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nimport particula as par\n</pre> # In Colab uncomment the following command to install particula: #!pip install particula[extra] --quiet import numpy as np import matplotlib.pyplot as plt  import particula as par In\u00a0[10]: Copied! <pre>masses_1 = np.linspace(0, 100, 1000)\nmasses_2 = np.full_like(masses_1, 30)\nmasses_3 = np.linspace(150, 10, 1000)\n\ndensity_1 = 1000  # kg/m^3\ndensity_2 = 2000  # kg/m^3\ndensity_3 = 1500  # kg/m^3\n\nmolar_mass_1 = 18.01528e-3  # g/mol\nmolar_mass_2 = 200e-3  # g/mol\nmolar_mass_3 = 150e-3  # g/mol\n\nmass_2component = np.column_stack((masses_1, masses_2))\nmass_3component = np.column_stack((masses_1, masses_2, masses_3))\n\ndensity_2component = np.array([density_1, density_2])\ndensity_3component = np.array([density_1, density_2, density_3])\n\n# get mole fractions\nmass_fractions_2component = par.util.get_mole_fraction_from_mass(\n    mass_2component, molar_masses=np.array([molar_mass_1, molar_mass_2])\n)\nmass_fractions_3component = par.util.get_mole_fraction_from_mass(\n    mass_3component,\n    molar_masses=np.array([molar_mass_1, molar_mass_2, molar_mass_3]),\n)\n</pre> masses_1 = np.linspace(0, 100, 1000) masses_2 = np.full_like(masses_1, 30) masses_3 = np.linspace(150, 10, 1000)  density_1 = 1000  # kg/m^3 density_2 = 2000  # kg/m^3 density_3 = 1500  # kg/m^3  molar_mass_1 = 18.01528e-3  # g/mol molar_mass_2 = 200e-3  # g/mol molar_mass_3 = 150e-3  # g/mol  mass_2component = np.column_stack((masses_1, masses_2)) mass_3component = np.column_stack((masses_1, masses_2, masses_3))  density_2component = np.array([density_1, density_2]) density_3component = np.array([density_1, density_2, density_3])  # get mole fractions mass_fractions_2component = par.util.get_mole_fraction_from_mass(     mass_2component, molar_masses=np.array([molar_mass_1, molar_mass_2]) ) mass_fractions_3component = par.util.get_mole_fraction_from_mass(     mass_3component,     molar_masses=np.array([molar_mass_1, molar_mass_2, molar_mass_3]), ) In\u00a0[11]: Copied! <pre>activity_2component_molar = par.particles.get_ideal_activity_molar(\n    mass_concentration=mass_2component,\n    molar_mass=np.array([molar_mass_1, molar_mass_2]),\n)\n\n\nactivity_3component_molar = par.particles.get_ideal_activity_molar(\n    mass_concentration=mass_3component,\n    molar_mass=np.array([molar_mass_1, molar_mass_2, molar_mass_3]),\n)\n\n\n# Create the figure and axis objects\nfig, ax = plt.subplots(2, 1, figsize=(5, 8))\n\n# Plot each component in the 2-component system with separate colors\nax[0].plot(\n    mass_fractions_2component[:, 0],\n    activity_2component_molar[:, 0],\n    color=\"blue\",\n    label=\"Water (1)\",\n)\nax[0].plot(\n    mass_fractions_2component[:, 0],\n    activity_2component_molar[:, 1],\n    color=\"green\",\n    label=\"Component 2\",\n)\nax[0].set_xlabel(\"Water Mole Fraction\")\nax[0].set_ylabel(\"Activity coefficient\")\nax[0].set_title(\"Activity coefficient vs mass fraction for 2 components\")\nax[0].legend()\n\n# Plot the 3-component system without setting specific colors\nax[1].plot(\n    mass_fractions_3component[:, 0],\n    activity_3component_molar[:, 0],\n    label=\"Water (1)\",\n    color=\"blue\",\n)\nax[1].plot(\n    mass_fractions_3component[:, 0],\n    activity_3component_molar[:, 1],\n    label=\"Component 2\",\n    color=\"green\",\n)\nax[1].plot(\n    mass_fractions_3component[:, 0],\n    activity_3component_molar[:, 2],\n    label=\"Component 3\",\n    color=\"red\",\n)\nax[1].set_xlabel(\"Water Mole Fraction\")\nax[1].set_ylabel(\"Activity coefficient\")\nax[1].set_title(\"Activity coefficient vs mass fraction for 3 components\")\nax[1].legend()\n\n# Display the plot\nplt.tight_layout()\nplt.show()\n</pre> activity_2component_molar = par.particles.get_ideal_activity_molar(     mass_concentration=mass_2component,     molar_mass=np.array([molar_mass_1, molar_mass_2]), )   activity_3component_molar = par.particles.get_ideal_activity_molar(     mass_concentration=mass_3component,     molar_mass=np.array([molar_mass_1, molar_mass_2, molar_mass_3]), )   # Create the figure and axis objects fig, ax = plt.subplots(2, 1, figsize=(5, 8))  # Plot each component in the 2-component system with separate colors ax[0].plot(     mass_fractions_2component[:, 0],     activity_2component_molar[:, 0],     color=\"blue\",     label=\"Water (1)\", ) ax[0].plot(     mass_fractions_2component[:, 0],     activity_2component_molar[:, 1],     color=\"green\",     label=\"Component 2\", ) ax[0].set_xlabel(\"Water Mole Fraction\") ax[0].set_ylabel(\"Activity coefficient\") ax[0].set_title(\"Activity coefficient vs mass fraction for 2 components\") ax[0].legend()  # Plot the 3-component system without setting specific colors ax[1].plot(     mass_fractions_3component[:, 0],     activity_3component_molar[:, 0],     label=\"Water (1)\",     color=\"blue\", ) ax[1].plot(     mass_fractions_3component[:, 0],     activity_3component_molar[:, 1],     label=\"Component 2\",     color=\"green\", ) ax[1].plot(     mass_fractions_3component[:, 0],     activity_3component_molar[:, 2],     label=\"Component 3\",     color=\"red\", ) ax[1].set_xlabel(\"Water Mole Fraction\") ax[1].set_ylabel(\"Activity coefficient\") ax[1].set_title(\"Activity coefficient vs mass fraction for 3 components\") ax[1].legend()  # Display the plot plt.tight_layout() plt.show() In\u00a0[12]: Copied! <pre># Volume activity coefficient\nactivity_2component_volume = par.particles.get_ideal_activity_volume(\n    mass_concentration=mass_2component,\n    density=density_2component,\n)\n\nactivity_3component_volume = par.particles.get_ideal_activity_volume(\n    mass_concentration=mass_3component,\n    density=density_3component,\n)\n\n# Create the figure and axis objects\nfig, ax = plt.subplots(2, 1, figsize=(5, 8))\n\n# Plot each component in the 2-component system with separate colors\nax[0].plot(\n    mass_fractions_2component[:, 0],\n    activity_2component_volume[:, 0],\n    color=\"blue\",\n    label=\"Water (1)\",\n)\nax[0].plot(\n    mass_fractions_2component[:, 0],\n    activity_2component_volume[:, 1],\n    color=\"green\",\n    label=\"Component 2\",\n)\nax[0].set_xlabel(\"Water Mole Fraction\")\nax[0].set_ylabel(\"Activity coefficient\")\nax[0].set_title(\"Activity coefficient vs mass fraction for 2 components\")\nax[0].legend()\n\n# Plot the 3-component system without setting specific colors\nax[1].plot(\n    mass_fractions_3component[:, 0],\n    activity_3component_volume[:, 0],\n    label=\"Water (1)\",\n    color=\"blue\",\n)\nax[1].plot(\n    mass_fractions_3component[:, 0],\n    activity_3component_volume[:, 1],\n    label=\"Component 2\",\n    color=\"green\",\n)\nax[1].plot(\n    mass_fractions_3component[:, 0],\n    activity_3component_volume[:, 2],\n    label=\"Component 3\",\n    color=\"red\",\n)\nax[1].set_xlabel(\"Water Mole Fraction\")\nax[1].set_ylabel(\"Activity coefficient\")\nax[1].set_title(\"Activity coefficient vs mass fraction for 3 components\")\nax[1].legend()\n\n# Display the plot\nplt.tight_layout()\nplt.show()\n</pre> # Volume activity coefficient activity_2component_volume = par.particles.get_ideal_activity_volume(     mass_concentration=mass_2component,     density=density_2component, )  activity_3component_volume = par.particles.get_ideal_activity_volume(     mass_concentration=mass_3component,     density=density_3component, )  # Create the figure and axis objects fig, ax = plt.subplots(2, 1, figsize=(5, 8))  # Plot each component in the 2-component system with separate colors ax[0].plot(     mass_fractions_2component[:, 0],     activity_2component_volume[:, 0],     color=\"blue\",     label=\"Water (1)\", ) ax[0].plot(     mass_fractions_2component[:, 0],     activity_2component_volume[:, 1],     color=\"green\",     label=\"Component 2\", ) ax[0].set_xlabel(\"Water Mole Fraction\") ax[0].set_ylabel(\"Activity coefficient\") ax[0].set_title(\"Activity coefficient vs mass fraction for 2 components\") ax[0].legend()  # Plot the 3-component system without setting specific colors ax[1].plot(     mass_fractions_3component[:, 0],     activity_3component_volume[:, 0],     label=\"Water (1)\",     color=\"blue\", ) ax[1].plot(     mass_fractions_3component[:, 0],     activity_3component_volume[:, 1],     label=\"Component 2\",     color=\"green\", ) ax[1].plot(     mass_fractions_3component[:, 0],     activity_3component_volume[:, 2],     label=\"Component 3\",     color=\"red\", ) ax[1].set_xlabel(\"Water Mole Fraction\") ax[1].set_ylabel(\"Activity coefficient\") ax[1].set_title(\"Activity coefficient vs mass fraction for 3 components\") ax[1].legend()  # Display the plot plt.tight_layout() plt.show() In\u00a0[14]: Copied! <pre># Mass activity coefficient\nactivity_2component_mass = par.particles.get_ideal_activity_mass(\n    mass_concentration=mass_2component,\n)\nactivity_3component_mass = par.particles.get_ideal_activity_mass(\n    mass_concentration=mass_3component,\n)\n\n# Create the figure and axis objects\nfig, ax = plt.subplots(2, 1, figsize=(5, 8))\n\n# Plot each component in the 2-component system with separate colors\nax[0].plot(\n    mass_fractions_2component[:, 0],\n    activity_2component_mass[:, 0],\n    color=\"blue\",\n    label=\"Water (1)\",\n    linewidth=4,\n    linestyle=\"--\",\n)\nax[0].plot(\n    mass_fractions_2component[:, 0],\n    activity_2component_mass[:, 1],\n    color=\"green\",\n    label=\"Component 2\",\n)\nax[0].set_xlabel(\"Water Mole Fraction\")\nax[0].set_ylabel(\"Activity coefficient\")\nax[0].set_title(\"Activity coefficient vs mass fraction for 2 components\")\nax[0].legend()\n\n# Plot the 3-component system without setting specific colors\nax[1].plot(\n    mass_fractions_3component[:, 0],\n    activity_3component_mass[:, 0],\n    label=\"Water (1)\",\n    color=\"blue\",\n    linewidth=4,\n    linestyle=\"--\",\n)\nax[1].plot(\n    mass_fractions_3component[:, 0],\n    activity_3component_mass[:, 1],\n    label=\"Component 2\",\n    color=\"green\",\n    linewidth=3,\n)\nax[1].plot(\n    mass_fractions_3component[:, 0],\n    activity_3component_mass[:, 2],\n    label=\"Component 3\",\n    color=\"red\",\n)\nax[1].set_xlabel(\"Water Mole Fraction\")\nax[1].set_ylabel(\"Activity coefficient\")\nax[1].set_title(\"Activity coefficient vs mass fraction for 3 components\")\nax[1].legend()\n\n# Display the plot\nplt.tight_layout()\nplt.show()\n</pre> # Mass activity coefficient activity_2component_mass = par.particles.get_ideal_activity_mass(     mass_concentration=mass_2component, ) activity_3component_mass = par.particles.get_ideal_activity_mass(     mass_concentration=mass_3component, )  # Create the figure and axis objects fig, ax = plt.subplots(2, 1, figsize=(5, 8))  # Plot each component in the 2-component system with separate colors ax[0].plot(     mass_fractions_2component[:, 0],     activity_2component_mass[:, 0],     color=\"blue\",     label=\"Water (1)\",     linewidth=4,     linestyle=\"--\", ) ax[0].plot(     mass_fractions_2component[:, 0],     activity_2component_mass[:, 1],     color=\"green\",     label=\"Component 2\", ) ax[0].set_xlabel(\"Water Mole Fraction\") ax[0].set_ylabel(\"Activity coefficient\") ax[0].set_title(\"Activity coefficient vs mass fraction for 2 components\") ax[0].legend()  # Plot the 3-component system without setting specific colors ax[1].plot(     mass_fractions_3component[:, 0],     activity_3component_mass[:, 0],     label=\"Water (1)\",     color=\"blue\",     linewidth=4,     linestyle=\"--\", ) ax[1].plot(     mass_fractions_3component[:, 0],     activity_3component_mass[:, 1],     label=\"Component 2\",     color=\"green\",     linewidth=3, ) ax[1].plot(     mass_fractions_3component[:, 0],     activity_3component_mass[:, 2],     label=\"Component 3\",     color=\"red\", ) ax[1].set_xlabel(\"Water Mole Fraction\") ax[1].set_ylabel(\"Activity coefficient\") ax[1].set_title(\"Activity coefficient vs mass fraction for 3 components\") ax[1].legend()  # Display the plot plt.tight_layout() plt.show() In\u00a0[15]: Copied! <pre># kappa activity coefficient\n\nkappa_1 = 0.0  # kappa of water\nkappa_2 = 0.6  # kappa of component 2\nkappa_3 = 1.2  # kappa of component 3\n\nwater_index = 0\n\nactivity_2component_kappa = par.particles.get_kappa_activity(\n    mass_concentration=mass_2component,\n    kappa=np.array([kappa_1, kappa_2]),\n    density=density_2component,\n    molar_mass=np.array([molar_mass_1, molar_mass_2]),\n    water_index=water_index,\n)\nactivity_3component_kappa = par.particles.get_kappa_activity(\n    mass_concentration=mass_3component,\n    kappa=np.array([kappa_1, kappa_2, kappa_3]),\n    density=density_3component,\n    molar_mass=np.array([molar_mass_1, molar_mass_2, molar_mass_3]),\n    water_index=water_index,\n)\n\n# Create the figure and axis objects\nfig, ax = plt.subplots(2, 1, figsize=(5, 8))\n\n# Plot each component in the 2-component system with separate colors\nax[0].plot(\n    mass_fractions_2component[:, 0],\n    activity_2component_kappa[:, 0],\n    color=\"blue\",\n    label=\"Water (1)\",\n)\nax[0].plot(\n    mass_fractions_2component[:, 0],\n    activity_2component_kappa[:, 1],\n    color=\"green\",\n    label=\"Component 2\",\n)\nax[0].set_xlabel(\"Water Mole Fraction\")\nax[0].set_ylabel(\"Activity coefficient\")\nax[0].set_title(\"Kappa Activity coefficient vs mass fraction for 2 components\")\nax[0].legend()\n\n# Plot the 3-component system without setting specific colors\nax[1].plot(\n    mass_fractions_3component[:, 0],\n    activity_3component_kappa[:, 0],\n    label=\"Water (1)\",\n    color=\"blue\",\n)\nax[1].plot(\n    mass_fractions_3component[:, 0],\n    activity_3component_kappa[:, 1],\n    label=\"Component 2\",\n    color=\"green\",\n)\nax[1].plot(\n    mass_fractions_3component[:, 0],\n    activity_3component_kappa[:, 2],\n    label=\"Component 3\",\n    color=\"red\",\n)\nax[1].set_xlabel(\"Water Mole Fraction\")\nax[1].set_ylabel(\"Activity coefficient\")\nax[1].set_title(\"Kappa Activity coefficient vs mass fraction for 3 components\")\nax[1].legend()\n\n# Display the plot\nplt.tight_layout()\nplt.show()\n</pre> # kappa activity coefficient  kappa_1 = 0.0  # kappa of water kappa_2 = 0.6  # kappa of component 2 kappa_3 = 1.2  # kappa of component 3  water_index = 0  activity_2component_kappa = par.particles.get_kappa_activity(     mass_concentration=mass_2component,     kappa=np.array([kappa_1, kappa_2]),     density=density_2component,     molar_mass=np.array([molar_mass_1, molar_mass_2]),     water_index=water_index, ) activity_3component_kappa = par.particles.get_kappa_activity(     mass_concentration=mass_3component,     kappa=np.array([kappa_1, kappa_2, kappa_3]),     density=density_3component,     molar_mass=np.array([molar_mass_1, molar_mass_2, molar_mass_3]),     water_index=water_index, )  # Create the figure and axis objects fig, ax = plt.subplots(2, 1, figsize=(5, 8))  # Plot each component in the 2-component system with separate colors ax[0].plot(     mass_fractions_2component[:, 0],     activity_2component_kappa[:, 0],     color=\"blue\",     label=\"Water (1)\", ) ax[0].plot(     mass_fractions_2component[:, 0],     activity_2component_kappa[:, 1],     color=\"green\",     label=\"Component 2\", ) ax[0].set_xlabel(\"Water Mole Fraction\") ax[0].set_ylabel(\"Activity coefficient\") ax[0].set_title(\"Kappa Activity coefficient vs mass fraction for 2 components\") ax[0].legend()  # Plot the 3-component system without setting specific colors ax[1].plot(     mass_fractions_3component[:, 0],     activity_3component_kappa[:, 0],     label=\"Water (1)\",     color=\"blue\", ) ax[1].plot(     mass_fractions_3component[:, 0],     activity_3component_kappa[:, 1],     label=\"Component 2\",     color=\"green\", ) ax[1].plot(     mass_fractions_3component[:, 0],     activity_3component_kappa[:, 2],     label=\"Component 3\",     color=\"red\", ) ax[1].set_xlabel(\"Water Mole Fraction\") ax[1].set_ylabel(\"Activity coefficient\") ax[1].set_title(\"Kappa Activity coefficient vs mass fraction for 3 components\") ax[1].legend()  # Display the plot plt.tight_layout() plt.show()"},{"location":"Examples/Particle_Phase/Notebooks/Functional/Activity_Functions/#activity-tutorial","title":"Activity Tutorial\u00b6","text":"<p>This Jupyter notebook is designed to deepen your understanding of mixing behaviors in solutions, focusing on both theoretical models and practical applications. We will explore ideal and non-ideal mixing rules, differentiate between mass-based and molar-based approaches, and introduce the kappa value parameterization for predicting water activity.</p>"},{"location":"Examples/Particle_Phase/Notebooks/Functional/Activity_Functions/#introduction-to-mixing-rules","title":"Introduction to Mixing Rules\u00b6","text":"<p>Mixing rules are essential for predicting the properties of solutions, including their thermodynamic behavior and phase equilibria. In this notebook, we will:</p> <ul> <li>Define and compare different mixing rules: Understand how various rules apply to different types of solutions.</li> <li>Mass-Based vs. Molar-Based Mixing: Discuss the implications of choosing mass-based or molar-based calculations for different applications.</li> <li>Kappa Value based Activity: Learn about the kappa value parameterization and its role in modeling water activity in non-ideal solutions.</li> </ul>"},{"location":"Examples/Particle_Phase/Notebooks/Functional/Activity_Functions/#structure-of-the-notebook","title":"Structure of the Notebook\u00b6","text":"<ol> <li><p>Mass-Based vs. Molar-Based vs. Volueme-Based</p> <ul> <li>Definitions and when to use each method</li> <li>Examples and comparative analysis</li> </ul> </li> <li><p>Kappa Value Parameterization</p> <ul> <li>Theory behind kappa values</li> <li>Practical exercises on calculating water activity</li> </ul> </li> </ol>"},{"location":"Examples/Particle_Phase/Notebooks/Functional/Activity_Functions/#mass-arrays","title":"Mass Arrays\u00b6","text":"<p>First we'll need to create some mass concentration arrays to use in our examples. We will use a 2-component and 3-component system for demonstration purposes.</p> <p>In each the first component is water and the second component is a solute. The mass fractions of the solute will be varied to demonstrate the different mixing rules.</p>"},{"location":"Examples/Particle_Phase/Notebooks/Functional/Activity_Functions/#molar-based-mixing","title":"Molar-Based Mixing\u00b6","text":"<p>The ideal in this context refers to all the activity coefficients being equal to 1. This is the simplest case and is often used as a reference point for more complex models. In this case, then we are just mixing based on molar fractions.</p>"},{"location":"Examples/Particle_Phase/Notebooks/Functional/Activity_Functions/#volume-based-mixing","title":"Volume-Based Mixing\u00b6","text":"<p>In this next example, we will use volume-based mixing. This is common for use with liquid mixtures, where the volume of the solution is the sum of the volumes of the components. This is a simple way to mix solutions, but it is not always accurate.</p>"},{"location":"Examples/Particle_Phase/Notebooks/Functional/Activity_Functions/#mass-based-mixing","title":"Mass-Based Mixing\u00b6","text":"<p>In this example, we will use mass-based mixing. This is the simplest, as our mass fractions are directly proportional to the mass of the components.</p>"},{"location":"Examples/Particle_Phase/Notebooks/Functional/Activity_Functions/#kappa-activity","title":"Kappa-Activity\u00b6","text":"<p>The kappa value parameterization is a simple way to model non-ideal water interactions in solutions.</p>"},{"location":"Examples/Particle_Phase/Notebooks/Functional/Activity_Functions/#summary","title":"Summary\u00b6","text":"<p>By the end of this notebook, you should have a better understanding of mixing rules, mass-based vs. molar-based calculations, and the kappa value parameterization for predicting water activity in non-ideal solutions. You will also have learned how to apply these concepts to practical examples and visualize the results using plots.</p> <p>You saw how different mixing rules can be used to predict the properties of solutions and how they can affect the accuracy of the predictions. You also learned about the kappa value parameterization and how it can be used to model water activity in non-ideal solutions. These concepts are essential for condensation and phase equilibrium calculations when aerosol particles are present in the atmosphere.</p>"},{"location":"Examples/Setup_Particula/","title":"Setup\u202fParticula","text":"<p>Welcome!  Choose the route that matches your comfort level:</p> <ul> <li>I already use Python every day \u2192 Quick\u2011start for Experienced Users</li> <li>I\u2019m new to Python \u2192 Guide for New Users</li> <li>I want to contribute to Particula \u2192 Contributing to Particula</li> </ul>"},{"location":"Examples/Setup_Particula/#quickstart-for-experienced-users","title":"Quick\u2011start for Experienced Users","text":""},{"location":"Examples/Setup_Particula/#create-isolated-environment","title":"Create Isolated Environment","text":"<p>See the conda, pip, or uv guides for exact commands.</p>"},{"location":"Examples/Setup_Particula/#install-particula","title":"Install Particula","text":"<p>If your Python Environment is already set up, install Particula directly using one of the following methods:</p>"},{"location":"Examples/Setup_Particula/#uv-installation","title":"uv Installation","text":"<p>uv is a fast rust-based Python package manager.</p> <pre><code>uv pip install particula                   # uv \u2248 much faster pip drop\u2011in \n</code></pre> <p>with optional extras: <pre><code>uv pip install \"particula[extra]\"\n</code></pre></p>"},{"location":"Examples/Setup_Particula/#pypi-installation","title":"PyPI Installation","text":"<p>pip is Python\u2019s default package manager and installs packages from the Python Package Index (PyPI).</p> <pre><code>pip install particula                   # PyPI\n</code></pre> <p>with optional extras: <pre><code>pip install \"particula[extra]\"\n</code></pre></p>"},{"location":"Examples/Setup_Particula/#conda-installation","title":"Conda Installation","text":"<p>conda is a cross\u2011platform environment &amp; package manager; Particula is distributed via the community\u2011maintained conda\u2011forge channel.</p> <pre><code>conda install -c conda-forge particula\n</code></pre> <p>Optional extras: <pre><code>conda install -c conda-forge particula matplotlib pandas tqdm pint \n</code></pre></p>"},{"location":"Examples/Setup_Particula/Details/Contributor_Setup/","title":"Contributor Setup","text":""},{"location":"Examples/Setup_Particula/Details/Contributor_Setup/#developer-setup-stepbystep","title":"Developer\u00a0Setup\u00a0Step\u2011by\u2011Step","text":"<p>This guide is a ground\u2011up walkthrough for first\u2011time contributors. You will fork Particula on GitHub (or GitHub\u00a0Desktop), clone it locally, create a private Python environment, install the package in editable mode, and learn the branch\u00a0\u2192\u00a0code\u00a0\u2192\u00a0commit\u00a0\u2192\u00a0PR cycle.</p> <p>Interested in contributing to the Particula project? This section explains how to set up a development environment and the workflow for contributing changes. We assume you have a GitHub account and Git installed (see the Beginner Setup if not). Following these steps will allow you to run the latest development version of Particula and prepare your contributions for a pull request.</p>"},{"location":"Examples/Setup_Particula/Details/Contributor_Setup/#fork-the-repository-on-github","title":"Fork the repository on GitHub","text":"<p>First, fork the Particula repository to your own GitHub account. Forking creates your personal copy of the project:</p> <ul> <li>Visit the Particula GitHub repo: https://github.com/uncscode/particula.  </li> <li>Click the \u201cFork\u201d button in the top-right corner of the page.  </li> <li>GitHub will create a fork under your account (e.g., <code>github.com/&lt;your-username&gt;/particula</code>).</li> </ul> <p>(If you\u2019re new to forking, see GitHub\u2019s guide on how to fork a repository for more details.)</p>"},{"location":"Examples/Setup_Particula/Details/Contributor_Setup/#get-the-code-on-your-computer","title":"Get the code on your computer","text":"<p>Choose one of the two methods below.</p> <p>A.\u00a0Git (command\u2011line) 1.\u00a0Open a terminal and move to the folder where you keep projects. 2.\u00a0Clone your fork (replace <code>&lt;your-username&gt;</code>): <pre><code>git clone https://github.com/&lt;your-username&gt;/particula.git\n</code></pre> 3.\u00a0Change into the project directory: <pre><code>cd particula\n</code></pre></p> <p>B.\u00a0GitHub\u00a0Desktop (GUI) 1.\u00a0Install GitHub\u00a0Desktop from https://desktop.github.com/. 2.\u00a0File\u00a0\u2192\u00a0Clone\u00a0repository\u2026\u00a0\u2192\u00a0URL tab \u2192 paste <code>https://github.com/&lt;your-username&gt;/particula.git</code>. 3.\u00a0Click Clone; GitHub\u00a0Desktop puts the files on disk and lets you open the    folder in your code editor.</p> <p>Either path leaves you with a <code>particula/</code> folder containing the source code.</p>"},{"location":"Examples/Setup_Particula/Details/Contributor_Setup/#set-up-a-development-environment-venv","title":"Set Up a Development Environment (<code>.venv</code>)","text":"<p>Create an isolated Python environment so development dependencies stay separate from other projects. We recommend the lightning\u2011fast uv tool\u2014see the\u00a0uv setup guide for details.</p> <ul> <li>Using uv: You can create and activate the env in one step: <pre><code>uv venv .venv      # creates &amp; auto\u2011activates .venv for uv commands\n</code></pre>    This will create <code>.venv</code> and automatically make it active for subsequent <code>uv</code> commands.</li> <li>Install Editable: with virtual environment active, install Particula in development mode with the required dev dependencies:    <pre><code>uv pip install -e \".[dev,extra]\"\n</code></pre></li> </ul> <p>The <code>pip install -e \".[dev,extra]\"</code> command tells pip to install the package in editable mode (<code>-e</code>) from the current directory (<code>.</code>) including the <code>[dev,extra]</code> optional dependencies (which include development and extra tools). This will pull in things like testing frameworks, linters, etc., as defined by Particula\u2019s <code>pyproject.toml</code>. If using uv, run <code>uv pip install -e \".[dev,extra]\"</code> equivalently.</p> <p>Tip: The <code>.[dev,extra]</code> syntax installs all standard and extra dependencies needed for development (such as documentation or additional features). You can inspect <code>pyproject.toml</code> for the exact extras defined.</p>"},{"location":"Examples/Setup_Particula/Details/Contributor_Setup/#development-workflow-branch-code-commit-pr","title":"Development Workflow: Branch, Code, Commit, PR","text":"<p>You are now ready to create a feature branch, write code, commit, push, and open a pull request.</p>"},{"location":"Examples/Setup_Particula/Details/New_to_Python/","title":"New to Python?","text":"<p>This guide walks you from no Python on your machine to a working Particula installation.  You will  </p> <ol> <li>pick a code editor  </li> <li>pick a python package manager,  </li> <li>create / activate an isolated environment,  </li> <li>install Particula, and  </li> <li>explore the documentation.</li> </ol>"},{"location":"Examples/Setup_Particula/Details/New_to_Python/#1-learn-a-few-python-basics","title":"1\u00a0\u00b7\u00a0Learn a few Python basics\u00a0\ud83d\udcda","text":"<p>New to programming?  Spend an evening with the free course \u201cPython\u00a0for\u00a0Everybody.\u201d Videos + quizzes + e\u2011textbook: https://www.py4e.com</p>"},{"location":"Examples/Setup_Particula/Details/New_to_Python/#2-install-the-essential-tools","title":"2\u00a0\u00b7\u00a0Install the essential tools","text":"<p>Choose one code editor.  You can always try others later, but this is a good starting point. The table shows the most common choices:</p> Tool Why you need it Where to get it Visual\u00a0Studio\u00a0Code Full\u2011featured editor with great Python support Download VS\u00a0Code Spyder Scientific IDE, MATLAB\u2011like Download Spyder Google\u00a0Colab Nothing to install \u2013 runs in the browser Google\u00a0Colab"},{"location":"Examples/Setup_Particula/Details/New_to_Python/#3-install-a-package-manager","title":"3\u00a0\u00b7\u00a0Install a Package Manager","text":"<p>Pick one package manager.  Conda is used in the step\u2011by\u2011step below, but uv or pip will also work (guides linked).</p> Package Manager Why you need it Where to get it uv Rust\u2011powered, lightning\u2011fast uv installation guide pip Comes with Python pip installation guide Conda\u00a0/\u00a0Miniconda Easiest way to manage multiple Pythons Miniconda installers <p>Install Git if you plan to contribute code (optional for pure user):</p> <ul> <li>Windows/macOS: https://git-scm.com/downloads </li> <li>Linux: <code>sudo apt install git</code> or your distro\u2019s package manager</li> </ul>"},{"location":"Examples/Setup_Particula/Details/New_to_Python/#4-install-particula-in-an-isolated-environment","title":"4\u00a0\u00b7\u00a0Install Particula in an isolated environment","text":"<p>Follow their dedicated guides:</p> <ul> <li>Install with uv </li> <li>Install with pip</li> <li>Install with conda</li> </ul>"},{"location":"Examples/Setup_Particula/Details/New_to_Python/#5-next-steps","title":"5\u00a0\u00b7\u00a0Next steps","text":"<ul> <li>Ready to dive deeper?  Browse the documentation and example gallery.  </li> <li>Want to contribute code?  See the Contributor Setup and install Particula in editable <code>[dev,extra]</code> mode.  </li> </ul>"},{"location":"Examples/Setup_Particula/Details/New_to_Python/#troubleshooting","title":"Troubleshooting\u00a0\ud83d\udee0\ufe0f","text":""},{"location":"Examples/Setup_Particula/Details/New_to_Python/#common-pitfalls","title":"Common pitfalls","text":"<ul> <li> <p><code>command not found</code> for <code>python</code>, <code>conda</code>, <code>uv</code>, or <code>pip</code>   The tool is not on your system PATH.\u00a0Close/re\u2011open the terminal or follow the   installer\u2019s instructions to add it to your environment variables.  </p> </li> <li> <p><code>No module named particula</code>   You\u2019re running a Python interpreter where Particula isn\u2019t installed.   Activate the correct environment (<code>conda activate particula</code>,   <code>source .venv/bin/activate</code>, etc.) or select it inside your editor.  </p> </li> <li> <p>C compiler missing   Some optional dependencies need a compiler.  </p> </li> </ul> <p>-\u00a0Windows\u00a0\u2192 \u201cBuild Tools for Visual\u00a0Studio\u201d   -\u00a0macOS\u00a0\u2192 <code>xcode-select --install</code>   -\u00a0Linux\u00a0\u2192 <code>sudo apt install build-essential</code> (or your distro equivalent)  </p> <ul> <li>\u201cPermission denied\u201d / read\u2011only file system   Work in a directory where you have write permission,   or add <code>--user</code> when using <code>pip</code> (less reproducible),   or create the environment in your home folder.  </li> </ul>"},{"location":"Examples/Setup_Particula/Details/New_to_Python/#still-stuck-ask-a","title":"Still stuck? Ask a \ud83e\udd16","text":"<p>Copy the error message into a Large\u2011Language\u2011Model chat (e.g. OpenAI\u00a0ChatGPT, Claude, Gemini) and request an explanation plus possible fixes.</p>"},{"location":"Examples/Setup_Particula/Details/Setup_Conda/","title":"Setup via\u00a0conda","text":"<p><code>conda</code> is a cross\u2011platform environment &amp; package manager.  Using an isolated Conda environment keeps Particula\u2019s dependencies from colliding with other projects.</p>"},{"location":"Examples/Setup_Particula/Details/Setup_Conda/#1-install-miniconda-onetime","title":"1.\u00a0Install\u00a0Miniconda\u00a0(one\u2011time)","text":"<p>Download the latest Miniconda installer for your OS from https://docs.conda.io/en/latest/miniconda.html and run it (accept the defaults).  After installation, open a new terminal so the <code>conda</code> command is on your path.</p>"},{"location":"Examples/Setup_Particula/Details/Setup_Conda/#2-create-activate-an-environment","title":"2.\u00a0Create &amp; activate an environment","text":"<p>Create an environment named\u00a0<code>particula</code> with Python:</p> <pre><code>conda create -n particula python=3.12\n</code></pre> <p>Activate it:</p> <pre><code>conda activate particula\n</code></pre> <p>Your prompt now starts with\u00a0<code>(particula)</code>\u2014everything you install will stay inside this environment.</p>"},{"location":"Examples/Setup_Particula/Details/Setup_Conda/#3-add-the-condaforge-channel-recommended","title":"3.\u00a0Add the conda\u2011forge channel (recommended)","text":"<p>Particula is published on the community\u2011maintained conda\u2011forge channel:</p> <pre><code>conda config --add channels conda-forge\nconda config --set channel_priority strict\n</code></pre>"},{"location":"Examples/Setup_Particula/Details/Setup_Conda/#4-install-particula","title":"4.\u00a0Install Particula","text":"<p>Install the core package:</p> <pre><code>conda install particula\n</code></pre> <p>Need the tutorial extras (plots, progress\u2011bars, etc.)?</p> <pre><code>conda install matplotlib pandas pint tqdm\n</code></pre>"},{"location":"Examples/Setup_Particula/Details/Setup_Conda/#5-upgrade-uninstall","title":"5.\u00a0Upgrade\u00a0/\u00a0Uninstall","text":"<p>Upgrade Particula:</p> <pre><code>conda update particula\n</code></pre> <p>Uninstall Particula:</p> <pre><code>conda remove particula\n</code></pre>"},{"location":"Examples/Setup_Particula/Details/Setup_Conda/#6-developing-particula-from-source","title":"6.\u00a0Developing Particula from source","text":"<p>Working from a fork?  After activating your <code>particula</code> environment, install Particula editable + dev extras with pip (inside Conda it\u2019s safe):</p> <p>Install editable:</p> <pre><code>pip install -e \".[dev,extra]\"\n</code></pre> <p>If you want to contribute to Particula, see the Contributor Setup section for details on setting up a development environment and workflow.</p>"},{"location":"Examples/Setup_Particula/Details/Setup_PIP/","title":"Setup via\u00a0pip","text":"<p><code>pip</code> is Python\u2019s default package manager\u2014already on most systems and easy to learn.  If you have Python, you have pip!  Use it inside a virtual environment to keep Particula\u2019s dependencies isolated from other projects.</p> <p>If you need to install Python, use the miniconda distribution (which includes pip).  If you prefer to install Python separately, see the Python.org page for instructions.</p>"},{"location":"Examples/Setup_Particula/Details/Setup_PIP/#1-ensure-pip-is-uptodate","title":"1.\u00a0Ensure pip is up\u2011to\u2011date","text":"<p>Upgrade pip itself (recommended):</p> <pre><code>python -m pip install --upgrade pip\n</code></pre>"},{"location":"Examples/Setup_Particula/Details/Setup_PIP/#2-create-a-virtual-environment-recommended","title":"2.\u00a0Create a virtual environment (recommended)","text":"<p>Create an isolated environment named\u00a0<code>.venv</code>:</p> <pre><code>python -m venv .venv\n</code></pre> <p>Activate it on\u00a0Linux\u00a0/\u00a0macOS:</p> <pre><code>source .venv/bin/activate\n</code></pre> <p>Activate it on\u00a0Windows\u00a0(CMD or PowerShell):</p> <pre><code>.\\.venv\\Scripts\\activate\n</code></pre>"},{"location":"Examples/Setup_Particula/Details/Setup_PIP/#3-install-particula","title":"3.\u00a0Install Particula","text":"<p>Install the core package:</p> <pre><code>pip install particula\n</code></pre> <p>Need the tutorial extras (plots, progress\u2011bars, etc.)?  Install them with:</p> <pre><code>pip install \"particula[extra]\"\n</code></pre>"},{"location":"Examples/Setup_Particula/Details/Setup_PIP/#4-upgrade-uninstall","title":"4.\u00a0Upgrade\u00a0/\u00a0Uninstall","text":"<p>Upgrade Particula:</p> <pre><code>pip install -U particula\n</code></pre> <p>Uninstall Particula:</p> <pre><code>pip uninstall particula\n</code></pre>"},{"location":"Examples/Setup_Particula/Details/Setup_PIP/#6-developing-particula-from-source","title":"6.\u00a0Developing Particula from source","text":"<p>If you want to contribute to Particula, see the Contributor Setup section for details on setting up a development environment and workflow.</p> <p>Install Particula editable + dev extras:</p> <pre><code>pip install -e \".[dev,extra]\"\n</code></pre> <p>The package is now linked to your working copy\u2014changes you make in the repository are picked up immediately.</p>"},{"location":"Examples/Setup_Particula/Details/Setup_UV/","title":"Setup via uv","text":"<p>uv (by Astral) is a modern, Rust\u2011powered replacement for both <code>pip</code> and <code>virtualenv</code>.</p> <ul> <li>Up to 10\u00a0\u00d7 faster installs &amp; upgrades (parallel resolver + global cache)  </li> <li>One tool for creating environments and installing packages  </li> <li>Drop\u2011in syntax \u2013 just say <code>uv pip \u2026</code> where you would normally use <code>pip</code> </li> </ul> <p>If you have never used a Python package manager before, uv combines the jobs of Conda and pip.  See the official\u00a0uv documentation for all options.</p>"},{"location":"Examples/Setup_Particula/Details/Setup_UV/#1-install-uv-onetime","title":"1.\u00a0Install\u00a0uv\u00a0(one\u2011time)","text":"<p>Install via\u00a0pipx\u00a0(recommended): <pre><code>pipx install uv\n</code></pre></p> <p>If\u00a0pipx\u00a0is not available, install directly with\u00a0pip: <pre><code>python -m pip install --upgrade uv\n</code></pre></p>"},{"location":"Examples/Setup_Particula/Details/Setup_UV/#2-create-an-environment-install-particula","title":"2. Create an environment &amp; install Particula","text":"<p>In the folder or git repo you want to work in create a new virtual environment called\u00a0.venv: <pre><code>uv venv .venv\n</code></pre></p> <p>Activate it on\u00a0Linux\u00a0/\u00a0macOS: <pre><code>source .venv/bin/activate\n</code></pre></p> <p>Activate it on\u00a0Windows\u00a0(CMD or PowerShell): <pre><code>.\\.venv\\Scripts\\activate\n</code></pre></p> <p>Install Particula into the active environment: <pre><code>uv pip install particula\n</code></pre></p> <p>Need the tutorial extras (plots, progress\u2011bars, etc.)?\u00a0Install them with:</p> <pre><code>uv pip install \"particula[extra]\"\n</code></pre>"},{"location":"Examples/Setup_Particula/Details/Setup_UV/#3-upgrade-uninstall","title":"3. Upgrade\u00a0/\u00a0Uninstall","text":"<p>Upgrade Particula: <pre><code>uv pip install -U particula\n</code></pre></p> <p>Uninstall Particula: <pre><code>uv pip uninstall particula\n</code></pre></p>"},{"location":"Examples/Setup_Particula/Details/Setup_UV/#use-a-specific-python-version","title":"Use a specific Python version","text":"<p>If you want to use a specific Python version, you can specify it with the <code>--python</code> flag:</p> <pre><code>uv venv .venv --python=python3.12\n</code></pre>"},{"location":"Examples/Setup_Particula/Details/Setup_UV/#4-install-editable-with-contributing","title":"4. Install Editable with Contributing","text":"<p>If you want to contribute to Particula, see the Contributor Setup section for details on setting up a development environment and workflow.</p> <p>Once in your forked repo, create the same <code>.venv</code> as above, then you can install Particula in editable mode with the required dev dependencies:</p> <pre><code>uv pip install -e \".[dev,extra]\"\n</code></pre>"},{"location":"Examples/Simulations/","title":"Simulations","text":"<p>This directory hosts end\u2011to\u2011end aerosol simulation notebooks built with Particula. Each notebook walks you through a complete modeling workflow\u2014from setup to visualization or analysis.</p>"},{"location":"Examples/Simulations/#available-simulations","title":"Available Simulations","text":"<ul> <li> <p>Biomass Burning Cloud Interactions   End\u2011to\u2011end biomass burning aerosol\u2011cloud simulation using Particula.</p> </li> <li> <p>Organic Partitioning and Coagulation   End\u2011to\u2011end organic aerosol partitioning and coagulation simulation using Particula.</p> </li> <li> <p>Cough Droplets Partitioning   Simulates the evaporation of cough droplets in a well-mixed air environment, tracking size distribution and composition changes over time.</p> </li> <li> <p>Soot Formation in Flames   Simulates soot formation in a cooling combustion plume, tracking particle growth and chemical speciation.</p> </li> </ul>"},{"location":"Examples/Simulations/Notebooks/Biomass_Burning_Cloud_Interactions/","title":"Biomass Burning Cloud Interactions","text":"In\u00a0[\u00a0]: Copied! <pre># In Colab uncomment the following command to install particula:\n#!pip install particula[extra] --quiet\n\nimport copy\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport particula as par\nfrom tqdm import tqdm\n\n# plot settings\nTAILWIND = par.util.colors.TAILWIND\nbase_color = TAILWIND[\"gray\"][\"600\"]\nplt.rcParams.update(\n    {\n        \"text.color\": base_color,\n        \"axes.labelcolor\": base_color,\n        \"figure.figsize\": (5, 4),\n        \"font.size\": 14,\n        \"axes.edgecolor\": base_color,\n        \"axes.labelcolor\": base_color,\n        \"xtick.color\": base_color,\n        \"ytick.color\": base_color,\n        \"pdf.fonttype\": 42,\n        \"ps.fonttype\": 42,\n    }\n)\n</pre> # In Colab uncomment the following command to install particula: #!pip install particula[extra] --quiet  import copy import matplotlib.pyplot as plt import numpy as np import particula as par from tqdm import tqdm  # plot settings TAILWIND = par.util.colors.TAILWIND base_color = TAILWIND[\"gray\"][\"600\"] plt.rcParams.update(     {         \"text.color\": base_color,         \"axes.labelcolor\": base_color,         \"figure.figsize\": (5, 4),         \"font.size\": 14,         \"axes.edgecolor\": base_color,         \"axes.labelcolor\": base_color,         \"xtick.color\": base_color,         \"ytick.color\": base_color,         \"pdf.fonttype\": 42,         \"ps.fonttype\": 42,     } ) In\u00a0[11]: Copied! <pre># Reproducibility\nnp.random.seed(100)\n\n# 1a. Species properties\nmolar_mass_organics = 250e-3  # kg/mol\nmolar_mass_soot = 1000e-3  # kg/mol\nmolar_mass_water = 18.01528e-3  # kg/mol\n\ndensity_organics = 1400.0  # kg/m^3\ndensity_soot = 1800.0\ndensity_water = 1000.0\n\nkappa_organics = 0.15\nkappa_soot = 0.01\nkappa_water = 0.01\n\nnumber_of_samples = 10_000  # number of particles to sample\nsimulation_volume = 1e-6  # 1/m^3\nwater_activity = 1.02  # initial water activity\ntemperature = 298.15\n\n# Vapor pressure strategies\nvapor_organics = (\n    par.gas.ConstantVaporPressureBuilder().set_vapor_pressure(2e-12, \"Pa\").build()\n)\nvapor_soot = par.gas.ConstantVaporPressureBuilder().set_vapor_pressure(1e-30, \"Pa\").build()\nvapor_water = par.gas.WaterBuckVaporPressureBuilder().build()\n\n# Gas species\nwater_sat = vapor_water.saturation_concentration(molar_mass_water, temperature)\nwater_conc = water_sat * water_activity\n\ngas_species = (\n    par.gas.GasSpeciesBuilder()\n    .set_name(np.array([\"organics\", \"soot\", \"water\"]))\n    .set_molar_mass(\n        np.array([molar_mass_organics, molar_mass_soot, molar_mass_water]),\n        \"kg/mol\",\n    )\n    .set_partitioning(True)\n    .set_vapor_pressure_strategy([vapor_organics, vapor_soot, vapor_water])\n    .set_concentration(np.array([1e-12, 1e-12, water_conc]), \"kg/m^3\")\n    .build()\n)\n\natmosphere = (\n    par.gas.AtmosphereBuilder()\n    .set_more_partitioning_species(gas_species)\n    .set_temperature(temperature, \"K\")\n    .set_pressure(1, \"atm\")\n    .build()\n)\n\n# Particle distributions\nradii_organics = par.particles.get_lognormal_sample_distribution(\n    mode=np.array([30e-9, 110e-9]),\n    geometric_standard_deviation=np.array([1.3, 1.2]),\n    number_of_particles=np.array([0.2, 0.6]),\n    number_of_samples=number_of_samples,\n)\nradii_soot = par.particles.get_lognormal_sample_distribution(\n    mode=np.array([75e-9, 120e-9]),\n    geometric_standard_deviation=np.array([1.3, 1.4]),\n    number_of_particles=np.array([2, 1]),\n    number_of_samples=number_of_samples,\n)\n\nmass_organic = 4 / 3 * np.pi * (radii_organics**3) * density_organics\nmass_soot = 4 / 3 * np.pi * (radii_soot**3) * density_soot\nmass_water = mass_organic + mass_soot\n\nmass_speciation = np.column_stack((mass_organic, mass_soot, mass_water))\n\n# Activity strategy\nactivity_strategy = (\n    par.particles.ActivityKappaParameterBuilder()\n    .set_density([density_organics, density_soot, density_water], \"kg/m^3\")\n    .set_molar_mass(\n        [molar_mass_organics, molar_mass_soot, molar_mass_water], \"kg/mol\"\n    )\n    .set_kappa(np.array([kappa_organics, kappa_soot, kappa_water]))\n    .set_water_index(2)\n    .build()\n)\n\nsurface_strategy = par.particles.SurfaceStrategyVolume()\n\n# Create Particula particle object\nresolved_masses = (\n    par.particles.ResolvedParticleMassRepresentationBuilder()\n    .set_distribution_strategy(par.particles.ParticleResolvedSpeciatedMass())\n    .set_activity_strategy(activity_strategy)\n    .set_surface_strategy(surface_strategy)\n    .set_mass(mass_speciation, \"kg\")\n    .set_density(\n        np.array([density_organics, density_soot, density_water]), \"kg/m^3\"\n    )\n    .set_charge(0)  # no charge on particles\n    .set_volume(simulation_volume, \"m^3\")\n    .build()\n)\n\n# Create Aerosol object\naerosol = par.Aerosol(atmosphere=atmosphere, particles=resolved_masses)\nprint(aerosol)\n\n\n# Plot initial size distribution\nfig, ax = plt.subplots()\nax.hist(\n    np.log10(resolved_masses.get_radius()), bins=50, density=False, alpha=0.5\n)\nax.set_xlabel(\"log10(Diameter [m])\")\nax.set_ylabel(\"Bin counts\")\nax.set_title(\"Initial Particle Size Distribution\");\n</pre> # Reproducibility np.random.seed(100)  # 1a. Species properties molar_mass_organics = 250e-3  # kg/mol molar_mass_soot = 1000e-3  # kg/mol molar_mass_water = 18.01528e-3  # kg/mol  density_organics = 1400.0  # kg/m^3 density_soot = 1800.0 density_water = 1000.0  kappa_organics = 0.15 kappa_soot = 0.01 kappa_water = 0.01  number_of_samples = 10_000  # number of particles to sample simulation_volume = 1e-6  # 1/m^3 water_activity = 1.02  # initial water activity temperature = 298.15  # Vapor pressure strategies vapor_organics = (     par.gas.ConstantVaporPressureBuilder().set_vapor_pressure(2e-12, \"Pa\").build() ) vapor_soot = par.gas.ConstantVaporPressureBuilder().set_vapor_pressure(1e-30, \"Pa\").build() vapor_water = par.gas.WaterBuckVaporPressureBuilder().build()  # Gas species water_sat = vapor_water.saturation_concentration(molar_mass_water, temperature) water_conc = water_sat * water_activity  gas_species = (     par.gas.GasSpeciesBuilder()     .set_name(np.array([\"organics\", \"soot\", \"water\"]))     .set_molar_mass(         np.array([molar_mass_organics, molar_mass_soot, molar_mass_water]),         \"kg/mol\",     )     .set_partitioning(True)     .set_vapor_pressure_strategy([vapor_organics, vapor_soot, vapor_water])     .set_concentration(np.array([1e-12, 1e-12, water_conc]), \"kg/m^3\")     .build() )  atmosphere = (     par.gas.AtmosphereBuilder()     .set_more_partitioning_species(gas_species)     .set_temperature(temperature, \"K\")     .set_pressure(1, \"atm\")     .build() )  # Particle distributions radii_organics = par.particles.get_lognormal_sample_distribution(     mode=np.array([30e-9, 110e-9]),     geometric_standard_deviation=np.array([1.3, 1.2]),     number_of_particles=np.array([0.2, 0.6]),     number_of_samples=number_of_samples, ) radii_soot = par.particles.get_lognormal_sample_distribution(     mode=np.array([75e-9, 120e-9]),     geometric_standard_deviation=np.array([1.3, 1.4]),     number_of_particles=np.array([2, 1]),     number_of_samples=number_of_samples, )  mass_organic = 4 / 3 * np.pi * (radii_organics**3) * density_organics mass_soot = 4 / 3 * np.pi * (radii_soot**3) * density_soot mass_water = mass_organic + mass_soot  mass_speciation = np.column_stack((mass_organic, mass_soot, mass_water))  # Activity strategy activity_strategy = (     par.particles.ActivityKappaParameterBuilder()     .set_density([density_organics, density_soot, density_water], \"kg/m^3\")     .set_molar_mass(         [molar_mass_organics, molar_mass_soot, molar_mass_water], \"kg/mol\"     )     .set_kappa(np.array([kappa_organics, kappa_soot, kappa_water]))     .set_water_index(2)     .build() )  surface_strategy = par.particles.SurfaceStrategyVolume()  # Create Particula particle object resolved_masses = (     par.particles.ResolvedParticleMassRepresentationBuilder()     .set_distribution_strategy(par.particles.ParticleResolvedSpeciatedMass())     .set_activity_strategy(activity_strategy)     .set_surface_strategy(surface_strategy)     .set_mass(mass_speciation, \"kg\")     .set_density(         np.array([density_organics, density_soot, density_water]), \"kg/m^3\"     )     .set_charge(0)  # no charge on particles     .set_volume(simulation_volume, \"m^3\")     .build() )  # Create Aerosol object aerosol = par.Aerosol(atmosphere=atmosphere, particles=resolved_masses) print(aerosol)   # Plot initial size distribution fig, ax = plt.subplots() ax.hist(     np.log10(resolved_masses.get_radius()), bins=50, density=False, alpha=0.5 ) ax.set_xlabel(\"log10(Diameter [m])\") ax.set_ylabel(\"Bin counts\") ax.set_title(\"Initial Particle Size Distribution\"); <pre>Gas mixture at 298.15 K, 101325.0 Pa, partitioning=['organics' 'soot' 'water'], gas_only_species=None\nParticle Representation:\n\tStrategy: ParticleResolvedSpeciatedMass\n\tActivity: ActivityKappaParameter\n\tSurface: SurfaceStrategyVolume\n\tMass Concentration: 3.423e-07 [kg/m^3]\n\tNumber Concentration: 1.000e+10 [#/m^3]\n</pre> In\u00a0[12]: Copied! <pre># Condensation process setup\ncondensation_strategy = par.dynamics.CondensationIsothermal(\n    molar_mass=np.array(\n        [molar_mass_organics, molar_mass_soot, molar_mass_water]\n    ),\n    diffusion_coefficient=2e-5,\n    accommodation_coefficient=1,\n)\ncondensation_process = par.dynamics.MassCondensation(condensation_strategy)\n\n# Copy aerosol and define time bins\naerosol_activated = copy.deepcopy(aerosol)\ntime_step = 600  # total simulation time in seconds\ntotal_steps = 5_000  # total sub\u2011steps for finer resolution\ntime = np.linspace(0, time_step, time_step)  # 1\u2011second resolution\nbins_lognormal = np.logspace(-8, -2, 200)  # radius bins from 10\u207b\u2078 to 10\u207b\u00b2 m\ndistribution_counts = np.zeros((len(time), len(bins_lognormal) - 1))\n\n# Pre\u2011activation \u201cspin\u2011up\u201d\naerosol_activated = condensation_process.execute(\n    aerosol=aerosol_activated, time_step=0.01, sub_steps=3_000\n)\n\n# Main simulation loop\nsub_steps_per_sec = int(total_steps / time_step)\nfor i, t in enumerate(tqdm(time, desc=\"Condensing\")):\n    if i &gt; 0:\n        aerosol_activated = condensation_process.execute(\n            aerosol=aerosol_activated, time_step=1, sub_steps=sub_steps_per_sec\n        )\n    # Record the size distribution at this time\n    distribution_counts[i, :], edges = np.histogram(\n        aerosol_activated.particles.get_radius(clone=True), bins=bins_lognormal\n    )\n\n# Print final state and water saturation\nprint(aerosol_activated)\nprint(\n    \"Final water saturation ratio:\",\n    aerosol_activated.atmosphere.partitioning_species.get_saturation_ratio(298.15)[-1],\n)\n\n# Convert counts \u2192 number concentration (#/m\u00b3)\nconcentrations = distribution_counts / simulation_volume\n\n# Contour plot of log10(number concentration)\nfig, ax = plt.subplots(figsize=(7, 5))\nX, Y = np.meshgrid(time, edges[:-1])\nlog_conc = np.log10(\n    concentrations,\n    where=concentrations &gt; 0,\n    out=np.full_like(concentrations, np.nan),\n)\ncont = ax.contourf(X, Y, log_conc.T)\n\nax.set_yscale(\"log\")\nax.set_ylim(1e-7, 1e-5)\nax.set_xlabel(\"Time (s)\")\nax.set_ylabel(\"Particle Radius (m)\")\nfig.colorbar(cont, label=\"Log\u2081\u2080 Number Concentration\")\nplt.tight_layout()\nplt.show()\n</pre> # Condensation process setup condensation_strategy = par.dynamics.CondensationIsothermal(     molar_mass=np.array(         [molar_mass_organics, molar_mass_soot, molar_mass_water]     ),     diffusion_coefficient=2e-5,     accommodation_coefficient=1, ) condensation_process = par.dynamics.MassCondensation(condensation_strategy)  # Copy aerosol and define time bins aerosol_activated = copy.deepcopy(aerosol) time_step = 600  # total simulation time in seconds total_steps = 5_000  # total sub\u2011steps for finer resolution time = np.linspace(0, time_step, time_step)  # 1\u2011second resolution bins_lognormal = np.logspace(-8, -2, 200)  # radius bins from 10\u207b\u2078 to 10\u207b\u00b2 m distribution_counts = np.zeros((len(time), len(bins_lognormal) - 1))  # Pre\u2011activation \u201cspin\u2011up\u201d aerosol_activated = condensation_process.execute(     aerosol=aerosol_activated, time_step=0.01, sub_steps=3_000 )  # Main simulation loop sub_steps_per_sec = int(total_steps / time_step) for i, t in enumerate(tqdm(time, desc=\"Condensing\")):     if i &gt; 0:         aerosol_activated = condensation_process.execute(             aerosol=aerosol_activated, time_step=1, sub_steps=sub_steps_per_sec         )     # Record the size distribution at this time     distribution_counts[i, :], edges = np.histogram(         aerosol_activated.particles.get_radius(clone=True), bins=bins_lognormal     )  # Print final state and water saturation print(aerosol_activated) print(     \"Final water saturation ratio:\",     aerosol_activated.atmosphere.partitioning_species.get_saturation_ratio(298.15)[-1], )  # Convert counts \u2192 number concentration (#/m\u00b3) concentrations = distribution_counts / simulation_volume  # Contour plot of log10(number concentration) fig, ax = plt.subplots(figsize=(7, 5)) X, Y = np.meshgrid(time, edges[:-1]) log_conc = np.log10(     concentrations,     where=concentrations &gt; 0,     out=np.full_like(concentrations, np.nan), ) cont = ax.contourf(X, Y, log_conc.T)  ax.set_yscale(\"log\") ax.set_ylim(1e-7, 1e-5) ax.set_xlabel(\"Time (s)\") ax.set_ylabel(\"Particle Radius (m)\") fig.colorbar(cont, label=\"Log\u2081\u2080 Number Concentration\") plt.tight_layout() plt.show() <pre>Condensing: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 600/600 [00:30&lt;00:00, 19.97it/s]\n</pre> <pre>Gas mixture at 298.15 K, 101325.0 Pa, partitioning=['organics' 'soot' 'water'], gas_only_species=None\nParticle Representation:\n\tStrategy: ParticleResolvedSpeciatedMass\n\tActivity: ActivityKappaParameter\n\tSurface: SurfaceStrategyVolume\n\tMass Concentration: 4.613e-04 [kg/m^3]\n\tNumber Concentration: 1.000e+10 [#/m^3]\nFinal water saturation ratio: 0.9999831326202219\n</pre> In\u00a0[13]: Copied! <pre># Define coagulation strategies\nbrownian = (\n    par.dynamics.BrownianCoagulationBuilder()\n    .set_distribution_type(\"particle_resolved\")\n    .build()\n)\nsedimentation = (\n    par.dynamics.SedimentationCoagulationBuilder()\n    .set_distribution_type(\"particle_resolved\")\n    .build()\n)\ncombined_brown_sed = (\n    par.dynamics.CombineCoagulationStrategyBuilder()\n    .set_strategies([brownian, sedimentation])\n    .build()\n)\n\nturbulent_dns = (\n    par.dynamics.TurbulentDNSCoagulationBuilder()\n    .set_distribution_type(\"particle_resolved\")\n    .set_relative_velocity(0, \"m/s\")\n    .set_reynolds_lambda(72, \"dimensionless\")\n    .set_turbulent_dissipation(1000, \"cm^2/s^3\")\n    .set_fluid_density(1.225, \"kg/m^3\")\n    .build()\n)\n\n# Define Sequences for each Scenarios\nseq_condensation = par.RunnableSequence() | condensation_process\nseq_brown = (\n    par.RunnableSequence()\n    | par.dynamics.Coagulation(brownian)\n    | condensation_process\n)\nseq_comb = (\n    par.RunnableSequence()\n    | par.dynamics.Coagulation(combined_brown_sed)\n    | condensation_process\n)\nseq_turb = (\n    par.RunnableSequence()\n    | par.dynamics.Coagulation(turbulent_dns)\n    | condensation_process\n)\n\n# Run each\nresults = {}\nfor name, seq in [\n    (\"CondensationOnly\", seq_condensation),\n    (\"Brownian\", seq_brown),\n    (\"Brownian+Sed\", seq_comb),\n    (\"Brownian+TurbulentDNS\", seq_turb),\n]:\n    print(\"Started simulation:\", name)\n    obj = copy.deepcopy(aerosol_activated)\n    obj = seq.execute(aerosol=obj, time_step=3600, sub_steps=10_000)\n    results[name] = obj\n    print(obj)\n    print(\n        f\"{name} water saturation ratio:\",\n        obj.atmosphere.partitioning_species.get_saturation_ratio(298.15)[-1],\n    )\n    print(\"\\n\")\n</pre> # Define coagulation strategies brownian = (     par.dynamics.BrownianCoagulationBuilder()     .set_distribution_type(\"particle_resolved\")     .build() ) sedimentation = (     par.dynamics.SedimentationCoagulationBuilder()     .set_distribution_type(\"particle_resolved\")     .build() ) combined_brown_sed = (     par.dynamics.CombineCoagulationStrategyBuilder()     .set_strategies([brownian, sedimentation])     .build() )  turbulent_dns = (     par.dynamics.TurbulentDNSCoagulationBuilder()     .set_distribution_type(\"particle_resolved\")     .set_relative_velocity(0, \"m/s\")     .set_reynolds_lambda(72, \"dimensionless\")     .set_turbulent_dissipation(1000, \"cm^2/s^3\")     .set_fluid_density(1.225, \"kg/m^3\")     .build() )  # Define Sequences for each Scenarios seq_condensation = par.RunnableSequence() | condensation_process seq_brown = (     par.RunnableSequence()     | par.dynamics.Coagulation(brownian)     | condensation_process ) seq_comb = (     par.RunnableSequence()     | par.dynamics.Coagulation(combined_brown_sed)     | condensation_process ) seq_turb = (     par.RunnableSequence()     | par.dynamics.Coagulation(turbulent_dns)     | condensation_process )  # Run each results = {} for name, seq in [     (\"CondensationOnly\", seq_condensation),     (\"Brownian\", seq_brown),     (\"Brownian+Sed\", seq_comb),     (\"Brownian+TurbulentDNS\", seq_turb), ]:     print(\"Started simulation:\", name)     obj = copy.deepcopy(aerosol_activated)     obj = seq.execute(aerosol=obj, time_step=3600, sub_steps=10_000)     results[name] = obj     print(obj)     print(         f\"{name} water saturation ratio:\",         obj.atmosphere.partitioning_species.get_saturation_ratio(298.15)[-1],     )     print(\"\\n\") <pre>Started simulation: CondensationOnly\nGas mixture at 298.15 K, 101325.0 Pa, partitioning=['organics' 'soot' 'water'], gas_only_species=None\nParticle Representation:\n\tStrategy: ParticleResolvedSpeciatedMass\n\tActivity: ActivityKappaParameter\n\tSurface: SurfaceStrategyVolume\n\tMass Concentration: 4.613e-04 [kg/m^3]\n\tNumber Concentration: 1.000e+10 [#/m^3]\nCondensationOnly water saturation ratio: 0.9999828525679759\n\n\nStarted simulation: Brownian\nGas mixture at 298.15 K, 101325.0 Pa, partitioning=['organics' 'soot' 'water'], gas_only_species=None\nParticle Representation:\n\tStrategy: ParticleResolvedSpeciatedMass\n\tActivity: ActivityKappaParameter\n\tSurface: SurfaceStrategyVolume\n\tMass Concentration: 4.613e-04 [kg/m^3]\n\tNumber Concentration: 9.883e+09 [#/m^3]\nBrownian water saturation ratio: 0.9999828529371749\n\n\nStarted simulation: Brownian+Sed\nGas mixture at 298.15 K, 101325.0 Pa, partitioning=['organics' 'soot' 'water'], gas_only_species=None\nParticle Representation:\n\tStrategy: ParticleResolvedSpeciatedMass\n\tActivity: ActivityKappaParameter\n\tSurface: SurfaceStrategyVolume\n\tMass Concentration: 4.613e-04 [kg/m^3]\n\tNumber Concentration: 4.533e+09 [#/m^3]\nBrownian+Sed water saturation ratio: 0.9999828835354667\n\n\nStarted simulation: Brownian+TurbulentDNS\nGas mixture at 298.15 K, 101325.0 Pa, partitioning=['organics' 'soot' 'water'], gas_only_species=None\nParticle Representation:\n\tStrategy: ParticleResolvedSpeciatedMass\n\tActivity: ActivityKappaParameter\n\tSurface: SurfaceStrategyVolume\n\tMass Concentration: 4.611e-04 [kg/m^3]\n\tNumber Concentration: 4.629e+09 [#/m^3]\nBrownian+TurbulentDNS water saturation ratio: 0.999982882210794\n\n\n</pre> In\u00a0[14]: Copied! <pre>num_bins = 140\nBIN_EDGES = np.logspace(np.log10(0.01), np.log10(100), num_bins + 1)\n\n\ndef get_wet_diameters(aero_obj):\n    \"\"\"\n    Return an array of nonzero wet diameters (\u00b5m).\n    \"\"\"\n    radii_m = aero_obj.particles.get_radius(clone=True)\n    radii_um = radii_m * par.util.get_unit_conversion(\"m\", \"um\")\n    diameters_um = radii_um[radii_um &gt; 0] * 2\n    return diameters_um\n\n\ndef compute_dndlogdp(diameters, volume_m3):\n    \"\"\"\n    Convert diameter samples into dN/dlogDp (#/cm\u00b3).\n    \"\"\"\n    counts, _ = np.histogram(diameters, bins=BIN_EDGES)\n    m3_to_cm3 = par.util.get_unit_conversion(\"m^3\", \"cm^3\")\n    dn_number = counts / (volume_m3 * m3_to_cm3)\n    centers = (BIN_EDGES[:-1] + BIN_EDGES[1:]) / 2\n    strategy = par.particles.get_distribution_conversion_strategy(\n        \"dN/dlogDp\", \"pmf\"\n    )\n    dndlogdp = strategy.convert(centers, dn_number, inverse=True)\n    return centers, dndlogdp\n\n\n# Compute distributions for all cases\ndistributions = {}\ncases = [(\"Initial\", aerosol), (\"Start\", aerosol_activated)] + list(\n    results.items()\n)\n\nfor label, aero_obj in cases:\n    diameters = get_wet_diameters(aero_obj)\n    volume = aero_obj.particles.get_volume()\n    centers, dnd = compute_dndlogdp(diameters, volume)\n    distributions[label] = (centers, dnd)\n</pre> num_bins = 140 BIN_EDGES = np.logspace(np.log10(0.01), np.log10(100), num_bins + 1)   def get_wet_diameters(aero_obj):     \"\"\"     Return an array of nonzero wet diameters (\u00b5m).     \"\"\"     radii_m = aero_obj.particles.get_radius(clone=True)     radii_um = radii_m * par.util.get_unit_conversion(\"m\", \"um\")     diameters_um = radii_um[radii_um &gt; 0] * 2     return diameters_um   def compute_dndlogdp(diameters, volume_m3):     \"\"\"     Convert diameter samples into dN/dlogDp (#/cm\u00b3).     \"\"\"     counts, _ = np.histogram(diameters, bins=BIN_EDGES)     m3_to_cm3 = par.util.get_unit_conversion(\"m^3\", \"cm^3\")     dn_number = counts / (volume_m3 * m3_to_cm3)     centers = (BIN_EDGES[:-1] + BIN_EDGES[1:]) / 2     strategy = par.particles.get_distribution_conversion_strategy(         \"dN/dlogDp\", \"pmf\"     )     dndlogdp = strategy.convert(centers, dn_number, inverse=True)     return centers, dndlogdp   # Compute distributions for all cases distributions = {} cases = [(\"Initial\", aerosol), (\"Start\", aerosol_activated)] + list(     results.items() )  for label, aero_obj in cases:     diameters = get_wet_diameters(aero_obj)     volume = aero_obj.particles.get_volume()     centers, dnd = compute_dndlogdp(diameters, volume)     distributions[label] = (centers, dnd) In\u00a0[15]: Copied! <pre># 1. Create figure &amp; axes\nfig, ax = plt.subplots(figsize=(8, 4))\n\n# 2. Extract &amp; clean data for each case\ncenters_init, dnd_init = distributions[\"Initial\"]\ndnd_init = np.where(dnd_init == 0, np.nan, dnd_init)\n\ncenters_start, dnd_start = distributions[\"Start\"]\ndnd_start = np.where(dnd_start == 0, np.nan, dnd_start)\n\ncenters_cond, dnd_cond = distributions[\"CondensationOnly\"]\ndnd_cond = np.where(dnd_cond == 0, np.nan, dnd_cond)\n\ncenters_brown, dnd_brown = distributions[\"Brownian\"]\ndnd_brown = np.where(dnd_brown == 0, np.nan, dnd_brown)\n\ncenters_sed, dnd_sed = distributions[\"Brownian+Sed\"]\ndnd_sed = np.where(dnd_sed == 0, np.nan, dnd_sed)\n\ncenters_turb, dnd_turb = distributions[\"Brownian+TurbulentDNS\"]\ndnd_turb = np.where(dnd_turb == 0, np.nan, dnd_turb)\n\n# 3. Plot each line explicitly\nax.plot(\n    centers_init,\n    dnd_init,\n    linewidth=3,\n    alpha=0.5,\n    color=TAILWIND[\"slate\"][\"800\"],\n    label=\"Initial\",\n)\n\nax.plot(\n    centers_start,\n    dnd_start,\n    linewidth=15,\n    alpha=0.8,\n    color=TAILWIND[\"sky\"][\"300\"],\n    label=\"Activated start\",\n)\n\nax.plot(\n    centers_cond,\n    dnd_cond,\n    linewidth=6,\n    alpha=0.5,\n    color=TAILWIND[\"sky\"][\"800\"],\n    label=\"Condensation Only\",\n)\n\nax.plot(\n    centers_brown,\n    dnd_brown,\n    linewidth=2,\n    linestyle=\"--\",\n    color=TAILWIND[\"slate\"][\"100\"],\n    label=\"Brownian Only\",\n)\n\nax.plot(\n    centers_sed,\n    dnd_sed,\n    marker=\"o\",\n    markersize=4,\n    linewidth=5,\n    alpha=1,\n    color=TAILWIND[\"rose\"][\"300\"],\n    linestyle=\"\",\n    label=\"with Sedimentation\",\n)\n\nax.plot(\n    centers_turb,\n    dnd_turb,\n    linewidth=3,\n    alpha=0.75,\n    color=TAILWIND[\"amber\"][\"900\"],\n    label=\"with turbulentDNS\",\n)\n\n# 5. Configure axes, grid, legend, and limits\nax.set_xscale(\"log\")\nax.set_yscale(\"log\")\nax.set_xlim(0.05, 100)\nax.set_ylim(10, 3e5)\nax.set_xlabel(\"Wet Diameter [\u00b5m]\")\nax.set_ylabel(\"dN/dlogDp [#/cm\u00b3]\")\nax.grid(alpha=0.5, which=\"both\")\nax.legend(\n    loc=\"center left\",  # anchor the legend\u2019s \u201ccenter left\u201d corner\n    bbox_to_anchor=(\n        1.02,\n        0.5,\n    ),  # (x, y) in axes coordinates: x=1.02 is just past the right edge\n    borderaxespad=0.5,  # padding between axes and legend\n)\nplt.tight_layout()\nplt.show()\n</pre> # 1. Create figure &amp; axes fig, ax = plt.subplots(figsize=(8, 4))  # 2. Extract &amp; clean data for each case centers_init, dnd_init = distributions[\"Initial\"] dnd_init = np.where(dnd_init == 0, np.nan, dnd_init)  centers_start, dnd_start = distributions[\"Start\"] dnd_start = np.where(dnd_start == 0, np.nan, dnd_start)  centers_cond, dnd_cond = distributions[\"CondensationOnly\"] dnd_cond = np.where(dnd_cond == 0, np.nan, dnd_cond)  centers_brown, dnd_brown = distributions[\"Brownian\"] dnd_brown = np.where(dnd_brown == 0, np.nan, dnd_brown)  centers_sed, dnd_sed = distributions[\"Brownian+Sed\"] dnd_sed = np.where(dnd_sed == 0, np.nan, dnd_sed)  centers_turb, dnd_turb = distributions[\"Brownian+TurbulentDNS\"] dnd_turb = np.where(dnd_turb == 0, np.nan, dnd_turb)  # 3. Plot each line explicitly ax.plot(     centers_init,     dnd_init,     linewidth=3,     alpha=0.5,     color=TAILWIND[\"slate\"][\"800\"],     label=\"Initial\", )  ax.plot(     centers_start,     dnd_start,     linewidth=15,     alpha=0.8,     color=TAILWIND[\"sky\"][\"300\"],     label=\"Activated start\", )  ax.plot(     centers_cond,     dnd_cond,     linewidth=6,     alpha=0.5,     color=TAILWIND[\"sky\"][\"800\"],     label=\"Condensation Only\", )  ax.plot(     centers_brown,     dnd_brown,     linewidth=2,     linestyle=\"--\",     color=TAILWIND[\"slate\"][\"100\"],     label=\"Brownian Only\", )  ax.plot(     centers_sed,     dnd_sed,     marker=\"o\",     markersize=4,     linewidth=5,     alpha=1,     color=TAILWIND[\"rose\"][\"300\"],     linestyle=\"\",     label=\"with Sedimentation\", )  ax.plot(     centers_turb,     dnd_turb,     linewidth=3,     alpha=0.75,     color=TAILWIND[\"amber\"][\"900\"],     label=\"with turbulentDNS\", )  # 5. Configure axes, grid, legend, and limits ax.set_xscale(\"log\") ax.set_yscale(\"log\") ax.set_xlim(0.05, 100) ax.set_ylim(10, 3e5) ax.set_xlabel(\"Wet Diameter [\u00b5m]\") ax.set_ylabel(\"dN/dlogDp [#/cm\u00b3]\") ax.grid(alpha=0.5, which=\"both\") ax.legend(     loc=\"center left\",  # anchor the legend\u2019s \u201ccenter left\u201d corner     bbox_to_anchor=(         1.02,         0.5,     ),  # (x, y) in axes coordinates: x=1.02 is just past the right edge     borderaxespad=0.5,  # padding between axes and legend ) plt.tight_layout() plt.show() In\u00a0[16]: Copied! <pre>#  1. Retrieve and prepare mass arrays\ncombined_dns_mass = results[\n    \"Brownian+TurbulentDNS\"\n].particles.get_species_mass(clone=True)\ninitial_mass = aerosol.particles.get_species_mass(clone=True)\n\nmask = results[\"Brownian+TurbulentDNS\"].particles.get_radius() &gt; 0\ncombined_dns_mass[:, -1] = 0.0  # drop water\ninitial_mass[:, -1] = 0.0\n\ndns_mass_fraction = combined_dns_mass[mask, 0] / combined_dns_mass[mask].sum(\n    axis=1\n)\ninitial_mass_fraction = initial_mass[:, 0] / initial_mass.sum(axis=1)\n\n# 2. Compute wet diameters\ndns_dp = get_wet_diameters(results[\"Brownian+TurbulentDNS\"])\ninitial_dp = get_wet_diameters(aerosol)\n\n# 3. Plot scatter\nfig, ax = plt.subplots(figsize=(5, 4))\n\nax.scatter(\n    dns_dp,\n    dns_mass_fraction,\n    s=1,\n    alpha=0.3,\n    color=TAILWIND[\"amber\"][\"800\"],\n    label=\"After DNS\",\n)\nax.scatter(\n    initial_dp,\n    initial_mass_fraction,\n    s=1,\n    alpha=0.1,\n    color=TAILWIND[\"slate\"][\"500\"],\n    label=\"Initial\",\n)\n\n# 4. Aesthetics\nax.set_xscale(\"log\")\nax.set_xlim(0.05, 100)\nax.set_ylim(0, 1.0)\nax.set_xlabel(\"Wet Diameter [\u00b5m]\")\nax.set_ylabel(\"Organic Mass Fraction\")\nax.grid(alpha=0.5, which=\"both\")\nax.legend(loc=\"upper right\")\n\nplt.tight_layout()\nplt.show()\n</pre> #  1. Retrieve and prepare mass arrays combined_dns_mass = results[     \"Brownian+TurbulentDNS\" ].particles.get_species_mass(clone=True) initial_mass = aerosol.particles.get_species_mass(clone=True)  mask = results[\"Brownian+TurbulentDNS\"].particles.get_radius() &gt; 0 combined_dns_mass[:, -1] = 0.0  # drop water initial_mass[:, -1] = 0.0  dns_mass_fraction = combined_dns_mass[mask, 0] / combined_dns_mass[mask].sum(     axis=1 ) initial_mass_fraction = initial_mass[:, 0] / initial_mass.sum(axis=1)  # 2. Compute wet diameters dns_dp = get_wet_diameters(results[\"Brownian+TurbulentDNS\"]) initial_dp = get_wet_diameters(aerosol)  # 3. Plot scatter fig, ax = plt.subplots(figsize=(5, 4))  ax.scatter(     dns_dp,     dns_mass_fraction,     s=1,     alpha=0.3,     color=TAILWIND[\"amber\"][\"800\"],     label=\"After DNS\", ) ax.scatter(     initial_dp,     initial_mass_fraction,     s=1,     alpha=0.1,     color=TAILWIND[\"slate\"][\"500\"],     label=\"Initial\", )  # 4. Aesthetics ax.set_xscale(\"log\") ax.set_xlim(0.05, 100) ax.set_ylim(0, 1.0) ax.set_xlabel(\"Wet Diameter [\u00b5m]\") ax.set_ylabel(\"Organic Mass Fraction\") ax.grid(alpha=0.5, which=\"both\") ax.legend(loc=\"upper right\")  plt.tight_layout() plt.show()"},{"location":"Examples/Simulations/Notebooks/Biomass_Burning_Cloud_Interactions/#biomass-burning-aerosol-with-cloud-interactions","title":"Biomass Burning Aerosol with Cloud Interactions\u00b6","text":"<p>Welcome to the Biomass Burning Aerosol with Cloud Interactions notebook, your step\u2011by\u2011step guide to setting up and running multi\u2011component aerosol simulations using Particula. Even if you\u2019re new to aerosol modeling or cloud microphysics, this notebook will walk you through:</p> <ol> <li><p>What This Notebook Is About This notebook demonstrates how to set up and run a multi\u2011component particle resolved aerosol simulation using Particula. The example focuses on biomass burning aerosols, which are a mixture of soot, organics, and water. The simulation will explore how these aerosols behave under cloud conditions, including their activation into cloud droplets and subsequent evolution through condensation and coagulation processes.</p> </li> <li><p>Why It Matters Biomass burning aerosols (soot\u00a0+\u00a0organics\u00a0+\u00a0water) play a critical role in cloud formation, climate forcing, and air quality. Understanding how these mixed particles activate into cloud droplets and evolve through condensation and coagulation helps bridge experiments and models.</p> </li> <li><p>What You\u2019ll Learn</p> <ul> <li>Configuring species properties (molar masses, densities, hygroscopicity)</li> <li>Building gas\u2011phase and particle\u2011phase objects</li> <li>Running isothermal condensation and four coagulation scenarios:<ul> <li>Condensation Only</li> <li>Condensation\u00a0+\u00a0Brownian Coagulation</li> <li>Condensation\u00a0+\u00a0Brownian\u00a0+\u00a0Sedimentation Coagulation</li> <li>Condensation\u00a0+\u00a0Brownian\u00a0+\u00a0Turbulent DNS Coagulation</li> </ul> </li> <li>Visualizing size distributions, number concentrations, and mass fractions</li> <li>Comparing saturation ratios across processes</li> </ul> </li> </ol> <p>No prior experience with Particula is required\u2014simply follow the markdown cells and code examples to explore how mixed\u2010phase aerosols behave under cloud\u2010like conditions.</p>"},{"location":"Examples/Simulations/Notebooks/Biomass_Burning_Cloud_Interactions/#setup-for-biomassburning-organic-aerosol-bboa-in-a-cloud-environment","title":"Setup for Biomass\u2010Burning Organic Aerosol (BBOA) in a Cloud Environment\u00b6","text":"<p>In this section we configure a particle\u2011resolved BBOA simulation under cloud\u2011like conditions:</p> <ol> <li><p>Reproducibility \u2013 Fix the random seed (<code>np.random.seed(100)</code>) for consistent sampling across runs.</p> </li> <li><p>Species Properties \u2013 Molar masses (organics, soot, water) \u2013 Densities (kg\u00a0m\u207b\u00b3) \u2013 Hygroscopicity parameters (\u03ba values)</p> </li> <li><p>Simulation Parameters \u2013 <code>number_of_samples</code> (particles) \u2013 Simulation volume (<code>1e\u20116\u00a0m\u207b\u00b3</code>) \u2013 Initial water activity (<code>1.02</code>) and temperature (<code>298.15\u00a0K</code>)</p> </li> <li><p>Vapor\u2011Pressure Strategies \u2013 Constant builder for organics and soot \u2013 Buck equation for water vapor</p> </li> <li><p>Gas\u2011Phase Composition \u2013 Build a <code>GasSpecies</code> object with condensable vapors and set concentrations \u2013 Assemble into an <code>Atmosphere</code> with temperature and pressure</p> </li> <li><p>Particle Size Distributions \u2013 Draw lognormal samples for organics and soot modes \u2013 Initialize water mass as the sum of organics and soot volumes (so water mass = 0 at start)</p> </li> <li><p>Mass Speciation &amp; Parameterization \u2013 Stack species masses into an (N\u00d73) array \u2013 Define a \u03ba\u2011K\u00f6hler activity strategy and a surface\u2011volume strategy</p> </li> <li><p>Particle\u2011Resolved Representation \u2013 Use <code>ResolvedParticleMassRepresentationBuilder</code> to combine mass, density, charge (0), and volume</p> </li> <li><p>Aerosol Object &amp; Initial Visualization \u2013 Instantiate <code>par.Aerosol(atmosphere, particles)</code> \u2013 Plot a histogram of log\u2081\u2080 particle radii to verify the initial distribution</p> </li> </ol> <p>Pro tip: For fast prototyping, begin with <code>5\u00a0000\u00a0\u2013\u00a010\u00a0000</code> particles. Once your setup is validated, increase <code>number_of_samples</code>, simulation length, or time resolution.</p>"},{"location":"Examples/Simulations/Notebooks/Biomass_Burning_Cloud_Interactions/#simulation-isothermal-condensation","title":"Simulation: Isothermal Condensation\u00b6","text":"<p>In this section we run an isothermal condensation on our activated aerosol, track how the size distribution evolves over time, and visualize the result as a contour of number concentration.</p> <ol> <li><p>Define the Condensation Process We use <code>CondensationIsothermal</code> with specified molar masses, diffusion coefficient, and accommodation coefficient, wrapped by <code>MassCondensation</code>.</p> </li> <li><p>Pre\u2011activation Step A small \u201cspin\u2011up\u201d condensation to initialize vapors on the dry aerosol.</p> </li> <li><p>Time Loop</p> <ul> <li>Divide the total simulation time into equal \u201csub\u2011step\u201d chunks.</li> <li>At each time step, execute the condensation process and record the particle radii histogram.</li> </ul> </li> <li><p>Post\u2011processing &amp; Plotting</p> <ul> <li>Convert raw counts to number concentration (#\u00a0m\u207b\u00b3).</li> <li>Build a 2D mesh of time vs. radius and plot <code>log10</code> of concentration on a log\u2011radius axis.</li> </ul> </li> </ol> <p>Pro tip: If the water saturation ratio is much lower than 1, in a cloud environment, the time step may be too large. Consider reducing the time step to ensure accurate results.</p>"},{"location":"Examples/Simulations/Notebooks/Biomass_Burning_Cloud_Interactions/#four-coagulation-condensation-scenarios","title":"Four Coagulation + Condensation Scenarios\u00b6","text":"<p>We apply each coagulation strategy in sequence with isothermal condensation to see how different particle interactions impact the final water saturation ratio:</p> <ol> <li><p>Condensation Only No coagulation\u2014particles grow only by condensation.</p> </li> <li><p>Brownian Coagulation Particle\u2010resolved Brownian collisions followed by condensation.</p> </li> <li><p>Brownian + Sedimentation Coagulation Combines Brownian motion and gravitational settling before condensation.</p> </li> <li><p>Brownian + Turbulent DNS Coagulation Includes Brownian collisions, DNS\u2010derived turbulent relative velocities, and fluid properties prior to condensation.</p> </li> </ol>"},{"location":"Examples/Simulations/Notebooks/Biomass_Burning_Cloud_Interactions/#processing-distributions-and-final-graphs","title":"Processing Distributions and Final Graphs\u00b6","text":"<p>Before plotting, we convert each aerosol object into a <code>dN/dlogDp</code> distribution:</p> <ol> <li><p>Define histogram bins Create <code>num_bins+1</code> logarithmically spaced diameter edges from 0.01 to 100\u00a0\u00b5m.</p> </li> <li><p>Utility functions</p> <ul> <li><code>get_wet_diameters(aero_obj)</code>: Extract nonzero wet diameters (\u00b5m) from an aerosol\u2019s radius array.</li> <li><code>compute_dndlogdp(diameters, volume_m3)</code>:<ul> <li>Bin diameters \u2192 raw counts</li> <li>Convert counts to number concentration (#\u00a0/\u00a0cm\u00b3)</li> <li>Convert to dN/dlogDp using Particula\u2019s distribution strategy</li> </ul> </li> </ul> </li> <li><p>Assemble distributions Loop over the \u201cInitial,\u201d \u201cStart,\u201d and each coagulation scenario to populate a <code>distributions</code> dict mapping label \u2192 <code>(diameter_centers, dN/dlogDp)</code>.</p> </li> </ol>"},{"location":"Examples/Simulations/Notebooks/Biomass_Burning_Cloud_Interactions/#graph-size-distribution-comparison","title":"Graph Size Distribution Comparison\u00b6","text":"<p>In this section we plot the wet\u2011diameter distributions for each scenario on a single log\u2013log axis:</p> <ol> <li><p>Extract and clean each distribution</p> <ul> <li>Retrieve <code>(centers, dN/dlogDp)</code> for \u201cInitial\u201d, \u201cStart\u201d, \u201cCondensationOnly\u201d, \u201cBrownian\u201d, \u201cBrownian+Sed\u201d, and \u201cBrownian+TurbulentDNS\u201d.</li> <li>Replace zeros with <code>NaN</code> so they don\u2019t appear as flat lines on the log scale.</li> </ul> </li> <li><p>Plot each case</p> <ul> <li>Initial: thick, semi\u2011transparent slate line</li> <li>Activated start: very thick sky\u2011blue line</li> <li>Condensation Only: medium-thick sky\u2011blue line</li> <li>Brownian Only: dashed light-slate line</li> <li>with Sedimentation: rose\u2011colored circles</li> <li>with turbulentDNS: amber solid line</li> </ul> </li> </ol>"},{"location":"Examples/Simulations/Notebooks/Biomass_Burning_Cloud_Interactions/#interpretation-of-final-size-distributions","title":"Interpretation of Final Size Distributions\u00b6","text":"<ul> <li><p>Initial (gray) The dry aerosol starts as a sub\u2011micron population, peaking around 0.1\u20130.2\u00a0\u00b5m\u2014reflecting the log\u2011normal organic and soot modes before any growth.</p> </li> <li><p>Activated Start (blue band) Once exposed to supersaturation, particles grow rapidly into two droplet modes: a smaller mode near 1.8\u00a0\u00b5m and a larger mode near 5\u00a0\u00b5m.</p> </li> <li><p>Condensation Only (dark blue) Pure vapor condensation leads to little change in the size distribution. The first mode remains nearly unchanged, indicating that it was well equilibrated with the water vapor. The second mode, however, grows slightly larger and broader.</p> </li> <li><p>Brownian Coagulation (dashed pale line) Adding only Brownian collisions barely alters the overall shape\u2014slight smoothing of the peaks indicates a few particle pairs merging, but number concentration remains nearly unchanged.</p> </li> <li><p>Brownian + Sedimentation (pink dots) Including gravitational settling removes the largest droplets most efficiently, lowering the second\u2010mode concentration more than the first and slightly skewing the distribution toward larger diameters.</p> </li> <li><p>Brownian + Turbulent DNS (brown) Turbulence\u2011enhanced collisions also broadens the distribution and reduce peak concentrations, especially for the larger droplets, illustrating how combined Brownian, and turbulent (with sedimentation) effects accelerate coagulation and deplete droplet counts at the largest sizes.</p> </li> </ul>"},{"location":"Examples/Simulations/Notebooks/Biomass_Burning_Cloud_Interactions/#graph-organic-mass-fraction-vs-wet-diameter","title":"Graph Organic Mass Fraction vs. Wet Diameter\u00b6","text":"<p>Here we compare each particle\u2019s organic mass fraction before and after the turbulent DNS coagulation:</p> <ol> <li><p>Extract species masses</p> <ul> <li>Get the final species\u2010mass array from the \u201cBrownian+TurbulentDNS\u201d result and the initial aerosol.</li> <li>Zero out the water column so fractions are computed from organics\u00a0+\u00a0soot only.</li> </ul> </li> <li><p>Compute per\u2011particle organic fraction</p> <ul> <li>f_org = m_organics \u2215 (m_organics + m_soot)</li> <li>Apply a mask to exclude any zero\u2011radius particles.</li> </ul> </li> <li><p>Convert to wet diameters Use <code>get_wet_diameters(...)</code> to obtain each particle\u2019s diameter in \u00b5m.</p> </li> <li><p>Scatter plot</p> <ul> <li>After DNS (amber, semi\u2011transparent): shows how turbulence\u2010enhanced coagulation shifts organic fraction across sizes.</li> <li>Initial (slate, very faint): baseline before any coagulation.</li> </ul> </li> </ol>"},{"location":"Examples/Simulations/Notebooks/Biomass_Burning_Cloud_Interactions/#impact-of-turbulent-dns-on-sizecomposition-space","title":"Impact of Turbulent DNS on Size\u2013Composition Space\u00b6","text":"<p>This scatter plot shows each particle\u2019s organic mass fraction versus wet diameter before (brown) and after (blue) applying the Turbulent DNS coagulation sequence.</p> <p>What this tells us: Turbulence\u2011enhanced coagulation preferentially drives mixed droplets to collide and merge into a narrower, organic\u2011rich population, while leaving a distinct soot\u2011rich mode of small particles. In other words, turbulent DNS \u201csorts\u201d particles by both size and composition. The largest mixed droplets then concentrate organics into a tighter size band.</p>"},{"location":"Examples/Simulations/Notebooks/Biomass_Burning_Cloud_Interactions/#takehome-messages","title":"Take\u2011Home Messages\u00b6","text":"<ul> <li><p>End\u2011to\u2011End Workflow: We walked through a complete Particula pipeline\u2014from defining species properties and gas/particle builders, to running time\u2011resolved condensation and four coagulation scenarios\u2014culminating in clear visualizations of size distributions and mass fractions.</p> </li> <li><p>Key Insights:</p> <ul> <li>Condensation Only produces the highest droplet peaks, since no particles are lost to collisions.</li> <li>Brownian Coagulation alone has a minimal smoothing effect on the bimodal droplet distribution.</li> <li>Sedimentation preferentially coagulates larger droplets, with smaller. On this time scale and droplet size the effect is similar to Turbulent DNS.</li> <li>Turbulent DNS Broadens the size spectrum and grows large\u2010diameter droplets, illustrating the combined importance of Brownian, gravitational, and turbulent collisions.</li> </ul> </li> <li><p>Particle\u2010Resolved Mass Analysis: By plotting per\u2011particle organic mass fraction vs. wet diameter, we saw how turbulent coagulation alters composition across size bins\u2014an approach you can adapt to other species or processes.</p> </li> <li><p>Extensibility: This modular, object\u2011oriented approach can be extended to:</p> <ul> <li>Other dynamic processes (e.g., activation kinetics, heterogeneous chemistry)</li> <li>Different aerosol types and multicomponent mixtures</li> <li>Automated code lookup and suggestion via an LLM\u2011backed vector store</li> </ul> </li> </ul> <p>Bottom Line: Particula makes it straightforward to prototype complex aerosol\u2013cloud interactions, compare physical mechanisms quantitatively, and extract particle\u2010resolved insights\u2014all within a few hundred lines of Python.</p>"},{"location":"Examples/Simulations/Notebooks/Cough_Droplets_Partitioning/","title":"Cough Droplets Partitioning","text":"In\u00a0[23]: Copied! <pre># \ud83d\udea7 Install Particula if you're running this in Google Colab\n# Remove the comment below to enable installation\n# !pip install particula[extra] --quiet\n\n# \ud83d\udce6 Import necessary libraries\nimport copy  # to safely duplicate Python objects\nimport matplotlib.pyplot as plt  # for plotting\nimport numpy as np  # numerical tools\nimport particula as par  # the main Particula package\nfrom tqdm import tqdm  # optional: for progress bars during simulation\n\n# \ud83c\udfa8 Set default plot styling using Tailwind-inspired colors from Particula\nTAILWIND = par.util.colors.TAILWIND\nbase_color = TAILWIND[\"gray\"][\"600\"]\n\nplt.rcParams.update({\n    \"text.color\": base_color,\n    \"axes.labelcolor\": base_color,\n    \"figure.figsize\": (5, 4),\n    \"font.size\": 14,\n    \"axes.edgecolor\": base_color,\n    \"axes.labelcolor\": base_color,\n    \"xtick.color\": base_color,\n    \"ytick.color\": base_color,\n    \"pdf.fonttype\": 42,\n    \"ps.fonttype\": 42,\n})\n</pre> # \ud83d\udea7 Install Particula if you're running this in Google Colab # Remove the comment below to enable installation # !pip install particula[extra] --quiet  # \ud83d\udce6 Import necessary libraries import copy  # to safely duplicate Python objects import matplotlib.pyplot as plt  # for plotting import numpy as np  # numerical tools import particula as par  # the main Particula package from tqdm import tqdm  # optional: for progress bars during simulation  # \ud83c\udfa8 Set default plot styling using Tailwind-inspired colors from Particula TAILWIND = par.util.colors.TAILWIND base_color = TAILWIND[\"gray\"][\"600\"]  plt.rcParams.update({     \"text.color\": base_color,     \"axes.labelcolor\": base_color,     \"figure.figsize\": (5, 4),     \"font.size\": 14,     \"axes.edgecolor\": base_color,     \"axes.labelcolor\": base_color,     \"xtick.color\": base_color,     \"ytick.color\": base_color,     \"pdf.fonttype\": 42,     \"ps.fonttype\": 42, })  In\u00a0[24]: Copied! <pre>list_of_chemicals = [\n    \"Water\",\n    \"NaCl\",\n    \"potassium bicarbonate (KHCO3)\",\n    \"potassium dihydrogen phosphate (KH2PO4)\",  # K+ + H2PO4\u2013\n    \"calcium bicarbonate [Ca(HCO3)2]\",\n    \"magnesium bicarbonate [Mg(HCO3)2]\",\n    \"Urea\",\n    \"Lactate\",\n    \"Glucose\",\n    \"Lysozyme\",\n    \"IgA\",\n    \"cholesterol\",\n]\ninitial_mass_fraction_bounds = [\n    (0.985, 0.995),  # Water\n    (0.0006, 0.0023),  # NaCl\n    (0.0007, 0.0030),  # KHCO3\n    (0.0002, 0.0027),  # KH2PO4\n    (0.00002, 0.00045),  # Ca(HCO3)2\n    (0.000006, 0.00003),  # Mg(HCO3)2\n    (0.0002, 0.0015),  # Urea\n    (0.00005, 0.0004),  # Lactate\n    (0.00001, 0.0002),  # Glucose\n    (0.000005, 0.00002),  # Lysozyme\n    (0.00002, 0.0002),  # IgA\n    (0.00005, 0.0005),  # Cholesterol\n]\n\ndensity_array = np.array([])\nmolar_mass_array = np.array([])\nsurface_tension_array = np.array([])\nshort_name = []\nchemical_dict = {}\n# Get the CAS numbers for each chemical\nfor chem in list_of_chemicals:\n    cas = par.util.get_chemical_search(chem)\n    print(f\"{chem}: {cas}\")\n    chemical_dict[chem] = par.util.get_chemical_stp_properties(cas)\n    # Store the molar mass and density\n    molar_mass_array = np.append(\n        molar_mass_array, chemical_dict[chem][\"molar_mass\"]\n    )\n    density_array = np.append(density_array, chemical_dict[chem][\"density\"])\n    surface_tension_array = np.append(\n        surface_tension_array, chemical_dict[chem][\"surface_tension\"]\n    )\n    short_name.append(chemical_dict[chem][\"name\"])\n\n# correct NaCl surface tension\nsurface_tension_array[1] = 0.091  # N/m, typical value\n\n# Print the chemical properties\nfor chem, props in chemical_dict.items():\n    print(f\"{chem}:\")\n    print(f\"  Name: {props['name']}\")\n    print(f\"  CAS: {props['cas_name']}\")\n    print(f\"  Smiles: {props['smiles']}\")\n    print(f\"  Molar Mass: {props['molar_mass']:.4f} kg/mol\")\n    print(f\"  Density: {props['density']:.2f} kg/m\u00b3\")\n    print(f\"  Surface Tension: {props['surface_tension']} N/m\")\n    print(f\"  Vapor Pressure: {props['pure_vapor_pressure']} Pa\\n\")\n</pre> list_of_chemicals = [     \"Water\",     \"NaCl\",     \"potassium bicarbonate (KHCO3)\",     \"potassium dihydrogen phosphate (KH2PO4)\",  # K+ + H2PO4\u2013     \"calcium bicarbonate [Ca(HCO3)2]\",     \"magnesium bicarbonate [Mg(HCO3)2]\",     \"Urea\",     \"Lactate\",     \"Glucose\",     \"Lysozyme\",     \"IgA\",     \"cholesterol\", ] initial_mass_fraction_bounds = [     (0.985, 0.995),  # Water     (0.0006, 0.0023),  # NaCl     (0.0007, 0.0030),  # KHCO3     (0.0002, 0.0027),  # KH2PO4     (0.00002, 0.00045),  # Ca(HCO3)2     (0.000006, 0.00003),  # Mg(HCO3)2     (0.0002, 0.0015),  # Urea     (0.00005, 0.0004),  # Lactate     (0.00001, 0.0002),  # Glucose     (0.000005, 0.00002),  # Lysozyme     (0.00002, 0.0002),  # IgA     (0.00005, 0.0005),  # Cholesterol ]  density_array = np.array([]) molar_mass_array = np.array([]) surface_tension_array = np.array([]) short_name = [] chemical_dict = {} # Get the CAS numbers for each chemical for chem in list_of_chemicals:     cas = par.util.get_chemical_search(chem)     print(f\"{chem}: {cas}\")     chemical_dict[chem] = par.util.get_chemical_stp_properties(cas)     # Store the molar mass and density     molar_mass_array = np.append(         molar_mass_array, chemical_dict[chem][\"molar_mass\"]     )     density_array = np.append(density_array, chemical_dict[chem][\"density\"])     surface_tension_array = np.append(         surface_tension_array, chemical_dict[chem][\"surface_tension\"]     )     short_name.append(chemical_dict[chem][\"name\"])  # correct NaCl surface tension surface_tension_array[1] = 0.091  # N/m, typical value  # Print the chemical properties for chem, props in chemical_dict.items():     print(f\"{chem}:\")     print(f\"  Name: {props['name']}\")     print(f\"  CAS: {props['cas_name']}\")     print(f\"  Smiles: {props['smiles']}\")     print(f\"  Molar Mass: {props['molar_mass']:.4f} kg/mol\")     print(f\"  Density: {props['density']:.2f} kg/m\u00b3\")     print(f\"  Surface Tension: {props['surface_tension']} N/m\")     print(f\"  Vapor Pressure: {props['pure_vapor_pressure']} Pa\\n\") <pre>Water: Water\nNaCl: NaCl\npotassium bicarbonate (KHCO3): potassium bicarbonate (KHCO3)\npotassium dihydrogen phosphate (KH2PO4): potassium dihydrogen phosphate (KH2PO4)\ncalcium bicarbonate [Ca(HCO3)2]: calcium carbonate [usan]\nmagnesium bicarbonate [Mg(HCO3)2]: magnesium carbonate (mgco3)\nUrea: Urea\nLactate: Lactate\nGlucose: Glucose\nLysozyme: soy-dome\nIgA: IgA\ncholesterol: cholesterol\nWater:\n  Name: water\n  CAS: 7732-18-5\n  Smiles: O\n  Molar Mass: 0.0180 kg/mol\n  Density: 997.06 kg/m\u00b3\n  Surface Tension: 0.07197220523022962 N/m\n  Vapor Pressure: 3169.9293388738784 Pa\n\nNaCl:\n  Name: sodium chloride\n  CAS: 7647-14-5\n  Smiles: [Na+].[Cl-]\n  Molar Mass: 0.0584 kg/mol\n  Density: 2169.99 kg/m\u00b3\n  Surface Tension: 0.35290821232462 N/m\n  Vapor Pressure: 2.245741871175006e-30 Pa\n\npotassium bicarbonate (KHCO3):\n  Name: potassium bicarbonate\n  CAS: 298-14-6\n  Smiles: C(=O)(O)[O-].[K+]\n  Molar Mass: 0.1001 kg/mol\n  Density: 2170.00 kg/m\u00b3\n  Surface Tension: None N/m\n  Vapor Pressure: None Pa\n\npotassium dihydrogen phosphate (KH2PO4):\n  Name: potassium dihydrogen phosphate\n  CAS: 7778-77-0\n  Smiles: OP(=O)(O)[O-].[K+]\n  Molar Mass: 0.1361 kg/mol\n  Density: 2340.01 kg/m\u00b3\n  Surface Tension: None N/m\n  Vapor Pressure: None Pa\n\ncalcium bicarbonate [Ca(HCO3)2]:\n  Name: calcium carbonate\n  CAS: 471-34-1\n  Smiles: C(=O)([O-])[O-].[Ca+2]\n  Molar Mass: 0.1001 kg/mol\n  Density: 2710.00 kg/m\u00b3\n  Surface Tension: None N/m\n  Vapor Pressure: None Pa\n\nmagnesium bicarbonate [Mg(HCO3)2]:\n  Name: magnesium carbonate\n  CAS: 546-93-0\n  Smiles: C(=O)([O-])[O-].[Mg+2]\n  Molar Mass: 0.0843 kg/mol\n  Density: 3010.00 kg/m\u00b3\n  Surface Tension: None N/m\n  Vapor Pressure: None Pa\n\nUrea:\n  Name: urea\n  CAS: 57-13-6\n  Smiles: C(=O)(N)N\n  Molar Mass: 0.0601 kg/mol\n  Density: 932.80 kg/m\u00b3\n  Surface Tension: 0.06630868366869905 N/m\n  Vapor Pressure: 9.647479358454168 Pa\n\nLactate:\n  Name: lactic acid\n  CAS: 50-21-5\n  Smiles: CC(C(=O)O)O\n  Molar Mass: 0.0901 kg/mol\n  Density: 1146.11 kg/m\u00b3\n  Surface Tension: 0.06892887098077884 N/m\n  Vapor Pressure: 0.42214021514470007 Pa\n\nGlucose:\n  Name: glucose\n  CAS: 50-99-7\n  Smiles: O=C[C@H](O)[C@@H](O)[C@H](O)[C@H](O)CO\n  Molar Mass: 0.1802 kg/mol\n  Density: 1618.57 kg/m\u00b3\n  Surface Tension: 0.10078381855423499 N/m\n  Vapor Pressure: 3.472643152420593e-11 Pa\n\nLysozyme:\n  Name: hexachlorophene\n  CAS: 70-30-4\n  Smiles: C1=C(C(=C(C(=C1Cl)Cl)CC2=C(C(=CC(=C2Cl)Cl)Cl)O)O)Cl\n  Molar Mass: 0.4069 kg/mol\n  Density: 2009.99 kg/m\u00b3\n  Surface Tension: 0.07787535981784431 N/m\n  Vapor Pressure: 9.468715811988936e-14 Pa\n\nIgA:\n  Name: isoguanine\n  CAS: 3373-53-3\n  Smiles: C1=NC2=NC(=O)NC(=C2N1)N\n  Molar Mass: 0.1511 kg/mol\n  Density: 815.71 kg/m\u00b3\n  Surface Tension: 0.1373263034398279 N/m\n  Vapor Pressure: 0.00012951501534944908 Pa\n\ncholesterol:\n  Name: cholesterol\n  CAS: 57-88-5\n  Smiles: CC(C)CCC[C@@H](C)[C@H]1CC[C@H]2[C@@H]3CC=C4C[C@@H](O)CC[C@]4(C)[C@H]3CC[C@]12C\n  Molar Mass: 0.3867 kg/mol\n  Density: 1064.37 kg/m\u00b3\n  Surface Tension: 0.03942801914463943 N/m\n  Vapor Pressure: 8.548725890318368e-07 Pa\n\n</pre> In\u00a0[25]: Copied! <pre># %% Step 1: Define system size, temperature, and vapor pressure strategies\n\n# \ud83c\udfb2 Ensure reproducibility\nnp.random.seed(100)\n\n# \ud83d\udd22 Simulation settings\nnumber_of_samples = 10_000  # Number of particles to simulate\ntotal_number_per_cm3 = 1e-4  # Particle number concentration [#/cm\u00b3]\nsimulation_volume = (\n    number_of_samples / total_number_per_cm3 * 1e-6\n)  # Simulation volume in m\u00b3 (converted from cm\u00b3)\n\ntemperature = 298.15  # System temperature in Kelvin (25\u00b0C)\n\n# \ud83c\udf21 Build vapor pressure strategies for each chemical\nvapor_pressure_strategy_list = []\n\nfor chem_i, props in chemical_dict.items():\n    vapor_pressure_temp = props[\"pure_vapor_pressure\"]\n\n    if vapor_pressure_temp is None:\n        print(\n            f\"\u26a0\ufe0f Warning: No vapor pressure data for {chem_i}, using default.\"\n        )\n        vapor_pressure_temp = 1e-30  # fallback for non-volatile species\n\n    vapor_pressure_i = (\n        par.gas.ConstantVaporPressureBuilder()\n        .set_vapor_pressure(vapor_pressure_temp, \"Pa\")\n        .build()\n    )\n\n    vapor_pressure_strategy_list.append(vapor_pressure_i)\n\n# \ud83d\udca7 Ensure surface tension values are set\nsurface_tension_array = np.array(\n    [0.072 if x is None else x for x in surface_tension_array]\n)\n</pre> # %% Step 1: Define system size, temperature, and vapor pressure strategies  # \ud83c\udfb2 Ensure reproducibility np.random.seed(100)  # \ud83d\udd22 Simulation settings number_of_samples = 10_000  # Number of particles to simulate total_number_per_cm3 = 1e-4  # Particle number concentration [#/cm\u00b3] simulation_volume = (     number_of_samples / total_number_per_cm3 * 1e-6 )  # Simulation volume in m\u00b3 (converted from cm\u00b3)  temperature = 298.15  # System temperature in Kelvin (25\u00b0C)  # \ud83c\udf21 Build vapor pressure strategies for each chemical vapor_pressure_strategy_list = []  for chem_i, props in chemical_dict.items():     vapor_pressure_temp = props[\"pure_vapor_pressure\"]      if vapor_pressure_temp is None:         print(             f\"\u26a0\ufe0f Warning: No vapor pressure data for {chem_i}, using default.\"         )         vapor_pressure_temp = 1e-30  # fallback for non-volatile species      vapor_pressure_i = (         par.gas.ConstantVaporPressureBuilder()         .set_vapor_pressure(vapor_pressure_temp, \"Pa\")         .build()     )      vapor_pressure_strategy_list.append(vapor_pressure_i)  # \ud83d\udca7 Ensure surface tension values are set surface_tension_array = np.array(     [0.072 if x is None else x for x in surface_tension_array] ) <pre>\u26a0\ufe0f Warning: No vapor pressure data for potassium bicarbonate (KHCO3), using default.\n\u26a0\ufe0f Warning: No vapor pressure data for potassium dihydrogen phosphate (KH2PO4), using default.\n\u26a0\ufe0f Warning: No vapor pressure data for calcium bicarbonate [Ca(HCO3)2], using default.\n\u26a0\ufe0f Warning: No vapor pressure data for magnesium bicarbonate [Mg(HCO3)2], using default.\n</pre> In\u00a0[26]: Copied! <pre># %% Step 2: Define gas-phase concentrations and thermodynamic environment\n\n# \ud83d\udca8 Initialize gas-phase concentrations near zero\nconcentration_gas = np.ones(len(list_of_chemicals)) * 1e-30  # kg/m\u00b3\n\n# \ud83d\udca7 Set water vapor to 30% RH\nisat_water = vapor_pressure_strategy_list[0].saturation_concentration(\n    molar_mass_array[0], temperature\n)\nconcentration_gas[0] = isat_water * 0.3  # 30% RH\n\n# \ud83e\uddea Build gas-phase species with vapor strategies and concentrations\ngas_species = (\n    par.gas.GasSpeciesBuilder()\n    .set_name(np.array(list_of_chemicals))\n    .set_molar_mass(molar_mass_array, \"kg/mol\")\n    .set_partitioning(True)\n    .set_vapor_pressure_strategy(vapor_pressure_strategy_list)\n    .set_concentration(concentration_gas, \"kg/m^3\")\n    .build()\n)\n\n# \ud83c\udf21 Create atmosphere: includes temperature, pressure, and gas species\natmosphere = (\n    par.gas.AtmosphereBuilder()\n    .set_more_partitioning_species(gas_species)\n    .set_temperature(temperature, \"K\")\n    .set_pressure(1, \"atm\")\n    .build()\n)\n</pre> # %% Step 2: Define gas-phase concentrations and thermodynamic environment  # \ud83d\udca8 Initialize gas-phase concentrations near zero concentration_gas = np.ones(len(list_of_chemicals)) * 1e-30  # kg/m\u00b3  # \ud83d\udca7 Set water vapor to 30% RH isat_water = vapor_pressure_strategy_list[0].saturation_concentration(     molar_mass_array[0], temperature ) concentration_gas[0] = isat_water * 0.3  # 30% RH  # \ud83e\uddea Build gas-phase species with vapor strategies and concentrations gas_species = (     par.gas.GasSpeciesBuilder()     .set_name(np.array(list_of_chemicals))     .set_molar_mass(molar_mass_array, \"kg/mol\")     .set_partitioning(True)     .set_vapor_pressure_strategy(vapor_pressure_strategy_list)     .set_concentration(concentration_gas, \"kg/m^3\")     .build() )  # \ud83c\udf21 Create atmosphere: includes temperature, pressure, and gas species atmosphere = (     par.gas.AtmosphereBuilder()     .set_more_partitioning_species(gas_species)     .set_temperature(temperature, \"K\")     .set_pressure(1, \"atm\")     .build() ) In\u00a0[27]: Copied! <pre># %% Step 3: Define particle composition and create aerosol object\n\n# \ud83d\udca0 3a. Lognormal size distributions for cough droplet modes\n# Modes: bronchiolar, laryngeal, oropharyngeal\nmodes = np.array([0.6, 8.0, 80.0]) / 2 * 1e-6  # radii in meters\ngeometric_standard_deviations = np.array([1.65, 2.4, 1.6])\nrelative_number = np.array([15, 2, 0.2])  # relative weights\n\n# Generate sampled radii\nradii_cough = par.particles.get_lognormal_sample_distribution(\n    mode=modes,\n    geometric_standard_deviation=geometric_standard_deviations,\n    number_of_particles=relative_number,\n    number_of_samples=number_of_samples,\n)\n\n# \ud83d\udca7 3b. Assign initial water mass and scale by chemical mass fractions\nmass_water = 4 / 3 * np.pi * (radii_cough**3) * density_array[0]\n\nmass_speciation = np.repeat(\n    mass_water[:, np.newaxis], len(list_of_chemicals), axis=1\n)\n\n# Apply random mass fractions from defined bounds\nfor i, (chem, bounds) in enumerate(\n    zip(list_of_chemicals, initial_mass_fraction_bounds)\n):\n    mass_fraction = np.random.uniform(bounds[0], bounds[1], number_of_samples)\n    mass_speciation[:, i] *= mass_fraction\n\n# \u2697\ufe0f 3c. Define activity strategy using kappa parameters\nkappa_parameter = np.array(\n    [0.0, 1.1, 0.6, 0.6, 0.6, 0.6, 0.3, 0.2, 0.1, 0.1, 0.1, 0.01]\n)\n\nactivity_strategy = (\n    par.particles.ActivityKappaParameterBuilder()\n    .set_molar_mass(molar_mass_array, \"kg/mol\")\n    .set_density(density_array, \"kg/m^3\")\n    .set_kappa(kappa_parameter)\n    .set_water_index(0)\n    .build()\n)\n\n# Define surface tension strategy\nsurface_strategy = (\n    par.particles.SurfaceStrategyMassBuilder()\n    .set_surface_tension(surface_tension_array, \"N/m\")\n    .set_density(density_array, \"kg/m^3\")\n    .set_phase_index(np.arange(len(list_of_chemicals)))\n    .build()\n)\n\n# \ud83e\uddf1 3d. Build resolved particle object\nresolved_masses = (\n    par.particles.ResolvedParticleMassRepresentationBuilder()\n    .set_distribution_strategy(par.particles.ParticleResolvedSpeciatedMass())\n    .set_activity_strategy(activity_strategy)\n    .set_surface_strategy(surface_strategy)\n    .set_mass(mass_speciation, \"kg\")\n    .set_density(density_array, \"kg/m^3\")\n    .set_charge(0)\n    .set_volume(simulation_volume, \"m^3\")\n    .build()\n)\n\n# Combine gas and particle phases into full aerosol system\naerosol = par.Aerosol(atmosphere=atmosphere, particles=resolved_masses)\n\n# Optional: print summary of aerosol system\nprint(aerosol)\n</pre> # %% Step 3: Define particle composition and create aerosol object  # \ud83d\udca0 3a. Lognormal size distributions for cough droplet modes # Modes: bronchiolar, laryngeal, oropharyngeal modes = np.array([0.6, 8.0, 80.0]) / 2 * 1e-6  # radii in meters geometric_standard_deviations = np.array([1.65, 2.4, 1.6]) relative_number = np.array([15, 2, 0.2])  # relative weights  # Generate sampled radii radii_cough = par.particles.get_lognormal_sample_distribution(     mode=modes,     geometric_standard_deviation=geometric_standard_deviations,     number_of_particles=relative_number,     number_of_samples=number_of_samples, )  # \ud83d\udca7 3b. Assign initial water mass and scale by chemical mass fractions mass_water = 4 / 3 * np.pi * (radii_cough**3) * density_array[0]  mass_speciation = np.repeat(     mass_water[:, np.newaxis], len(list_of_chemicals), axis=1 )  # Apply random mass fractions from defined bounds for i, (chem, bounds) in enumerate(     zip(list_of_chemicals, initial_mass_fraction_bounds) ):     mass_fraction = np.random.uniform(bounds[0], bounds[1], number_of_samples)     mass_speciation[:, i] *= mass_fraction  # \u2697\ufe0f 3c. Define activity strategy using kappa parameters kappa_parameter = np.array(     [0.0, 1.1, 0.6, 0.6, 0.6, 0.6, 0.3, 0.2, 0.1, 0.1, 0.1, 0.01] )  activity_strategy = (     par.particles.ActivityKappaParameterBuilder()     .set_molar_mass(molar_mass_array, \"kg/mol\")     .set_density(density_array, \"kg/m^3\")     .set_kappa(kappa_parameter)     .set_water_index(0)     .build() )  # Define surface tension strategy surface_strategy = (     par.particles.SurfaceStrategyMassBuilder()     .set_surface_tension(surface_tension_array, \"N/m\")     .set_density(density_array, \"kg/m^3\")     .set_phase_index(np.arange(len(list_of_chemicals)))     .build() )  # \ud83e\uddf1 3d. Build resolved particle object resolved_masses = (     par.particles.ResolvedParticleMassRepresentationBuilder()     .set_distribution_strategy(par.particles.ParticleResolvedSpeciatedMass())     .set_activity_strategy(activity_strategy)     .set_surface_strategy(surface_strategy)     .set_mass(mass_speciation, \"kg\")     .set_density(density_array, \"kg/m^3\")     .set_charge(0)     .set_volume(simulation_volume, \"m^3\")     .build() )  # Combine gas and particle phases into full aerosol system aerosol = par.Aerosol(atmosphere=atmosphere, particles=resolved_masses)  # Optional: print summary of aerosol system print(aerosol) <pre>Gas mixture at 298.15 K, 101325.0 Pa, partitioning=['Water' 'NaCl' 'potassium bicarbonate (KHCO3)'\n 'potassium dihydrogen phosphate (KH2PO4)'\n 'calcium bicarbonate [Ca(HCO3)2]' 'magnesium bicarbonate [Mg(HCO3)2]'\n 'Urea' 'Lactate' 'Glucose' 'Lysozyme' 'IgA' 'cholesterol'], gas_only_species=None\nParticle Representation:\n\tStrategy: ParticleResolvedSpeciatedMass\n\tActivity: ActivityKappaParameter\n\tSurface: SurfaceStrategyMass\n\tMass Concentration: 1.592e-09 [kg/m^3]\n\tNumber Concentration: 1.000e+02 [#/m^3]\n</pre> In\u00a0[28]: Copied! <pre># %% Step 4: Plot initial particle size distribution\n\nfig, ax = plt.subplots()\n\n# Log-scale histogram of particle radii\nax.hist(\n    np.log10(aerosol.particles.get_radius()),  # convert to log10\n    bins=50,\n    density=False,\n    alpha=0.5,\n)\n\nax.set_xlabel(\"log\u2081\u2080(Radius [m])\")\nax.set_ylabel(\"Bin Counts\")\nax.set_title(\"Initial Particle Size Distribution\")\nplt.tight_layout()\nplt.show()\n</pre> # %% Step 4: Plot initial particle size distribution  fig, ax = plt.subplots()  # Log-scale histogram of particle radii ax.hist(     np.log10(aerosol.particles.get_radius()),  # convert to log10     bins=50,     density=False,     alpha=0.5, )  ax.set_xlabel(\"log\u2081\u2080(Radius [m])\") ax.set_ylabel(\"Bin Counts\") ax.set_title(\"Initial Particle Size Distribution\") plt.tight_layout() plt.show() In\u00a0[29]: Copied! <pre># %% Step 5: Set up physical aerosol processes\n\n# \ud83d\udca7 Isothermal Condensation\ncondensation_strategy = par.dynamics.CondensationIsothermal(\n    molar_mass=np.array(molar_mass_array),\n    diffusion_coefficient=2e-5,  # typical air value [m\u00b2/s]\n    accommodation_coefficient=1,  # full sticking efficiency\n    # skip_partitioning_indices=[]      # optional: exclude species\n)\ncondensation_process = par.dynamics.MassCondensation(condensation_strategy)\n\n# \u26aa Brownian Coagulation\ncoagulation_strategy = (\n    par.dynamics.BrownianCoagulationBuilder()\n    .set_distribution_type(\"particle_resolved\")  # use individual particles\n    .build()\n)\ncoagulation_process = par.dynamics.Coagulation(coagulation_strategy)\n</pre> # %% Step 5: Set up physical aerosol processes  # \ud83d\udca7 Isothermal Condensation condensation_strategy = par.dynamics.CondensationIsothermal(     molar_mass=np.array(molar_mass_array),     diffusion_coefficient=2e-5,  # typical air value [m\u00b2/s]     accommodation_coefficient=1,  # full sticking efficiency     # skip_partitioning_indices=[]      # optional: exclude species ) condensation_process = par.dynamics.MassCondensation(condensation_strategy)  # \u26aa Brownian Coagulation coagulation_strategy = (     par.dynamics.BrownianCoagulationBuilder()     .set_distribution_type(\"particle_resolved\")  # use individual particles     .build() ) coagulation_process = par.dynamics.Coagulation(coagulation_strategy) In\u00a0[30]: Copied! <pre># %% Step 6: Run the simulation loop\n\nprint(aerosol)  # print system state before simulation\n\n# \ud83d\udd01 Deep copy for simulation\naerosol_process = copy.deepcopy(aerosol)\n\n# Simulation parameters\ntotal_time = 120  # seconds\ntotal_steps = 200\n\ncondensation_sub_step = 100\ncoagulation_sub_step = 1\n\ntime_step = total_time / total_steps\ntime_array = np.linspace(0, total_time, total_steps)\ntime_len = len(time_array)\n\n# \ud83d\udcca Initialize arrays for tracking outputs\nbins_lognormal = np.logspace(-8, -4, 100)\ndistribution_counts = np.zeros((time_len, len(bins_lognormal) - 1))\nspecies_mass = np.zeros((time_len, len(list_of_chemicals)))\nvapor_saturation = np.zeros((time_len, len(list_of_chemicals)))\n\n# \ud83c\udf00 Time integration loop\nfor step, t in enumerate(\n    tqdm(time_array, desc=\"Running Sim\", mininterval=0.5)\n):\n    if step &gt; 0:\n\n        # Optional: fix water vapor concentration (e.g. controlled RH)\n        # aerosol_process.atmosphere.partitioning_species.concentration[0] = (\n        #     aerosol.atmosphere.partitioning_species.concentration[0]\n        # )\n\n        # \ud83d\udca7 Execute condensation\n        aerosol_process = condensation_process.execute(\n            aerosol=aerosol_process,\n            time_step=time_step,\n            sub_steps=condensation_sub_step,\n        )\n\n        # \u26aa Optional: execute coagulation\n        # aerosol_process = coagulation_process.execute(\n        #     aerosol=aerosol_process,\n        #     time_step=time_step,\n        #     sub_steps=coagulation_sub_step,\n        # )\n\n    # Record size distribution\n    distribution_counts[step, :], edges = np.histogram(\n        aerosol_process.particles.get_radius(clone=True),\n        bins=bins_lognormal,\n        density=False,\n    )\n\n    # Record species mass in particles\n    species_temp = aerosol_process.particles.get_species_mass(clone=True)\n    species_mass[step, :] = np.sum(species_temp, axis=0)\n\n    # Record vapor saturation ratios\n    vapor_saturation[step, :] = (\n        aerosol_process.atmosphere.partitioning_species.get_saturation_ratio(\n            temperature=temperature\n        )\n    )\n\n# Normalize counts to number concentration (#/m\u00b3)\nconcentrations = distribution_counts / simulation_volume\n\n# Final system state\nprint(aerosol_process)\n</pre> # %% Step 6: Run the simulation loop  print(aerosol)  # print system state before simulation  # \ud83d\udd01 Deep copy for simulation aerosol_process = copy.deepcopy(aerosol)  # Simulation parameters total_time = 120  # seconds total_steps = 200  condensation_sub_step = 100 coagulation_sub_step = 1  time_step = total_time / total_steps time_array = np.linspace(0, total_time, total_steps) time_len = len(time_array)  # \ud83d\udcca Initialize arrays for tracking outputs bins_lognormal = np.logspace(-8, -4, 100) distribution_counts = np.zeros((time_len, len(bins_lognormal) - 1)) species_mass = np.zeros((time_len, len(list_of_chemicals))) vapor_saturation = np.zeros((time_len, len(list_of_chemicals)))  # \ud83c\udf00 Time integration loop for step, t in enumerate(     tqdm(time_array, desc=\"Running Sim\", mininterval=0.5) ):     if step &gt; 0:          # Optional: fix water vapor concentration (e.g. controlled RH)         # aerosol_process.atmosphere.partitioning_species.concentration[0] = (         #     aerosol.atmosphere.partitioning_species.concentration[0]         # )          # \ud83d\udca7 Execute condensation         aerosol_process = condensation_process.execute(             aerosol=aerosol_process,             time_step=time_step,             sub_steps=condensation_sub_step,         )          # \u26aa Optional: execute coagulation         # aerosol_process = coagulation_process.execute(         #     aerosol=aerosol_process,         #     time_step=time_step,         #     sub_steps=coagulation_sub_step,         # )      # Record size distribution     distribution_counts[step, :], edges = np.histogram(         aerosol_process.particles.get_radius(clone=True),         bins=bins_lognormal,         density=False,     )      # Record species mass in particles     species_temp = aerosol_process.particles.get_species_mass(clone=True)     species_mass[step, :] = np.sum(species_temp, axis=0)      # Record vapor saturation ratios     vapor_saturation[step, :] = (         aerosol_process.atmosphere.partitioning_species.get_saturation_ratio(             temperature=temperature         )     )  # Normalize counts to number concentration (#/m\u00b3) concentrations = distribution_counts / simulation_volume  # Final system state print(aerosol_process) <pre>Gas mixture at 298.15 K, 101325.0 Pa, partitioning=['Water' 'NaCl' 'potassium bicarbonate (KHCO3)'\n 'potassium dihydrogen phosphate (KH2PO4)'\n 'calcium bicarbonate [Ca(HCO3)2]' 'magnesium bicarbonate [Mg(HCO3)2]'\n 'Urea' 'Lactate' 'Glucose' 'Lysozyme' 'IgA' 'cholesterol'], gas_only_species=None\nParticle Representation:\n\tStrategy: ParticleResolvedSpeciatedMass\n\tActivity: ActivityKappaParameter\n\tSurface: SurfaceStrategyMass\n\tMass Concentration: 1.592e-09 [kg/m^3]\n\tNumber Concentration: 1.000e+02 [#/m^3]\n</pre> <pre>Running Sim: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 200/200 [01:55&lt;00:00,  1.73it/s]</pre> <pre>Gas mixture at 298.15 K, 101325.0 Pa, partitioning=['Water' 'NaCl' 'potassium bicarbonate (KHCO3)'\n 'potassium dihydrogen phosphate (KH2PO4)'\n 'calcium bicarbonate [Ca(HCO3)2]' 'magnesium bicarbonate [Mg(HCO3)2]'\n 'Urea' 'Lactate' 'Glucose' 'Lysozyme' 'IgA' 'cholesterol'], gas_only_species=None\nParticle Representation:\n\tStrategy: ParticleResolvedSpeciatedMass\n\tActivity: ActivityKappaParameter\n\tSurface: SurfaceStrategyMass\n\tMass Concentration: 1.068e-11 [kg/m^3]\n\tNumber Concentration: 1.000e+02 [#/m^3]\n</pre> <pre>\n</pre> In\u00a0[31]: Copied! <pre># %% Step 7: Plot initial vs final size distributions\n\nfig, ax = plt.subplots(figsize=(7, 5))\n\n# Get radii before and after simulation\ninitial_distribution = aerosol.particles.get_radius(clone=True)\nfinal_distribution = aerosol_process.particles.get_radius(clone=True)\n\n# Compute binned counts\ncounts_initial, _ = np.histogram(\n    initial_distribution, bins=bins_lognormal, density=False\n)\ncounts_final, _ = np.histogram(\n    final_distribution, bins=bins_lognormal, density=False\n)\n\n# Plot initial distribution\nax.plot(\n    bins_lognormal[:-1],\n    counts_initial / simulation_volume,\n    label=\"Initial Size Distribution\",\n    color=TAILWIND[\"sky\"][\"800\"],\n    linestyle=\"--\",\n)\n\n# Plot final distribution\nax.plot(\n    bins_lognormal[:-1],\n    counts_final / simulation_volume,\n    label=\"Final Size Distribution\",\n    color=TAILWIND[\"rose\"][\"400\"],\n    linestyle=\"-\",\n)\n\n# Set axis scales and labels\nax.set_xscale(\"log\")\nax.set_xlabel(\"Particle Radius (m)\")\nax.set_ylabel(\"Concentration (#/m\u207b\u00b3)\")\nax.legend()\nplt.tight_layout()\nplt.show()\n</pre> # %% Step 7: Plot initial vs final size distributions  fig, ax = plt.subplots(figsize=(7, 5))  # Get radii before and after simulation initial_distribution = aerosol.particles.get_radius(clone=True) final_distribution = aerosol_process.particles.get_radius(clone=True)  # Compute binned counts counts_initial, _ = np.histogram(     initial_distribution, bins=bins_lognormal, density=False ) counts_final, _ = np.histogram(     final_distribution, bins=bins_lognormal, density=False )  # Plot initial distribution ax.plot(     bins_lognormal[:-1],     counts_initial / simulation_volume,     label=\"Initial Size Distribution\",     color=TAILWIND[\"sky\"][\"800\"],     linestyle=\"--\", )  # Plot final distribution ax.plot(     bins_lognormal[:-1],     counts_final / simulation_volume,     label=\"Final Size Distribution\",     color=TAILWIND[\"rose\"][\"400\"],     linestyle=\"-\", )  # Set axis scales and labels ax.set_xscale(\"log\") ax.set_xlabel(\"Particle Radius (m)\") ax.set_ylabel(\"Concentration (#/m\u207b\u00b3)\") ax.legend() plt.tight_layout() plt.show() In\u00a0[32]: Copied! <pre># %% Step 8: Plot water vapor saturation ratio over time\n\nfig, ax = plt.subplots(figsize=(7, 5))\n\n# Plot water vapor saturation ratio (species index 0)\nax.plot(\n    time_array,\n    vapor_saturation[:, 0],\n    color=TAILWIND[\"sky\"][\"800\"],\n    label=\"Vapor Saturation Ratio (Water)\",\n)\n\nax.set_ylim(0, 1.1)\nax.set_xlabel(\"Time (s)\")\nax.set_ylabel(\"Vapor Saturation Ratio\")\nax.set_title(\"Vapor Saturation Ratio for Water Over Time\")\nax.legend()\n\nplt.tight_layout()\nplt.show()\n</pre> # %% Step 8: Plot water vapor saturation ratio over time  fig, ax = plt.subplots(figsize=(7, 5))  # Plot water vapor saturation ratio (species index 0) ax.plot(     time_array,     vapor_saturation[:, 0],     color=TAILWIND[\"sky\"][\"800\"],     label=\"Vapor Saturation Ratio (Water)\", )  ax.set_ylim(0, 1.1) ax.set_xlabel(\"Time (s)\") ax.set_ylabel(\"Vapor Saturation Ratio\") ax.set_title(\"Vapor Saturation Ratio for Water Over Time\") ax.legend()  plt.tight_layout() plt.show() In\u00a0[33]: Copied! <pre># %% Step 9: Plot particle mass fraction evolution\n\n# Compute total mass fraction over time\nmass_fraction = species_mass / np.sum(species_mass, axis=1, keepdims=True)\n\n# Set color palette (one color per species)\ncolor_list = [\n    TAILWIND[\"sky\"][\"800\"],  # Water\n    TAILWIND[\"rose\"][\"400\"],  # NaCl\n    TAILWIND[\"red\"][\"800\"],  # KHCO3\n    TAILWIND[\"red\"][\"600\"],  # KH2PO4\n    TAILWIND[\"amber\"][\"500\"],  # Ca(HCO3)2\n    TAILWIND[\"orange\"][\"400\"],  # Mg(HCO3)2\n    TAILWIND[\"teal\"][\"900\"],  # Urea\n    TAILWIND[\"teal\"][\"700\"],  # Lactate\n    TAILWIND[\"green\"][\"500\"],  # Glucose\n    TAILWIND[\"indigo\"][\"600\"],  # Lysozyme\n    TAILWIND[\"indigo\"][\"400\"],  # IgA\n    TAILWIND[\"cyan\"][\"500\"],  # Cholesterol\n]\n\n# Create stackplot of species mass fraction\nfig, ax = plt.subplots(figsize=(8, 5))\nax.stackplot(\n    time_array,\n    mass_fraction.T,  # Each row = one species\n    labels=short_name,  # Species names\n    colors=color_list,\n    alpha=1.0,\n)\n\nax.set_xlabel(\"Time (s)\")\nax.set_ylabel(\"Mean Mass Fraction in Particles\")\nax.set_ylim(0, 1)\nax.grid(True)\nax.legend(\n    title=\"Species\",\n    loc=\"lower left\",\n    framealpha=0.9,\n    fontsize=10,\n)\nplt.tight_layout()\nplt.show()\n</pre> # %% Step 9: Plot particle mass fraction evolution  # Compute total mass fraction over time mass_fraction = species_mass / np.sum(species_mass, axis=1, keepdims=True)  # Set color palette (one color per species) color_list = [     TAILWIND[\"sky\"][\"800\"],  # Water     TAILWIND[\"rose\"][\"400\"],  # NaCl     TAILWIND[\"red\"][\"800\"],  # KHCO3     TAILWIND[\"red\"][\"600\"],  # KH2PO4     TAILWIND[\"amber\"][\"500\"],  # Ca(HCO3)2     TAILWIND[\"orange\"][\"400\"],  # Mg(HCO3)2     TAILWIND[\"teal\"][\"900\"],  # Urea     TAILWIND[\"teal\"][\"700\"],  # Lactate     TAILWIND[\"green\"][\"500\"],  # Glucose     TAILWIND[\"indigo\"][\"600\"],  # Lysozyme     TAILWIND[\"indigo\"][\"400\"],  # IgA     TAILWIND[\"cyan\"][\"500\"],  # Cholesterol ]  # Create stackplot of species mass fraction fig, ax = plt.subplots(figsize=(8, 5)) ax.stackplot(     time_array,     mass_fraction.T,  # Each row = one species     labels=short_name,  # Species names     colors=color_list,     alpha=1.0, )  ax.set_xlabel(\"Time (s)\") ax.set_ylabel(\"Mean Mass Fraction in Particles\") ax.set_ylim(0, 1) ax.grid(True) ax.legend(     title=\"Species\",     loc=\"lower left\",     framealpha=0.9,     fontsize=10, ) plt.tight_layout() plt.show() In\u00a0[34]: Copied! <pre># %% Step 10: Contour plot of particle size distribution over time\n\nfig, ax = plt.subplots(figsize=(7, 5))\n\n# Create 2D mesh grid for time and particle radius\nX, Y = np.meshgrid(time_array, edges[:-1])\n\n# Convert number concentration to log10 scale (avoid log(0) issues)\nlog_conc = np.log10(\n    concentrations,\n    where=concentrations &gt; 0,\n    out=np.full_like(concentrations, np.nan),  # mask zeros\n)\n\n# Contour plot of log concentration\ncont = ax.contourf(X, Y, log_conc.T)\n\n# Axis settings\nax.set_yscale(\"log\")\nax.set_ylim(1e-7, 1e-4)\nax.set_xlabel(\"Time (s)\")\nax.set_ylabel(\"Particle Radius (m)\")\n\n# Add colorbar\nfig.colorbar(cont, label=\"Log\u2081\u2080 Number Concentration\")\nplt.tight_layout()\nplt.show()\n</pre> # %% Step 10: Contour plot of particle size distribution over time  fig, ax = plt.subplots(figsize=(7, 5))  # Create 2D mesh grid for time and particle radius X, Y = np.meshgrid(time_array, edges[:-1])  # Convert number concentration to log10 scale (avoid log(0) issues) log_conc = np.log10(     concentrations,     where=concentrations &gt; 0,     out=np.full_like(concentrations, np.nan),  # mask zeros )  # Contour plot of log concentration cont = ax.contourf(X, Y, log_conc.T)  # Axis settings ax.set_yscale(\"log\") ax.set_ylim(1e-7, 1e-4) ax.set_xlabel(\"Time (s)\") ax.set_ylabel(\"Particle Radius (m)\")  # Add colorbar fig.colorbar(cont, label=\"Log\u2081\u2080 Number Concentration\") plt.tight_layout() plt.show()"},{"location":"Examples/Simulations/Notebooks/Cough_Droplets_Partitioning/#cough-droplets-partitioning","title":"Cough Droplets Partitioning\u00b6","text":"<p>Welcome to the Cough Droplets Partitioning notebook\u2014a step-by-step walkthrough to help you set up and run multi-component aerosol simulations using the Particula Python package.</p> <p>This example focuses on modeling cough droplets, a mixture of water, salts, and biological materials, as they evaporate under different humidity conditions.</p>"},{"location":"Examples/Simulations/Notebooks/Cough_Droplets_Partitioning/#what-this-notebook-covers","title":"\ud83c\udf1f What This Notebook Covers\u00b6","text":"<p>In this notebook, you\u2019ll learn how to:</p> <ol> <li>Model realistic aerosol particles (like cough droplets)</li> <li>Set up species properties (molar masses, densities, hygroscopicity)</li> <li>Construct gas-phase and particle-phase objects</li> <li>Run isothermal evaporation simulations</li> <li>Visualize how particle size and composition change over time</li> </ol>"},{"location":"Examples/Simulations/Notebooks/Cough_Droplets_Partitioning/#why-it-matters","title":"\ud83d\udca1 Why It Matters\u00b6","text":"<p>Cough droplets are central to human exposure studies:</p> <ul> <li>They can carry infectious agents</li> <li>Influence indoor air quality</li> <li>Affect aerosol dynamics in confined environments like classrooms, hospitals, or aircraft cabins</li> </ul>"},{"location":"Examples/Simulations/Notebooks/Cough_Droplets_Partitioning/#getting-started","title":"\ud83d\ude80 Getting Started\u00b6","text":"<p>This notebook is beginner-friendly. No prior experience with Particula or aerosol modeling is needed. Each step is clearly explained and includes code snippets to help you build intuition and experiment with your own setups.</p>"},{"location":"Examples/Simulations/Notebooks/Cough_Droplets_Partitioning/#defining-chemical-species-in-cough-droplets","title":"\ud83e\uddea Defining Chemical Species in Cough Droplets\u00b6","text":"<p>In this section, we define the chemical makeup of the simulated cough droplets. These are multi-component aerosols made up of water, salts, buffers, proteins, and other organics commonly found in human respiratory fluids.</p>"},{"location":"Examples/Simulations/Notebooks/Cough_Droplets_Partitioning/#chemical-components","title":"\ud83d\udd2c Chemical Components\u00b6","text":"<p>We create a list of 12 representative chemicals that capture the diversity of real cough droplet composition:</p> <ul> <li>Water (main solvent)</li> <li>Inorganic salts like NaCl, KHCO\u2083, KH\u2082PO\u2084, Ca(HCO\u2083)\u2082, Mg(HCO\u2083)\u2082</li> <li>Organic compounds like urea, glucose, and lactate</li> <li>Biological macromolecules like lysozyme, IgA, and cholesterol</li> </ul>"},{"location":"Examples/Simulations/Notebooks/Cough_Droplets_Partitioning/#initial-mass-fractions","title":"\ud83d\udcca Initial Mass Fractions\u00b6","text":"<p>For each chemical, we define a range of initial mass fractions that represent its likely concentration in fresh respiratory droplets. These values are approximate and intended to capture real-world variability.</p>"},{"location":"Examples/Simulations/Notebooks/Cough_Droplets_Partitioning/#automatic-property-retrieval","title":"\u2699\ufe0f Automatic Property Retrieval\u00b6","text":"<p>Using Particula\u2019s <code>get_chemical_search()</code> and <code>get_chemical_stp_properties()</code> utilities, we fetch:</p> <ul> <li>Molar mass (kg/mol)</li> <li>Density (kg/m\u00b3)</li> <li>Surface tension (N/m)</li> <li>Vapor pressure (Pa)</li> <li>Molecular identity (e.g. SMILES, CAS)</li> </ul> <p>These properties are needed to accurately simulate evaporation, condensation, and phase partitioning.</p>"},{"location":"Examples/Simulations/Notebooks/Cough_Droplets_Partitioning/#manual-adjustment","title":"\ud83d\udee0 Manual Adjustment\u00b6","text":"<p>We manually correct the surface tension for NaCl, since tabulated value was for the solid phase. Here, we use a typical value of <code>0.091 N/m</code>.</p>"},{"location":"Examples/Simulations/Notebooks/Cough_Droplets_Partitioning/#output","title":"\ud83e\uddfe Output\u00b6","text":"<p>For each species, the notebook prints:</p> <ul> <li>Name, CAS identifier, SMILES string</li> <li>Molar mass, density, surface tension, and vapor pressure</li> </ul> <p>This lets you verify the chemical setup before moving forward with building the aerosol system.</p>"},{"location":"Examples/Simulations/Notebooks/Cough_Droplets_Partitioning/#step-1-set-up-particle-and-species-properties","title":"\ud83e\uddee Step 1: Set Up Particle and Species Properties\u00b6","text":""},{"location":"Examples/Simulations/Notebooks/Cough_Droplets_Partitioning/#reproducibility","title":"\ud83c\udfb2 Reproducibility\u00b6","text":"<p>To ensure that simulations can be reproduced exactly (e.g. for comparison or debugging), we seed NumPy\u2019s random number generator:</p> <pre>np.random.seed(100)\n</pre>"},{"location":"Examples/Simulations/Notebooks/Cough_Droplets_Partitioning/#1a-define-particle-sampling-and-environmental-conditions","title":"\ud83e\uddeb 1a. Define Particle Sampling and Environmental Conditions\u00b6","text":"<p>We now define the simulation scale and temperature conditions:</p> <ul> <li><code>number_of_samples</code>: number of particles we\u2019ll track individually</li> <li><code>total_number_per_cm3</code>: assumed number concentration in the air</li> <li><code>simulation_volume</code>: computed simulation volume based on the above</li> <li><code>temperature</code>: constant system temperature (isothermal)</li> </ul> <p>This configuration controls the scale and realism of the simulation.</p>"},{"location":"Examples/Simulations/Notebooks/Cough_Droplets_Partitioning/#1b-assign-vapor-pressure-strategies","title":"\ud83c\udf21 1b. Assign Vapor Pressure Strategies\u00b6","text":"<p>Each species needs a vapor pressure strategy, which defines how readily it transitions between the gas and particle phases.</p> <p>We retrieve each species\u2019 vapor pressure (at room temperature), and if missing, assign a small fallback value. Then we use Particula\u2019s <code>ConstantVaporPressureBuilder</code> to build the vapor behavior for each compound.</p> <p>\u26a0\ufe0f Surface tensions are also cleaned: if missing, a default of <code>0.072 N/m</code> is applied (typical for water at 25\u00b0C).</p>"},{"location":"Examples/Simulations/Notebooks/Cough_Droplets_Partitioning/#step-2-set-up-the-gas-phase-environment","title":"\ud83c\udf2c Step 2: Set Up the Gas-Phase Environment\u00b6","text":"<p>To simulate how particles exchange mass with the air (e.g. water evaporating), we need to define the surrounding gas-phase composition and thermodynamic conditions.</p>"},{"location":"Examples/Simulations/Notebooks/Cough_Droplets_Partitioning/#relative-humidity-for-water","title":"\ud83d\udca7 Relative Humidity for Water\u00b6","text":"<p>We begin by setting near-zero concentrations for all species in the gas phase to simulate dry air. Then we adjust the water vapor concentration to simulate a 30% relative humidity environment:</p> <ul> <li>The saturation concentration for water is calculated using its vapor pressure strategy.</li> <li>The RH is applied by multiplying by 0.3.</li> </ul>"},{"location":"Examples/Simulations/Notebooks/Cough_Droplets_Partitioning/#building-gas-phase-species","title":"\ud83e\uddea Building Gas-Phase Species\u00b6","text":"<p>We use <code>GasSpeciesBuilder()</code> to define:</p> <ul> <li>Species names and molar masses</li> <li>Their ability to partition</li> <li>Vapor pressure strategies</li> <li>Initial gas-phase concentrations</li> </ul>"},{"location":"Examples/Simulations/Notebooks/Cough_Droplets_Partitioning/#creating-the-atmosphere","title":"\ud83c\udf21 Creating the Atmosphere\u00b6","text":"<p>Finally, we construct the atmosphere with temperature, pressure, and link the gas-phase species. This environment will be used to govern evaporation/condensation dynamics during the simulation.</p>"},{"location":"Examples/Simulations/Notebooks/Cough_Droplets_Partitioning/#step-3-define-particle-composition-and-build-the-aerosol-phase","title":"\ud83d\udca0 Step 3: Define Particle Composition and Build the Aerosol Phase\u00b6","text":"<p>Now that the gas-phase environment is ready, we define the particle-phase system\u2014realistic cough droplets containing a mix of water, salts, organics, and proteins.</p>"},{"location":"Examples/Simulations/Notebooks/Cough_Droplets_Partitioning/#3a-size-distribution-of-cough-droplets","title":"\ud83c\udf21 3a. Size Distribution of Cough Droplets\u00b6","text":"<p>Human coughs produce droplets from different regions of the respiratory tract, which can be modeled using lognormal size distributions:</p> <ul> <li>Bronchiolar: smaller mode (~0.3 \u03bcm radius)</li> <li>Laryngeal: medium mode (~4 \u03bcm radius)</li> <li>Oropharyngeal: large mode (~40 \u03bcm radius)</li> </ul> <p>We use <code>par.particles.get_lognormal_sample_distribution()</code> to sample droplet radii based on these modes, weighted by their relative occurrence.</p>"},{"location":"Examples/Simulations/Notebooks/Cough_Droplets_Partitioning/#3b-assign-mass-composition","title":"\ud83d\udca7 3b. Assign Mass Composition\u00b6","text":"<p>We assume all particles start as water droplets, then apply random mass fractions to simulate different droplet compositions. These fractions are sampled from the ranges defined earlier for each chemical species.</p>"},{"location":"Examples/Simulations/Notebooks/Cough_Droplets_Partitioning/#3c-define-activity-and-surface-strategies","title":"\u2697\ufe0f 3c. Define Activity and Surface Strategies\u00b6","text":"<p>We use \u03ba-K\u00f6hler theory to estimate hygroscopicity, setting <code>kappa</code> values for each species. This is fed into <code>ActivityKappaParameterBuilder</code>.</p> <p>We also define a surface tension strategy that accounts for the mass of each component using <code>SurfaceStrategyMassBuilder</code>.</p>"},{"location":"Examples/Simulations/Notebooks/Cough_Droplets_Partitioning/#create-the-resolved-particle-and-aerosol-system","title":"\ud83e\uddf1 Create the Resolved Particle and Aerosol System\u00b6","text":"<p>We wrap everything into a <code>ResolvedParticleMassRepresentation</code> and then build the full Aerosol object by combining:</p> <ul> <li>Particle-phase definition (<code>resolved_masses</code>)</li> <li>Gas-phase environment (<code>atmosphere</code>)</li> </ul> <p>This sets up the full simulation-ready aerosol system.</p>"},{"location":"Examples/Simulations/Notebooks/Cough_Droplets_Partitioning/#step-4-visualize-the-initial-particle-size-distribution","title":"\ud83d\udcca Step 4: Visualize the Initial Particle Size Distribution\u00b6","text":"<p>Before simulating evaporation or chemical evolution, let\u2019s examine the initial state of the aerosol system we\u2019ve just created.</p>"},{"location":"Examples/Simulations/Notebooks/Cough_Droplets_Partitioning/#summary-of-the-initialized-system","title":"\ud83e\uddfe Summary of the Initialized System\u00b6","text":"<p>At this point, the system contains:</p> <ul> <li><p>Gas Mixture at:</p> <ul> <li>Temperature: <code>298.15 K</code></li> <li>Pressure: <code>101325 Pa</code> (1 atm)</li> <li>Partitioning Species: Water, salts, organics, proteins</li> </ul> </li> <li><p>Particle Representation:</p> <ul> <li>Strategy: <code>ParticleResolvedSpeciatedMass</code></li> <li>Activity Model: <code>ActivityKappaParameter</code></li> <li>Surface Model: <code>SurfaceStrategyMass</code></li> <li>Mass Concentration: ~<code>1.6 \u00d7 10\u207b\u2079 kg/m\u00b3</code></li> <li>Number Concentration: <code>1.0 \u00d7 10\u00b2 #/m\u00b3</code></li> </ul> </li> </ul>"},{"location":"Examples/Simulations/Notebooks/Cough_Droplets_Partitioning/#plotting-initial-size-distribution","title":"\ud83d\udcc8 Plotting Initial Size Distribution\u00b6","text":"<p>To visualize the initial aerosol size distribution:</p> <ul> <li>We extract particle radii using <code>aerosol.particles.get_radius()</code></li> <li>Convert to log10 scale (standard for aerosol data)</li> <li>Plot a histogram to show how particle sizes are distributed</li> </ul>"},{"location":"Examples/Simulations/Notebooks/Cough_Droplets_Partitioning/#step-5-define-aerosol-dynamics-condensation-coagulation","title":"\ud83d\udd01 Step 5: Define Aerosol Dynamics \u2013 Condensation &amp; Coagulation\u00b6","text":"<p>To simulate how aerosol particles evolve in time, we need to define physical processes that change their size, mass, and composition.</p> <p>In this example, we model:</p>"},{"location":"Examples/Simulations/Notebooks/Cough_Droplets_Partitioning/#5a-isothermal-condensation","title":"\ud83d\udca7 5a. Isothermal Condensation\u00b6","text":"<p>We simulate mass transfer from the gas phase to particles via isothermal condensation. Particula\u2019s <code>CondensationIsothermal</code> model accounts for:</p> <ul> <li>Molar mass of each species</li> <li>Diffusion coefficient (typically ~2e-5 m\u00b2/s for air)</li> <li>Accommodation coefficient (set to 1 for full sticking)</li> </ul> <p>This sets up a <code>MassCondensation</code> process that can be used during time evolution.</p>"},{"location":"Examples/Simulations/Notebooks/Cough_Droplets_Partitioning/#5b-brownian-coagulation","title":"\u26aa 5b. Brownian Coagulation\u00b6","text":"<p>We also define a Brownian coagulation process, where particles randomly collide and merge based on their sizes and thermal motion. This uses Particula\u2019s:</p> <ul> <li><code>BrownianCoagulationBuilder()</code> with <code>particle_resolved</code> distribution</li> <li>Wrapped into a <code>Coagulation</code> object</li> </ul>"},{"location":"Examples/Simulations/Notebooks/Cough_Droplets_Partitioning/#step-6-run-the-simulation-loop","title":"\u23f1 Step 6: Run the Simulation Loop\u00b6","text":"<p>Now that the aerosol system and physical processes are set up, we simulate how particles change over time due to condensation and optionally coagulation.</p>"},{"location":"Examples/Simulations/Notebooks/Cough_Droplets_Partitioning/#simulation-settings","title":"\u2699\ufe0f Simulation Settings\u00b6","text":"<ul> <li>Duration: 120 seconds</li> <li>Steps: 200</li> <li>Condensation sub-steps: 100 (to improve resolution for fast vapor interactions)</li> <li>Coagulation sub-steps: 1 (low priority here due to low concentration)</li> </ul> <pre>time_array = np.linspace(0, total_time, total_steps)\ntime_step = total_time / total_steps\n</pre>"},{"location":"Examples/Simulations/Notebooks/Cough_Droplets_Partitioning/#data-tracking","title":"\ud83d\udcbe Data Tracking\u00b6","text":"<p>At each time step, we record:</p> <ul> <li>Particle size distribution (histogram of radii)</li> <li>Species mass across all particles</li> <li>Gas-phase saturation ratio for each chemical</li> </ul> <p>The size distribution is stored in log-spaced bins ranging from 10\u207b\u2078 to 10\u207b\u2074 m \u2014 a typical range for atmospheric aerosol particles.</p>"},{"location":"Examples/Simulations/Notebooks/Cough_Droplets_Partitioning/#optional-toggle-physical-processes","title":"\ud83e\uddea Optional: Toggle Physical Processes\u00b6","text":"<p>Users can choose to:</p> <ul> <li>Fix the water vapor concentration (e.g. simulate a constant RH environment)</li> <li>Disable condensation or coagulation individually to isolate effects</li> </ul> <p>These are included as commented lines in the code and easy to turn on/off.</p>"},{"location":"Examples/Simulations/Notebooks/Cough_Droplets_Partitioning/#step-7-compare-initial-and-final-size-distributions","title":"\ud83d\udcc9 Step 7: Compare Initial and Final Size Distributions\u00b6","text":"<p>This plot shows how the particle size distribution evolved during the simulation.</p>"},{"location":"Examples/Simulations/Notebooks/Cough_Droplets_Partitioning/#what-it-shows","title":"\ud83d\udccc What It Shows:\u00b6","text":"<ul> <li>Dashed line: Initial size distribution before simulation</li> <li>Solid line: Final distribution after 120 seconds</li> <li>X-axis (log scale): Particle radius in meters</li> <li>Y-axis: Particle number concentration (#/m\u00b3)</li> </ul>"},{"location":"Examples/Simulations/Notebooks/Cough_Droplets_Partitioning/#what-to-look-for","title":"\ud83e\uddea What to Look For:\u00b6","text":"<ul> <li>If the final peak shifts left, particles are shrinking due to evaporation</li> <li>If the peak moves right or broadens, it may indicate condensation or growth</li> <li>In this case, we observe a leftward shift for larger particles, consistent with net evaporation</li> </ul>"},{"location":"Examples/Simulations/Notebooks/Cough_Droplets_Partitioning/#step-8-track-water-vapor-saturation-over-time","title":"\ud83d\udca7 Step 8: Track Water Vapor Saturation Over Time\u00b6","text":"<p>To understand how the gas phase responds during the simulation, we track the vapor saturation ratio for water (RH) throughout the 120 seconds.</p>"},{"location":"Examples/Simulations/Notebooks/Cough_Droplets_Partitioning/#what-is-the-saturation-ratio","title":"\ud83d\udd0d What Is the Saturation Ratio?\u00b6","text":"<p>The saturation ratio is the ratio of actual vapor concentration to the saturation vapor concentration at a given temperature. For water:</p> <p>$$ \\text{Saturation Ratio} = \\frac{C_{\\text{vapor}}}{C_{\\text{sat}}} $$</p> <ul> <li>1.0 indicates equilibrium (100% RH)</li> <li>&lt; 1.0 indicates subsaturation</li> <li>&gt; 1.0 indicates supersaturation</li> </ul>"},{"location":"Examples/Simulations/Notebooks/Cough_Droplets_Partitioning/#what-we-learn","title":"\ud83d\udccc What We Learn:\u00b6","text":"<p>In this case, the saturation ratio remains nearly constant, meaning:</p> <ul> <li>The amount of water vapor in the gas phase is high enough</li> <li>The mass transferred into particles (via condensation or evaporation) is too small to significantly disturb the vapor reservoir</li> </ul> <p>This is typical in low mass-loading regimes, such as indoor air with sparse respiratory aerosols.</p>"},{"location":"Examples/Simulations/Notebooks/Cough_Droplets_Partitioning/#step-9-track-composition-evolution-particle-mass-fractions","title":"\ud83e\uddea Step 9: Track Composition Evolution \u2013 Particle Mass Fractions\u00b6","text":"<p>As water evaporates from particles, their composition changes over time. This plot shows the mean mass fraction of each species remaining in the particles during the simulation.</p>"},{"location":"Examples/Simulations/Notebooks/Cough_Droplets_Partitioning/#what-this-plot-tells-us","title":"\ud83d\udccc What This Plot Tells Us:\u00b6","text":"<ul> <li>Water (sky blue) dominates at the start</li> <li>As evaporation progresses, non-volatile species (salts, organics, proteins) become relatively more concentrated</li> <li>Supermicron particles (initially 4\u201340 \u03bcm) retain water much longer, showing water mass persists before stabilizing.</li> </ul> <p>This plot illustrates size-dependent evaporation timescales: larger droplets lose water more slowly due to lower surface-area-to-volume ratios.</p>"},{"location":"Examples/Simulations/Notebooks/Cough_Droplets_Partitioning/#step-10-size-distribution-evolution-over-time","title":"\ud83d\udcc8 Step 10: Size Distribution Evolution Over Time\u00b6","text":"<p>This contour plot shows how the number concentration of aerosol particles changes across time and particle size. It's an excellent way to visualize both evaporation dynamics and distribution narrowing.</p>"},{"location":"Examples/Simulations/Notebooks/Cough_Droplets_Partitioning/#what-to-look-for","title":"\ud83d\udd0d What to Look For:\u00b6","text":"<ul> <li>The Y-axis (log scale) shows particle radius from $10^{-7}$ to $10^{-4}$ meters</li> <li>The X-axis tracks simulation time from 0 to 120 seconds</li> <li>The color map shows $\\log_{10}$ of number concentration (#/m\u00b3)</li> </ul>"},{"location":"Examples/Simulations/Notebooks/Cough_Droplets_Partitioning/#interpretation","title":"\ud83d\udca7 Interpretation:\u00b6","text":"<ul> <li>Supermicron particles (initially &gt;1 \u00b5m) evaporate rapidly in the first few seconds</li> <li>As water is lost, particles shrink and the size distribution stabilizes</li> <li>Smaller droplets reach their equilibrium sizes faster due to greater surface-to-volume ratios</li> </ul> <p>This plot captures the transient drying behavior of cough droplets in a controlled environment.</p>"},{"location":"Examples/Simulations/Notebooks/Cough_Droplets_Partitioning/#summary-modeling-cough-droplet-evaporation-with-particula","title":"\u2705 Summary: Modeling Cough Droplet Evaporation with Particula\u00b6","text":"<p>In this notebook, we used Particula to simulate the isothermal evaporation of cough droplets in a well-mixed air environment. We walked step-by-step through the setup of both gas-phase and particle-phase systems, created a realistic multicomponent chemical composition, and applied condensation dynamics to understand how droplets evolve over time.</p> <p>The simulated particles ranged from submicron to supermicron sizes, following a lognormal distribution that reflects real-world respiratory emissions. As expected, supermicron particles took significantly longer for their water mass fraction to decrease, highlighting the importance of size when modeling indoor exposure or transport of pathogens.</p> <p>We tracked changes in size distribution, vapor saturation ratio, and particle composition over time, and visualized how water loss drives dynamic shifts in mass fraction and droplet behavior.</p>"},{"location":"Examples/Simulations/Notebooks/Cough_Droplets_Partitioning/#take-home-points","title":"\ud83e\udde0 Take-Home Points\u00b6","text":"<ol> <li><p>Multicomponent aerosols are easy to build with Particula You can represent realistic droplet mixtures using species-specific mass fractions, thermodynamic properties, and hygroscopicity (\u03ba values).</p> </li> <li><p>Water loss dominates early evaporation dynamics In low humidity environments, water rapidly evaporates from smaller particles, while larger ones persist due to slower mass transfer rates.</p> </li> <li><p>Gas\u2013particle coupling is size- and concentration-dependent In this example, the gas-phase RH stayed nearly constant, showing that low particle loading may have minimal impact on ambient vapor conditions.</p> </li> <li><p>Particula supports modular, testable dynamics Processes like condensation, coagulation, and even fixed-RH simulations can be toggled and combined, offering flexibility for exploring a wide range of scenarios.</p> </li> </ol> <p>This notebook provides a foundational example for respiratory aerosol simulations. You can now extend it to test:</p> <ul> <li>Different relative humidity levels</li> <li>Effects of ventilation or air exchange</li> <li>Indoor vs. outdoor aerosol transport scenarios</li> <li>Inclusion of more complex chemistry or temperature effects</li> </ul>"},{"location":"Examples/Simulations/Notebooks/Organic_Partitioning_and_Coagulation/","title":"Organic Partitioning and Coagulation","text":"\u25b6\ufe0f Install Particula try:     import google.colab except ImportError:     # not Colab \u2192 do nothing     pass else:     # in Colab \u2192 install quietly     get_ipython().system(\"pip install particula[extra] --quiet\")  In\u00a0[17]: Copied! <pre>import numpy as np\nfrom tqdm import tqdm\nimport copy\nimport matplotlib.pyplot as plt\nimport particula as par\n\n# move to particle properties and update to API style.\nfrom particula.activity.species_density import organic_array\n\n# plot settings\nTAILWIND = par.util.colors.TAILWIND\nbase_color = TAILWIND[\"gray\"][\"600\"]\nplt.rcParams.update(\n    {\n        \"text.color\": base_color,\n        \"axes.labelcolor\": base_color,\n        \"figure.figsize\": (5, 4),\n        \"font.size\": 14,\n        \"axes.edgecolor\": base_color,\n        \"axes.labelcolor\": base_color,\n        \"xtick.color\": base_color,\n        \"ytick.color\": base_color,\n        \"pdf.fonttype\": 42,\n        \"ps.fonttype\": 42,\n    }\n)\n</pre>  import numpy as np from tqdm import tqdm import copy import matplotlib.pyplot as plt import particula as par  # move to particle properties and update to API style. from particula.activity.species_density import organic_array  # plot settings TAILWIND = par.util.colors.TAILWIND base_color = TAILWIND[\"gray\"][\"600\"] plt.rcParams.update(     {         \"text.color\": base_color,         \"axes.labelcolor\": base_color,         \"figure.figsize\": (5, 4),         \"font.size\": 14,         \"axes.edgecolor\": base_color,         \"axes.labelcolor\": base_color,         \"xtick.color\": base_color,         \"ytick.color\": base_color,         \"pdf.fonttype\": 42,         \"ps.fonttype\": 42,     } ) In\u00a0[18]: Copied! <pre>M_gmol = np.array(\n    [200.0, 188.0, 216.0, 368.0, 186.0, 204.0, 195.0, 368.0, 158.0, 206.0]\n)\n\nOC_ratio = np.array(\n    [0.40, 0.444, 0.50, 0.368, 0.444, 0.556, 0.857, 0.368, 0.375, 0.75]\n)\n\nHC_ratio = np.array(\n    [1.60, 1.78, 1.60, 1.47, 1.56, 1.78, 1.75, 1.56, 1.75, 1.75]\n)\n\n\ndensity_organics_g_cm3 = organic_array(\n    molar_mass=M_gmol,\n    oxygen2carbon=OC_ratio,\n    hydrogen2carbon=HC_ratio,\n)  # g/cm^3\n\nc_total_ug_per_m3 = (\n    np.array([8.79, 3.98, 1.13, 4.07, 0.628, 0.919, 0.766, 1.02, 0.399, 0.313])\n    * 10000\n)\n\nname = np.array(\n    [\n        \"C107OOH\",\n        \"C97OOH\",\n        \"C108OOH\",\n        \"ALDOL_dimer_C19H28O7\",\n        \"PINIC\",\n        \"C921OOH\",\n        \"C812OOH\",\n        \"ESTER_dimer\",\n        \"C811OH\",\n        \"C813OOH\",\n    ]\n)\n\nc_sat_ug_per_m3 = np.array(\n    [\n        8620.171693,\n        522.7659518,\n        231.757194,\n        2.27e-06,\n        24.13243017,\n        3.131375563,\n        1.107025816,\n        2.97e-06,\n        2197.484083,\n        0.04398829,\n    ]\n)\n\n# sulfate properties\nsulfate_density = 1.77 * 1000  # kg/m^3\nsulfate_molar_mass = 96.06  # g/mol\n\ntemperature_K = 298.15\n</pre> M_gmol = np.array(     [200.0, 188.0, 216.0, 368.0, 186.0, 204.0, 195.0, 368.0, 158.0, 206.0] )  OC_ratio = np.array(     [0.40, 0.444, 0.50, 0.368, 0.444, 0.556, 0.857, 0.368, 0.375, 0.75] )  HC_ratio = np.array(     [1.60, 1.78, 1.60, 1.47, 1.56, 1.78, 1.75, 1.56, 1.75, 1.75] )   density_organics_g_cm3 = organic_array(     molar_mass=M_gmol,     oxygen2carbon=OC_ratio,     hydrogen2carbon=HC_ratio, )  # g/cm^3  c_total_ug_per_m3 = (     np.array([8.79, 3.98, 1.13, 4.07, 0.628, 0.919, 0.766, 1.02, 0.399, 0.313])     * 10000 )  name = np.array(     [         \"C107OOH\",         \"C97OOH\",         \"C108OOH\",         \"ALDOL_dimer_C19H28O7\",         \"PINIC\",         \"C921OOH\",         \"C812OOH\",         \"ESTER_dimer\",         \"C811OH\",         \"C813OOH\",     ] )  c_sat_ug_per_m3 = np.array(     [         8620.171693,         522.7659518,         231.757194,         2.27e-06,         24.13243017,         3.131375563,         1.107025816,         2.97e-06,         2197.484083,         0.04398829,     ] )  # sulfate properties sulfate_density = 1.77 * 1000  # kg/m^3 sulfate_molar_mass = 96.06  # g/mol  temperature_K = 298.15 In\u00a0[19]: Copied! <pre># vapor pressures\nvapor_pressure_strategies = []\nfor i in range(len(name)):\n    vapor_pressure_organic = (\n        par.gas.SaturationConcentrationVaporPressureBuilder()\n        .set_molar_mass(M_gmol[i], \"g/mol\")\n        .set_temperature(temperature_K, \"K\")\n        .set_saturation_concentration(c_sat_ug_per_m3[i], \"ug/m^3\")\n        .build()\n    )\n    vapor_pressure_strategies.append(vapor_pressure_organic)\n\norganics_gases = (\n    par.gas.GasSpeciesBuilder()\n    .set_name(name)\n    .set_molar_mass(M_gmol, \"g/mol\")\n    .set_vapor_pressure_strategy(vapor_pressure_strategies)\n    .set_concentration(c_total_ug_per_m3, \"ug/m^3\")\n    .set_partitioning(True)\n    .build()\n)\n</pre> # vapor pressures vapor_pressure_strategies = [] for i in range(len(name)):     vapor_pressure_organic = (         par.gas.SaturationConcentrationVaporPressureBuilder()         .set_molar_mass(M_gmol[i], \"g/mol\")         .set_temperature(temperature_K, \"K\")         .set_saturation_concentration(c_sat_ug_per_m3[i], \"ug/m^3\")         .build()     )     vapor_pressure_strategies.append(vapor_pressure_organic)  organics_gases = (     par.gas.GasSpeciesBuilder()     .set_name(name)     .set_molar_mass(M_gmol, \"g/mol\")     .set_vapor_pressure_strategy(vapor_pressure_strategies)     .set_concentration(c_total_ug_per_m3, \"ug/m^3\")     .set_partitioning(True)     .build() ) In\u00a0[20]: Copied! <pre>sulfate_vapor_pressure = (\n    par.gas.ConstantVaporPressureBuilder()\n    .set_vapor_pressure(1e-30, \"Pa\")\n    .build()\n)\nsulfate_gas = (\n    par.gas.GasSpeciesBuilder()\n    .set_name(\"Sulfate\")\n    .set_molar_mass(96.06, \"g/mol\")\n    .set_vapor_pressure_strategy(sulfate_vapor_pressure)\n    .set_concentration(0, \"ug/m^3\")\n    .set_partitioning(True)\n    .build()\n)\n\n# create atmosphere\natmosphere = (\n    par.gas.AtmosphereBuilder()\n    .set_temperature(temperature_K, \"K\")\n    .set_pressure(1.0, \"atm\")\n    .set_more_partitioning_species(sulfate_gas)\n    .set_more_partitioning_species(organics_gases)\n    .build()\n)\n</pre> sulfate_vapor_pressure = (     par.gas.ConstantVaporPressureBuilder()     .set_vapor_pressure(1e-30, \"Pa\")     .build() ) sulfate_gas = (     par.gas.GasSpeciesBuilder()     .set_name(\"Sulfate\")     .set_molar_mass(96.06, \"g/mol\")     .set_vapor_pressure_strategy(sulfate_vapor_pressure)     .set_concentration(0, \"ug/m^3\")     .set_partitioning(True)     .build() )  # create atmosphere atmosphere = (     par.gas.AtmosphereBuilder()     .set_temperature(temperature_K, \"K\")     .set_pressure(1.0, \"atm\")     .set_more_partitioning_species(sulfate_gas)     .set_more_partitioning_species(organics_gases)     .build() ) In\u00a0[\u00a0]: Copied! <pre>total_number_concentration = np.array([1e13])  # /m-3\nparticle_radius = np.logspace(-7.5, -6.3, 250)  # m\n\n# create sulfate seeds\nnumber_concentration = par.particles.get_lognormal_pmf_distribution(\n    x_values=particle_radius,\n    mode=np.array([100e-9]),\n    geometric_standard_deviation=np.array([1.4]),\n    number_of_particles=total_number_concentration,\n)\n\n# calculate mass in each bin\nsulfate_volume_distribution = 4.0 / 3.0 * np.pi * particle_radius**3\nsulfate_mass_distribution = sulfate_volume_distribution * sulfate_density\n\norganic_mass_distribution = np.zeros(\n    (len(sulfate_mass_distribution), len(M_gmol)), dtype=float\n) \n\nmass_distribution = np.concatenate(\n    (sulfate_mass_distribution[:, np.newaxis], organic_mass_distribution),\n    axis=1,\n)\n\nparticle_molar_mass = np.append(sulfate_molar_mass, M_gmol)\nparticle_densities = np.append(\n    sulfate_density, density_organics_g_cm3 * 1000\n)  # kg/m^3\nactivity_strategies = (\n    par.particles.ActivityIdealMolarBuilder()\n    .set_molar_mass(particle_molar_mass, \"g/mol\")\n    .build()\n)\n\n# the surface tension and activity may have a bug in it causing it to be more evaporative\n# than it should be, so we set it to a very low value, and are investigating it.\nsurface_tension = np.append(0.09, np.ones(len(M_gmol)) * 0.0003)  # N/m\nsurface_strategy = (\n    par.particles.SurfaceStrategyVolumeBuilder()\n    .set_surface_tension(surface_tension, \"N/m\")\n    .set_density(particle_densities, \"kg/m^3\")\n    .set_phase_index(np.append(0, np.ones(len(M_gmol))))\n    .build()\n)\n</pre> total_number_concentration = np.array([1e13])  # /m-3 particle_radius = np.logspace(-7.5, -6.3, 250)  # m  # create sulfate seeds number_concentration = par.particles.get_lognormal_pmf_distribution(     x_values=particle_radius,     mode=np.array([100e-9]),     geometric_standard_deviation=np.array([1.4]),     number_of_particles=total_number_concentration, )  # calculate mass in each bin sulfate_volume_distribution = 4.0 / 3.0 * np.pi * particle_radius**3 sulfate_mass_distribution = sulfate_volume_distribution * sulfate_density  organic_mass_distribution = np.zeros(     (len(sulfate_mass_distribution), len(M_gmol)), dtype=float )   mass_distribution = np.concatenate(     (sulfate_mass_distribution[:, np.newaxis], organic_mass_distribution),     axis=1, )  particle_molar_mass = np.append(sulfate_molar_mass, M_gmol) particle_densities = np.append(     sulfate_density, density_organics_g_cm3 * 1000 )  # kg/m^3 activity_strategies = (     par.particles.ActivityIdealMolarBuilder()     .set_molar_mass(particle_molar_mass, \"g/mol\")     .build() )  # the surface tension and activity may have a bug in it causing it to be more evaporative # than it should be, so we set it to a very low value, and are investigating it. surface_tension = np.append(0.09, np.ones(len(M_gmol)) * 0.0003)  # N/m surface_strategy = (     par.particles.SurfaceStrategyVolumeBuilder()     .set_surface_tension(surface_tension, \"N/m\")     .set_density(particle_densities, \"kg/m^3\")     .set_phase_index(np.append(0, np.ones(len(M_gmol))))     .build() ) In\u00a0[22]: Copied! <pre>particle_representation = (\n    par.particles.ParticleMassRepresentationBuilder()\n    .set_distribution_strategy(par.particles.SpeciatedMassMovingBin())\n    .set_activity_strategy(activity_strategies)\n    .set_mass(mass_distribution, \"kg\")\n    .set_concentration(number_concentration, \"1/m^3\")\n    .set_charge(0)\n    .set_density(particle_densities, \"kg/m^3\")\n    .set_surface_strategy(surface_strategy)\n    .build()\n)\n</pre> particle_representation = (     par.particles.ParticleMassRepresentationBuilder()     .set_distribution_strategy(par.particles.SpeciatedMassMovingBin())     .set_activity_strategy(activity_strategies)     .set_mass(mass_distribution, \"kg\")     .set_concentration(number_concentration, \"1/m^3\")     .set_charge(0)     .set_density(particle_densities, \"kg/m^3\")     .set_surface_strategy(surface_strategy)     .build() )  In\u00a0[23]: Copied! <pre># Build aerosol\naerosol = (\n    par.AerosolBuilder()\n    .set_atmosphere(atmosphere)\n    .set_particles(particle_representation)\n    .build()\n)\n\nprint(aerosol)\n</pre> # Build aerosol aerosol = (     par.AerosolBuilder()     .set_atmosphere(atmosphere)     .set_particles(particle_representation)     .build() )  print(aerosol) <pre>Gas mixture at 298.15 K, 101325.0 Pa, partitioning=['Sulfate' 'C107OOH' 'C97OOH' 'C108OOH' 'ALDOL_dimer_C19H28O7' 'PINIC'\n 'C921OOH' 'C812OOH' 'ESTER_dimer' 'C811OH' 'C813OOH'], gas_only_species=None\nParticle Representation:\n\tStrategy: SpeciatedMassMovingBin\n\tActivity: ActivityIdealMolar\n\tSurface: SurfaceStrategyVolume\n\tMass Concentration: 1.234e-04 [kg/m^3]\n\tNumber Concentration: 1.000e+13 [#/m^3]\n</pre> In\u00a0[24]: Copied! <pre># Condensation Coagulation process setup\ncondensation_strategy = par.dynamics.CondensationIsothermal(\n    molar_mass=particle_molar_mass,\n    diffusion_coefficient=2e-5,\n    accommodation_coefficient=1,\n    update_gases=True,\n    skip_partitioning_indices=[0],  # no partitioning for sulfate\n)\ncondensation_process = par.dynamics.MassCondensation(condensation_strategy)\n\nsequence_condensation = par.RunnableSequence() | condensation_process\n\n# Copy aerosol and define time bins\naerosol_initial = copy.deepcopy(aerosol)\naerosol_soa = copy.deepcopy(aerosol)\n</pre> # Condensation Coagulation process setup condensation_strategy = par.dynamics.CondensationIsothermal(     molar_mass=particle_molar_mass,     diffusion_coefficient=2e-5,     accommodation_coefficient=1,     update_gases=True,     skip_partitioning_indices=[0],  # no partitioning for sulfate ) condensation_process = par.dynamics.MassCondensation(condensation_strategy)  sequence_condensation = par.RunnableSequence() | condensation_process  # Copy aerosol and define time bins aerosol_initial = copy.deepcopy(aerosol) aerosol_soa = copy.deepcopy(aerosol) In\u00a0[25]: Copied! <pre>aerosol_soa = sequence_condensation.execute(\n    aerosol=aerosol_soa,\n    time_step=20,\n    sub_steps=100_000,\n)\n\nprint(aerosol_soa)\n\nfig, ax = plt.subplots(figsize=(7, 5))\nax.plot(\n    aerosol_initial.particles.get_radius(),\n    aerosol_initial.particles.get_concentration(),\n    label=\"Initial Seeds\",\n)\nax.plot(\n    aerosol_soa.particles.get_radius(),\n    aerosol_soa.particles.get_concentration(),\n    label=\"Seeds+SOA\",\n)\nax.legend(loc=\"upper left\")\nax.set_xscale(\"log\")\nax.set_xlim(left=1e-8, right=1e-6)\nax.grid(alpha=0.25)\nfig.tight_layout()\n</pre> aerosol_soa = sequence_condensation.execute(     aerosol=aerosol_soa,     time_step=20,     sub_steps=100_000, )  print(aerosol_soa)  fig, ax = plt.subplots(figsize=(7, 5)) ax.plot(     aerosol_initial.particles.get_radius(),     aerosol_initial.particles.get_concentration(),     label=\"Initial Seeds\", ) ax.plot(     aerosol_soa.particles.get_radius(),     aerosol_soa.particles.get_concentration(),     label=\"Seeds+SOA\", ) ax.legend(loc=\"upper left\") ax.set_xscale(\"log\") ax.set_xlim(left=1e-8, right=1e-6) ax.grid(alpha=0.25) fig.tight_layout() <pre>Executing Runnable: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 100000/100000 [03:08&lt;00:00, 530.42it/s]\n</pre> <pre>Gas mixture at 298.15 K, 101325.0 Pa, partitioning=['Sulfate' 'C107OOH' 'C97OOH' 'C108OOH' 'ALDOL_dimer_C19H28O7' 'PINIC'\n 'C921OOH' 'C812OOH' 'ESTER_dimer' 'C811OH' 'C813OOH'], gas_only_species=None\nParticle Representation:\n\tStrategy: SpeciatedMassMovingBin\n\tActivity: ActivityIdealMolar\n\tSurface: SurfaceStrategyVolume\n\tMass Concentration: 2.749e-04 [kg/m^3]\n\tNumber Concentration: 1.000e+13 [#/m^3]\n</pre> In\u00a0[26]: Copied! <pre># coagulation process setup\ncoagulation_strategy = (\n    par.dynamics.BrownianCoagulationBuilder()\n    .set_distribution_type(\"discrete\")\n    .build()\n)\ncoagulation_process = par.dynamics.Coagulation(coagulation_strategy)\n</pre> # coagulation process setup coagulation_strategy = (     par.dynamics.BrownianCoagulationBuilder()     .set_distribution_type(\"discrete\")     .build() ) coagulation_process = par.dynamics.Coagulation(coagulation_strategy) In\u00a0[27]: Copied! <pre># %% staggered time stepping\n\naerosol_process = copy.deepcopy(aerosol_soa)\n\ntotal_time = 600  # seconds\ntotal_steps = 60\n\ncoagulation_sub_step = 1\ncondensation_sub_step = 50_000\n\ntime_step = total_time / total_steps\n\nfor step in tqdm(range(total_steps), desc=\"Running Sim\", mininterval=0.5):\n\n    # execute condensation process, this is the slowest computationally\n    # feel free to comment this out to see the effect of coagulation only\n    # aerosol_process = condensation_process.execute(\n    #     aerosol=aerosol_process,\n    #     time_step=time_step,\n    #     sub_steps=condensation_sub_step,\n    # )\n\n    # execute coagulation process\n    aerosol_process = coagulation_process.execute(\n        aerosol=aerosol_process,\n        time_step=time_step,\n        sub_steps=coagulation_sub_step,\n    )\n</pre> # %% staggered time stepping  aerosol_process = copy.deepcopy(aerosol_soa)  total_time = 600  # seconds total_steps = 60  coagulation_sub_step = 1 condensation_sub_step = 50_000  time_step = total_time / total_steps  for step in tqdm(range(total_steps), desc=\"Running Sim\", mininterval=0.5):      # execute condensation process, this is the slowest computationally     # feel free to comment this out to see the effect of coagulation only     # aerosol_process = condensation_process.execute(     #     aerosol=aerosol_process,     #     time_step=time_step,     #     sub_steps=condensation_sub_step,     # )      # execute coagulation process     aerosol_process = coagulation_process.execute(         aerosol=aerosol_process,         time_step=time_step,         sub_steps=coagulation_sub_step,     ) <pre>Running Sim: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 60/60 [00:02&lt;00:00, 25.65it/s]\n</pre> In\u00a0[\u00a0]: Copied! <pre>fig, ax = plt.subplots(figsize=(7, 5))\nax.plot(\n    aerosol_initial.particles.get_radius(),\n    aerosol_initial.particles.get_concentration(),\n    label=\"Initial Seeds\",\n)\nax.plot(\n    aerosol_soa.particles.get_radius(),\n    aerosol_soa.particles.get_concentration(),\n    label=\"20 sec SOA partitioning\",\n)\nax.plot(\n    aerosol_process.particles.get_radius(),\n    aerosol_process.particles.get_concentration(),\n    label=\"600 sec coagulation\",\n    # marker=\".\",\n)\nax.legend(loc=\"upper left\")\nax.set_xscale(\"log\")\nax.grid(alpha=0.25)\nax.set_xlim(left=1e-8, right=1e-6)\nfig.tight_layout()\n</pre> fig, ax = plt.subplots(figsize=(7, 5)) ax.plot(     aerosol_initial.particles.get_radius(),     aerosol_initial.particles.get_concentration(),     label=\"Initial Seeds\", ) ax.plot(     aerosol_soa.particles.get_radius(),     aerosol_soa.particles.get_concentration(),     label=\"20 sec SOA partitioning\", ) ax.plot(     aerosol_process.particles.get_radius(),     aerosol_process.particles.get_concentration(),     label=\"600 sec coagulation\",     # marker=\".\", ) ax.legend(loc=\"upper left\") ax.set_xscale(\"log\") ax.grid(alpha=0.25) ax.set_xlim(left=1e-8, right=1e-6) fig.tight_layout()"},{"location":"Examples/Simulations/Notebooks/Organic_Partitioning_and_Coagulation/#organic-partitioning-coagulation-simulation","title":"Organic Partitioning &amp; Coagulation Simulation\u00b6","text":"<p>This notebook demonstrates how to form secondary organic aerosol (SOA) from a mixture of gas-phase organics and to follow its evolution by Brownian coagulation.</p> <p>We will use a moving bin representation of particles, with vapor-liquid partitioning of organic vapours.</p> <p>Road-map</p> <ol> <li>Define physicochemical inputs</li> <li>Build gas species and the atmosphere</li> <li>Create seed particles and a particle representation</li> <li>Assemble an <code>Aerosol</code> object</li> <li>Run isothermal condensation (20 s)</li> <li>Add Brownian coagulation and continue for 10 min</li> <li>Visualise &amp; discuss results</li> </ol> <p>Concept \u2013 Secondary Organic Aerosol (SOA): particles that originate when low-volatility organic vapours condense onto pre-existing seeds.</p> <p>Concept \u2013 Partitioning: the reversible transfer of a compound between the gas phase and the particle phase until thermodynamic equilibrium is reached.</p> <p>Concept \u2013 Brownian Coagulation: random collisions driven by thermal motion that merge individual particles into larger ones, reducing number concentration while conserving mass.</p>"},{"location":"Examples/Simulations/Notebooks/Organic_Partitioning_and_Coagulation/#physicochemical-inputs","title":"Physicochemical inputs\u00b6","text":"<p>Molecular weight, O:C &amp; H:C ratios, saturation concentrations and total gas-phase concentrations gathered from the literature.</p> <p>O:C ratio (oxygen-to-carbon): proxy for oxidation state \u2013 a higher ratio usually implies higher polarity and lower volatility.</p> <p>c_sat: saturation concentration (often noted C*); at this concentration the compound is in equilibrium between gas and particle phases.</p> <p>All concentrations are specified in \u00b5g m\u207b\u00b3 to mimic experimental data and are converted to SI units by the builders.</p>"},{"location":"Examples/Simulations/Notebooks/Organic_Partitioning_and_Coagulation/#build-gas-phase-species","title":"Build gas-phase species\u00b6","text":"<p>Each species receives a vapour-pressure strategy so that the code can evaluate temperature-dependent properties on the fly. Note: the saturation-concentration builder is a convenient wrapper converting \u03bcg m\u207b\u00b3 \u2192 Pa.</p> <p>Strategy pattern: every species owns a strategy object that knows how to compute its pure vapour pressure \u2013 we can switch correlations without touching core logic.</p> <p><code>SaturationConcentrationVaporPressureBuilder</code> back-calculates vapour pressure from the published saturation concentration C*.</p>"},{"location":"Examples/Simulations/Notebooks/Organic_Partitioning_and_Coagulation/#compose-the-atmosphere","title":"Compose the atmosphere\u00b6","text":"<p>Combine temperature, pressure and the list of partitioning species into a single <code>Atmosphere</code> container.</p> <p>Atmosphere object: central thermodynamic context (temperature &amp; pressure).  All processes query these values rather than carrying their own copies. sulfate vapor pressure</p>"},{"location":"Examples/Simulations/Notebooks/Organic_Partitioning_and_Coagulation/#seed-particles","title":"Seed particles\u00b6","text":"<p>Generate a log-normal size distribution of sulfate seeds and assign species-resolved mass bins. Tip: for speed you may reduce the radius grid \u2013 250 points is rather fine for demonstration purposes.</p> <p>Log-normal distribution: widely observed for atmospheric aerosols; characterised by a modal radius and geometric standard deviation (GSD).</p> <p>We convert the number distribution to a probability-mass function (PMF) so the integral equals the desired particle count.</p>"},{"location":"Examples/Simulations/Notebooks/Organic_Partitioning_and_Coagulation/#particle-representation","title":"Particle representation\u00b6","text":"<p>Attach activity, surface and distribution strategies.  Using <code>SpeciatedMassMovingBin</code> lets the bin boundaries adapt when mass is added.</p> <p>SpeciatedMassMovingBin: bin boundaries adapt when mass is added \u2013 avoids artificial dilution present in fixed-grid schemes.</p> <p>Activity &amp; surface strategies: thermodynamics (ideal, etc.) and surface tension models are swappable components, keeping the main algorithm clean.</p>"},{"location":"Examples/Simulations/Notebooks/Organic_Partitioning_and_Coagulation/#assemble-aerosol","title":"Assemble aerosol\u00b6","text":"<p>Wrap atmosphere + particles into a single high-level object that the dynamical processes will modify in place.</p> <p>Big picture: <code>Aerosol</code> = <code>Atmosphere</code> + <code>ParticleRepresentation</code>. Every subsequent Runnable process expects a single aerosol object and modifies it in place.</p>"},{"location":"Examples/Simulations/Notebooks/Organic_Partitioning_and_Coagulation/#condensation-process","title":"Condensation process\u00b6","text":"<p>We use an isothermal Fuchs\u2013Sutugin formulation. <code>skip_partitioning_indices=[0]</code> excludes sulfate from condensation.</p> <p>Performance hint \u2013 the number of sub-steps controls accuracy.</p> <p><code>update_gases=True</code> removes vapours from the gas pool as they condense, enforcing mass conservation.</p> <p>The <code>RunnableSequence</code> uses the <code>|</code> pipe operator for a fluent interface</p>"},{"location":"Examples/Simulations/Notebooks/Organic_Partitioning_and_Coagulation/#single-20-s-condensation-pulse","title":"Single 20 s condensation pulse\u00b6","text":"<p>Useful for inspecting how much SOA forms before coagulation starts.</p> <p>We pick a very small internal sub-step (<code>\u0394t_sub = 20 s / 100 000 \u2248 2\u00d710\u207b\u2074 s</code>) to capture the rapid initial uptake of vapours onto nano-particles. 10 sec simulation</p>"},{"location":"Examples/Simulations/Notebooks/Organic_Partitioning_and_Coagulation/#coagulation-process","title":"Coagulation process\u00b6","text":"<p>Builder selects a discrete Brownian kernel.  Other kernels are available and can be swapped by changing the builder called.</p> <p>Brownian kernel: collision frequency determined solely by random thermal motion; other kernels can be swapped by changing a single builder call.</p>"},{"location":"Examples/Simulations/Notebooks/Organic_Partitioning_and_Coagulation/#combined-simulation-10-min","title":"Combined simulation (10 min)\u00b6","text":"<p>We alternate long, finely-resolved condensation steps with coarse coagulation steps. Rule of thumb: <code>time_step / sub_steps \u2248 0.01 s</code> keeps condensation stable while minimising overhead.</p> <p>Experiment: toggle condensation on to see if coagulation+condensation changes the particle size distribution.</p> <p>We loop over 60 outer steps of 10 s each to reach 10 min.  Inside every step we could run condensation with many sub-steps while keeping coagulation coarse \u2013 a trade-off between accuracy and speed. .</p>"},{"location":"Examples/Simulations/Notebooks/Organic_Partitioning_and_Coagulation/#results","title":"Results\u00b6","text":"<p>The figure contrasts (i) the initial seed distribution, (ii) mass growth after 20 s of SOA partitioning, and (iii) its further evolution through coagulation.</p> <p>Observe how number concentration drops (coagulation) while the median radius grows (condensation + coagulation). Try commenting out condensation to isolate the effect of pure coagulation broadening the distribution without adding mass.</p>"},{"location":"Examples/Simulations/Notebooks/Organic_Partitioning_and_Coagulation/#summary","title":"Summary\u00b6","text":"<p>This notebook demonstrates how to simulate the formation of secondary organic aerosol (SOA) from gas-phase organics and its evolution by Brownian coagulation.  We used a moving bin representation of particles with vapour-liquid partitioning, allowing us to model the complex interactions between gas-phase species and particle growth.</p>"},{"location":"Examples/Simulations/Notebooks/Soot_Formation_in_Flames/","title":"Soot Formation in Flames","text":"In\u00a0[14]: Copied! <pre># \ud83d\udea7 Install Particula if you're running this in Google Colab\n# Remove the comment below to enable installation\n# !pip install particula[extra] --quiet\n\n# \ud83d\udce6 Import necessary libraries\nimport copy  # to safely duplicate Python objects\nimport matplotlib.pyplot as plt  # for plotting\nimport numpy as np  # numerical tools\nimport particula as par  # the main Particula package\nfrom tqdm import tqdm  # optional: for progress bars during simulation\nfrom typing import Union\nfrom numpy.typing import NDArray\n\nfrom matplotlib.colors import LogNorm\n\n# \ud83c\udfa8 Set default plot styling using Tailwind-inspired colors from Particula\nTAILWIND = par.util.colors.TAILWIND\nbase_color = TAILWIND[\"gray\"][\"600\"]\n\nplt.rcParams.update(\n    {\n        \"text.color\": base_color,\n        \"axes.labelcolor\": base_color,\n        \"figure.figsize\": (5, 4),\n        \"font.size\": 14,\n        \"axes.edgecolor\": base_color,\n        \"axes.labelcolor\": base_color,\n        \"xtick.color\": base_color,\n        \"ytick.color\": base_color,\n        \"pdf.fonttype\": 42,\n        \"ps.fonttype\": 42,\n    }\n)\n\n# \ud83c\udf0c Define the colors for the chemical species involved in the simulation\ncolor_list = (\n    # 1\u20132 ring aromatics (amber)\n    [\n        TAILWIND[\"amber\"][shade]\n        for shade in [\"400\", \"500\", \"600\", \"700\", \"800\", \"900\"]\n    ]\n    +\n    # 3\u20134 ring PAHs (sky)\n    [\n        TAILWIND[\"sky\"][shade]\n        for shade in [\n            \"300\",\n            \"400\",\n            \"500\",\n            \"600\",\n            \"700\",\n            \"800\",\n            \"900\",\n            \"200\",\n        ]\n    ]\n    +\n    # 5\u20137 ring PAHs (rose)\n    [\n        TAILWIND[\"rose\"][shade]\n        for shade in [\n            \"300\",\n            \"400\",\n            \"500\",\n            \"600\",\n            \"700\",\n            \"800\",\n            \"900\",\n            \"200\",\n        ]\n    ]\n    +\n    # Extra-large PAH surrogate (slate)\n    [TAILWIND[\"slate\"][\"800\"]]\n    +\n    # Fullerene (indigo)\n    [TAILWIND[\"indigo\"][\"700\"]]\n)\n</pre> # \ud83d\udea7 Install Particula if you're running this in Google Colab # Remove the comment below to enable installation # !pip install particula[extra] --quiet  # \ud83d\udce6 Import necessary libraries import copy  # to safely duplicate Python objects import matplotlib.pyplot as plt  # for plotting import numpy as np  # numerical tools import particula as par  # the main Particula package from tqdm import tqdm  # optional: for progress bars during simulation from typing import Union from numpy.typing import NDArray  from matplotlib.colors import LogNorm  # \ud83c\udfa8 Set default plot styling using Tailwind-inspired colors from Particula TAILWIND = par.util.colors.TAILWIND base_color = TAILWIND[\"gray\"][\"600\"]  plt.rcParams.update(     {         \"text.color\": base_color,         \"axes.labelcolor\": base_color,         \"figure.figsize\": (5, 4),         \"font.size\": 14,         \"axes.edgecolor\": base_color,         \"axes.labelcolor\": base_color,         \"xtick.color\": base_color,         \"ytick.color\": base_color,         \"pdf.fonttype\": 42,         \"ps.fonttype\": 42,     } )  # \ud83c\udf0c Define the colors for the chemical species involved in the simulation color_list = (     # 1\u20132 ring aromatics (amber)     [         TAILWIND[\"amber\"][shade]         for shade in [\"400\", \"500\", \"600\", \"700\", \"800\", \"900\"]     ]     +     # 3\u20134 ring PAHs (sky)     [         TAILWIND[\"sky\"][shade]         for shade in [             \"300\",             \"400\",             \"500\",             \"600\",             \"700\",             \"800\",             \"900\",             \"200\",         ]     ]     +     # 5\u20137 ring PAHs (rose)     [         TAILWIND[\"rose\"][shade]         for shade in [             \"300\",             \"400\",             \"500\",             \"600\",             \"700\",             \"800\",             \"900\",             \"200\",         ]     ]     +     # Extra-large PAH surrogate (slate)     [TAILWIND[\"slate\"][\"800\"]]     +     # Fullerene (indigo)     [TAILWIND[\"indigo\"][\"700\"]] ) In\u00a0[15]: Copied! <pre># Define species list grouped by volatility\nlist_of_chemicals = [\n    # 1\u20132-ring aromatics (gas-phase precursors, ~65%)\n    \"Benzene\",\n    \"Toluene\",\n    \"Ethylbenzene\",\n    \"p-Xylene\",\n    \"Styrene\",\n    \"Indene\",\n    # 2\u20134-ring PAHs (semi-volatile, ~35%)\n    \"Naphthalene\",\n    \"Acenaphthylene\",\n    \"Acenaphthene\",\n    \"Anthracene\",\n    \"Fluoranthene\",\n    \"Pyrene\",\n    \"Chrysene\",\n    \"Benzo[a]anthracene\",\n    # 5\u20137-ring PAHs (low volatility)\n    \"Benzo[b]fluoranthene\",\n    \"Benzo[k]fluoranthene\",\n    \"Benzo[a]pyrene\",\n    \"Perylene\",\n    \"Benzo[ghi]perylene\",\n    \"Indeno[1,2,3-cd]pyrene\",\n    \"Dibenzo[a,h]anthracene\",\n    \"Coronene\",\n    # Optional \u22657-ring surrogate and soot seed\n    \"Ovalene\",\n    \"Fullerene\",\n]\n\n# Initial mass fractions (normalized)\ninitial_mass_fractions = np.array(\n    [\n        # ------- 1\u20132-ring aromatics (~65%)\n        0.20,\n        0.15,\n        0.10,\n        0.10,\n        0.05,\n        0.05,\n        # ------- 2\u20134-ring PAHs (~35%)\n        0.12068966,\n        0.01931034,\n        0.01448276,\n        0.01448276,\n        0.02896552,\n        0.02896552,\n        0.01448276,\n        0.00965517,\n        # ------- 5\u20137-ring PAHs\n        0.01448276,\n        0.00965517,\n        0.00965517,\n        0.00724138,\n        0.00724138,\n        0.00482759,\n        0.00337931,\n        0.00241379,\n        0.00144828,\n        0.00072414,\n    ],\n    dtype=np.float64,\n)\n\n# Normalize to sum to 1\ninitial_mass_fractions /= np.sum(initial_mass_fractions)\n\n# Initialize property arrays\ndensity_array = np.array([])\nmolar_mass_array = np.array([])\nsurface_tension_array = np.array([])\ncas_name = []\nchemical_dict = {}\n\n# Retrieve and store properties\nfor chem in list_of_chemicals:\n    cas = par.util.get_chemical_search(chem)\n    print(f\"{chem}: {cas}\")\n    chemical_dict[chem] = par.util.get_chemical_stp_properties(cas)\n\n    molar_mass_array = np.append(\n        molar_mass_array, chemical_dict[chem][\"molar_mass\"]\n    )\n    density_array = np.append(density_array, chemical_dict[chem][\"density\"])\n    surface_tension_array = np.append(\n        surface_tension_array, chemical_dict[chem][\"surface_tension\"]\n    )\n    cas_name.append(cas)\n\n# Display property summary\nfor chem, props in chemical_dict.items():\n    print(f\"{chem}:\")\n    print(f\"  Molar Mass: {props['molar_mass']:.4f} kg/mol\")\n    print(f\"  Density: {props['density']:.2f} kg/m\u00b3\")\n    print(f\"  Surface Tension: {props['surface_tension']} N/m\")\n    print(f\"  Vapor Pressure: {props['pure_vapor_pressure']} Pa\\n\")\n</pre> # Define species list grouped by volatility list_of_chemicals = [     # 1\u20132-ring aromatics (gas-phase precursors, ~65%)     \"Benzene\",     \"Toluene\",     \"Ethylbenzene\",     \"p-Xylene\",     \"Styrene\",     \"Indene\",     # 2\u20134-ring PAHs (semi-volatile, ~35%)     \"Naphthalene\",     \"Acenaphthylene\",     \"Acenaphthene\",     \"Anthracene\",     \"Fluoranthene\",     \"Pyrene\",     \"Chrysene\",     \"Benzo[a]anthracene\",     # 5\u20137-ring PAHs (low volatility)     \"Benzo[b]fluoranthene\",     \"Benzo[k]fluoranthene\",     \"Benzo[a]pyrene\",     \"Perylene\",     \"Benzo[ghi]perylene\",     \"Indeno[1,2,3-cd]pyrene\",     \"Dibenzo[a,h]anthracene\",     \"Coronene\",     # Optional \u22657-ring surrogate and soot seed     \"Ovalene\",     \"Fullerene\", ]  # Initial mass fractions (normalized) initial_mass_fractions = np.array(     [         # ------- 1\u20132-ring aromatics (~65%)         0.20,         0.15,         0.10,         0.10,         0.05,         0.05,         # ------- 2\u20134-ring PAHs (~35%)         0.12068966,         0.01931034,         0.01448276,         0.01448276,         0.02896552,         0.02896552,         0.01448276,         0.00965517,         # ------- 5\u20137-ring PAHs         0.01448276,         0.00965517,         0.00965517,         0.00724138,         0.00724138,         0.00482759,         0.00337931,         0.00241379,         0.00144828,         0.00072414,     ],     dtype=np.float64, )  # Normalize to sum to 1 initial_mass_fractions /= np.sum(initial_mass_fractions)  # Initialize property arrays density_array = np.array([]) molar_mass_array = np.array([]) surface_tension_array = np.array([]) cas_name = [] chemical_dict = {}  # Retrieve and store properties for chem in list_of_chemicals:     cas = par.util.get_chemical_search(chem)     print(f\"{chem}: {cas}\")     chemical_dict[chem] = par.util.get_chemical_stp_properties(cas)      molar_mass_array = np.append(         molar_mass_array, chemical_dict[chem][\"molar_mass\"]     )     density_array = np.append(density_array, chemical_dict[chem][\"density\"])     surface_tension_array = np.append(         surface_tension_array, chemical_dict[chem][\"surface_tension\"]     )     cas_name.append(cas)  # Display property summary for chem, props in chemical_dict.items():     print(f\"{chem}:\")     print(f\"  Molar Mass: {props['molar_mass']:.4f} kg/mol\")     print(f\"  Density: {props['density']:.2f} kg/m\u00b3\")     print(f\"  Surface Tension: {props['surface_tension']} N/m\")     print(f\"  Vapor Pressure: {props['pure_vapor_pressure']} Pa\\n\") <pre>Benzene: Benzene\nToluene: Toluene\nEthylbenzene: Ethylbenzene\np-Xylene: p-Xylene\nStyrene: Styrene\nIndene: Indene\nNaphthalene: Naphthalene\nAcenaphthylene: Acenaphthylene\nAcenaphthene: Acenaphthene\nAnthracene: Anthracene\nFluoranthene: Fluoranthene\nPyrene: Pyrene\nChrysene: Chrysene\nBenzo[a]anthracene: Benzo[a]anthracene\nBenzo[b]fluoranthene: Benzo[b]fluoranthene\nBenzo[k]fluoranthene: Benzo[k]fluoranthene\nBenzo[a]pyrene: Benzo[a]pyrene\nPerylene: Perylene\nBenzo[ghi]perylene: Benzo[ghi]perylene\nIndeno[1,2,3-cd]pyrene: Indeno[1,2,3-cd]pyrene\nDibenzo[a,h]anthracene: Dibenzo[a,h]anthracene\nCoronene: Coronene\nOvalene: Ovalene\nFullerene: Fullerene\nBenzene:\n  Molar Mass: 0.0781 kg/mol\n  Density: 873.76 kg/m\u00b3\n  Surface Tension: 0.028206202466830844 N/m\n  Vapor Pressure: 12695.06760788906 Pa\n\nToluene:\n  Molar Mass: 0.0921 kg/mol\n  Density: 862.34 kg/m\u00b3\n  Surface Tension: 0.027906333880214882 N/m\n  Vapor Pressure: 3799.2916085833076 Pa\n\nEthylbenzene:\n  Molar Mass: 0.1062 kg/mol\n  Density: 862.64 kg/m\u00b3\n  Surface Tension: 0.028519673106300977 N/m\n  Vapor Pressure: 1278.8635512049998 Pa\n\np-Xylene:\n  Molar Mass: 0.1062 kg/mol\n  Density: 856.84 kg/m\u00b3\n  Surface Tension: 0.02780489434006062 N/m\n  Vapor Pressure: 1177.6548935579035 Pa\n\nStyrene:\n  Molar Mass: 0.1041 kg/mol\n  Density: 900.52 kg/m\u00b3\n  Surface Tension: 0.030530851011226136 N/m\n  Vapor Pressure: 821.533882502462 Pa\n\nIndene:\n  Molar Mass: 0.1162 kg/mol\n  Density: 957.15 kg/m\u00b3\n  Surface Tension: 0.019075436088789817 N/m\n  Vapor Pressure: 225.95221357669246 Pa\n\nNaphthalene:\n  Molar Mass: 0.1282 kg/mol\n  Density: 1120.20 kg/m\u00b3\n  Surface Tension: 0.041817073351975 N/m\n  Vapor Pressure: 42.179417148049055 Pa\n\nAcenaphthylene:\n  Molar Mass: 0.1522 kg/mol\n  Density: 1113.30 kg/m\u00b3\n  Surface Tension: 0.04143820989061258 N/m\n  Vapor Pressure: 2.83294928153961 Pa\n\nAcenaphthene:\n  Molar Mass: 0.1542 kg/mol\n  Density: 972.47 kg/m\u00b3\n  Surface Tension: 0.0385194992687528 N/m\n  Vapor Pressure: 1.9222921879309003 Pa\n\nAnthracene:\n  Molar Mass: 0.1782 kg/mol\n  Density: 1106.97 kg/m\u00b3\n  Surface Tension: 0.04831768955111898 N/m\n  Vapor Pressure: 0.362912065174679 Pa\n\nFluoranthene:\n  Molar Mass: 0.2023 kg/mol\n  Density: 1116.91 kg/m\u00b3\n  Surface Tension: 0.046639222539928284 N/m\n  Vapor Pressure: 0.0008003908764101553 Pa\n\nPyrene:\n  Molar Mass: 0.2023 kg/mol\n  Density: 1158.87 kg/m\u00b3\n  Surface Tension: 0.04893250644932069 N/m\n  Vapor Pressure: 5.1375589253832836e-05 Pa\n\nChrysene:\n  Molar Mass: 0.2283 kg/mol\n  Density: 1077.02 kg/m\u00b3\n  Surface Tension: 0.04985254377774797 N/m\n  Vapor Pressure: 2.6846652822105422e-05 Pa\n\nBenzo[a]anthracene:\n  Molar Mass: 0.2283 kg/mol\n  Density: 1203.04 kg/m\u00b3\n  Surface Tension: 0.05157277097913564 N/m\n  Vapor Pressure: 5.569142923796036e-05 Pa\n\nBenzo[b]fluoranthene:\n  Molar Mass: 0.2523 kg/mol\n  Density: 1150.91 kg/m\u00b3\n  Surface Tension: 0.050472914014624566 N/m\n  Vapor Pressure: 4.393050525936658e-06 Pa\n\nBenzo[k]fluoranthene:\n  Molar Mass: 0.2523 kg/mol\n  Density: 1171.82 kg/m\u00b3\n  Surface Tension: 0.04582707666133075 N/m\n  Vapor Pressure: 0.0005678510119370869 Pa\n\nBenzo[a]pyrene:\n  Molar Mass: 0.2523 kg/mol\n  Density: 1186.70 kg/m\u00b3\n  Surface Tension: 0.04608662360222815 N/m\n  Vapor Pressure: 0.0004701165050824623 Pa\n\nPerylene:\n  Molar Mass: 0.2523 kg/mol\n  Density: 1145.59 kg/m\u00b3\n  Surface Tension: 0.0461198819597169 N/m\n  Vapor Pressure: 0.00045887128419603445 Pa\n\nBenzo[ghi]perylene:\n  Molar Mass: 0.2763 kg/mol\n  Density: 1175.67 kg/m\u00b3\n  Surface Tension: 0.04702177589801932 N/m\n  Vapor Pressure: 7.126539938521257e-05 Pa\n\nIndeno[1,2,3-cd]pyrene:\n  Molar Mass: 0.2763 kg/mol\n  Density: 1213.67 kg/m\u00b3\n  Surface Tension: 0.04679231808084244 N/m\n  Vapor Pressure: 8.535388889438557e-05 Pa\n\nDibenzo[a,h]anthracene:\n  Molar Mass: 0.2783 kg/mol\n  Density: 1172.69 kg/m\u00b3\n  Surface Tension: 0.04880049181278169 N/m\n  Vapor Pressure: 9.217001932898797e-06 Pa\n\nCoronene:\n  Molar Mass: 0.3004 kg/mol\n  Density: 1116.06 kg/m\u00b3\n  Surface Tension: 0.04653055920308998 N/m\n  Vapor Pressure: 3.467366635539694e-05 Pa\n\nOvalene:\n  Molar Mass: 0.3985 kg/mol\n  Density: 1240.61 kg/m\u00b3\n  Surface Tension: 0.07585556520479782 N/m\n  Vapor Pressure: 7.325250517430775e-14 Pa\n\nFullerene:\n  Molar Mass: 0.7206 kg/mol\n  Density: 1441.72 kg/m\u00b3\n  Surface Tension: 0.040270320922924846 N/m\n  Vapor Pressure: 4.1068395355330673e-17 Pa\n\n</pre> In\u00a0[16]: Copied! <pre># For reproducibility\nnp.random.seed(100)\n\n# Simulation parameters\nnumber_of_samples = 25_000  # Simulated particles\ntotal_number_per_cm3 = 10_000_000  # #/cm\u00b3\nsimulation_volume = number_of_samples / total_number_per_cm3 * 1e-6  # m\u00b3\n\n# Initial gas phase loading and temperature\ntotal_mass_gas_phase = 5e-5  # kg/m\u00b3\ntemperature = 1200  # Initial gas temperature [K]\n\n# Temperature range for property tables\ntemperature_range_table = np.linspace(200, 1500, 200)\n\n# Preallocate property tables\nvapor_pressure_strategy_list = []\nsurface_tension_table = np.zeros(\n    (len(temperature_range_table), len(list_of_chemicals))\n)\nvapor_pressure_table = np.zeros(\n    (len(temperature_range_table), len(list_of_chemicals))\n)\n\n# Loop through chemicals to build property tables\nfor chem_i in list(chemical_dict.keys()):\n    idx = list_of_chemicals.index(chem_i)\n\n    # Vapor pressure vs temperature\n    vapor_pressure_temp = par.util.get_chemical_vapor_pressure(\n        chemical_identifier=chem_i,\n        temperature=temperature_range_table,\n    )\n    vapor_pressure_table[:, idx] = vapor_pressure_temp\n\n    vapor_pressure_strategy = (\n        par.gas.TableVaporPressureBuilder()\n        .set_temperature_table(temperature_range_table, \"K\")\n        .set_vapor_pressure_table(vapor_pressure_temp, \"Pa\")\n        .build()\n    )\n    vapor_pressure_strategy_list.append(vapor_pressure_strategy)\n\n    # Surface tension vs temperature\n    surface_tension_temp = par.util.get_chemical_surface_tension(\n        chemical_identifier=chem_i,\n        temperature=temperature_range_table,\n    )\n    surface_tension_table[:, idx] = surface_tension_temp\n\n# Clean up NaNs or extreme values\nsurface_tension_table = np.nan_to_num(surface_tension_table, nan=2e-2)\nsurface_tension_table = np.clip(surface_tension_table, a_min=2e-2, a_max=None)\nvapor_pressure_table = np.clip(vapor_pressure_table, a_min=1e-50, a_max=1e100)\n\n# \ud83d\udd0d Plot property tables\nfig, ax = plt.subplots(2, 1, figsize=(10, 8), sharex=True)\n\nfor i, chem in enumerate(list_of_chemicals):\n    ax[0].plot(\n        temperature_range_table,\n        surface_tension_table[:, i],\n        label=chem,\n        linewidth=2,\n        color=color_list[i],\n    )\n    ax[1].plot(\n        temperature_range_table,\n        vapor_pressure_table[:, i],\n        label=chem,\n        linewidth=2,\n        color=color_list[i],\n    )\n\nax[0].set_ylabel(\"Surface Tension (N/m)\")\nax[0].set_title(\"Surface Tension vs Temperature\")\nax[0].grid()\n\nax[1].set_yscale(\"log\")\nax[1].set_ylabel(\"Vapor Pressure (Pa)\")\nax[1].set_xlabel(\"Temperature (K)\")\nax[1].set_title(\"Vapor Pressure vs Temperature\")\nax[1].grid()\n\n# Combined legend\nfig.legend(\n    list_of_chemicals,\n    loc=\"center left\",\n    bbox_to_anchor=(1.02, 0.5),\n    title=\"Chemicals\",\n    fontsize=\"small\",\n)\nplt.tight_layout(rect=[0, 0, 1, 1])\nplt.show()\n</pre> # For reproducibility np.random.seed(100)  # Simulation parameters number_of_samples = 25_000  # Simulated particles total_number_per_cm3 = 10_000_000  # #/cm\u00b3 simulation_volume = number_of_samples / total_number_per_cm3 * 1e-6  # m\u00b3  # Initial gas phase loading and temperature total_mass_gas_phase = 5e-5  # kg/m\u00b3 temperature = 1200  # Initial gas temperature [K]  # Temperature range for property tables temperature_range_table = np.linspace(200, 1500, 200)  # Preallocate property tables vapor_pressure_strategy_list = [] surface_tension_table = np.zeros(     (len(temperature_range_table), len(list_of_chemicals)) ) vapor_pressure_table = np.zeros(     (len(temperature_range_table), len(list_of_chemicals)) )  # Loop through chemicals to build property tables for chem_i in list(chemical_dict.keys()):     idx = list_of_chemicals.index(chem_i)      # Vapor pressure vs temperature     vapor_pressure_temp = par.util.get_chemical_vapor_pressure(         chemical_identifier=chem_i,         temperature=temperature_range_table,     )     vapor_pressure_table[:, idx] = vapor_pressure_temp      vapor_pressure_strategy = (         par.gas.TableVaporPressureBuilder()         .set_temperature_table(temperature_range_table, \"K\")         .set_vapor_pressure_table(vapor_pressure_temp, \"Pa\")         .build()     )     vapor_pressure_strategy_list.append(vapor_pressure_strategy)      # Surface tension vs temperature     surface_tension_temp = par.util.get_chemical_surface_tension(         chemical_identifier=chem_i,         temperature=temperature_range_table,     )     surface_tension_table[:, idx] = surface_tension_temp  # Clean up NaNs or extreme values surface_tension_table = np.nan_to_num(surface_tension_table, nan=2e-2) surface_tension_table = np.clip(surface_tension_table, a_min=2e-2, a_max=None) vapor_pressure_table = np.clip(vapor_pressure_table, a_min=1e-50, a_max=1e100)  # \ud83d\udd0d Plot property tables fig, ax = plt.subplots(2, 1, figsize=(10, 8), sharex=True)  for i, chem in enumerate(list_of_chemicals):     ax[0].plot(         temperature_range_table,         surface_tension_table[:, i],         label=chem,         linewidth=2,         color=color_list[i],     )     ax[1].plot(         temperature_range_table,         vapor_pressure_table[:, i],         label=chem,         linewidth=2,         color=color_list[i],     )  ax[0].set_ylabel(\"Surface Tension (N/m)\") ax[0].set_title(\"Surface Tension vs Temperature\") ax[0].grid()  ax[1].set_yscale(\"log\") ax[1].set_ylabel(\"Vapor Pressure (Pa)\") ax[1].set_xlabel(\"Temperature (K)\") ax[1].set_title(\"Vapor Pressure vs Temperature\") ax[1].grid()  # Combined legend fig.legend(     list_of_chemicals,     loc=\"center left\",     bbox_to_anchor=(1.02, 0.5),     title=\"Chemicals\",     fontsize=\"small\", ) plt.tight_layout(rect=[0, 0, 1, 1]) plt.show() In\u00a0[17]: Copied! <pre># Compute gas-phase concentration [kg/m\u00b3]\nconcentration_gas = initial_mass_fractions * total_mass_gas_phase\n\n# Initialize gas-phase species with vapor pressure strategy\ngas_species = (\n    par.gas.GasSpeciesBuilder()\n    .set_name(np.array(list_of_chemicals))\n    .set_molar_mass(molar_mass_array, \"kg/mol\")\n    .set_partitioning(True)\n    .set_vapor_pressure_strategy(vapor_pressure_strategy_list)\n    .set_concentration(concentration_gas, \"kg/m^3\")\n    .build()\n)\n\n# Define atmospheric conditions for the parcel\natmosphere = (\n    par.gas.AtmosphereBuilder()\n    .set_more_partitioning_species(gas_species)\n    .set_temperature(temperature, \"K\")\n    .set_pressure(1, \"atm\")\n    .build()\n)\n</pre> # Compute gas-phase concentration [kg/m\u00b3] concentration_gas = initial_mass_fractions * total_mass_gas_phase  # Initialize gas-phase species with vapor pressure strategy gas_species = (     par.gas.GasSpeciesBuilder()     .set_name(np.array(list_of_chemicals))     .set_molar_mass(molar_mass_array, \"kg/mol\")     .set_partitioning(True)     .set_vapor_pressure_strategy(vapor_pressure_strategy_list)     .set_concentration(concentration_gas, \"kg/m^3\")     .build() )  # Define atmospheric conditions for the parcel atmosphere = (     par.gas.AtmosphereBuilder()     .set_more_partitioning_species(gas_species)     .set_temperature(temperature, \"K\")     .set_pressure(1, \"atm\")     .build() ) In\u00a0[18]: Copied! <pre># Generate bi-modal seed particle distribution [m]\nradii_seeds = par.particles.get_lognormal_sample_distribution(\n    mode=np.array([1e-9, 5e-9]),  # 1 nm and 5 nm modes\n    geometric_standard_deviation=np.array([1.8, 1.8]),\n    number_of_particles=np.array([1, 0.5]),  # relative mode strength\n    number_of_samples=number_of_samples,\n)\n\n# Calculate seed mass assuming all are pure fullerene\nmass_seeds = (4 / 3) * np.pi * (radii_seeds**3) * density_array[-1]\n\n# Initialize mass speciation matrix: all mass in fullerene (last index)\nmass_speciation = np.zeros((number_of_samples, len(list_of_chemicals)))\nmass_speciation[:, -1] = mass_seeds\n\n# Activity strategy (ideal molar)\nactivity_strategy = (\n    par.particles.ActivityIdealMolarBuilder()\n    .set_molar_mass(molar_mass_array, \"kg/mol\")\n    .build()\n)\n\n# Phase indices: all condensed except the seed\nphases = np.ones_like(density_array)\nphases[-1] = 0  # last species (fullerene) is seed, not condensing\n\n# Surface tension strategy (temperature-dependent)\nsurface_strategy = (\n    par.particles.SurfaceStrategyMassBuilder()\n    .set_surface_tension(surface_tension_array, \"N/m\")\n    .set_density(density_array, \"kg/m^3\")\n    .set_phase_index(phases)\n    .set_surface_tension_table(surface_tension_table, \"N/m\")\n    .set_temperature_table(temperature_range_table, \"K\")\n    .build()\n)\n\n# Build the particle representation\nresolved_masses = (\n    par.particles.ResolvedParticleMassRepresentationBuilder()\n    .set_distribution_strategy(par.particles.ParticleResolvedSpeciatedMass())\n    .set_activity_strategy(activity_strategy)\n    .set_surface_strategy(surface_strategy)\n    .set_mass(mass_speciation, \"kg\")\n    .set_density(density_array, \"kg/m^3\")\n    .set_charge(0)  # neutral\n    .set_volume(simulation_volume, \"m^3\")\n    .build()\n)\n\n# Wrap into full aerosol system with gas phase\naerosol = par.Aerosol(atmosphere=atmosphere, particles=resolved_masses)\nprint(aerosol)\n\n# \ud83d\udcca Plot the initial size distribution\nfig, ax = plt.subplots()\nax.hist(np.log10(resolved_masses.get_radius()), bins=50, alpha=0.5)\nax.set_xlabel(\"log10(Radius [m])\")\nax.set_ylabel(\"Bin counts\")\nax.set_title(\"Initial Particle Size Distribution\")\nplt.show()\n</pre> # Generate bi-modal seed particle distribution [m] radii_seeds = par.particles.get_lognormal_sample_distribution(     mode=np.array([1e-9, 5e-9]),  # 1 nm and 5 nm modes     geometric_standard_deviation=np.array([1.8, 1.8]),     number_of_particles=np.array([1, 0.5]),  # relative mode strength     number_of_samples=number_of_samples, )  # Calculate seed mass assuming all are pure fullerene mass_seeds = (4 / 3) * np.pi * (radii_seeds**3) * density_array[-1]  # Initialize mass speciation matrix: all mass in fullerene (last index) mass_speciation = np.zeros((number_of_samples, len(list_of_chemicals))) mass_speciation[:, -1] = mass_seeds  # Activity strategy (ideal molar) activity_strategy = (     par.particles.ActivityIdealMolarBuilder()     .set_molar_mass(molar_mass_array, \"kg/mol\")     .build() )  # Phase indices: all condensed except the seed phases = np.ones_like(density_array) phases[-1] = 0  # last species (fullerene) is seed, not condensing  # Surface tension strategy (temperature-dependent) surface_strategy = (     par.particles.SurfaceStrategyMassBuilder()     .set_surface_tension(surface_tension_array, \"N/m\")     .set_density(density_array, \"kg/m^3\")     .set_phase_index(phases)     .set_surface_tension_table(surface_tension_table, \"N/m\")     .set_temperature_table(temperature_range_table, \"K\")     .build() )  # Build the particle representation resolved_masses = (     par.particles.ResolvedParticleMassRepresentationBuilder()     .set_distribution_strategy(par.particles.ParticleResolvedSpeciatedMass())     .set_activity_strategy(activity_strategy)     .set_surface_strategy(surface_strategy)     .set_mass(mass_speciation, \"kg\")     .set_density(density_array, \"kg/m^3\")     .set_charge(0)  # neutral     .set_volume(simulation_volume, \"m^3\")     .build() )  # Wrap into full aerosol system with gas phase aerosol = par.Aerosol(atmosphere=atmosphere, particles=resolved_masses) print(aerosol)  # \ud83d\udcca Plot the initial size distribution fig, ax = plt.subplots() ax.hist(np.log10(resolved_masses.get_radius()), bins=50, alpha=0.5) ax.set_xlabel(\"log10(Radius [m])\") ax.set_ylabel(\"Bin counts\") ax.set_title(\"Initial Particle Size Distribution\") plt.show() <pre>Gas mixture at 1200 K, 101325.0 Pa, partitioning=['Benzene' 'Toluene' 'Ethylbenzene' 'p-Xylene' 'Styrene' 'Indene'\n 'Naphthalene' 'Acenaphthylene' 'Acenaphthene' 'Anthracene' 'Fluoranthene'\n 'Pyrene' 'Chrysene' 'Benzo[a]anthracene' 'Benzo[b]fluoranthene'\n 'Benzo[k]fluoranthene' 'Benzo[a]pyrene' 'Perylene' 'Benzo[ghi]perylene'\n 'Indeno[1,2,3-cd]pyrene' 'Dibenzo[a,h]anthracene' 'Coronene' 'Ovalene'\n 'Fullerene'], gas_only_species=None\nParticle Representation:\n\tStrategy: ParticleResolvedSpeciatedMass\n\tActivity: ActivityIdealMolar\n\tSurface: SurfaceStrategyMass\n\tMass Concentration: 1.279e-08 [kg/m^3]\n\tNumber Concentration: 1.000e+13 [#/m^3]\n</pre> In\u00a0[19]: Copied! <pre># \ud83c\udf00 Condensation strategy setup (isothermal)\ncondensation_strategy = par.dynamics.CondensationIsothermal(\n    molar_mass=np.array(molar_mass_array),\n    diffusion_coefficient=2e-5,  # m\u00b2/s\n    accommodation_coefficient=1.0,  # perfect uptake\n    skip_partitioning_indices=[23],  # skip \"Fullerene\"\n)\n\n# Wrap into condensation process object\ncondensation_process = par.dynamics.MassCondensation(condensation_strategy)\n\n# \u26ab Coagulation strategy (Brownian motion)\ncoagulation_strategy = (\n    par.dynamics.BrownianCoagulationBuilder()\n    .set_distribution_type(\"particle_resolved\")\n    .build()\n)\n\n# Wrap into coagulation process object\ncoagulation_process = par.dynamics.Coagulation(coagulation_strategy)\n</pre> # \ud83c\udf00 Condensation strategy setup (isothermal) condensation_strategy = par.dynamics.CondensationIsothermal(     molar_mass=np.array(molar_mass_array),     diffusion_coefficient=2e-5,  # m\u00b2/s     accommodation_coefficient=1.0,  # perfect uptake     skip_partitioning_indices=[23],  # skip \"Fullerene\" )  # Wrap into condensation process object condensation_process = par.dynamics.MassCondensation(condensation_strategy)  # \u26ab Coagulation strategy (Brownian motion) coagulation_strategy = (     par.dynamics.BrownianCoagulationBuilder()     .set_distribution_type(\"particle_resolved\")     .build() )  # Wrap into coagulation process object coagulation_process = par.dynamics.Coagulation(coagulation_strategy) In\u00a0[20]: Copied! <pre># %% Temperature cooling setup\n\ndef temperature_profile(\n    time: Union[float, NDArray[np.float64]],\n    initial_temperature: float = 1200.0,\n    intermediate_temperature: float = 700.0,\n    ambient_temperature: float = 298.0,\n    fast_e_folding_time: float = 0.05,\n    slow_e_folding_time: float = 4.0,\n) -&gt; Union[float, NDArray[np.float64]]:\n    \"\"\"Compute a two-stage exponential cooling profile [K].\n\n    Arguments:\n        time: Time after emission [s].\n        initial_temperature: Initial temperature at t = 0 [K].\n        intermediate_temperature: Intermediate temperature level [K].\n        ambient_temperature: Ambient (final) temperature [K].\n        fast_e_folding_time: Fast cooling e-folding time constant [s].\n        slow_e_folding_time: Slow cooling e-folding time constant [s].\n\n    Returns:\n        Temperature as a function of time [K], with two exponential\n        decay components toward the ambient temperature.\n    \"\"\"\n    t_array = np.asanyarray(time, dtype=float)\n    fast_decay = (initial_temperature - ambient_temperature) * np.exp(\n        -t_array / fast_e_folding_time\n    )\n    slow_decay = (intermediate_temperature - ambient_temperature) * np.exp(\n        -t_array / slow_e_folding_time\n    )\n    return ambient_temperature + fast_decay + slow_decay\n</pre> # %% Temperature cooling setup  def temperature_profile(     time: Union[float, NDArray[np.float64]],     initial_temperature: float = 1200.0,     intermediate_temperature: float = 700.0,     ambient_temperature: float = 298.0,     fast_e_folding_time: float = 0.05,     slow_e_folding_time: float = 4.0, ) -&gt; Union[float, NDArray[np.float64]]:     \"\"\"Compute a two-stage exponential cooling profile [K].      Arguments:         time: Time after emission [s].         initial_temperature: Initial temperature at t = 0 [K].         intermediate_temperature: Intermediate temperature level [K].         ambient_temperature: Ambient (final) temperature [K].         fast_e_folding_time: Fast cooling e-folding time constant [s].         slow_e_folding_time: Slow cooling e-folding time constant [s].      Returns:         Temperature as a function of time [K], with two exponential         decay components toward the ambient temperature.     \"\"\"     t_array = np.asanyarray(time, dtype=float)     fast_decay = (initial_temperature - ambient_temperature) * np.exp(         -t_array / fast_e_folding_time     )     slow_decay = (intermediate_temperature - ambient_temperature) * np.exp(         -t_array / slow_e_folding_time     )     return ambient_temperature + fast_decay + slow_decay In\u00a0[24]: Copied! <pre># Show initial aerosol state\nprint(aerosol)\n\n# Make a copy to apply dynamic updates\naerosol_process = copy.deepcopy(aerosol)\n\n# Simulation timing\ntotal_time = 20  # seconds\ntotal_steps = 500\n\ncoagulation_sub_step = 1\ncondensation_sub_step = 50\n\ntime_step = total_time / total_steps\ntime_array = np.linspace(0, total_time, total_steps)\n# Alternative: use logspace for finer early-time resolution\n# time_array = np.logspace(-6, np.log10(total_time), total_steps)\n\ntime_len = len(time_array)\n\n# Temperature profile over time\ntemperature_array = temperature_profile(\n    time_array,\n    initial_temperature=1200.0,\n    intermediate_temperature=700.0,\n    ambient_temperature=300.0,\n    fast_e_folding_time=0.05,\n    slow_e_folding_time=6.0,\n)\n\n# Set initial temperature in atmosphere\naerosol_process.atmosphere.temperature = temperature_array[0]\n\n# Plot the cooling profile\nfig, ax = plt.subplots(figsize=(7, 5))\nax.plot(\n    time_array,\n    temperature_array,\n    color=TAILWIND[\"rose\"][\"500\"],\n    label=\"Temperature Profile\",\n    linewidth=4,\n    linestyle=\"--\",\n)\nax.set_xlabel(\"Time (s)\")\nax.set_ylabel(\"Temperature (K)\")\nax.set_title(\"Flame Emission Temperature Profile\")\nax.grid()\nplt.tight_layout()\nplt.show()\n</pre> # Show initial aerosol state print(aerosol)  # Make a copy to apply dynamic updates aerosol_process = copy.deepcopy(aerosol)  # Simulation timing total_time = 20  # seconds total_steps = 500  coagulation_sub_step = 1 condensation_sub_step = 50  time_step = total_time / total_steps time_array = np.linspace(0, total_time, total_steps) # Alternative: use logspace for finer early-time resolution # time_array = np.logspace(-6, np.log10(total_time), total_steps)  time_len = len(time_array)  # Temperature profile over time temperature_array = temperature_profile(     time_array,     initial_temperature=1200.0,     intermediate_temperature=700.0,     ambient_temperature=300.0,     fast_e_folding_time=0.05,     slow_e_folding_time=6.0, )  # Set initial temperature in atmosphere aerosol_process.atmosphere.temperature = temperature_array[0]  # Plot the cooling profile fig, ax = plt.subplots(figsize=(7, 5)) ax.plot(     time_array,     temperature_array,     color=TAILWIND[\"rose\"][\"500\"],     label=\"Temperature Profile\",     linewidth=4,     linestyle=\"--\", ) ax.set_xlabel(\"Time (s)\") ax.set_ylabel(\"Temperature (K)\") ax.set_title(\"Flame Emission Temperature Profile\") ax.grid() plt.tight_layout() plt.show() <pre>Gas mixture at 1200 K, 101325.0 Pa, partitioning=['Benzene' 'Toluene' 'Ethylbenzene' 'p-Xylene' 'Styrene' 'Indene'\n 'Naphthalene' 'Acenaphthylene' 'Acenaphthene' 'Anthracene' 'Fluoranthene'\n 'Pyrene' 'Chrysene' 'Benzo[a]anthracene' 'Benzo[b]fluoranthene'\n 'Benzo[k]fluoranthene' 'Benzo[a]pyrene' 'Perylene' 'Benzo[ghi]perylene'\n 'Indeno[1,2,3-cd]pyrene' 'Dibenzo[a,h]anthracene' 'Coronene' 'Ovalene'\n 'Fullerene'], gas_only_species=None\nParticle Representation:\n\tStrategy: ParticleResolvedSpeciatedMass\n\tActivity: ActivityIdealMolar\n\tSurface: SurfaceStrategyMass\n\tMass Concentration: 1.279e-08 [kg/m^3]\n\tNumber Concentration: 1.000e+13 [#/m^3]\n</pre> In\u00a0[25]: Copied! <pre># Set up histogram bins for radius distribution\nbins_lognormal = np.logspace(-10, -6, 200)  # 0.1 nm to 1 \u03bcm\ndistribution_counts = np.zeros((time_len, len(bins_lognormal) - 1))\n\n# Time series storage\nmass_concentration = np.zeros_like(time_array)  # kg/m\u00b3\nmode_diameter = np.zeros_like(time_array)  # m\nspecies_mass = np.zeros((time_len, len(list_of_chemicals)))  # kg\n\n# Simulation loop\nfor step, t in enumerate(\n    tqdm(time_array, desc=\"Running Sim\", mininterval=0.5)\n):\n    if step &gt; 0:\n        # Update temperature\n        aerosol_process.atmosphere.temperature = temperature_array[step]\n\n        # --- Condensation process (optional toggle for speed) ---\n        aerosol_process = condensation_process.execute(\n            aerosol=aerosol_process,\n            time_step=time_step,\n            sub_steps=condensation_sub_step,\n        )\n\n        # --- Coagulation process ---\n        aerosol_process = coagulation_process.execute(\n            aerosol=aerosol_process,\n            time_step=time_step,\n            sub_steps=coagulation_sub_step,\n        )\n\n    # Record radius distribution\n    distribution_counts[step, :], edges = np.histogram(\n        aerosol_process.particles.get_radius(clone=True),\n        bins=bins_lognormal,\n        density=False,\n    )\n\n    # Total particle-phase mass [kg/m\u00b3]\n    mass_concentration[step] = (\n        aerosol_process.particles.get_mass_concentration(clone=True)\n    )\n\n    # Mean particle radius [m]\n    radius_temp = aerosol_process.particles.get_radius(clone=True)\n    mask_valid = radius_temp &gt; 0\n    mode_diameter[step] = np.mean(radius_temp[mask_valid])\n\n    # Species-specific particle mass [kg]\n    species_temp = aerosol_process.particles.get_species_mass(clone=True)\n    species_mass[step, :] = np.sum(species_temp, axis=0)\n\n# Convert counts and masses to concentrations [#/m\u00b3] and [kg/m\u00b3]\nconcentrations = distribution_counts / simulation_volume\nspecies_mass = species_mass / simulation_volume\n\n# Final aerosol state\nprint(aerosol_process)\n</pre> # Set up histogram bins for radius distribution bins_lognormal = np.logspace(-10, -6, 200)  # 0.1 nm to 1 \u03bcm distribution_counts = np.zeros((time_len, len(bins_lognormal) - 1))  # Time series storage mass_concentration = np.zeros_like(time_array)  # kg/m\u00b3 mode_diameter = np.zeros_like(time_array)  # m species_mass = np.zeros((time_len, len(list_of_chemicals)))  # kg  # Simulation loop for step, t in enumerate(     tqdm(time_array, desc=\"Running Sim\", mininterval=0.5) ):     if step &gt; 0:         # Update temperature         aerosol_process.atmosphere.temperature = temperature_array[step]          # --- Condensation process (optional toggle for speed) ---         aerosol_process = condensation_process.execute(             aerosol=aerosol_process,             time_step=time_step,             sub_steps=condensation_sub_step,         )          # --- Coagulation process ---         aerosol_process = coagulation_process.execute(             aerosol=aerosol_process,             time_step=time_step,             sub_steps=coagulation_sub_step,         )      # Record radius distribution     distribution_counts[step, :], edges = np.histogram(         aerosol_process.particles.get_radius(clone=True),         bins=bins_lognormal,         density=False,     )      # Total particle-phase mass [kg/m\u00b3]     mass_concentration[step] = (         aerosol_process.particles.get_mass_concentration(clone=True)     )      # Mean particle radius [m]     radius_temp = aerosol_process.particles.get_radius(clone=True)     mask_valid = radius_temp &gt; 0     mode_diameter[step] = np.mean(radius_temp[mask_valid])      # Species-specific particle mass [kg]     species_temp = aerosol_process.particles.get_species_mass(clone=True)     species_mass[step, :] = np.sum(species_temp, axis=0)  # Convert counts and masses to concentrations [#/m\u00b3] and [kg/m\u00b3] concentrations = distribution_counts / simulation_volume species_mass = species_mass / simulation_volume  # Final aerosol state print(aerosol_process) <pre>Running Sim: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 500/500 [08:28&lt;00:00,  1.02s/it]</pre> <pre>Gas mixture at 314.26959733890095 K, 101325.0 Pa, partitioning=['Benzene' 'Toluene' 'Ethylbenzene' 'p-Xylene' 'Styrene' 'Indene'\n 'Naphthalene' 'Acenaphthylene' 'Acenaphthene' 'Anthracene' 'Fluoranthene'\n 'Pyrene' 'Chrysene' 'Benzo[a]anthracene' 'Benzo[b]fluoranthene'\n 'Benzo[k]fluoranthene' 'Benzo[a]pyrene' 'Perylene' 'Benzo[ghi]perylene'\n 'Indeno[1,2,3-cd]pyrene' 'Dibenzo[a,h]anthracene' 'Coronene' 'Ovalene'\n 'Fullerene'], gas_only_species=None\nParticle Representation:\n\tStrategy: ParticleResolvedSpeciatedMass\n\tActivity: ActivityIdealMolar\n\tSurface: SurfaceStrategyMass\n\tMass Concentration: 8.297e-06 [kg/m^3]\n\tNumber Concentration: 7.579e+12 [#/m^3]\n</pre> <pre>\n</pre> In\u00a0[27]: Copied! <pre>dp_in_nm = 2 * 1e9  # Convert radius [m] \u2192 diameter [nm]\n\n# Plot 1: Mass concentration over time\nfig, ax = plt.subplots(figsize=(7, 5))\nax.plot(\n    time_array,\n    mass_concentration,\n    color=TAILWIND[\"sky\"][\"800\"],\n    linewidth=6,\n)\nax.set_xlabel(\"Time (s)\")\nax.set_ylabel(\"Mass Concentration (kg/m\u00b3)\")\nax.set_title(\"Mass Concentration Over Time\")\nax.grid()\n\n# Add temperature on second axis\ntwinx = ax.twinx()\ntwinx.plot(\n    time_array,\n    temperature_array,\n    color=TAILWIND[\"rose\"][\"500\"],\n    linestyle=\"--\",\n    linewidth=4,\n)\ntwinx.set_ylabel(\"Temperature (K)\", color=TAILWIND[\"rose\"][\"500\"])\ntwinx.tick_params(axis=\"y\", labelcolor=TAILWIND[\"rose\"][\"500\"])\n\nplt.xticks(rotation=45)\nplt.tight_layout()\nplt.show()\n\n# Plot 2: Mean diameter over time\nfig, ax = plt.subplots(figsize=(7, 5))\nax.plot(\n    time_array,\n    mode_diameter * dp_in_nm,  # mean diameter [nm]\n    color=TAILWIND[\"sky\"][\"800\"],\n    linewidth=6,\n)\nax.set_xlabel(\"Time (s)\")\nax.set_ylabel(\"Mean Diameter (nm)\")\nax.set_title(\"Mean Particle Diameter Over Time\")\nax.grid()\n\n# Add temperature on second axis\ntwinx = ax.twinx()\ntwinx.plot(\n    time_array,\n    temperature_array,\n    color=TAILWIND[\"rose\"][\"500\"],\n    linestyle=\"--\",\n    linewidth=4,\n    label=\"Temperature (K)\",\n)\ntwinx.set_ylabel(\"Temperature (K)\", color=TAILWIND[\"rose\"][\"500\"])\ntwinx.tick_params(axis=\"y\", labelcolor=TAILWIND[\"rose\"][\"500\"])\n\nplt.xticks(rotation=45)\nplt.tight_layout()\nplt.show()\n</pre> dp_in_nm = 2 * 1e9  # Convert radius [m] \u2192 diameter [nm]  # Plot 1: Mass concentration over time fig, ax = plt.subplots(figsize=(7, 5)) ax.plot(     time_array,     mass_concentration,     color=TAILWIND[\"sky\"][\"800\"],     linewidth=6, ) ax.set_xlabel(\"Time (s)\") ax.set_ylabel(\"Mass Concentration (kg/m\u00b3)\") ax.set_title(\"Mass Concentration Over Time\") ax.grid()  # Add temperature on second axis twinx = ax.twinx() twinx.plot(     time_array,     temperature_array,     color=TAILWIND[\"rose\"][\"500\"],     linestyle=\"--\",     linewidth=4, ) twinx.set_ylabel(\"Temperature (K)\", color=TAILWIND[\"rose\"][\"500\"]) twinx.tick_params(axis=\"y\", labelcolor=TAILWIND[\"rose\"][\"500\"])  plt.xticks(rotation=45) plt.tight_layout() plt.show()  # Plot 2: Mean diameter over time fig, ax = plt.subplots(figsize=(7, 5)) ax.plot(     time_array,     mode_diameter * dp_in_nm,  # mean diameter [nm]     color=TAILWIND[\"sky\"][\"800\"],     linewidth=6, ) ax.set_xlabel(\"Time (s)\") ax.set_ylabel(\"Mean Diameter (nm)\") ax.set_title(\"Mean Particle Diameter Over Time\") ax.grid()  # Add temperature on second axis twinx = ax.twinx() twinx.plot(     time_array,     temperature_array,     color=TAILWIND[\"rose\"][\"500\"],     linestyle=\"--\",     linewidth=4,     label=\"Temperature (K)\", ) twinx.set_ylabel(\"Temperature (K)\", color=TAILWIND[\"rose\"][\"500\"]) twinx.tick_params(axis=\"y\", labelcolor=TAILWIND[\"rose\"][\"500\"])  plt.xticks(rotation=45) plt.tight_layout() plt.show() In\u00a0[26]: Copied! <pre># \ud83d\udcca Plot 1: Absolute species mass concentration [kg/m\u00b3]\nfig, ax = plt.subplots(figsize=(8, 6))\n\n# stackplot expects shape (n_series, n_times), so transpose\nax.stackplot(\n    time_array,\n    species_mass.T,  # shape (n_species, n_time)\n    labels=list_of_chemicals,\n    colors=color_list,\n    alpha=1.0,\n)\n\nax.set_xlabel(\"Time (s)\")\nax.set_ylabel(\"Species Mass Concentration (kg/m\u00b3)\")\nax.set_title(\"Particle-Phase Species Mass Over Time\")\nax.grid(True)\n\n# Overlay temperature curve\ntwinx = ax.twinx()\ntwinx.plot(\n    time_array,\n    temperature_array,\n    color=TAILWIND[\"rose\"][\"500\"],\n    linestyle=\"--\",\n    label=\"Temperature (K)\",\n    linewidth=4,\n)\ntwinx.set_ylabel(\"Temperature (K)\", color=TAILWIND[\"rose\"][\"500\"])\ntwinx.tick_params(axis=\"y\", labelcolor=TAILWIND[\"rose\"][\"500\"])\n\n# External legend\nfig.legend(\n    list_of_chemicals,\n    loc=\"center left\",\n    bbox_to_anchor=(1.02, 0.5),\n    title=\"Chemicals\",\n    fontsize=\"small\",\n)\nplt.tight_layout(rect=[0, 0, 1, 1])\nplt.show()\n\n# \ud83d\udcca Plot 2: Mass fraction (normalized by total particle mass)\nmass_fraction = species_mass / np.sum(species_mass, axis=1, keepdims=True)\n\nfig, ax = plt.subplots(figsize=(8, 6))\nax.stackplot(\n    time_array,\n    mass_fraction.T,\n    labels=list_of_chemicals,\n    colors=color_list,\n    alpha=1.0,\n)\n\nax.set_xlabel(\"Time (s)\")\nax.set_ylabel(\"Mean Mass Fraction in Particles\")\nax.set_title(\"Species Mass Fractions in Particle Phase\")\nax.grid(True)\n\n# Overlay temperature\ntwinx = ax.twinx()\ntwinx.plot(\n    time_array,\n    temperature_array,\n    color=TAILWIND[\"rose\"][\"500\"],\n    linestyle=\"--\",\n    label=\"Temperature (K)\",\n    linewidth=4,\n)\ntwinx.set_ylabel(\"Temperature (K)\", color=TAILWIND[\"rose\"][\"500\"])\ntwinx.tick_params(axis=\"y\", labelcolor=TAILWIND[\"rose\"][\"500\"])\n\nfig.legend(\n    list_of_chemicals,\n    loc=\"center left\",\n    bbox_to_anchor=(1.02, 0.5),\n    title=\"Chemicals\",\n    fontsize=\"small\",\n)\nplt.tight_layout(rect=[0, 0, 1, 1])\nplt.show()\n</pre> # \ud83d\udcca Plot 1: Absolute species mass concentration [kg/m\u00b3] fig, ax = plt.subplots(figsize=(8, 6))  # stackplot expects shape (n_series, n_times), so transpose ax.stackplot(     time_array,     species_mass.T,  # shape (n_species, n_time)     labels=list_of_chemicals,     colors=color_list,     alpha=1.0, )  ax.set_xlabel(\"Time (s)\") ax.set_ylabel(\"Species Mass Concentration (kg/m\u00b3)\") ax.set_title(\"Particle-Phase Species Mass Over Time\") ax.grid(True)  # Overlay temperature curve twinx = ax.twinx() twinx.plot(     time_array,     temperature_array,     color=TAILWIND[\"rose\"][\"500\"],     linestyle=\"--\",     label=\"Temperature (K)\",     linewidth=4, ) twinx.set_ylabel(\"Temperature (K)\", color=TAILWIND[\"rose\"][\"500\"]) twinx.tick_params(axis=\"y\", labelcolor=TAILWIND[\"rose\"][\"500\"])  # External legend fig.legend(     list_of_chemicals,     loc=\"center left\",     bbox_to_anchor=(1.02, 0.5),     title=\"Chemicals\",     fontsize=\"small\", ) plt.tight_layout(rect=[0, 0, 1, 1]) plt.show()  # \ud83d\udcca Plot 2: Mass fraction (normalized by total particle mass) mass_fraction = species_mass / np.sum(species_mass, axis=1, keepdims=True)  fig, ax = plt.subplots(figsize=(8, 6)) ax.stackplot(     time_array,     mass_fraction.T,     labels=list_of_chemicals,     colors=color_list,     alpha=1.0, )  ax.set_xlabel(\"Time (s)\") ax.set_ylabel(\"Mean Mass Fraction in Particles\") ax.set_title(\"Species Mass Fractions in Particle Phase\") ax.grid(True)  # Overlay temperature twinx = ax.twinx() twinx.plot(     time_array,     temperature_array,     color=TAILWIND[\"rose\"][\"500\"],     linestyle=\"--\",     label=\"Temperature (K)\",     linewidth=4, ) twinx.set_ylabel(\"Temperature (K)\", color=TAILWIND[\"rose\"][\"500\"]) twinx.tick_params(axis=\"y\", labelcolor=TAILWIND[\"rose\"][\"500\"])  fig.legend(     list_of_chemicals,     loc=\"center left\",     bbox_to_anchor=(1.02, 0.5),     title=\"Chemicals\",     fontsize=\"small\", ) plt.tight_layout(rect=[0, 0, 1, 1]) plt.show() In\u00a0[30]: Copied! <pre>fig, ax = plt.subplots(figsize=(7, 5))\n\n# Create mesh grid: time vs radius bins (left edges only)\nX, Y = np.meshgrid(time_array, edges[:-1])\n\n# Plot number concentration on a log scale\nmesh = ax.pcolormesh(\n    X,\n    Y,\n    concentrations.T,  # shape (n_bins, n_times)\n    shading=\"auto\",\n    norm=LogNorm(\n        vmin=concentrations[concentrations &gt; 0].min(),\n        vmax=concentrations.max(),\n    ),\n)\n\nax.set_yscale(\"log\")\nax.set_ylim(5e-10, 1e-7)\nax.set_xlabel(\"Time (s)\")\nax.set_ylabel(\"Particle Radius (m)\")\nax.set_title(\"Time-Evolving Particle Size Distribution\")\n\n# Colorbar for number concentration\nfig.colorbar(mesh, label=\"Number Concentration (#/m\u00b3)\")\n\nplt.tight_layout()\nplt.show()\n</pre> fig, ax = plt.subplots(figsize=(7, 5))  # Create mesh grid: time vs radius bins (left edges only) X, Y = np.meshgrid(time_array, edges[:-1])  # Plot number concentration on a log scale mesh = ax.pcolormesh(     X,     Y,     concentrations.T,  # shape (n_bins, n_times)     shading=\"auto\",     norm=LogNorm(         vmin=concentrations[concentrations &gt; 0].min(),         vmax=concentrations.max(),     ), )  ax.set_yscale(\"log\") ax.set_ylim(5e-10, 1e-7) ax.set_xlabel(\"Time (s)\") ax.set_ylabel(\"Particle Radius (m)\") ax.set_title(\"Time-Evolving Particle Size Distribution\")  # Colorbar for number concentration fig.colorbar(mesh, label=\"Number Concentration (#/m\u00b3)\")  plt.tight_layout() plt.show()"},{"location":"Examples/Simulations/Notebooks/Soot_Formation_in_Flames/#soot-formation-in-flames","title":"Soot Formation in Flames\u00b6","text":"<p>Welcome to the Soot Formation in Flames notebook \u2014 a practical walkthrough to simulate the partitioning and growth of soot precursors using the Particula Python package.</p> <p>This example models the transformation of flame-emitted aromatic compounds into condensed-phase particles (e.g. PAHs and soot) during cooling of combustion plumes.</p>"},{"location":"Examples/Simulations/Notebooks/Soot_Formation_in_Flames/#what-this-notebook-covers","title":"\ud83d\udd25 What This Notebook Covers\u00b6","text":"<p>In this notebook, you'll learn how to:</p> <ol> <li>Define a realistic suite of aromatic and polyaromatic hydrocarbons (PAHs) from combustion</li> <li>Set up temperature-dependent vapor pressure and partitioning</li> <li>Simulate a two-stage cooling profile of a flame parcel</li> <li>Track gas-to-particle conversion and coagulation for soot growth</li> <li>Visualize mass transfer and particle-phase evolution</li> </ol>"},{"location":"Examples/Simulations/Notebooks/Soot_Formation_in_Flames/#why-it-matters","title":"\ud83d\udca1 Why It Matters\u00b6","text":"<p>Understanding soot formation is critical for:</p> <ul> <li>Assessing air pollution and climate impacts of combustion emissions</li> <li>Evaluating combustion efficiency and emissions</li> <li>Connecting with health exposure and regulatory metrics</li> </ul>"},{"location":"Examples/Simulations/Notebooks/Soot_Formation_in_Flames/#getting-started","title":"\ud83d\ude80 Getting Started\u00b6","text":"<p>This example is beginner-friendly. It walks through every step of simulating a cooling and condensing parcel from a flame. No prior experience with Particula or advanced aerosol thermodynamics is required.</p>"},{"location":"Examples/Simulations/Notebooks/Soot_Formation_in_Flames/#defining-the-chemical-inventory-and-properties","title":"\ud83e\uddea Defining the Chemical Inventory and Properties\u00b6","text":"<p>To model soot formation from combustion emissions, we start by specifying a realistic chemical inventory of aromatic hydrocarbons. These include both gas-phase precursors and low-volatility polycyclic aromatic hydrocarbons (PAHs) responsible for early-stage particle growth and soot inception.</p> <p>We also assign mass fractions that approximate real-world emission ratios, for primary combustion aerosols.</p> <p>\ud83d\udccb Chemical List</p> <p>Our inventory includes:</p> <ul> <li>1\u20132 ring aromatics (e.g. benzene, toluene) \u2013 highly volatile gas-phase precursors</li> <li>2\u20134 ring PAHs (e.g. naphthalene, pyrene) \u2013 semi-volatile and early particle growth contributors</li> <li>5\u20137 ring PAHs (e.g. benzo[a]pyrene, coronene) \u2013 low volatility, soot-nucleating species</li> <li>Optional soot seed (e.g. fullerene) \u2013 inert core for modeling inception</li> </ul> <p>\u2696\ufe0f Assigning Mass Fractions</p> <p>Mass fractions are allocated to approximate emission contributions, with normalization to ensure the total sums to 1:</p> <p>Note: 65% is distributed among volatile aromatics and 35% among PAHs.</p> <p>Fetching Thermophysical Properties</p> <p>For each chemical, we use <code>particula.util.get_chemical_search()</code> to retrieve the database entry, then fetch properties at standard temperature and pressure using <code>get_chemical_stp_properties()</code>.</p> <p>This builds the core property arrays required for simulation, including molar mass, density, and surface tension \u2014 key inputs for modeling evaporation, condensation, and partitioning.</p>"},{"location":"Examples/Simulations/Notebooks/Soot_Formation_in_Flames/#thermodynamic-setup-and-property-tables","title":"\ud83c\udf21\ufe0f Thermodynamic Setup and Property Tables\u00b6","text":"<p>To accurately simulate gas-to-particle transitions during cooling, we need to initialize:</p> <ul> <li>Reproducible random sampling</li> <li>Simulation volume and particle number density</li> <li>Temperature-dependent vapor pressure and surface tension for each species</li> </ul> <p>This allows us to model how each chemical transitions between gas and particle phases over a realistic cooling profile (e.g. flame exhaust).</p> <p>\ud83d\udd22 Global Simulation Settings</p> <p>We define a parcel volume, particle number concentration, and a representative initial temperature. These choices reflect typical combustion plume environments.</p> <ul> <li>Total particle number: 10\u2077 particles/cm\u00b3</li> <li>Sampled particles: 25,000</li> <li>Simulation volume: adjusted to match real concentration</li> <li>Initial gas temperature: 1200 K     # we override this later with a cooling profile</li> <li>Temperature sweep: 200\u20131500 K for vapor pressure and surface tension</li> </ul> <p>\ud83d\udcc8 Build Property Tables Over Temperature</p> <p>Using the <code>particula.util</code> and <code>particula.gas.TableVaporPressureBuilder</code>, we compute:</p> <ul> <li>A vapor pressure table for each species over 200\u20131500 K</li> <li>A corresponding surface tension table</li> <li>Vapor pressure strategies for the simulation</li> </ul> <p>Missing or extreme values are safely clipped to avoid numerical issues.</p> <p>\ud83d\udcca Plotting Thermophysical Properties</p> <p>Finally, we plot how vapor pressure and surface tension change with temperature for all species \u2014 a key step in diagnosing volatility trends and ensuring proper simulation input.</p>"},{"location":"Examples/Simulations/Notebooks/Soot_Formation_in_Flames/#initializing-the-gas-phase-and-atmospheric-conditions","title":"\ud83c\udf2b\ufe0f Initializing the Gas Phase and Atmospheric Conditions\u00b6","text":"<p>With our chemical properties and concentrations ready, the next step is to construct the gas phase and define the surrounding atmosphere.</p> <p>This is where vapor-phase species, thermodynamic conditions, and partitioning logic are encoded \u2014 setting the stage for subsequent evaporation or condensation processes as the system cools.</p> <p>\ud83e\uddf1 Build Gas Species</p> <p>We define the gas phase using <code>GasSpeciesBuilder()</code>:</p> <ul> <li><p>Each species is initialized with:</p> <ul> <li>Name</li> <li>Molar mass</li> <li>Initial gas-phase concentration (from <code>initial_mass_fractions \u00d7 total_mass_gas_phase</code>)</li> <li>Partitioning enabled</li> <li>Custom vapor pressure strategy (temperature-dependent)</li> </ul> </li> </ul> <p>\ud83c\udf0d Set Atmospheric Properties</p> <p>Using <code>AtmosphereBuilder()</code>, we define:</p> <ul> <li>Temperature: initial gas temperature (e.g. 1200 K)</li> <li>Pressure: atmospheric (1 atm)</li> <li>The atmosphere wraps around the gas and supports gas-particle equilibrium calculations throughout the simulation.</li> </ul>"},{"location":"Examples/Simulations/Notebooks/Soot_Formation_in_Flames/#defining-the-particle-phase-seeds-and-composition","title":"\ud83d\udca0 Defining the Particle Phase: Seeds and Composition\u00b6","text":"<p>With the gas-phase and atmospheric environment set up, we now define the initial aerosol particles in the system. These represent potential condensation sites for PAHs and soot-forming species.</p> <p>\ud83c\udf31 Seed Particle Distribution</p> <p>We use a bi-modal lognormal distribution to represent:</p> <ul> <li>Nucleation mode (~1 nm)</li> <li>And a bit larger mode (~5 nm)</li> </ul> <p>All particles are assumed to be pure fullerene seeds at the beginning, serving as a placeholder for previous soot nucleation cores in the flame.</p> <p>\ud83d\udce6 Mass and Composition Setup</p> <p>Each particle's mass is computed using:</p> <ul> <li>Volume from radius</li> <li>Fullerene density</li> </ul> <p>A mass speciation matrix is initialized with zeroes, and all mass is assigned to the last species (Fullerene).</p> <p>\u2697\ufe0f Particle Thermodynamic Strategies</p> <p>We define strategies for:</p> <ul> <li>Activity coefficients: Ideal molar activity using molar masses</li> <li>Surface tension: Temperature-dependent and species-specific</li> <li>Phase states: All in the same condensed phase except for the inert seed</li> </ul> <p>\ud83e\uddf1 Building the Particle Object</p> <p>We combine mass, density, thermodynamic strategies, and charge state (neutral) into a <code>ResolvedParticleMassRepresentation</code>, then wrap it in an <code>Aerosol</code> object alongside the atmosphere.</p> <p>\ud83d\udcca Plot Initial Size Distribution</p> <p>A histogram shows the initial particle size distribution, highlighting the multi-modal nature of soot-seeding aerosols.</p> <p>\u2705 You're getting closer to simulate gas-particle interactions under dynamic temperature conditions.</p>"},{"location":"Examples/Simulations/Notebooks/Soot_Formation_in_Flames/#dynamics-setup-condensation-and-coagulation","title":"\ud83d\udd01 Dynamics Setup: Condensation and Coagulation\u00b6","text":"<p>With the gas phase, atmosphere, and initial particle population defined, we now configure the physical processes that drive aerosol evolution:</p> <ul> <li>Condensation \u2014 gas-phase species depositing onto particles</li> <li>Coagulation \u2014 particles merging through Brownian motion</li> </ul> <p>These are essential for modeling soot aging, mass transfer, and particle growth in a dynamic combustion environment.</p> <p>\ud83d\udca7 Condensation Strategy</p> <p>We use <code>CondensationIsothermal</code> to simulate species uptake based on:</p> <ul> <li>Species molar mass</li> <li>Diffusion coefficient (assumed constant)</li> <li>Accommodation coefficient (mass transfer efficiency)</li> <li>Excluded indices: we skip partitioning to the seed species (index <code>23</code> = \"Fullerene\")</li> </ul> <p>This reflects a system where Fullerene acts only as a passive core, with no vapor partitioning.</p> <p>\u26ab Coagulation Strategy</p> <p>Coagulation is handled via <code>BrownianCoagulationBuilder</code>, applied to a particle-resolved distribution \u2014 matching our earlier setup.</p> <p>Together, these strategies are bundled into <code>MassCondensation</code> and <code>Coagulation</code> process objects, ready to be passed into the simulation loop.</p>"},{"location":"Examples/Simulations/Notebooks/Soot_Formation_in_Flames/#modeling-the-temperature-profile-after-combustion","title":"\ud83d\udd25 Modeling the Temperature Profile After Combustion\u00b6","text":"<p>Below is a practical, two-stage temperature profile that is widely used in aerosol post-combustion models. It captures both:</p> <ul> <li>A fast entrainment/mixing stage (sub-second), and</li> <li>A slow ambient dilution stage (multi-second)</li> </ul> <p>...while remaining smooth, differentiable, and easy to integrate into kinetic solvers.</p> <p>\ud83e\uddee Functional Form</p> <p>$$ T(t) = T_\\infty +  (T_0 - T_\\infty) \\cdot \\exp\\left(-\\frac{t}{\\tau_1}\\right) + (T_\\mathrm{mix} - T_\\infty) \\cdot \\exp\\left(-\\frac{t}{\\tau_2}\\right) $$</p> <p>Where:</p> <ul> <li>T\u2080 = initial flame or stack temperature</li> <li>T\u221e = ambient background temperature (\u2248 298 K)</li> <li>T\u2098\u1d62\u2093 = temperature after rapid entrainment (~500\u2013700 K)</li> <li>\u03c4\u2081 = fast cooling timescale (e.g. 0.05\u20130.3 s)</li> <li>\u03c4\u2082 = slow dilution or mixing timescale (e.g. 2\u201310 s)</li> </ul> <p>\ud83d\udcca Example Parameter Values</p> Scenario T\u2080 (K) T\u2098\u1d62\u2093 (K) \u03c4\u2081 (s) \u03c4\u2082 (s) Diesel tailpipe (idle) 750 550 0.10 4.0 Wick or candle flame 1200 700 0.05 6.0 Lab methane burner 1450 650 0.03 2.0 Small wood stove in room air 1050 600 0.15 8.0 <p>\ud83e\udde0 Why use two exponentials?</p> <ul> <li>Captures the supersaturation spike critical for soot nucleation</li> <li>Smooth and differentiable for ODE solvers</li> <li>Easily fit from real thermocouple data</li> <li>Matches behavior in combustion and indoor air scenarios</li> </ul>"},{"location":"Examples/Simulations/Notebooks/Soot_Formation_in_Flames/#time-setup-and-temperature-evolution","title":"\ud83d\udd52 Time Setup and Temperature Evolution\u00b6","text":"<p>We now define the time vector and compute the temperature profile over the course of the simulation.</p> <p>This temperature is used to update the atmospheric state at each step \u2014 controlling condensation rates and vapor pressures as the parcel cools and mixes with ambient air.</p> <p>\u23f1\ufe0f Simulation Time Setup</p> <ul> <li><p>Total simulation time: 20 seconds</p> </li> <li><p>Steps: 500 (\u21d2 0.04 s per step)</p> </li> <li><p>Substeps:</p> <ul> <li>Condensation: 50 per main step</li> <li>Coagulation: 1 per main step</li> </ul> </li> </ul> <p>You can optionally use a <code>logspace</code> time grid if high temporal resolution is needed near <code>t = 0</code>.</p> <p>\ud83c\udf21\ufe0f Compute the Temperature Profile</p> <p>We call the <code>temperature_profile()</code> function with typical combustion parameters:</p> <ul> <li><code>T\u2080 = 1200 K</code> (flame)</li> <li><code>T\u2098\u1d62\u2093 = 700 K</code> (fast entrainment)</li> <li><code>T\u221e = 300 K</code> (ambient)</li> <li><code>\u03c4\u2081 = 0.05 s</code>, <code>\u03c4\u2082 = 6.0 s</code> (cooling timescales)</li> </ul> <p>\ud83d\udcc8 Plot the Temperature Evolution</p> <p>We visualize the cooling curve to verify that it captures the sharp initial drop and gradual ambient approach expected in realistic post-combustion environments.</p>"},{"location":"Examples/Simulations/Notebooks/Soot_Formation_in_Flames/#running-the-simulation-condensation-coagulation","title":"\ud83e\uddea Running the Simulation: Condensation + Coagulation\u00b6","text":"<p>Now we execute the full simulation loop over time, updating the atmosphere's temperature at each step and applying the previously defined physical processes:</p> <ul> <li>Condensation (temperature- and species-dependent mass uptake)</li> <li>Coagulation (Brownian coagulation of particles)</li> </ul> <p>\ud83d\udd22 What the Loop Tracks</p> <p>At each time step, we record:</p> <ol> <li>Radius distribution histogram (log-binned)</li> <li>Total particle-phase mass concentration</li> <li>Mean (mode) particle diameter</li> <li>Species-specific particle-phase mass (per chemical)</li> </ol> <p>\ud83e\uddca Notes on Performance</p> <ul> <li>Condensation is the most computationally intensive.</li> <li>You can disable it (comment it out) to isolate the effect of coagulation.</li> <li>Results are stored in arrays for easy plotting after the run.</li> </ul>"},{"location":"Examples/Simulations/Notebooks/Soot_Formation_in_Flames/#results-growth-and-cooling-dynamics","title":"\ud83d\udcc8 Results: Growth and Cooling Dynamics\u00b6","text":"<p>We now visualize the output from the simulation loop \u2014 focusing on:</p> <ol> <li>Total aerosol mass concentration (growth from condensation)</li> <li>Mean particle diameter (radius evolution from coagulation + condensation)</li> <li>Cooling temperature trajectory for reference</li> </ol> <p>\ud83e\uddea Interpreting the Results</p> <ul> <li>Mass increases as condensable vapors partition into the particle phase.</li> <li>Mean diameter grows from both condensation and coagulation.</li> <li>Some numerical wiggles may appear due to the Euler stepping scheme \u2014 which is simple but not adaptive or error-controlled.</li> </ul> <p>\ud83d\udd0d You can reduce wiggle artifacts by:</p> <ul> <li>Increasing <code>total_steps</code></li> <li>Switching to adaptive integrators in future Particula versions (or add your own!)</li> </ul> <p>\ud83d\udcca Plot 1: Total Mass Concentration</p> <p>This plot shows how much gas-phase material is transferred to particles over time.</p> <p>\ud83d\udccf Plot 2: Mean Particle Diameter</p> <p>This shows how particle size evolves, usually increasing due to condensation and merging.</p>"},{"location":"Examples/Simulations/Notebooks/Soot_Formation_in_Flames/#where-the-mass-is-species-level-partitioning","title":"\ud83e\uddea Where the Mass Is: Species-Level Partitioning\u00b6","text":"<p>In this section, we explore how different chemical species contribute to the particle-phase mass throughout the simulation.</p> <p>We plot:</p> <ol> <li>Absolute species mass concentrations \u2014 more stable and interpretable</li> <li>Mass fractions \u2014 show relative speciation but may exaggerate numerical wiggles</li> </ol> <p>\u26a0\ufe0f Mass fractions are sensitive to numerical artifacts, especially when the denominator (total mass) is small or fluctuating.</p> <p>\ud83d\udcca Plot 1: Species Mass Concentration (kg/m\u00b3)</p> <p>This stack plot shows how much of each species has condensed into the particle phase.</p> <ul> <li>The y-axis is the total particle-phase concentration of each compound.</li> <li>The plot grows as vapor species condense onto seeds.</li> </ul> <p>\ud83d\udcca Plot 2: Particle Mass Fraction</p> <p>This plot shows the relative speciation of the condensed-phase.</p> <ul> <li>Each band represents the mean mass fraction of a species in particles.</li> <li>The temperature overlay helps relate supersaturation to species uptake.</li> </ul> <p>\u2705 These plots let you diagnose volatility, partitioning trends, and multicomponent interactions.</p>"},{"location":"Examples/Simulations/Notebooks/Soot_Formation_in_Flames/#final-plot-particle-size-distribution-over-time","title":"\ud83d\udcc9 Final Plot: Particle Size Distribution Over Time\u00b6","text":"<p>The last plot shows the evolution of particle number concentration across the radius spectrum throughout the simulation.</p> <ul> <li>It reveals growth dynamics from ~1 nm up to submicron scale</li> <li>Shows how condensation fills out the distribution</li> <li>Captures coagulation shifting mass toward larger sizes</li> </ul> <p>\ud83d\udd2c What It Shows</p> <ul> <li>X-axis: Time after emission [s]</li> <li>Y-axis: Particle radius [m] (log scale)</li> <li>Color: Number concentration [#/m\u00b3] in each size bin</li> </ul> <p>\u26a0\ufe0f Interpolation artifacts can occur if <code>sub_steps</code> is too low or if the system is stiff \u2014 increase resolution or use adaptive solvers for higher precision.</p> <p>\u2705 This completes your simulation visualization pipeline: from gas-phase precursor evolution to fully resolved, dynamic aerosol size and composition.</p>"},{"location":"Examples/Simulations/Notebooks/Soot_Formation_in_Flames/#summary-modeling-soot-formation-and-growth-using-particula","title":"\u2705 Summary: Modeling Soot Formation and Growth Using Particula\u00b6","text":"<p>In this notebook, we used Particula to simulate the formation and transformation of soot precursors in a post-combustion environment. We built a fully coupled system combining:</p> <ul> <li>A multicomponent gas-phase mixture of aromatic and polycyclic hydrocarbons</li> <li>A lognormal seed particle distribution, representing incipient soot cores</li> <li>A two-stage cooling temperature profile, capturing entrainment and dilution dynamics</li> <li>Condensation and coagulation processes, applied step-by-step to resolve mass transfer and particle growth</li> </ul> <p>The simulation tracked the evolution of particle mass concentration, mean diameter, size distribution, and species-level mass partitioning over time.</p> <p>By using a realistic cooling profile, we reproduced the supersaturation window where low-volatility species (e.g. PAHs) rapidly condense \u2014 a critical moment in soot inception. The growth of particles in both number and mass was clearly visible, along with shifts in chemical speciation as the temperature dropped.</p>"},{"location":"Examples/Simulations/Notebooks/Soot_Formation_in_Flames/#take-home-points","title":"\ud83e\udde0 Take-Home Points\u00b6","text":"<ol> <li><p>Post-flame condensation drives rapid aerosol mass growth The temperature drop from 1200 K to ambient creates sharp vapor pressure gradients, allowing semi-volatile PAHs to condense onto seed particles almost immediately.</p> </li> <li><p>Soot-forming chemistry is driven by low-volatility species Larger PAHs (e.g., benzo[a]pyrene, coronene) dominate particle-phase mass over time, particularly once smaller aromatics remain in the vapor phase.</p> </li> <li><p>Euler time-stepping is simple but introduces wiggles Our choice of fixed-step Euler integration creates slight numerical noise in mass fraction plots \u2014 highlighting the tradeoff between speed and precision. Higher number of steps or adaptive stepping may improve accuracy.</p> </li> <li><p>Particula\u2019s modular design supports combustion plume modeling With <code>Gas</code>, <code>Particle</code>, and <code>Atmosphere</code> objects plus tunable process builders, you can recreate real-world conditions for combustion emissions, indoor air pollution, and exposure assessments.</p> </li> </ol> <p>This notebook serves as a foundational framework for modeling soot dynamics in cooling combustion plumes. From here, you can extend it to explore:</p> <ul> <li>Different burn conditions (diesel, wood smoke, indoor flames)</li> <li>Effects of ventilation, dilution rate, or ambient pressure</li> <li>Nucleation kinetics, oxidation, or secondary organic aerosol (SOA) formation</li> <li>Integration with exposure models for health and climate impact studies</li> </ul>"},{"location":"Theory/","title":"Theory","text":"<p>Particula's Theory section contains a collection of theoretical topics and concepts that are relevant to the Particula package. This includes mathematical equations, physical principles, and other scientific concepts that are used in the development and application of the Particula package.</p> <p>In addition, we have discussions on implementation details, such as the use of OpenAI models and the integration of various tools and libraries. This section is designed to provide a deeper understanding of the underlying principles and methodologies that drive the functionality of Particula.</p> <p>See the sidebar on the left for a list of topic categories and their contents.</p>"},{"location":"Theory/Accelerating_Python/","title":"Accelerating Python","text":"<p>Python\u2019s ease-of-use and rich ecosystem make it ideal for scientific computing\u2014but pure-Python loops and numeric operations can be orders of magnitude slower than optimized native code. To bridge this gap, projects routinely offload performance-critical kernels to compiled libraries rather than rewriting entire applications in lower-level languages.  </p> <p>This pattern is nothing new: classic Fortran and C programs have long relied on optimized BLAS/LAPACK routines, FFT libraries, or custom C modules to handle the heavy lifting. In the same spirit, we aim to explore the right approach for accelerating our own Python codebase, weighing trade-offs in portability, maintenance, and raw speed.</p>"},{"location":"Theory/Accelerating_Python/#what-well-explore","title":"What We\u2019ll Explore","text":""},{"location":"Theory/Accelerating_Python/#c-extensions","title":"C++ Extensions","text":"<ul> <li>Write custom C++ modules (via <code>pybind11</code>, CPython C-API, or <code>cffi</code>) for maximum control and access to state-of-the-art C++ libraries.  </li> <li>Pros: Full language power, mature toolchains, seamless integration with existing C++ code.  </li> <li>Cons: Steeper learning curve, manual memory management, more boilerplate.</li> <li>Example: Not yet available.</li> </ul>"},{"location":"Theory/Accelerating_Python/#taichi","title":"Taichi","text":"<ul> <li>A data-oriented language that compiles Python-like kernels into optimized vectorized code for CPU/GPU.  </li> <li>Pros: High-level syntax, automatic parallelization, built-in profiler and GPU backends.  </li> <li>Cons: Requires learning Taichi\u2019s data-model and kernel abstraction.</li> <li>Example: Taichi Exploration notebook.</li> </ul>"},{"location":"Theory/Accelerating_Python/#nvidia-warp","title":"NVIDIA Warp","text":"<ul> <li>A Python API for data-parallel C-style kernels, especially suited for physics and graphics simulations.  </li> <li>Pros: Easy dispatch to multicore CPUs or CUDA GPUs, familiar C-like syntax.  </li> <li>Cons: Niche use cases, less mature ecosystem than CUDA or Taichi.</li> <li>Example: Not yet available.</li> </ul>"},{"location":"Theory/Accelerating_Python/#cython-pypy","title":"Cython (PyPy)","text":"<ul> <li>A superset of Python that compiles to C, enabling static type declarations and direct C-API calls.  </li> <li>Pros: Incremental adoption via <code>*.pyx</code> files, excellent control over types and memory layout.  </li> <li>Cons: Requires writing Cython annotations, manual build configuration.</li> <li>Example: Not yet available.</li> </ul>"},{"location":"Theory/Accelerating_Python/#numba","title":"Numba","text":"<ul> <li>A JIT compiler that decorates Python functions for high-performance machine code (LLVM).  </li> <li>Pros: Minimal code changes for simple numeric loops, transparent parallelization options.  </li> <li>Cons: Limited coverage of the full NumPy API\u2014features like <code>np.any</code> or <code>isinstance</code> checks often fail, so non-trivial functions must be rewritten from scratch, just like with other options.</li> <li>Example: This was explored (no example notebook) and found not to be a simple drop-in solution; due to incomplete <code>numpy</code> coverage. So if we needed to re-write the code anyway, we might as well use one of the other options.</li> </ul>"},{"location":"Theory/Accelerating_Python/#how-we-envision-this-working","title":"How We Envision This Working","text":"<p>Our vision is to have a simple enable statement for <code>particula</code> that allows users to choose the acceleration method. For example, a user could run the following command in their notebook:</p> <pre><code>import particula as par\n\npar.use_backend(\"taichi\")  # or \"warp\", \"cpp\", etc.\n</code></pre> <p>The rest of the builder and other function calls would remain unchanged, and the user would be able to run their code as usual. The only difference would be that the kernels would be compiled to the selected backend (e.g., Taichi, Warp, etc.) and run there instead of in Python.</p> <p>See one option for how this could be done in the One-Line Vision document.</p>"},{"location":"Theory/Accelerating_Python/#why-this-matters","title":"Why This Matters","text":"<ul> <li>Performance: Offloading compute-intensive work can yield 10\u00d7\u201310,000\u00d7 speedups.  </li> <li>Maintainability: Choosing the right tool lets you keep most of your code in Python, while isolating optimized kernels.  </li> <li>Portability: Leveraging standard libraries ensures compatibility across platforms (Linux, Windows, macOS).  </li> </ul> <p>In the notebooks under <code>Details/</code> on the left, we\u2019ll benchmark each approach on real aerosol-simulation kernels, discuss integration strategies, and surface best practices.</p>"},{"location":"Theory/Accelerating_Python/Details/One-Line_Vision/","title":"One-line Vision","text":"<p>Objective Give users a single statement\u2014<code>par.use_backend(\"taichi\")</code>, <code>par.use_backend(\"warp\")</code>, or nothing at all\u2014to decide whether each heavy-duty kernel runs as plain-Python/NumPy or on an accelerated backend.  All builders, simulators, and analysis notebooks continue to call the same public functions (<code>par.coagulation_gain_rate</code>, <code>par.foo</code>, \u2026).  In other words: \u201cflip a switch, get speed, keep code.\u201d</p>"},{"location":"Theory/Accelerating_Python/Details/One-Line_Vision/#design-constraints-we-start-with","title":"Design constraints we start with","text":"Constraint Why it matters One-liner for users Notebooks shouldn\u2019t need <code>if backend:</code> blocks or different import paths. Clean public API Research scripts and tests written today must still run tomorrow. Graceful fallback If Taichi/c++ isn\u2019t installed, everything still works (slower). Low maintenance Contributors shouldn\u2019t touch every file each time we add a new backend. Lazy dependencies Heavy libraries load only when that backend is active. <p>Early idea: insert an <code>if par.backend.is_enabled(): \u2026</code> test inside every compute routine. Problem: scales poorly (hundreds of duplicated <code>if</code> blocks), scatters backend logic across the codebase, and complicates testing.</p>"},{"location":"Theory/Accelerating_Python/Details/One-Line_Vision/#why-we-chose-a-dispatch-decorator-registry","title":"Why we chose a dispatch-decorator + registry","text":"<p>See the Dispatch Decorator section below for a full code example.</p> Alternative Drawbacks we avoided Inline <code>if</code> statements Boilerplate in every function; easy to miss one path; hard to grep. Monkey-patching modules Breaks static analysis, doc generation, and can confuse IDEs. Separate \u201cbackend\u201d namespace (<code>par.taichi.foo</code>) Forces users to learn new call sites and duplicate builder logic. <p>Dispatch layer centralizes the decision in one lightweight wrapper:</p> <pre><code>@par.dispatchable        # decorates the Python reference impl\ndef coagulation_gain_rate(...):\n    ...\n\n@par.register(\"coagulation_gain_rate\", backend=\"taichi\")\ndef _fast_taichi_impl(...):\n    ...\n</code></pre> <ul> <li>The wrapper looks up <code>par.get_backend()</code>.</li> <li>If an accelerated version is registered for that name, it calls it.</li> <li>Otherwise it falls back to the original Python body.</li> </ul> <p>Outcome: zero duplication, single source-of-truth docstring, plug-and-play backends.</p>"},{"location":"Theory/Accelerating_Python/Details/One-Line_Vision/#how-integration-feels-to-each-stakeholder","title":"How integration feels to each stakeholder","text":"<p>Users</p> <pre><code>import particula as par\npar.use_backend(\"taichi\")      # one line, opt-in\nresult = par.coagulation_gain_rate(r, c, K)\n</code></pre> <p>If Taichi isn\u2019t available\u2014or if that particular kernel hasn\u2019t been ported yet\u2014the same call silently executes the pure-Python path.</p> <p>Backend Developer</p> <pre><code>from particula import register\n\n@register(\"coagulation_gain_rate\", backend=\"warp\")\ndef gain_rate_warp(...):\n    ...\n</code></pre> <p>No changes to public modules, no touching docstrings, no conflicts with other backends.</p> <p>Core maintainers</p> <ul> <li>Only the tiny <code>_dispatch.py</code> needs to know about backend state.</li> <li>Tests iterate over the registry to verify numerical consistency.</li> <li>Doc generation shows one canonical signature per function.</li> </ul>"},{"location":"Theory/Accelerating_Python/Details/One-Line_Vision/#key-benefits","title":"Key benefits","text":"<ul> <li>Scalability: add Taichi today, C++ tomorrow, SIMD next year\u2014public API untouched.</li> <li>Safety: automatic Python fallback guarantees correctness over performance.</li> <li>Maintainability: backend logic lives in dedicated files; diff-friendly and testable.</li> <li>Developer ergonomics: decorating existing functions is a two-second task.</li> <li>Performance isolation: heavy imports load only when a user explicitly selects them.</li> </ul>"},{"location":"Theory/Accelerating_Python/Details/One-Line_Vision/#dispatch-decorator","title":"Dispatch Decorator","text":"<p>Our goal is to have one line for users, zero friction for contributors. What changes is how we wire the backends. Instead of sprinkling <code>if par.backend.is_enabled(): \u2026</code> inside every kernel, we wrap each public-API function in a single decorator that does automatic dispatch:</p> <pre><code>import particula as par\n\npar.use_backend(\"taichi\")        # or \"warp\", \"cpp\", \u2026\n# builder code stays identical \u2193\ngain = par.coagulation_gain_rate(radius, conc, kernel)\n</code></pre> <p>Behind the scenes:</p> <ol> <li> <p>The original Python implementation is the source-of-truth.    It is defined once, carries the docstring, and is decorated with <code>@par.dispatchable</code>.</p> </li> <li> <p>The decorator installs a lightweight wrapper that:</p> </li> <li> <p>Looks up the currently active backend (<code>par.get_backend()</code>).</p> </li> <li>Checks a registry (<code>_registry[func_name].get(backend)</code>).</li> <li> <p>Calls the registered accelerated version if it exists; otherwise falls back to the original Python body.</p> </li> <li> <p>Accelerated versions live in separate modules and register themselves with:</p> </li> </ol> <pre><code>@par.register(\"coagulation_gain_rate\", backend=\"taichi\")\ndef coagulation_gain_rate_taichi(radius, conc, kernel):\n    # Taichi kernel here \u2026\n</code></pre> <ol> <li>No accelerated version? No problem.    The wrapper silently calls the pure-Python code, so functionality never breaks.</li> </ol>"},{"location":"Theory/Accelerating_Python/Details/One-Line_Vision/#why-this-approach-meets-our-requirements","title":"Why this approach meets our requirements","text":"Requirement How dispatch-decorator delivers \u201cSingle enable statement for users.\u201d <code>par.use_backend(\"taichi\")</code> sets one global flag (with an optional context manager for thread-safety). \u201cBuilder APIs and call sites stay unchanged.\u201d All backend logic lives inside the decorator wrapper; public signatures are untouched. \u201cMinimal boilerplate for new kernels.\u201d Add <code>@par.dispatchable</code> to the existing Python function \u2192 done.  If/when you write a faster Taichi/Warp/C++ version, just drop it into <code>_backend_taichi.py</code> with <code>@par.register</code>. \u201cAutomatic Python fallback.\u201d The wrapper uses <code>registry.get(backend, original_python_func)</code>, so the pure-Python path is always available."},{"location":"Theory/Accelerating_Python/Details/One-Line_Vision/#example-skeleton","title":"Example skeleton","text":"<pre><code># -------- particula/_dispatch.py -----------------\n_backend = \"python\"\n_registry: dict[str, dict[str, callable]] = defaultdict(dict)\n\ndef use_backend(name: str):  # user API\n    global _backend\n    _backend = name.lower()\n\ndef get_backend() -&gt; str:\n    return _backend\n\ndef dispatchable(func):\n    \"\"\"Decorator that enables backend dispatch with Python fallback.\"\"\"\n    func_name = func.__name__\n\n    def wrapper(*args, **kwargs):\n        impl = _registry.get(func_name, {}).get(_backend, func)\n        return impl(*args, **kwargs)\n\n    # register default python implementation\n    _registry.setdefault(func_name, {})[\"python\"] = func\n    wrapper.__doc__ = func.__doc__\n    return wrapper\n\ndef register(func_name: str, *, backend: str):\n    \"\"\"Decorator factory for accelerated implementations.\"\"\"\n    def decorator(accel_func):\n        _registry.setdefault(func_name, {})[backend.lower()] = accel_func\n        return accel_func\n    return decorator\n</code></pre> <pre><code># -------- particula/public_api.py ----------------\nfrom particula._dispatch import dispatchable\n\n@dispatchable\ndef coagulation_gain_rate(radius, concentration, kernel):\n    \"\"\"Compute gain rate by trapezoidal integration (pure Python).\"\"\"\n    return 0.5 * np.trapz(\n        kernel * concentration[:, None] * concentration,\n        radius,\n        axis=1,\n    )\n</code></pre> <pre><code># -------- particula/_backend_taichi.py -----------\nfrom particula._dispatch import register\nimport taichi as ti\n\n@register(\"coagulation_gain_rate\", backend=\"taichi\")\ndef coagulation_gain_rate_taichi(radius, concentration, kernel):\n    # Taichi implementation here \u2026\n    return ti_kernel(radius, concentration, kernel)\n</code></pre>"},{"location":"Theory/Accelerating_Python/Details/One-Line_Vision/#what-users-see","title":"What users see","text":"<pre><code>import particula as par\npar.use_backend(\"taichi\")          # one-liner switch\n\ngain_rate = par.coagulation_gain_rate(r, c, K)  # transparently fast\n</code></pre> <p>If the Taichi module is unavailable or that particular kernel hasn\u2019t been ported yet, the call runs the original Python version without any code change or error.</p>"},{"location":"Theory/Accelerating_Python/Details/One-Line_Vision/#bottom-line","title":"Bottom line","text":"<p>By decorating existing Python functions with <code>@dispatchable</code>, we add optional acceleration instead of rewriting for it.  The registry-based dispatch keeps maintenance low, guarantees a safe fallback path, and preserves the clean public API that users already know.</p>"},{"location":"Theory/Accelerating_Python/Details/Taichi_Exploration/","title":"Taichi Exploration","text":"In\u00a0[2]: Copied! <pre>import time\nimport statistics\nimport gc\nfrom typing import Callable, Optional, Any, Dict\nimport json\nimport platform\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\nimport particula as par\n\n# non-standard libraries for this script\nimport psutil\nimport taichi as ti\n\n# plot settings\nTAILWIND = par.util.colors.TAILWIND\nbase_color = TAILWIND[\"gray\"][\"600\"]\nplt.rcParams.update(\n    {\n        \"text.color\": base_color,\n        \"axes.labelcolor\": base_color,\n        \"figure.figsize\": (5, 4),\n        \"font.size\": 14,\n        \"axes.edgecolor\": base_color,\n        \"axes.labelcolor\": base_color,\n        \"xtick.color\": base_color,\n        \"ytick.color\": base_color,\n        \"pdf.fonttype\": 42,\n        \"ps.fonttype\": 42,\n    }\n)\n</pre> import time import statistics import gc from typing import Callable, Optional, Any, Dict import json import platform  import numpy as np import matplotlib.pyplot as plt from tqdm import tqdm import particula as par  # non-standard libraries for this script import psutil import taichi as ti  # plot settings TAILWIND = par.util.colors.TAILWIND base_color = TAILWIND[\"gray\"][\"600\"] plt.rcParams.update(     {         \"text.color\": base_color,         \"axes.labelcolor\": base_color,         \"figure.figsize\": (5, 4),         \"font.size\": 14,         \"axes.edgecolor\": base_color,         \"axes.labelcolor\": base_color,         \"xtick.color\": base_color,         \"ytick.color\": base_color,         \"pdf.fonttype\": 42,         \"ps.fonttype\": 42,     } ) <pre>[Taichi] version 1.8.0, llvm 15.0.1, commit d7c758fb, win, python 3.12.8\n</pre> In\u00a0[3]: Copied! <pre>ti.init(arch=ti.cpu)\n</pre> ti.init(arch=ti.cpu) <pre>[Taichi] Starting on arch=x64\n</pre> In\u00a0[4]: Copied! <pre>@ti.kernel\ndef get_coagulation_gain_rate_continuous_taichi(\n    radius: ti.types.ndarray(),\n    concentration: ti.types.ndarray(),\n    kernel: ti.types.ndarray(),\n    gain_rate: ti.types.ndarray(),\n):\n    \"\"\"\n    Compute the coagulation gain rate by discrete trapezoidal integration.\n\n    The rate is evaluated as:\n\n    - G\u1d62 = \u00bd \u2211\u2c7c (K\u1d62\u2c7c c\u1d62 c\u2c7c + K\u1d62\u2c7c\u208a\u2081 c\u1d62 c\u2c7c\u208a\u2081) \u0394r\u2c7c\n\n        - G\u1d62 is the gain rate for bin *i* (1/s),\n        - K\u1d62\u2c7c is the coagulation kernel (m\u00b3/s),\n        - c\u1d62, c\u2c7c are particle concentrations (#/m\u00b3),\n        - \u0394r\u2c7c is the radius interval (m).\n\n    Arguments:\n        - radius : 1-D array of particle radii in metres.\n        - concentration : 1-D array of particle number concentrations (# m\u207b\u00b3).\n        - kernel : 2-D coagulation-kernel matrix (m\u00b3 s\u207b\u00b9).\n        - gain_rate : Pre-allocated output array (same length as *radius*).\n\n    Returns:\n        - None.  Results are written in-place to *gain_rate*.\n\n    Examples:\n        ```py title=\"Example Usage\"\n        gain = np.empty_like(radius)\n        get_coagulation_gain_rate_continuous_taichi(radius, conc, K, gain)\n        ```\n    \"\"\"\n    n = radius.shape[0]\n    half = ti.cast(0.5, ti.f64)  # 0.5 for trapezoidal rule\n    for i in range(n):\n        acc = ti.cast(0, ti.f64)  # Accumulator for gain rate\n        for j in range(n - 1):\n            dr = radius[j + 1] - radius[j]\n            # trapezoid: \u00bd\u00b7[f(j) + f(j+1)]\u00b7\u0394r\n            acc += (\n                half\n                * (\n                    kernel[i, j] * concentration[i] * concentration[j]\n                    + kernel[i, j + 1]\n                    * concentration[i]\n                    * concentration[j + 1]\n                )\n                * dr\n            )\n        gain_rate[i] = acc\n</pre> @ti.kernel def get_coagulation_gain_rate_continuous_taichi(     radius: ti.types.ndarray(),     concentration: ti.types.ndarray(),     kernel: ti.types.ndarray(),     gain_rate: ti.types.ndarray(), ):     \"\"\"     Compute the coagulation gain rate by discrete trapezoidal integration.      The rate is evaluated as:      - G\u1d62 = \u00bd \u2211\u2c7c (K\u1d62\u2c7c c\u1d62 c\u2c7c + K\u1d62\u2c7c\u208a\u2081 c\u1d62 c\u2c7c\u208a\u2081) \u0394r\u2c7c          - G\u1d62 is the gain rate for bin *i* (1/s),         - K\u1d62\u2c7c is the coagulation kernel (m\u00b3/s),         - c\u1d62, c\u2c7c are particle concentrations (#/m\u00b3),         - \u0394r\u2c7c is the radius interval (m).      Arguments:         - radius : 1-D array of particle radii in metres.         - concentration : 1-D array of particle number concentrations (# m\u207b\u00b3).         - kernel : 2-D coagulation-kernel matrix (m\u00b3 s\u207b\u00b9).         - gain_rate : Pre-allocated output array (same length as *radius*).      Returns:         - None.  Results are written in-place to *gain_rate*.      Examples:         ```py title=\"Example Usage\"         gain = np.empty_like(radius)         get_coagulation_gain_rate_continuous_taichi(radius, conc, K, gain)         ```     \"\"\"     n = radius.shape[0]     half = ti.cast(0.5, ti.f64)  # 0.5 for trapezoidal rule     for i in range(n):         acc = ti.cast(0, ti.f64)  # Accumulator for gain rate         for j in range(n - 1):             dr = radius[j + 1] - radius[j]             # trapezoid: \u00bd\u00b7[f(j) + f(j+1)]\u00b7\u0394r             acc += (                 half                 * (                     kernel[i, j] * concentration[i] * concentration[j]                     + kernel[i, j + 1]                     * concentration[i]                     * concentration[j + 1]                 )                 * dr             )         gain_rate[i] = acc In\u00a0[5]: Copied! <pre>def collect_system_info():\n    \"\"\"\n    Gather basic CPU, OS and Python-runtime information.\n\n    Arguments:\n        - None.\n\n    Returns:\n        - Dictionary mapping descriptive keys to collected values.\n\n    Examples:\n        ```py\n        info = collect_system_info()\n        print(info[\"total_cores\"])\n        ```\n    \"\"\"\n    info = {}\n\n    # CPU counts\n    info[\"physical_cores\"] = psutil.cpu_count(logical=False)\n    info[\"total_cores\"] = psutil.cpu_count(logical=True)\n\n    # CPU frequencies\n    freq = psutil.cpu_freq()\n    info[\"max_frequency_mhz\"] = freq.max\n    info[\"min_frequency_mhz\"] = freq.min\n    info[\"current_frequency_mhz\"] = freq.current\n\n    # CPU usage\n    info[\"cpu_usage_per_core_%\"] = psutil.cpu_percent(percpu=True, interval=1)\n    info[\"total_cpu_usage_%\"] = psutil.cpu_percent()\n\n    # OS / machine info\n    uname = platform.uname()\n    info[\"system\"] = uname.system\n    info[\"release\"] = uname.release\n    info[\"version\"] = uname.version\n    info[\"machine\"] = uname.machine\n    info[\"processor\"] = uname.processor\n\n    # Python runtime\n    info[\"python_version\"] = platform.python_version()\n    info[\"python_build\"] = platform.python_build()\n    info[\"python_compiler\"] = platform.python_compiler()\n\n    return info\n</pre> def collect_system_info():     \"\"\"     Gather basic CPU, OS and Python-runtime information.      Arguments:         - None.      Returns:         - Dictionary mapping descriptive keys to collected values.      Examples:         ```py         info = collect_system_info()         print(info[\"total_cores\"])         ```     \"\"\"     info = {}      # CPU counts     info[\"physical_cores\"] = psutil.cpu_count(logical=False)     info[\"total_cores\"] = psutil.cpu_count(logical=True)      # CPU frequencies     freq = psutil.cpu_freq()     info[\"max_frequency_mhz\"] = freq.max     info[\"min_frequency_mhz\"] = freq.min     info[\"current_frequency_mhz\"] = freq.current      # CPU usage     info[\"cpu_usage_per_core_%\"] = psutil.cpu_percent(percpu=True, interval=1)     info[\"total_cpu_usage_%\"] = psutil.cpu_percent()      # OS / machine info     uname = platform.uname()     info[\"system\"] = uname.system     info[\"release\"] = uname.release     info[\"version\"] = uname.version     info[\"machine\"] = uname.machine     info[\"processor\"] = uname.processor      # Python runtime     info[\"python_version\"] = platform.python_version()     info[\"python_build\"] = platform.python_build()     info[\"python_compiler\"] = platform.python_compiler()      return info In\u00a0[6]: Copied! <pre># 1) Collect system information\nsystem_info = collect_system_info()\nprint(\"System Information:\")\nprint(json.dumps(system_info, indent=4))\n</pre> # 1) Collect system information system_info = collect_system_info() print(\"System Information:\") print(json.dumps(system_info, indent=4)) <pre>System Information:\n{\n    \"physical_cores\": 4,\n    \"total_cores\": 8,\n    \"max_frequency_mhz\": 2995.0,\n    \"min_frequency_mhz\": 0.0,\n    \"current_frequency_mhz\": 2995.0,\n    \"cpu_usage_per_core_%\": [\n        32.3,\n        35.4,\n        29.7,\n        18.5,\n        25.0,\n        20.3,\n        27.7,\n        28.1\n    ],\n    \"total_cpu_usage_%\": 31.7,\n    \"system\": \"Windows\",\n    \"release\": \"11\",\n    \"version\": \"10.0.26100\",\n    \"machine\": \"AMD64\",\n    \"processor\": \"Intel64 Family 6 Model 140 Stepping 1, GenuineIntel\",\n    \"python_version\": \"3.12.8\",\n    \"python_build\": [\n        \"main\",\n        \"Jan 14 2025 22:49:36\"\n    ],\n    \"python_compiler\": \"MSC v.1942 64 bit (AMD64)\"\n}\n</pre> In\u00a0[7]: Copied! <pre>def get_function_benchmark(\n    func: Callable[[], Any],\n    ops_per_call: float,\n    max_run_time_s: float = 2.0,\n    min_iterations: int = 5,\n    repeats: Optional[int] = None,\n) -&gt; dict[str, Any]:\n    \"\"\"\n    Benchmark a zero-argument function using perf_counter_ns, with GC disabled.\n\n    This function times repeated calls to a no-argument callable, collecting\n    statistics on execution time and estimating throughput and efficiency.\n    It adapts the number of repeats to ensure reliable timing, and returns\n    a dictionary of timing and performance metrics.\n\n    Arguments:\n        - func : A no-argument callable (e.g. `lambda: work(x, y)`).\n        - ops_per_call : Estimated floating-point operations per call.\n        - max_run_time_s : If `repeats` is None, run until this many seconds\n          elapse.\n        - min_iterations : If `repeats` is None, do at least this many calls.\n        - repeats : If set, run exactly this many calls.\n\n    Returns:\n        - Dictionary with timing and performance statistics, including:\n            - min_time_s : Minimum time per call (seconds).\n            - max_time_s : Maximum time per call (seconds).\n            - mean_time_s : Mean time per call (seconds).\n            - mode_time_s : Mode of time per call (seconds).\n            - median_time_s : Median time per call (seconds).\n            - std_time_s : Standard deviation of time per call (seconds).\n            - throughput_calls_per_s : Calls per second (1 / min_time_s).\n            - cycles_per_call : CPU cycles per call (min_time_s \u00d7 CPU_Hz).\n            - flops_per_call : Floating-point operations per call.\n            - flops_per_cycle : FLOPs per CPU cycle.\n            - function_calls : Number of function calls performed.\n            - report : Human-readable summary string.\n            - array_stats : List of all statistics above.\n            - array_headers : List of corresponding header strings.\n\n            Value types are mixed (float, int, str, list, etc).\n\n    Examples:\n        ```py title=\"Benchmark a trivial lambda\"\n        stats = benchmark_timer(lambda: sum([1, 2, 3]), ops_per_call=3)\n        print(stats[\"report\"])\n        ```\n\n    References:\n        - \"time.perf_counter_ns \u2014 Python documentation\",\n          https://docs.python.org/3/library/time.html#time.perf_counter_ns\n    \"\"\"\n    # disable GC for cleaner timing\n    gc_was_enabled = gc.isenabled()\n    if gc_was_enabled:\n        gc.disable()\n\n    timings: list[float] = []\n    try:\n        if repeats is None:\n            start_global = time.perf_counter_ns()\n            while (len(timings) &lt; min_iterations) or (\n                (time.perf_counter_ns() - start_global) / 1e9 &lt; max_run_time_s\n            ):\n                t0 = time.perf_counter_ns()\n                func()\n                t1 = time.perf_counter_ns()\n                timings.append((t1 - t0) / 1e9)\n        else:\n            for _ in range(repeats):\n                t0 = time.perf_counter_ns()\n                func()\n                t1 = time.perf_counter_ns()\n                timings.append((t1 - t0) / 1e9)\n        freq_tup = psutil.cpu_freq()\n        cpu_hz = (\n            freq_tup.current if freq_tup and freq_tup.current else 0.0\n        ) * 1e6\n    finally:\n        if gc_was_enabled:\n            gc.enable()\n\n    runs = len(timings)\n    # core stats\n    min_time = min(timings)\n    max_time = max(timings)\n    mean_time = statistics.mean(timings)\n    try:\n        mode_time = statistics.mode(timings)\n    except statistics.StatisticsError:\n        mode_time = float(\"nan\")\n    median_time = statistics.median(timings)\n    std_time = statistics.stdev(timings) if runs &gt; 1 else 0.0\n\n    # throughput &amp; cycle/flop estimates on best-case (min_time)\n    throughput = 1.0 / min_time\n    cycles_per_call = min_time * cpu_hz\n    flops_per_call = ops_per_call\n    flops_per_cycle = (\n        ops_per_call / cycles_per_call if cycles_per_call else float(\"nan\")\n    )\n\n    # build report\n    labels = [\n        (\"Throughput      (calls/s)\", f\"{throughput:,.0f}\"),\n        (\"CPU cycles      (cycles/call)\", f\"{cycles_per_call:,.0f}\"),\n        (\"Est. Flops      (flops/call)\", f\"{flops_per_call:,.0f}\"),\n        (\"Efficiency      (flops/cycle)\", f\"{flops_per_cycle:.4f}\"),\n        (\"Min time        (ms/call)\", f\"{min_time*1e3:.3f}\"),\n        (\"STDV time       (ms/call)\", f\"\u00b1{std_time*1e3:.3f}\"),\n    ]\n    header = f\"Benchmark: {runs} function calls.\"\n    lines = [header] + [f\"  {label:&lt;30}{value}\" for label, value in labels]\n    report = \"\\n\".join(lines)\n\n    array_stats = [\n        runs,\n        min_time,\n        max_time,\n        mean_time,\n        mode_time,\n        median_time,\n        std_time,\n        throughput,\n        cycles_per_call,\n        flops_per_call,\n        flops_per_cycle,\n    ]\n    array_headers = [\n        \"function_calls\",\n        \"min_time_s\",\n        \"max_time_s\",\n        \"mean_time_s\",\n        \"mode_time_s\",\n        \"median_time_s\",\n        \"std_time_s\",\n        \"throughput_calls_per_s\",\n        \"cycles_per_call\",\n        \"flops_per_call\",\n        \"flops_per_cycle\",\n    ]\n\n    return {\n        \"min_time_s\": min_time,\n        \"max_time_s\": max_time,\n        \"mean_time_s\": mean_time,\n        \"mode_time_s\": mode_time,\n        \"median_time_s\": median_time,\n        \"std_time_s\": std_time,\n        \"throughput_calls_per_s\": throughput,\n        \"cycles_per_call\": cycles_per_call,\n        \"flops_per_call\": flops_per_call,\n        \"flops_per_cycle\": flops_per_cycle,\n        \"function_calls\": runs,\n        \"report\": report,\n        \"array_stats\": array_stats,\n        \"array_headers\": array_headers,\n    }\n</pre> def get_function_benchmark(     func: Callable[[], Any],     ops_per_call: float,     max_run_time_s: float = 2.0,     min_iterations: int = 5,     repeats: Optional[int] = None, ) -&gt; dict[str, Any]:     \"\"\"     Benchmark a zero-argument function using perf_counter_ns, with GC disabled.      This function times repeated calls to a no-argument callable, collecting     statistics on execution time and estimating throughput and efficiency.     It adapts the number of repeats to ensure reliable timing, and returns     a dictionary of timing and performance metrics.      Arguments:         - func : A no-argument callable (e.g. `lambda: work(x, y)`).         - ops_per_call : Estimated floating-point operations per call.         - max_run_time_s : If `repeats` is None, run until this many seconds           elapse.         - min_iterations : If `repeats` is None, do at least this many calls.         - repeats : If set, run exactly this many calls.      Returns:         - Dictionary with timing and performance statistics, including:             - min_time_s : Minimum time per call (seconds).             - max_time_s : Maximum time per call (seconds).             - mean_time_s : Mean time per call (seconds).             - mode_time_s : Mode of time per call (seconds).             - median_time_s : Median time per call (seconds).             - std_time_s : Standard deviation of time per call (seconds).             - throughput_calls_per_s : Calls per second (1 / min_time_s).             - cycles_per_call : CPU cycles per call (min_time_s \u00d7 CPU_Hz).             - flops_per_call : Floating-point operations per call.             - flops_per_cycle : FLOPs per CPU cycle.             - function_calls : Number of function calls performed.             - report : Human-readable summary string.             - array_stats : List of all statistics above.             - array_headers : List of corresponding header strings.              Value types are mixed (float, int, str, list, etc).      Examples:         ```py title=\"Benchmark a trivial lambda\"         stats = benchmark_timer(lambda: sum([1, 2, 3]), ops_per_call=3)         print(stats[\"report\"])         ```      References:         - \"time.perf_counter_ns \u2014 Python documentation\",           https://docs.python.org/3/library/time.html#time.perf_counter_ns     \"\"\"     # disable GC for cleaner timing     gc_was_enabled = gc.isenabled()     if gc_was_enabled:         gc.disable()      timings: list[float] = []     try:         if repeats is None:             start_global = time.perf_counter_ns()             while (len(timings) &lt; min_iterations) or (                 (time.perf_counter_ns() - start_global) / 1e9 &lt; max_run_time_s             ):                 t0 = time.perf_counter_ns()                 func()                 t1 = time.perf_counter_ns()                 timings.append((t1 - t0) / 1e9)         else:             for _ in range(repeats):                 t0 = time.perf_counter_ns()                 func()                 t1 = time.perf_counter_ns()                 timings.append((t1 - t0) / 1e9)         freq_tup = psutil.cpu_freq()         cpu_hz = (             freq_tup.current if freq_tup and freq_tup.current else 0.0         ) * 1e6     finally:         if gc_was_enabled:             gc.enable()      runs = len(timings)     # core stats     min_time = min(timings)     max_time = max(timings)     mean_time = statistics.mean(timings)     try:         mode_time = statistics.mode(timings)     except statistics.StatisticsError:         mode_time = float(\"nan\")     median_time = statistics.median(timings)     std_time = statistics.stdev(timings) if runs &gt; 1 else 0.0      # throughput &amp; cycle/flop estimates on best-case (min_time)     throughput = 1.0 / min_time     cycles_per_call = min_time * cpu_hz     flops_per_call = ops_per_call     flops_per_cycle = (         ops_per_call / cycles_per_call if cycles_per_call else float(\"nan\")     )      # build report     labels = [         (\"Throughput      (calls/s)\", f\"{throughput:,.0f}\"),         (\"CPU cycles      (cycles/call)\", f\"{cycles_per_call:,.0f}\"),         (\"Est. Flops      (flops/call)\", f\"{flops_per_call:,.0f}\"),         (\"Efficiency      (flops/cycle)\", f\"{flops_per_cycle:.4f}\"),         (\"Min time        (ms/call)\", f\"{min_time*1e3:.3f}\"),         (\"STDV time       (ms/call)\", f\"\u00b1{std_time*1e3:.3f}\"),     ]     header = f\"Benchmark: {runs} function calls.\"     lines = [header] + [f\"  {label:&lt;30}{value}\" for label, value in labels]     report = \"\\n\".join(lines)      array_stats = [         runs,         min_time,         max_time,         mean_time,         mode_time,         median_time,         std_time,         throughput,         cycles_per_call,         flops_per_call,         flops_per_cycle,     ]     array_headers = [         \"function_calls\",         \"min_time_s\",         \"max_time_s\",         \"mean_time_s\",         \"mode_time_s\",         \"median_time_s\",         \"std_time_s\",         \"throughput_calls_per_s\",         \"cycles_per_call\",         \"flops_per_call\",         \"flops_per_cycle\",     ]      return {         \"min_time_s\": min_time,         \"max_time_s\": max_time,         \"mean_time_s\": mean_time,         \"mode_time_s\": mode_time,         \"median_time_s\": median_time,         \"std_time_s\": std_time,         \"throughput_calls_per_s\": throughput,         \"cycles_per_call\": cycles_per_call,         \"flops_per_call\": flops_per_call,         \"flops_per_cycle\": flops_per_cycle,         \"function_calls\": runs,         \"report\": report,         \"array_stats\": array_stats,         \"array_headers\": array_headers,     } In\u00a0[8]: Copied! <pre># 1. Generate size bins (1 nm to 10 \u00b5m, logarithmically spaced)\nbins_total = 500\nradius_bins = np.logspace(start=-9, stop=-4, num=bins_total)\n\n# 2. Compute mass per bin (density = 1000 kg/m\u00b3)\nmass_bins = (4.0 / 3.0) * np.pi * radius_bins**3 * 1e3  # kg\n\n# 3. Generate lognormal PMF distribution\n#    mode = 100 nm, GSD = 1.4, total concentration = 1e12 m\u207b\u00b3 (10000 cm\u207b\u00b3)\nconcentration_lognormal_0 = par.particles.get_lognormal_pmf_distribution(\n    x_values=radius_bins,\n    mode=np.array(100e-9),\n    geometric_standard_deviation=np.array(1.4),\n    number_of_particles=np.array(1e6 * 1e6),\n)\n\n# 4. Compute Brownian coagulation kernel\n#    T = 293.15 K, P = 101325 Pa, \u03b1_collision_efficiency = 1.0\nkernel = par.dynamics.get_brownian_kernel_via_system_state(\n    particle_radius=radius_bins,\n    particle_mass=mass_bins,\n    temperature=293.15,\n    pressure=101325,\n    alpha_collision_efficiency=1.0,\n)\n\n# 5. Prepare arrays for Taichi\n#    Allocate output and cast all arrays to float64\nout = np.zeros_like(concentration_lognormal_0, dtype=np.float64)\nradius_bins = np.asarray(radius_bins, dtype=np.float64)\nconcentration_lognormal_0 = np.asarray(\n    concentration_lognormal_0, dtype=np.float64\n)\nkernel = np.asarray(kernel, dtype=np.float64)\nout = np.asarray(out, dtype=np.float64)\n\n# 6. Estimate floating-point operations per kernel call\nops_per_call = 9 * bins_total * (bins_total - 1)\n\n# 7. Benchmark the Taichi kernel (max runtime = 5 seconds)\ntaichi_results = get_function_benchmark(\n    func=lambda: get_coagulation_gain_rate_continuous_taichi(\n        radius_bins, concentration_lognormal_0, kernel, out\n    ),\n    ops_per_call=ops_per_call,\n    max_run_time_s=5.0,\n)\n\nprint(\"Taichi Kernel Benchmark Results:\")\nprint(taichi_results[\"report\"])\n</pre> # 1. Generate size bins (1 nm to 10 \u00b5m, logarithmically spaced) bins_total = 500 radius_bins = np.logspace(start=-9, stop=-4, num=bins_total)  # 2. Compute mass per bin (density = 1000 kg/m\u00b3) mass_bins = (4.0 / 3.0) * np.pi * radius_bins**3 * 1e3  # kg  # 3. Generate lognormal PMF distribution #    mode = 100 nm, GSD = 1.4, total concentration = 1e12 m\u207b\u00b3 (10000 cm\u207b\u00b3) concentration_lognormal_0 = par.particles.get_lognormal_pmf_distribution(     x_values=radius_bins,     mode=np.array(100e-9),     geometric_standard_deviation=np.array(1.4),     number_of_particles=np.array(1e6 * 1e6), )  # 4. Compute Brownian coagulation kernel #    T = 293.15 K, P = 101325 Pa, \u03b1_collision_efficiency = 1.0 kernel = par.dynamics.get_brownian_kernel_via_system_state(     particle_radius=radius_bins,     particle_mass=mass_bins,     temperature=293.15,     pressure=101325,     alpha_collision_efficiency=1.0, )  # 5. Prepare arrays for Taichi #    Allocate output and cast all arrays to float64 out = np.zeros_like(concentration_lognormal_0, dtype=np.float64) radius_bins = np.asarray(radius_bins, dtype=np.float64) concentration_lognormal_0 = np.asarray(     concentration_lognormal_0, dtype=np.float64 ) kernel = np.asarray(kernel, dtype=np.float64) out = np.asarray(out, dtype=np.float64)  # 6. Estimate floating-point operations per kernel call ops_per_call = 9 * bins_total * (bins_total - 1)  # 7. Benchmark the Taichi kernel (max runtime = 5 seconds) taichi_results = get_function_benchmark(     func=lambda: get_coagulation_gain_rate_continuous_taichi(         radius_bins, concentration_lognormal_0, kernel, out     ),     ops_per_call=ops_per_call,     max_run_time_s=5.0, )  print(\"Taichi Kernel Benchmark Results:\") print(taichi_results[\"report\"]) <pre>Taichi Kernel Benchmark Results:\nBenchmark: 4943 function calls.\n  Throughput      (calls/s)     2,700\n  CPU cycles      (cycles/call) 1,109,348\n  Est. Flops      (flops/call)  2,245,500\n  Efficiency      (flops/cycle) 2.0242\n  Min time        (ms/call)     0.370\n  STDV time       (ms/call)     \u00b14.255\n</pre> In\u00a0[9]: Copied! <pre>bins_total_array = np.logspace(\n    1, 4, 50, dtype=int\n)  # Bin counts from 10 to 10000\ntaichi_benchmark = np.zeros((len(bins_total_array), 11), dtype=np.float64)\npython_benchmark = np.zeros((len(bins_total_array), 11), dtype=np.float64)\n\nfor i, bins_total in tqdm(\n    enumerate(bins_total_array),\n    desc=\"Benchmarking\",\n    total=len(bins_total_array),\n):\n    # 1. Generate size bins (1 nm to 10 \u00b5m)\n    radius_bins = np.logspace(start=-9, stop=-4, num=bins_total)\n\n    # 2. Compute mass per bin (density = 1000 kg/m\u00b3)\n    mass_bins = (4.0 / 3.0) * np.pi * radius_bins**3 * 1e3\n\n    # 3. Generate lognormal PMF distribution\n    concentration_lognormal_0 = par.particles.get_lognormal_pmf_distribution(\n        x_values=radius_bins,\n        mode=np.array(100e-9),\n        geometric_standard_deviation=np.array(1.4),\n        number_of_particles=np.array(1e6 * 1e6),\n    )\n\n    # 4. Compute Brownian coagulation kernel\n    kernel = par.dynamics.get_brownian_kernel_via_system_state(\n        particle_radius=radius_bins,\n        particle_mass=mass_bins,\n        temperature=293.15,\n        pressure=101325,\n        alpha_collision_efficiency=1.0,\n    )\n\n    # 5. Prepare arrays for Taichi\n    out = np.zeros_like(concentration_lognormal_0, dtype=np.float64)\n    radius_bins = np.asarray(radius_bins, dtype=np.float64)\n    concentration_lognormal_0 = np.asarray(\n        concentration_lognormal_0, dtype=np.float64\n    )\n    kernel = np.asarray(kernel, dtype=np.float64)\n    out = np.asarray(out, dtype=np.float64)\n\n    # 6. Estimate FLOPs per call\n    ops_per_call = 9 * bins_total * (bins_total - 1)\n\n    # 7. Benchmark Taichi kernel\n    taichi_results = get_function_benchmark(\n        func=lambda: get_coagulation_gain_rate_continuous_taichi(\n            radius_bins, concentration_lognormal_0, kernel, out\n        ),\n        ops_per_call=ops_per_call,\n        max_run_time_s=5.0,\n    )\n    taichi_benchmark[i, :] = taichi_results[\"array_stats\"]\n\n\n    if bins_total &gt; 2500:\n        # Skip large bin counts to avoid long python runtimes\n        python_benchmark[i, :] = np.nan\n        continue\n    # 8. Benchmark pure-Python implementation\n    python_results = get_function_benchmark(\n        func=lambda: par.dynamics.get_coagulation_gain_rate_continuous(\n            radius_bins, concentration_lognormal_0, kernel\n        ),\n        ops_per_call=ops_per_call,\n        max_run_time_s=5.0,\n    )\n    python_benchmark[i, :] = python_results[\"array_stats\"]\n\n# 9. Display final run summaries\nprint(\"Taichi Last Run Results:\")\nprint(taichi_results[\"report\"])\n</pre> bins_total_array = np.logspace(     1, 4, 50, dtype=int )  # Bin counts from 10 to 10000 taichi_benchmark = np.zeros((len(bins_total_array), 11), dtype=np.float64) python_benchmark = np.zeros((len(bins_total_array), 11), dtype=np.float64)  for i, bins_total in tqdm(     enumerate(bins_total_array),     desc=\"Benchmarking\",     total=len(bins_total_array), ):     # 1. Generate size bins (1 nm to 10 \u00b5m)     radius_bins = np.logspace(start=-9, stop=-4, num=bins_total)      # 2. Compute mass per bin (density = 1000 kg/m\u00b3)     mass_bins = (4.0 / 3.0) * np.pi * radius_bins**3 * 1e3      # 3. Generate lognormal PMF distribution     concentration_lognormal_0 = par.particles.get_lognormal_pmf_distribution(         x_values=radius_bins,         mode=np.array(100e-9),         geometric_standard_deviation=np.array(1.4),         number_of_particles=np.array(1e6 * 1e6),     )      # 4. Compute Brownian coagulation kernel     kernel = par.dynamics.get_brownian_kernel_via_system_state(         particle_radius=radius_bins,         particle_mass=mass_bins,         temperature=293.15,         pressure=101325,         alpha_collision_efficiency=1.0,     )      # 5. Prepare arrays for Taichi     out = np.zeros_like(concentration_lognormal_0, dtype=np.float64)     radius_bins = np.asarray(radius_bins, dtype=np.float64)     concentration_lognormal_0 = np.asarray(         concentration_lognormal_0, dtype=np.float64     )     kernel = np.asarray(kernel, dtype=np.float64)     out = np.asarray(out, dtype=np.float64)      # 6. Estimate FLOPs per call     ops_per_call = 9 * bins_total * (bins_total - 1)      # 7. Benchmark Taichi kernel     taichi_results = get_function_benchmark(         func=lambda: get_coagulation_gain_rate_continuous_taichi(             radius_bins, concentration_lognormal_0, kernel, out         ),         ops_per_call=ops_per_call,         max_run_time_s=5.0,     )     taichi_benchmark[i, :] = taichi_results[\"array_stats\"]       if bins_total &gt; 2500:         # Skip large bin counts to avoid long python runtimes         python_benchmark[i, :] = np.nan         continue     # 8. Benchmark pure-Python implementation     python_results = get_function_benchmark(         func=lambda: par.dynamics.get_coagulation_gain_rate_continuous(             radius_bins, concentration_lognormal_0, kernel         ),         ops_per_call=ops_per_call,         max_run_time_s=5.0,     )     python_benchmark[i, :] = python_results[\"array_stats\"]  # 9. Display final run summaries print(\"Taichi Last Run Results:\") print(taichi_results[\"report\"]) <pre>Benchmarking: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 50/50 [10:33&lt;00:00, 12.66s/it]</pre> <pre>Taichi Last Run Results:\nBenchmark: 169 function calls.\n  Throughput      (calls/s)     55\n  CPU cycles      (cycles/call) 54,779,748\n  Est. Flops      (flops/call)  899,910,000\n  Efficiency      (flops/cycle) 16.4278\n  Min time        (ms/call)     18.290\n  STDV time       (ms/call)     \u00b17.352\n</pre> <pre>\n</pre> In\u00a0[10]: Copied! <pre># figure\nx_array = bins_total_array\n\nfig, ax = plt.subplots()\n\n# Plot Taichi efficiency\nax.plot(\n    x_array,\n    taichi_benchmark[:, -1],\n    label=\"Taichi\",\n    marker=\"o\",\n    color=\"#67e8f9\",\n    markersize=5,\n)\n\n# Plot Python efficiency\nax.plot(\n    x_array,\n    python_benchmark[:, -1],\n    label=\"Python\",\n    marker=\"o\",\n    color=\"#306998\",\n    markersize=5,\n)\n\n# Secondary axis: Taichi-to-Python efficiency ratio\ntwinx = ax.twinx()\nratio = taichi_benchmark[:, 7] / python_benchmark[:, 7]\ntwinx.plot(\n    x_array,\n    ratio,\n    label=\"Taichi:Python\",\n    marker=\"o\",\n    linestyle=\"--\",\n    markersize=5,\n    color=\"gray\",\n)\ntwinx.set_ylabel(\"Taichi to Python Ratio\", color=\"gray\")\n\n# Shade above and below ratio=1\nymin, ymax = ax.get_ylim()\nax.axhspan(1, ymax, facecolor=TAILWIND['teal']['600'], alpha=0.2)\nax.axhspan(ymin, 1, facecolor=TAILWIND['rose']['300'], alpha=0.2)\n\n# Axis labels, title, and scale\nax.set_yscale(\"log\")\nax.set_xscale(\"log\")\nax.set_xlabel(\"Number of size bins\")\nax.set_ylabel(f\"Calculation Efficiency \\n [FLOP/cycle]\")\n\n# Legend and grid\nax.legend(loc=\"upper left\")\nax.grid(True)\n</pre> # figure x_array = bins_total_array  fig, ax = plt.subplots()  # Plot Taichi efficiency ax.plot(     x_array,     taichi_benchmark[:, -1],     label=\"Taichi\",     marker=\"o\",     color=\"#67e8f9\",     markersize=5, )  # Plot Python efficiency ax.plot(     x_array,     python_benchmark[:, -1],     label=\"Python\",     marker=\"o\",     color=\"#306998\",     markersize=5, )  # Secondary axis: Taichi-to-Python efficiency ratio twinx = ax.twinx() ratio = taichi_benchmark[:, 7] / python_benchmark[:, 7] twinx.plot(     x_array,     ratio,     label=\"Taichi:Python\",     marker=\"o\",     linestyle=\"--\",     markersize=5,     color=\"gray\", ) twinx.set_ylabel(\"Taichi to Python Ratio\", color=\"gray\")  # Shade above and below ratio=1 ymin, ymax = ax.get_ylim() ax.axhspan(1, ymax, facecolor=TAILWIND['teal']['600'], alpha=0.2) ax.axhspan(ymin, 1, facecolor=TAILWIND['rose']['300'], alpha=0.2)  # Axis labels, title, and scale ax.set_yscale(\"log\") ax.set_xscale(\"log\") ax.set_xlabel(\"Number of size bins\") ax.set_ylabel(f\"Calculation Efficiency \\n [FLOP/cycle]\")  # Legend and grid ax.legend(loc=\"upper left\") ax.grid(True)"},{"location":"Theory/Accelerating_Python/Details/Taichi_Exploration/#taichi-exploration","title":"Taichi Exploration\u00b6","text":"<p>This notebook investigates the performance benefits of using Taichi\u2014a high-performance, data-oriented programming language\u2014over a pure-Python implementation for computing the coagulation gain rate in aerosol simulations. We sweep the number of particle-size bins and measure:</p> <ul> <li>Execution Time (minimum, mean, and variability)</li> <li>Throughput (calls per second)</li> <li>CPU Cycles per Call</li> <li>Estimated FLOP per Call (fixed at 9 \u00d7 bins_total \u00d7 (bins_total \u2013 1))</li> <li>Efficiency (FLOP per CPU cycle)</li> </ul> <p>All timings use <code>time.perf_counter_ns</code> with garbage collection disabled to ensure clean measurements.</p> <p>Key Results</p> <ul> <li><p>Massive Speedup: Taichi delivers \u223c1,000\u00d7 faster execution than Python at 1,000 bins.</p> </li> <li><p>High Hardware Utilization:</p> <ul> <li>Taichi achieves &gt; 8 FLOPs/cycle, greater than a single AVX2 lane\u2019s double-precision peak (8 FLOPs/cycle).</li> <li>Python languishes at 0.003 FLOPs/cycle, reflecting interpreter overhead and lack of vectorization.</li> </ul> </li> <li><p>Scalability: Taichi\u2019s efficiency ramps up quickly and plateaus around \u223c20x FLOP/cycle for larger bin counts, while Python\u2019s efficiency declines with problem size.</p> </li> <li><p>Overhead Amortization: Startup and kernel-launch costs limit Taichi\u2019s advantage on very small problems, but for \u2265100 bins the benefits become overwhelmingly clear.</p> </li> </ul> <p>By combining a detailed benchmark harness with both numerical metrics and visual plots, this notebook demonstrates how Taichi can accelerate compute-intensive aerosol calculations\u2014making it an attractive choice for large-scale scientific simulations.</p>"},{"location":"Theory/Accelerating_Python/Details/Taichi_Exploration/#taichi-initialization","title":"Taichi Initialization\u00b6","text":"<p>Before running any Taichi kernels, we need to configure the Taichi runtime. Key options:</p> <ul> <li><code>arch</code>: target compute device<ul> <li><code>ti.cpu</code> for CPU execution</li> <li><code>ti.gpu</code> (or other backends) for GPU execution</li> </ul> </li> <li><code>debug</code>: enable extra runtime checks and clearer error messages</li> <li>(Optional) <code>logger_level</code>: control verbosity (<code>\"info\"</code>, <code>\"debug\"</code>, etc.)</li> </ul>"},{"location":"Theory/Accelerating_Python/Details/Taichi_Exploration/#taichi-kernel-continuous-coagulation-gain-rate","title":"Taichi Kernel: Continuous Coagulation Gain Rate\u00b6","text":"<p>This <code>@ti.kernel</code> implements a high-performance Taichi routine to compute the coagulation gain rate for a discrete set of particle size bins. By applying the trapezoidal rule across each adjacent pair of radius bins, it accumulates all pairwise coagulation contributions\u2014weighted by the kernel and concentrations\u2014into an output array. This in-place calculation is well-suited for parallel execution on CPU or GPU backends.</p> <p>Highlights:</p> <ul> <li>Discrete Trapezoidal Integration: Combines values at two neighboring radius points with a half-weighting factor.</li> <li>Pairwise Interaction: Loops over all source bins <code>j</code> for each target bin <code>i</code> to sum kernel\u00d7concentration products.</li> <li>In-Place Output: Writes results directly into the pre-allocated <code>gain_rate</code> array to minimize memory overhead.</li> </ul>"},{"location":"Theory/Accelerating_Python/Details/Taichi_Exploration/#system-information-collector","title":"System Information Collector\u00b6","text":"<p>This utility function aggregates key details about the host machine\u2019s hardware, operating system, and Python runtime environment. It leverages the <code>psutil</code> and <code>platform</code> modules to build a comprehensive snapshot\u2014ideal for diagnostics, logging, or tailoring performance-sensitive behavior.</p> <p>Key Features:</p> <ul> <li>CPU Topology &amp; Usage:<ul> <li>Detects both physical and logical core counts.</li> <li>Measures per-core and total CPU utilization.</li> </ul> </li> <li>CPU Frequencies:<ul> <li>Captures maximum, minimum, and current clock speeds (in MHz).</li> </ul> </li> <li>Platform Information:<ul> <li>Gathers OS name, release, version, machine architecture, and processor details.</li> </ul> </li> <li>Python Runtime Metadata:<ul> <li>Records interpreter version, build tuple, and compiler string.</li> </ul> </li> </ul>"},{"location":"Theory/Accelerating_Python/Details/Taichi_Exploration/#benchmarking-function","title":"Benchmarking Function\u00b6","text":"<p>This utility function measures the execution time of a no-argument function using <code>time.perf_counter_ns</code>, temporarily disabling garbage collection for cleaner measurements. It adapts the number of iterations to meet a minimum count or a maximum runtime, then computes detailed statistical and performance metrics\u2014such as throughput, CPU cycles per call, and floating-point efficiency\u2014returning both raw data and a human-readable summary.</p> <p>Key Features:</p> <ul> <li>GC-Free Timing: Disables and re-enables the garbage collector to avoid interference.</li> <li>Adaptive Iterations: Runs until a minimum number of calls or a maximum elapsed time is reached (unless a fixed repeat count is provided).</li> <li>Comprehensive Statistics: Calculates min, max, mean, mode, median, and standard deviation of per-call timings.</li> <li>Performance Metrics: Estimates calls per second, CPU cycles per call (using <code>psutil</code> to fetch CPU frequency), and FLOPs efficiency.</li> <li>Summary Report: Generates a formatted string summarizing the benchmark in human-readable form.</li> </ul>"},{"location":"Theory/Accelerating_Python/Details/Taichi_Exploration/#why-use-the-minimum-time-flops-based-metrics","title":"Why Use the Minimum Time &amp; FLOPs-Based Metrics\u00b6","text":"<p>When benchmarking numerical code on a modern, multitasking OS, your process competes with background tasks\u2014OS services, antivirus scans, indexing, other applications, etc.\u2014so the mean execution time often fluctuates wildly. The minimum observed time per call, however, reflects the best-case scenario with minimal interference. This makes it:</p> <ul> <li>More Stable: Outliers from context switches or cache misses are discarded.</li> <li>Reproducible: You get a consistent baseline, regardless of transient system load.</li> <li>Optimistic Bound: It approximates the true cost of your code under ideal conditions\u2014perfect for comparing implementations or optimizations.</li> </ul>"},{"location":"Theory/Accelerating_Python/Details/Taichi_Exploration/#tying-minimum-time-to-flops-per-cycle","title":"Tying Minimum Time to FLOPs per Cycle\u00b6","text":"<p>A FLOP (floating-point operation) is any arithmetic operation on floating-point numbers (e.g., add, multiply). By counting how many FLOPs your kernel performs per call and dividing by the minimum time, you obtain the FLOPs per cycle metric:</p> <p>FLOPs per cycle = Total FLOPs per call \u00f7 (min_time_s \u00d7 CPU_Hz)</p> <p>where:</p> <p>CPU cycles per call = min_time_s \u00d7 CPU_Hz</p> <ul> <li><p>Why use min_time_s? Using the minimum time ensures your FLOPs-per-cycle estimate isn\u2019t skewed by background noise. Any spikes in call duration (due to other processes) would artificially lower your measured throughput; the minimum time filters these out.</p> </li> <li><p>What it tells you:</p> <ul> <li>High FLOPs per cycle means you\u2019re effectively leveraging vector units and instruction-level parallelism.</li> <li>A stable FLOPs-per-cycle number lets you track real improvements as you optimize memory access patterns, data layout, or parallelism\u2014free from jitter introduced by OS scheduling.</li> </ul> </li> </ul> <p>Combining the minimum timing with FLOPs-based metrics delivers a clear, noise-resistant view of your code\u2019s true computational efficiency.</p>"},{"location":"Theory/Accelerating_Python/Details/Taichi_Exploration/#setup-for-taichi-kernel-benchmark","title":"Setup for Taichi Kernel Benchmark\u00b6","text":"<p>This snippet demonstrates how to:</p> <ol> <li><p>Define Size Bins: Generate 500 logarithmically spaced radius bins from 1 nm to 10 \u03bcm.</p> </li> <li><p>Compute Mass per Bin: Assume a particle density of 1 g/cm\u00b3 (1000 kg/m\u00b3) to calculate the mass of a spherical particle for each radius.</p> </li> <li><p>Create a Lognormal Distribution: Use a mode of 100 nm, geometric standard deviation of 1.4, and a total concentration of 10,000 cm\u207b\u00b3 (converted to m\u207b\u00b3) to generate the particle-number PMF.</p> </li> <li><p>Calculate the Brownian Coagulation Kernel: Obtain the collision kernel at 293.15 K and 1 atm assuming perfect collision efficiency.</p> </li> <li><p>Prepare for Taichi: Convert all arrays to <code>np.float64</code> for compatibility with the Taichi kernel.</p> </li> <li><p>Estimate Operation Count: Compute <code>ops_per_call = 9 \u00d7 bins_total \u00d7 (bins_total \u2013 1)</code> to reflect the cost of the double loop and trapezoidal integration.</p> </li> <li><p>Benchmark Execution: Run the custom <code>get_function_benchmark</code> for up to 5 s to produce timing and throughput metrics for the <code>get_coagulation_gain_rate_continuous_taichi</code> kernel.</p> </li> </ol>"},{"location":"Theory/Accelerating_Python/Details/Taichi_Exploration/#analysis-of-benchmark-results","title":"Analysis of Benchmark Results\u00b6","text":"<p>The benchmark results for the Taichi kernel <code>get_coagulation_gain_rate_continuous_taichi</code> are as follows:</p> <ul> <li>Total Calls: 7,292</li> <li>Measured Duration per Call: Best-case 0.349 ms; variability \u00b10.781 ms</li> </ul>"},{"location":"Theory/Accelerating_Python/Details/Taichi_Exploration/#key-metrics-interpretation","title":"Key Metrics &amp; Interpretation\u00b6","text":"Metric Value What It Means Throughput ~2,500 calls/s On average, the kernel can be invoked 2,500 times per second. CPU Cycles per Call ~1,000,000 cycles At a 3 GHz clock, that corresponds to ~0.3 ms per call. Estimated FLOP per Call 2,245,500 flops Based on 9 ops \u00d7 500 bins \u00d7 499 bin-pairs in the double loop. Efficiency (FLOP/cycle) ~2.0 flop/cycle Roughly 25 % of an 8 FLOP/cycle peak on a single AVX2 lane (see 3). Min Time ~0.35 ms Best-case latency, reflecting minimal system interference. Standard Deviation \u00b14.0 ms High spread\u2014likely due to OS scheduling, first-call overhead, or background tasks."},{"location":"Theory/Accelerating_Python/Details/Taichi_Exploration/#analysis-recommendations","title":"Analysis &amp; Recommendations\u00b6","text":"<ol> <li><p>Why Minimum Time Matters The min time filters out occasional spikes from OS context switches or cache cold-starts, giving a clearer view of true kernel performance under ideal conditions.</p> </li> <li><p>Throughput vs. Variability</p> <ul> <li>A steady throughput of ~2.5 k calls/s shows the kernel is performant overall.</li> <li>However, a std dev exceeding the mean latency indicates significant jitter. Consider discarding the first few \u201cwarm-up\u201d calls or running on an isolated CPU core to reduce noise.</li> </ul> </li> <li><p>Computational Efficiency At ~2 FLOPs per cycle, the implementation uses vector units but isn\u2019t yet saturating them. Potential optimizations include:</p> <ul> <li>Explicit vectorization (e.g., ensure loops map cleanly to AVX lanes).</li> <li>Data layout tuning to improve memory access patterns and cache usage.</li> <li>GPU offload (Taichi supports CUDA backends), which may boost performance if memory bandwidth and parallelism become limiting.</li> </ul> </li> </ol> <p>This analysis suggests the Taichi implementation delivers strong raw performance but leaves room for both consistency improvements and higher utilization of the hardware\u2019s vector capabilities.</p>"},{"location":"Theory/Accelerating_Python/Details/Taichi_Exploration/#python-vs-taichi-evaluation","title":"Python vs. Taichi Evaluation\u00b6","text":"<p>This snippet measures and compares the execution speed of the Taichi\u2010accelerated coagulation gain\u2010rate kernel against its Python (Numpy+Scipy) counterpart over a range of bin resolutions:</p> <ol> <li><p>Define Bin Resolutions Create <code>bins_total_array</code>, a logarithmically spaced array of bin counts (from 10\u00b9 to 10\u00b3), to sweep different problem sizes.</p> </li> <li><p>Pre\u2010allocate Result Storage Initialize two 2D NumPy arrays\u2014<code>taichi_benchmark</code> and <code>python_benchmark</code>\u2014to hold the 11 statistical metrics (<code>array_stats</code>) returned by our <code>get_function_benchmark</code> for each bin count.</p> </li> <li><p>Loop Over Each Resolution For each <code>bins_total</code> in <code>bins_total_array</code>:</p> <ul> <li>Generate Size Bins (1 nm to 10 \u00b5m)</li> <li>Compute Mass per Bin (density = 1000 kg/m\u00b3)</li> <li>Build Lognormal PMF (mode = 100 nm, GSD = 1.4, concentration = 1e12 m\u207b\u00b3)</li> <li>Calculate Brownian Kernel (T = 293.15 K, P = 101 325 Pa, \u03b1 = 1.0)</li> <li>Prepare Arrays for Taichi (cast to <code>float64</code>)</li> <li>Estimate FLOPs (<code>ops_per_call = 9 * bins_total * (bins_total - 1)</code>)</li> <li>Benchmark Taichi Kernel, storing its <code>array_stats</code></li> <li>Benchmark Pure-Python Implementation, storing its <code>array_stats</code></li> </ul> </li> <li><p>Report Final Results After the loop, print the human\u2010readable \u201creport\u201d summary for the last Taichi and Python runs.</p> </li> </ol>"},{"location":"Theory/Accelerating_Python/Details/Taichi_Exploration/#plot-efficiency-and-speedup","title":"Plot Efficiency and Speedup\u00b6","text":"<p>This figure visualizes how the computational efficiency (in FLOPs per cycle) of the Taichi-accelerated kernel compares to the pure-Python implementation as you vary the number of size bins. It also overlays the Taichi-to-Python speedup ratio on a secondary axis.</p>"},{"location":"Theory/Accelerating_Python/Details/Taichi_Exploration/#taichi-acceleration-analysis-summary","title":"Taichi Acceleration: Analysis &amp; Summary\u00b6","text":"<p>This notebook benchmarks a core coagulation gain\u2010rate kernel implemented both in Taichi and in pure Python, sweeping the number of size bins. For each configuration, it measures:</p> <ul> <li>Execution Time via <code>perf_counter_ns</code> (min/mean/std)</li> <li>Throughput (calls/sec)</li> <li>CPU Cycles per Call</li> <li>Estimated FLOP per Call</li> <li>Efficiency (FLOP per CPU cycle)</li> </ul>"},{"location":"Theory/Accelerating_Python/Details/Taichi_Exploration/#3-scalability-trends","title":"3. Scalability &amp; Trends\u00b6","text":"<ul> <li>Taichi Efficiency rises steeply with increasing bin count, then plateaus around 20 FLOPs/cycle for large problems.</li> <li>Python Efficiency gradually declines as problem size grows.</li> <li>Speedup Ratio (Taichi:Python) increases from a few hundred at small bin counts to \u22481,000\u00d7 at 1,000 bins\u2014demonstrating better amortization of Taichi\u2019s kernel-launch overhead on larger workloads.</li> </ul>"},{"location":"Theory/Accelerating_Python/Details/Taichi_Exploration/#4-interpretation","title":"4. Interpretation\u00b6","text":"<ol> <li><p>Vector &amp; Parallel Utilization Taichi effectively maps the double\u2010loop integration onto SIMD lanes (and potentially multithreading), yielding several FLOPs per cycle.</p> </li> <li><p>Overhead Amortization For very small problems, Taichi\u2019s kernel\u2010launch and data\u2010transfer costs limit speedup. As the workload grows, these overheads become negligible, showcasing Taichi\u2019s true compute advantages.</p> </li> <li><p>Pure-Python Limitations The Python implementation suffers from function\u2010call overhead, lack of parallelism, and no direct access to hardware vector units\u2014resulting in orders-of-magnitude lower throughput.</p> </li> </ol>"},{"location":"Theory/Accelerating_Python/Details/Taichi_Exploration/#5-conclusions-next-steps","title":"5. Conclusions &amp; Next Steps\u00b6","text":"<ul> <li>Taichi provides dramatic acceleration for compute-bound kernels once problem sizes exceed the launch\u2010overhead threshold.</li> </ul> <p>This makes a strong case for using an accelerated backend like Taichi for performance-critical applications in particula simulation package. Other backend options, should be explored before fully committing to one over another.</p>"},{"location":"Theory/Code_Concepts/","title":"Code Concepts","text":"<p>This section is the conceptual overview of the Particula codebase\u2014what design ideas we follow, why we follow them, and where you can dig deeper.</p> <p>If something feels unclear, ask and contribute to an issue or PR\u2014improving the docs is a meaningful contribution.</p>"},{"location":"Theory/Code_Concepts/#why-read-this","title":"Why read this?","text":"<ul> <li>You want to extend Particula without breaking existing work.  </li> <li>You need to audit a calculation and trace where a number comes from.  </li> <li>You plan to prototype a new physical model and wonder which files to touch.  </li> </ul>"},{"location":"Theory/Code_Concepts/#quick-tour","title":"Quick tour","text":"Topic Start here One\u2013line takeaway Philosophy WARMED principle Code must be Writable, Agreeable, Readable, Modifiable, Executable, Debuggable. Dual Paradigm Design Patterns Pick functions for notebooks, builders\u00a0+\u00a0strategies for experiments. OO cheat\u2011sheet Object\u2011Oriented Patterns Strategy, Builder, Factory \u2026 explained with aerosol examples."},{"location":"Theory/Code_Concepts/#naming-rules-tldr","title":"Naming rules (TL;DR)","text":"<ul> <li>Functions that return a value \u2192 <code>get_&lt;quantity&gt;()</code> </li> <li>Classes that encapsulate a pattern \u2192 <code>&lt;Descriptor&gt;&lt;PatternName&gt;</code> </li> </ul> <p>Keeping to these names makes <code>grep</code>, IDE auto\u2011completion, and LLM help far more effective for beginners and experts alike.</p>"},{"location":"Theory/Code_Concepts/Details/Design_Patterns/","title":"Particula Design","text":"<p>Particula purposefully sticks to two complementary coding paradigms so users can pick the style that fits their workflow.</p>"},{"location":"Theory/Code_Concepts/Details/Design_Patterns/#choosing-a-paradigm","title":"Choosing a paradigm","text":"Preference Use case Recommendation Procedural / notebooks Quick calculations, teaching demos Stick to <code>get_</code> functions. OO / large experiments Multiple interacting processes, validation, swapping kernels Use Builders + Strategies."},{"location":"Theory/Code_Concepts/Details/Design_Patterns/#1-procedural-functional-core-verbphrased-helpers","title":"1. Procedural: Functional core \u2013 \u201cverb\u2011phrased\u201d helpers","text":"<p>Pattern: Functions </p> <p>These core functions are in most cases stateless and return a value based on inputs. They have no hidden side effects and are not dependent on any object. They are easy to test and can be replaced with JIT\u2011compiled versions (Numba/C++) in the future.</p> <p>They are the building blocks of the simulation engine. They can be used in a procedural style, making them suitable for quick calculations or teaching demos.</p> <p><code>get_</code> \u2013 prefix that signals \u201cthis function returns a value\u201d.</p> <p>Example:  </p> <pre><code>import particula as par\n\nkernel = par.dynamics.get_turbulent_shear_kernel_st1956_via_system_state(\n    particle_radius=particle_radius,\n    turbulent_dissipation=eddy_dissipation,\n    temperature=temperature,\n    fluid_density=fluid_density,\n)\n</code></pre>"},{"location":"Theory/Code_Concepts/Details/Design_Patterns/#2-objectoriented-nounphrased-abstractions","title":"2. Object\u2011oriented: \u2013 \u201cnoun\u2011phrased\u201d abstractions","text":"<p>Patterns employed</p> <ul> <li>Strategy \u2013 e.g. <code>TurbulentShearCoagulationStrategy</code> selects which kernel to call, built of <code>get_</code> functions. These are the main building blocks of the simulation engine.</li> <li>Builder \u2013 e.g. <code>CombineCoagulationStrategyBuilder</code> validates input and assembles strategies.</li> <li>Factory \u2013 e.g. <code>ActivityFactory</code> creates an <code>ActivityStrategy</code> instance via an <code>ActivityBuilder</code>. These allow for more complex meta programming of simulation objects.</li> <li>Decorator \u2013 e.g. <code>@validate_inputs</code> checks for valid inputs before running the function. These are used to enforce domain specific invariants (positive radius, non\u2011negative concentration, finite Coulomb potential,\u00a0\u2026).</li> <li>Mixin \u2013 thin, single\u2011responsibility classes adding orthogonal capabilities (density, charge, surface\u00a0\u2026).  </li> </ul> <p>For a broader overview of design patterns, see Object\u2011Oriented Patterns.</p> <p>Example (combining two kernels):</p> <pre><code>import particula as par\n\n# Step 1: Build your individual strategies\nbrownian_strategy = (  # using a builder for the Brownian kernel\n    par.dynamics.BrownianCoagulationBuilder()\n    .set_distribution_type(\"discrete\")\n    .build()\n)\n\nturbulent_strategy = (  # directly creating the strategy\n    par.dynamics.TurbulentShearCoagulationStrategy(\n        distribution_type=\"discrete\",\n        turbulent_dissipation=0.01,    # example value [m^2/s^3]\n        fluid_density=1.225            # air at sea level [kg/m^3]\n    )\n)\n\n# Step 2: Combine strategies with the builder\nbuilder = par.dynamics.CombineCoagulationStrategyBuilder()\nbuilder.set_strategies([brownian_strategy, turbulent_strategy])\ncombined_strategy = builder.build()\n\n# Step 3: Use the combined strategy in a coagulation process\ncoagulation_process = par.dynamics.Coagulation(\n    coagulation_strategy=combined_strategy\n)\n</code></pre> <p>Benefits</p> <ul> <li>Plug\u2011and\u2011play process swapping \u2192 perfect for sensitivity studies.  </li> <li>Builder validation enforces Agreeing (the A in WARMED).</li> </ul>"},{"location":"Theory/Code_Concepts/Details/Design_Patterns/#naming-conventions","title":"Naming conventions","text":"<ul> <li>Functions \u2192 <code>get_&lt;quantity&gt;[_via_system_state]</code> </li> <li>Classes \u2192 <code>&lt;Descriptor&gt;&lt;PatternName&gt;</code> (<code>TurbulentShearCoagulationStrategy</code>, <code>PresetParticleRadiusBuilder</code>)  </li> </ul> <p>These rules make grep\u2011based discovery trivial and help LLMs auto\u2011suggest the correct object.</p>"},{"location":"Theory/Code_Concepts/Details/Design_Patterns/#future-evolution","title":"Future evolution","text":"<p>Performance work (Numba/C++) will follow the \u201creplace the function, keep the interface\u201d rule\u2014strategies will automatically inherit the speed\u2011ups without further changes.</p>"},{"location":"Theory/Code_Concepts/Details/Object_Oriented_Patterns/","title":"Object\u2011Oriented Patterns","text":"<p>Particula mixes a functional \u201ccore\u201d with a small, carefully chosen set of object\u2011oriented design patterns.</p> <p>The goal is to give researchers who are new to programming a mental map for how the library is organized and why certain classes look the way they do.</p>"},{"location":"Theory/Code_Concepts/Details/Object_Oriented_Patterns/#1-why-design-patterns","title":"1. Why design patterns?","text":"<p>Design patterns are reusable solutions to common software problems. They offer three big advantages:</p> <ol> <li>A shared vocabulary \u2013 \u201cStrategy\u201d, \u201cBuilder\u201d, \u201cFactory\u201d tell collaborators (and LLMs!) instantly what to expect.</li> <li>Separation of concerns \u2013 each class has one clear job, making the code easier to test and swap.</li> <li>Future proofing \u2013 performance upgrades or new physical models can be slotted in without touching user scripts.</li> </ol> <p>If these terms are new to you, don\u2019t panic. The next sections introduce each pattern and show how Particula uses it.</p>"},{"location":"Theory/Code_Concepts/Details/Object_Oriented_Patterns/#2-key-patterns-used-in-particula","title":"2. Key patterns used in Particula","text":""},{"location":"Theory/Code_Concepts/Details/Object_Oriented_Patterns/#21-strategy-selecting-how","title":"2.1 Strategy \u2013 selecting \u201chow\u201d","text":"<p>Problem\u00a0solved: \u201cI need to choose between different algorithms at run\u2011time.\u201d</p> <p>General idea <pre><code>Context \u2500\u2500&gt; StrategyA\n        \u2502\n        \u2514\u2500\u2500&gt; StrategyB\n</code></pre></p> <p>Particula examples \u2022 <code>TurbulentShearCoagulationStrategy</code> \u2013 calls the correct turbulence kernel. \u2022 <code>VaporPressureStrategy</code> (and its concrete subclasses) \u2013 picks the physical equation for a gas.</p> <p>Take\u2011away: A \u201cStrategy\u201d object is just a plug\u2011in. Swap it out, the rest of the simulation keeps running.</p>"},{"location":"Theory/Code_Concepts/Details/Object_Oriented_Patterns/#22-builder-piecing-together-valid-objects","title":"2.2 Builder \u2013 piecing together valid objects","text":"<p>Problem\u00a0solved: \u201cCreating the object requires many parameters and consistency checks.\u201d</p> <p>General idea <pre><code>builder = FancyBuilder()\nbuilder.set_x(\u2026)\nbuilder.set_y(\u2026)\nobj = builder.build()\n</code></pre></p> <p>Particula examples \u2022 <code>BrownianCoagulationBuilder</code> \u2013 validates distribution type, temperature, etc. \u2022 <code>CombineCoagulationStrategyBuilder</code> \u2013 glues several strategies into one composite strategy.</p> <p>Tip for new users: the builder pattern reads almost like an English sentence; you can\u2019t \u201cforget\u201d a required parameter because <code>build</code> would refuse to run.</p>"},{"location":"Theory/Code_Concepts/Details/Object_Oriented_Patterns/#23-factory-hiding-construction-complexity","title":"2.3 Factory \u2013 hiding construction complexity","text":"<p>Problem\u00a0solved: \u201cI want one function that returns a ready\u2011to\u2011use object, but internally different builders/strategies decide what\u2019s best.\u201d</p> <p>General idea (but not implemented in Particula yet) <pre><code>strategy = ActivityFactory.create(name=\"water\", temperature=298)\n</code></pre></p> <p>Particula example \u2022 <code>ActivityFactory</code> \u2013 selects the proper <code>ActivityStrategy</code> (Raoult | Pitzer | AI model \u2026) based on user input.</p>"},{"location":"Theory/Code_Concepts/Details/Object_Oriented_Patterns/#24-decorator-adding-orthogonal-behavior","title":"2.4 Decorator \u2013 adding orthogonal behavior","text":"<p>Problem\u00a0solved: \u201cI need to add validation or logging without touching the original function.\u201d</p> <p>Particula example <pre><code>@validate_inputs({\"radius\": \"positive\"})\ndef get_brownian_kernel(\u2026):\n    \u2026\n</code></pre> <code>@validate_inputs</code> throws a helpful error before the computation starts.</p>"},{"location":"Theory/Code_Concepts/Details/Object_Oriented_Patterns/#25-mixin-small-capability-boosters","title":"2.5 Mixin \u2013 small capability boosters","text":"<p>Problem\u00a0solved: \u201cSeveral unrelated classes need the same micro\u2011feature.\u201d</p> <p>Example (conceptual) <pre><code>class ChargeMixin:\n    def get_charge_density(self): \u2026\n\nclass Particle(ChargeMixin, BaseParticle): \u2026\n</code></pre></p> <p>Particula\u2019s <code>DensityMixin</code>, <code>ChargeMixin</code>, etc. inject a single extra property without polluting the main class hierarchy.</p>"},{"location":"Theory/Code_Concepts/Details/Object_Oriented_Patterns/#26-abstract-base-class-abc-enforcing-an-interface","title":"2.6 Abstract Base Class (ABC) \u2013 enforcing an interface","text":"<p>Python code can be \u201cduck\u2011typed\u201d, but aerosols need guarantees! <code>BuilderABC</code>, <code>DistributionStrategy</code>, and <code>VaporPressureStrategy</code> define required methods (<code>build</code>, <code>pure_vapor_pressure</code>, \u2026). Concrete subclasses must implement them or Python raises a clear error.</p>"},{"location":"Theory/Code_Concepts/Details/Object_Oriented_Patterns/#27-template-method-fixed-skeleton-overridable-steps","title":"2.7 Template Method \u2013 fixed skeleton, overridable steps","text":"<p><code>RunnableSequence</code> keeps the loop logic (\u201cfor each process: run, pass aerosol to next\u201d), while each individual <code>Runnable</code> supplies the physics in its <code>__execute__</code> method.</p>"},{"location":"Theory/Code_Concepts/Details/Object_Oriented_Patterns/#28-composition-inheritance","title":"2.8 Composition\u00a0&gt;\u00a0Inheritance","text":"<p>\u201cFavor composition over inheritance\u201d is the golden rule that keeps Particula\u2019s class tree shallow. Instead of a deep hierarchy like</p> <pre><code>BaseParticle\n\u2514\u2500\u2500 BrownianParticle\n    \u2514\u2500\u2500 ChargedBrownianParticle\n        \u2514\u2500\u2500 \u2026\n</code></pre> <p>Particula builds objects out of smaller collaborating parts:</p> <pre><code>representation = ParticleRepresentation(\n    strategy=MassBasedMovingBin(...),     # \u21e6 behaviour plug\u2011in\n    activity=RaoultActivityStrategy(...), # \u21e6 second behaviour plug\u2011in\n)\naerosol = Aerosol(atmosphere=atm, particle_representation=representation)\n</code></pre> <p>\u2022 <code>Aerosol</code> has an <code>Atmosphere</code>; it does not inherit from it. \u2022 <code>ParticleRepresentation</code> has a <code>DistributionStrategy</code>.  </p> <p>Benefits \u2013 no \u201cdiamond\u201d problems, \u2013 you can replace any sub\u2011component at run\u2011time, \u2013 unit tests target one responsibility at a time.</p>"},{"location":"Theory/Code_Concepts/Details/Object_Oriented_Patterns/#29-behavior-abstraction-naming-rules","title":"2.9 Behavior, abstraction\u00a0&amp; naming\u00a0rules","text":"<p>Particula leans on the four classic OO pillars:  </p> Pillar In practice Encapsulation State + behavior live together (<code>ParticleRepresentation.get_radius()</code> uses its own density). Abstraction Public API says what (\u201cget mass\u201d), strategies hide how (Brownian vs Gopalakrishnan). Inheritance Kept minimal\u2014mainly <code>ABC</code> bases and tiny mixins. Used for defining interfaces for strategies Polymorphism Swap one <code>DistributionStrategy</code> for another without touching calling code."},{"location":"Theory/Code_Concepts/Details/Object_Oriented_Patterns/#naming-quickreference","title":"Naming quick\u2011reference","text":"<ul> <li>Functions that return a value \u2192 <code>get_&lt;quantity&gt;()</code> </li> <li>Classes that encapsulate a pattern \u2192 <code>&lt;Descriptor&gt;&lt;PatternName&gt;</code>   \u2013 <code>BrownianCoagulationBuilder</code>, <code>WaterBuckStrategy</code>, <code>RunnableSequence</code> </li> </ul> <p>Sticking to these names makes grep, IDE auto\u2011complete and LLM help far more effective for beginners.</p>"},{"location":"Theory/Code_Concepts/Details/Object_Oriented_Patterns/#3-how-the-patterns-cooperate","title":"3. How the patterns cooperate","text":"<ol> <li>Builder validates user input and produces a Strategy.  </li> <li>Mixin adds common <code>set_</code> to builders.  </li> <li>Factory decides which Builder/Strategy combo to use.  </li> <li>Decorator checks invariants every time the Strategy\u2019s function is called.  </li> <li>Template Method (RunnableSequence) orchestrates the time\u2011stepping.</li> </ol> <p>This layering means you can:</p> <ul> <li>swap a Strategy for a faster JIT\u2011compiled one,  </li> <li>add a new vapor\u2011pressure correlation,  </li> <li>or prototype an entirely new process,</li> </ul> <p>without touching more than a single, well\u2011contained file.</p>"},{"location":"Theory/Code_Concepts/Details/Object_Oriented_Patterns/#4-cheatsheet-for-new-users","title":"4. Cheat\u2011sheet for new users","text":"Pattern You will see it as\u2026 What to remember Strategy <code>*Strategy</code> classes A plug\u2011in algorithm Builder <code>*Builder</code> classes Step\u2011wise, validated construction Factory <code>*Factory.get_strategy()</code> One\u2011line object creation Decorator <code>@validate_inputs</code> Adds checks around a function Mixin <code>ChargeMixin</code>, <code>DensityMixin</code> Supplies a single feature ABC Classes inheriting from <code>*ABC</code> Enforces required methods/interfaces Template <code>RunnableSequence</code> + <code>RunnableABC</code> Fixed loop, custom steps"},{"location":"Theory/Code_Concepts/Details/Object_Oriented_Patterns/#example","title":"Example","text":""},{"location":"Theory/Code_Concepts/Details/Object_Oriented_Patterns/#builder-pattern-with-inline-comments","title":"Builder Pattern with Inline Comments","text":"<p>In this example, we point out which parts are classes (blueprints), which parts are objects (instances created from these classes), and which are functions (methods) that you call to change the internal state or retrieve values from the final object. Notice in particular how properties and methods are \u201cinjected\u201d into the builder and, ultimately, become part of the final particle representation object (<code>particle_rep_mass</code>). This example is based on the Particle Representation Tutorial.</p> <pre><code>import numpy as np\nimport particula as par\n\n# Define basic particle parameters.\n# Here, 'radius' and 'concentration' are objects from NumPy (created by the np.array() function)\n# and 'density' is just a numerical value.\nradius = np.array([100, 200, 300], dtype=np.float64)  # Object: NumPy ndarray holding radii values in nanometers.\ndensity = 2.5  # A simple numeric value representing density.\nconcentration = np.array([1e2, 1e3, 1e4], dtype=np.float64)  # NumPy array holding concentration values.\n\n# ----------------------------------------------------------------------------\n# The following section uses builder classes to set up the particle properties.\n# ----------------------------------------------------------------------------\n\n# 'SurfaceStrategyMassBuilder' is a class (a blueprint) that, when instantiated,\n# returns an object (builder instance) which provides methods to set up a surface strategy.\n# Here, we call its methods 'set_surface_tension' and 'set_density'.\n# Each of these methods is a function defined on the builder class that sets a property\n# into the builder's internal state. These properties are later used to construct the final surface strategy object.\nsurface_tension_strategy = (\n    par.particles.SurfaceStrategyMassBuilder()  # Class constructor: returns a builder object for surface strategy.\n    .set_surface_tension(0.072, \"N/m\")          # Method: injects the surface tension value; function attached to the builder object.\n    .set_density(2.5, \"g/cm^3\")                 # Method: injects the density value; also a function on the builder.\n    .build()                                    # Method: finalizes the builder and returns the surface strategy object.\n)\n\n# 'ParticleRadiusRepresentationBuilder' is another class used to create a particle representation object (how particles are represented in the simulation).\n# This builder gives you a fluent interface where each set_* method is a function that updates the builder instance.\n# They are not standalone functions but methods that belong to the builder object.\nparticle_rep_mass = (\n    par.particles.ParticleRadiusRepresentationBuilder()            # Class call: creates a builder object for particle representation.\n    .set_distribution_strategy(par.particles.RadiiBasedMovingBin())  # Method call: sets the distribution strategy. Note: 'RadiiBasedMovingBin()' is itself a class constructor; its returned object is injected as a property.\n    .set_activity_strategy(par.particles.ActivityIdealMass())      # Method call: sets the activity strategy. 'ActivityIdealMass()' is created by its class constructor and injected here.\n    .set_surface_strategy(surface_tension_strategy)                # Method call: injects the previously built surface strategy object.\n    .set_concentration(concentration=concentration, concentration_units=\"1/cm^3\")  # Method: sets the concentration property; the function here attaches the numerical array to the builder.\n    .set_density(density=density, density_units=\"g/cm^3\")    # Method: sets the density property.\n    .set_radius(radius=radius, radius_units=\"nm\")            # Method: sets the radius property.\n    .set_charge(charge=0)                                    # Method: sets the charge property (for example, neutral particles).\n    .build()   # Method: finalizes the builder and returns the final particle representation object.\n               # After 'build()' is called, all were \"injected\" into a newly created ParticleRepresentation instance.\n)\n\n# ----------------------------------------------------------------------------\n# At this point, 'particle_rep_mass' is an object (an instance) of the ParticleRepresentation class.\n# The methods get_mass(), get_radius(), and get_mass_concentration() are functions defined on that object.\n# These functions are \"injected\" as part of the object's class definition \u2013 they allow you to retrieve calculated properties.\n# How the properties are calculated is different for each ParticleRepresentation class, but you see the same interface at the object level.\n# ----------------------------------------------------------------------------\n\n# Calling methods (functions attached to the object 'particle_rep_mass') to access computed properties:\nprint(\"Mass of particles:\", particle_rep_mass.get_mass())  \n# get_mass() is a method attached to the 'particle_rep_mass' object; it calculates and returns the mass.\nprint(\"Radius of particles:\", particle_rep_mass.get_radius())  \n# get_radius() is also an object method, returning the calculated radii.\nprint(\"Total mass of the particle distribution:\", particle_rep_mass.get_mass_concentration())\n# get_mass_concentration() is another method attached to the final object, computing the overall mass concentration.\n</code></pre> <p>In this commented code:</p> <ul> <li>Classes like <code>SurfaceStrategyMassBuilder</code> and <code>ParticleRadiusRepresentationBuilder</code> use PascalCase as is typical for class names. However, snake_case is used for methods (functions) that are called on the instances of these classes.</li> <li>When we call a class (like <code>par.particles.SurfaceStrategyMassBuilder()</code>), it creates an object (a builder instance) that we then use to set properties.</li> <li>Methods like <code>set_surface_tension</code>, <code>set_density</code>, <code>set_concentration</code>, etc., are functions defined on those builder objects \u2013 they modify the internal state (i.e., inject properties) so that when you call <code>build()</code>, their values are used to create the final product.</li> <li>The final built object, <code>particle_rep_mass</code>, is an instance of a <code>ParticleRepresentation</code>. It has methods (like <code>get_mass()</code>) that are injected via the class definition and allow you to retrieve data computed from the properties previously injected via the builder pattern.</li> </ul> <p>This clear separation of classes (blueprints), objects (instances created via constructors or build methods), and functions (methods attached to the objects) is a key principle in object-oriented programming and is leveraged by Particula for flexible aerosol simulations.</p>"},{"location":"Theory/Code_Concepts/Details/Object_Oriented_Patterns/#further-information","title":"Further Information","text":""},{"location":"Theory/Code_Concepts/Details/Object_Oriented_Patterns/#youtube-videos","title":"YouTube videos","text":"<ul> <li>Firebase's video on Design Patterns \u2013 a great introduction to the most common patterns.</li> <li>CodeAesthetic: Abstraction, Naming, The Flaws of Inheritance.</li> <li>ThePrimeagen's: 8 Design Patterns, Why Python.</li> </ul>"},{"location":"Theory/Code_Concepts/Details/Object_Oriented_Patterns/#reading","title":"Reading","text":"<ul> <li>The WARMED principle \u2013 Particula's philosophy for writing readable, swap\u2011friendly scientific code.</li> <li>Object\u2011Oriented Patterns \u2013 an expanded overview of design patterns in general.</li> <li>Design Patterns: Elements of Reusable Object\u2011Oriented Software \u2013 the classic book by Gamma et al. (1994).</li> </ul>"},{"location":"Theory/Code_Concepts/Details/WARMED_principle/","title":"WARMED Code","text":"<p>A concise philosophy for building and maintaining Particula.</p> Letter Focus One\u2013line guideline W Writing Write code that is direct, minimal, and fits the problem. A Agreeing Discuss and settle on how a feature is implemented before merging. R Reading Code and variable names must explain themselves; comments fill the gaps, not the voids. M Modifying Any competent dev should be able to extend or swap a component in minutes. E Executing Favor vectorization and avoid hidden <code>for</code>\u2011loops. D Debugging Fail fast with helpful messages and provide deterministic tests. <p>See Casey Muratori\u2019s Where Does Bad Code Come From? talk for a deep dive into the WARMED principles.</p>"},{"location":"Theory/Code_Concepts/Details/WARMED_principle/#why-warmed-instead-of-clean","title":"Why WARMED instead of CLEAN?","text":"<p>CLEAN\u00a0Code is not an effective guide. Aerosol scientists are usually both the developer and the user. WARMED shifts the emphasis from enterprise\u2011scale maintainability toward day\u2011to\u2011day research agility:</p> <ul> <li>Really short iterations: prototype \u2794 publish \u2794 archive.</li> <li>Minimal ceremony: no \u201cservice layers\u201d or factory jungles.</li> <li>Maximum clarity for humans and language models\u2014LLMs can audit, explain, and even refactor WARMED\u2011style code.</li> </ul> <p>See Casey Muratori\u2019s \"Clean\" Code, Horrible Performance talk for a deep dive into why CLEAN runs into problems.</p>"},{"location":"Theory/Code_Concepts/Details/WARMED_principle/#practical-safeguards-already-in-place","title":"Practical safeguards already in place","text":"<ul> <li>Builder classes check required parameters and types before any heavy work starts.</li> <li><code>@validate_inputs</code> decorators enforce domain\u2011specific invariants (positive radius, non\u2011negative concentration, finite Coulomb potential,\u00a0\u2026).</li> <li>Exhaustive docstrings + LLMs docs make auto\u2011completion meaningful in modern IDEs.</li> </ul>"},{"location":"Theory/Code_Concepts/Details/WARMED_principle/#where-warmed-shows-up-in-the-repo","title":"Where WARMED shows up in the repo","text":"<pre><code>particula/\n \u251c\u2500 dynamics/\u2026/turbulent_shear_kernel.py   \u2190 readable, single\u2011purpose functions\n \u251c\u2500 dynamics/\u2026/coagulation_builder/        \u2190 builders enforce \u201cA\u201d &amp; \u201cM\u201d\n \u251c\u2500 util/validate_inputs.py                \u2190 fast\u2011fail debugging\n \u2514\u2500 docs/                                  \u2190 you are here (R)\n</code></pre>"},{"location":"Theory/OpenAI_Models/","title":"OpenAI Models","text":"<p>High\u2011quality API docstrings, runnable examples, and deep theory notes are not mere decoration in Particula\u2014they are the very \u201cfuel\u201d of the OpenAI models and retrieval\u2011augmented\u2011generation (RAG) pipeline. Every one of those text chunks is embedded and stored in the shared vector database; when a user asks a question the RAG step pulls them back and feeds them to the model.  The clearer and more complete those chunks are, the more precise and executable the answers and Python simulation code the model can generate.  Improving documentation therefore directly improves the context and domain intelligence of the models.</p> <p>Particula uses OpenAI models in three functional layers.  </p> <p>Every request\u2014no matter which model you pick\u2014goes through the same retrieval\u2011augmented\u2011generation (RAG) pipeline:</p> <ol> <li>Embed the user prompt and generate additional related search terms. </li> <li>Pull the k nearest code\u00a0/\u00a0doc chunks from the shared vector store.  </li> <li>Prepend those chunks to the prompt before generating the final answer.</li> </ol> <p>This RAG step is therefore universal across all layers.</p> Layer RAG\u2011assisted purpose Main Models 1. Chat Conversational &amp; multimodal I/O (vector\u2011RAG enriched) gpt\u20114o, gpt\u20114.1, gpt\u20114.1\u2011mini/\u2011nano 2. Reasoning Tool\u2011calling, step\u2011by\u2011step logic (vector\u2011RAG enriched) o1, o3, o3\u2011mini, o4\u2011mini 3. Agent Orchestrates Chat\u00a0\uff0b\u00a0Reasoning with RAG. ParticulaAgent <p>The following pages drill into each layer.</p> <ul> <li>1. Chat \u2013 conversational generalists, vector\u2011RAG enriched.</li> <li>2. Reasoning \u2013 tool\u2011calling, step\u2011by\u2011step logic, vector\u2011RAG enriched.</li> <li>3. Agent \u2013 Self\u2011orchestrating agent that combines Chat\u00a0\u271a\u00a0Reasoning with RAG. Note: this is a work in progress.</li> </ul> <p>Tip: Start with Chat for \u201cHow do I\u2026?\u201d questions, move to Reasoning for multi\u2011step workflows.</p>"},{"location":"Theory/OpenAI_Models/#particula-assistant-openai-gpts-public-access","title":"Particula Assistant \u2013 OpenAI\u00a0GPTs (public access)","text":"<p>Anyone can use the public Particula Assistant. It runs the base GPT chat models and is perfect for quick Q&amp;A or simple code snippets\u2014no special approval required.</p> <pre><code>graph TB\n    U[\"User\"] --&gt;|prompt| CHAT[\"OpenAI-GPTs\"]\n    CHAT --&gt;|tool call| VS[(Vector Store)]\n    VS --&gt; |API/Examples/Theory| CHAT\n    CHAT --&gt;|answer| U</code></pre>"},{"location":"Theory/OpenAI_Models/#particula-chat-beta-advanced-models-via-access-request","title":"Particula\u00a0Chat\u00a0Beta \u2013 advanced models (via access request)","text":"<p>Access to the advanced GPT\u20114.1 and o\u2011series models (both Chat and Reasoning) requires a one\u2011time access request. See the link in the GitHub Discussions to apply, then login with GitHub at Particula Chat Beta.</p> <pre><code>graph TB\n    U[\"User\"] --&gt;|prompt| REAS[\"Chat or Reasoning Model\"]\n    REAS --&gt;|tool call| VS[(Vector Store)]\n    VS --&gt; |API/Examples/Theory| REAS\n    REAS --&gt;|final answer| U</code></pre>"},{"location":"Theory/OpenAI_Models/#other-model-families-future-support","title":"Other model families &amp; future support","text":"<p>Particula will eventually add adapters for Anthropic\u00a0Claude, Google\u00a0Gemini, and leading open\u2011source models (Llama\u00a03, Mixtral, etc.).  For now the docs focus on OpenAI because we want to scale deep before we scale wide:</p> <ol> <li>One provider \u2192 one API surface \u2192 fewer moving parts while we harden    the RAG/tool stack.</li> <li>Deep optimization of prompt templates, token accounting, error handling    and retries is possible only when the target is fixed.</li> <li>A single deterministic reference model keeps examples, tests and    benchmarks reproducible for every contributor.</li> </ol> <p>Once this vertical integration is rock\u2011solid, adding new providers is a matter of writing a thin adapter under the existing chat-interface facade\u2014the Agent, RAG retrieval, and prompt logic remain unchanged.</p> <p>This \u201cdepth\u2011first, breadth\u2011later\u201d strategy yields robust tools sooner, benefiting new users with stability and advanced users with a clear path to multi\u2011vendor redundancy.</p> <p>Reference: OpenAI Docs</p>"},{"location":"Theory/OpenAI_Models/Models/Agents/","title":"Agents","text":"<p>The Agent\u2019s role is to decide which model to invoke. It can be more independent than a simple chat or reasoning model, and can orchestrate multiple models and tools in a single workflow.</p>"},{"location":"Theory/OpenAI_Models/Models/Agents/#orchestration-flow","title":"Orchestration flow","text":"<p>This is our current vision for the Agent workflow. It is not yet implemented, but it will be the basis for the final design.</p> <pre><code>graph TB\n    subgraph User\n        U[\"Web Interface\"]\n    end\n    U --&gt;|prompt| A[\"Particula Agent\"]\n    A --&gt;|vector search| V[(Vector Store)]\n    V --&gt;|context| A\n    A --&gt;|choose model| M{\"Chat/Reasoning\"}\n    M --&gt;|LLM response| A\n\n    %% Python call delegated to a Chat model\n    A --&gt;|invoke| CP[\"Simulation Chat Model\"]\n    CP --&gt;|generate simulation| PT[[Python Tool]]\n    PT --&gt;|run simulation| SC[[Simulation Calculation]]\n    SC --&gt;|results| CP\n    CP --&gt;|return analysis| A\n\n    A --&gt;|final answer| U</code></pre> <p>Decision policy:</p> <ul> <li>quick explanations, short multimodal queries \u2192 Chat\u00a0(GPT\u20114o\u2011mini)  </li> <li>medium complexity with images or \u2264128\u00a0k context \u2192 Chat\u00a0(GPT\u20114o / GPT\u20114.1mini)  </li> <li>long context, code generation, or tool execution \u2192 Reasoning\u00a0(o3mini / o4\u2011mini)  </li> <li>deeply nested logic or heavy planning \u2192 Reasoning\u00a0(o3 or larger o\u2011series)</li> </ul> <p>Note: This Agent workflow is our goal.</p> <p>Reference: OpenAI Agents Docs</p>"},{"location":"Theory/OpenAI_Models/Models/Chat/","title":"Chat","text":"<p>Chat models are conversational generalists. In Particula they are used for:</p> <ul> <li>interactive tutorials &amp; \u201cexplain\u2011this\u2011output\u201d prompts,</li> <li>translating user intent to build small function or class calls.</li> </ul> <p>Each chat request is wrapped in a vector\u2011RAG layer that pulls the most relevant Particula API &amp; docs snippets before the prompt reaches the LLM.</p> <pre><code>graph TB\n    U[\"User\"] --&gt;|prompt| REAS[\"Chat Model\"]\n    REAS --&gt;|tool call| VS[(Vector Store)]\n    VS --&gt; |API/Examples/Theory| REAS\n    REAS --&gt;|final answer| U</code></pre>"},{"location":"Theory/OpenAI_Models/Models/Chat/#gpt4o","title":"GPT\u20114o","text":"<p>GPT\u20114o (o for omni) is a multimodal model that natively handles text, images, and (soon) audio &amp; video inside one architecture.</p> <ul> <li>128\u00a0k\u2011token context</li> <li>GPT\u20114\u2011Turbo parity on code &amp; English\u2003</li> <li>better vision &amp; non\u2011English.</li> </ul> <p>Use for: integrated visual or mixed\u2011media reasoning (diagrams, photos, future A/V).</p>"},{"location":"Theory/OpenAI_Models/Models/Chat/#gpt41","title":"GPT\u20114.1","text":"<p>April\u00a02025 upgrade to 4o.</p> <ul> <li>1\u00a0M\u2011token context window</li> <li>+21\u00a0% coding accuracy vs\u00a04o\u2003</li> <li>26\u00a0% cheaper ops.</li> </ul> <p>Use for: very\u2011long\u2011context refactors, legal/scientific deep\u2011dives, multi\u2011step agents.</p>"},{"location":"Theory/OpenAI_Models/Models/Chat/#gpt41mini-gpt41nano","title":"GPT\u20114.1mini &amp; GPT\u20114.1nano","text":"<ul> <li>mini \u2013 \u00bd\u00a0latency, 83\u00a0% cheaper than 4o, still beats it on many tasks.  </li> <li>nano \u2013 smallest &amp; fastest of 4.1.</li> </ul> <p>Use for: mini \u2192 balanced power/cost; nano \u2192 ultra\u2011light, real\u2011time or mobile agents.</p> <p>Reference:</p> <ul> <li>OpenAI Docs</li> <li>OpenAI 4.1 press release</li> </ul>"},{"location":"Theory/OpenAI_Models/Models/Reasoning/","title":"Reasoning","text":"<p>Reasoning models take over when a problem needs planning, tool\u2011execution or long chains of logic that go beyond ordinary chat. They can internally reflect (\u201cthink\u2011step\u2011by\u2011step\u201d), decide which tool to call, run it, and stitch the results into a final answer.</p> <p>Like the chat models, every reasoning call is loaded with the same vector\u2011store RAG retrieval: the user query is embedded, the k\u2011nearest Particula code/doc chunks are fetched, and those snippets are injected as system context before step\u2011by\u2011step reasoning begins.</p> <p>For Particula, the reasoning models are good at creating new simulations that integrate multiple examples. They are also good at explaining complex parts of the code, and can help with debugging.</p> <pre><code>graph TB\n    U[\"User\"] --&gt;|prompt| REAS[\"Reasoning Model\"]\n    REAS --&gt;|plans| REF[\"Reflection\"]\n    REF --&gt;|insights| REAS\n    REAS --&gt;|tool call| VS[(Vector Store)]\n    VS --&gt;|context| REAS\n    REAS --&gt;|final answer| U</code></pre>"},{"location":"Theory/OpenAI_Models/Models/Reasoning/#o1","title":"o1","text":"<p>Released Dec\u00a02024.</p> <p>Reflective model that \u201cthinks before it speaks\u201d, excelling at logic\u2011heavy tasks and often outscoring GPT\u20114o on scientific proofs or algorithm design.  </p> <p>Use for: pure\u2011text, deep step\u2011by\u2011step reasoning when no images are needed.</p>"},{"location":"Theory/OpenAI_Models/Models/Reasoning/#o3","title":"o3","text":"<p>April\u00a02025 flagship reasoning model.</p> <p>Combines multimodal thinking with full ChatGPT tool access (web, Python exec, file/vision analysis, memory).</p> <p>Use for: demanding multimodal + tool workflows (data\u2011science with charts, iterative coding with live runs, image\u2011grounded research).</p>"},{"location":"Theory/OpenAI_Models/Models/Reasoning/#o3-mini","title":"o3-mini","text":"<p>Compact version of o3. Same multimodal &amp; tool features, lower latency/cost.  </p> <p>Use for: throughput\u2011 or budget\u2011constrained environments needing o3 power.</p>"},{"location":"Theory/OpenAI_Models/Models/Reasoning/#o4mini","title":"o4\u2011mini","text":"<p>Released alongside o3, optimized for speed &amp; efficiency.  </p> <p>99.5\u00a0% AIME\u20112025 pass rate with Python interpreter, very low latency.  </p> <p>Use for: high\u2011volume or real\u2011time multimodal apps (edu tools, live autograding).</p> <p>Reference:</p> <ul> <li>OpenAI Docs</li> <li>OpenAI o3 o4-mini press release</li> </ul>"},{"location":"Theory/Technical/","title":"Technical","text":"<p>This section provides documentation for some of the technical aerosol science concepts and equations that are relevant to the Particula package. It includes mathematical equations, physical principles, and other scientific concepts that are used in the development and application of the Particula package.</p> <p>See the sidebar on the left for a list of topic categories and their contents.</p>"},{"location":"Theory/Technical/Dynamics/Condensation_Equations/","title":"Condensation Discussion","text":"<p>Isothermal and non-isothermal condensation processes are fundamental in aerosol dynamics. Condensation involves the transfer of gas-phase species to the particle phase, which can be reversible when the species evaporates back into the gas phase. This process is pivotal in the formation of cloud droplets and the growth of atmospheric particles, influencing climate and air quality.</p>"},{"location":"Theory/Technical/Dynamics/Condensation_Equations/#condensation-isothermal","title":"Condensation Isothermal","text":"<p>In the isothermal case, we consider condensation processes where the temperature remains constant, and the latent heat of vaporization is neglected. This approximation is valid when the heat released or absorbed during condensation or evaporation is insufficient to cause significant temperature changes.</p> <p>This follows Chapter 2 (EQ 2.41) by Topping, D., &amp; Bane, M. (2022). Introduction to Aerosol Modelling (D. Topping &amp; M. Bane, Eds.). Wiley. https://doi.org/10.1002/9781119625728. Also Chapter 12 and 13 (EQ 13.3) of Seinfeld, J. H., &amp; Pandis, S. N. (2016). Atmospheric Chemistry and Physics: From Air Pollution to Climate Change (3<sup>rd</sup> ed.). Wiley.</p> <p>The isothermal condensation or evaporation process is defined by the following equation:</p> <p>Equation 1: Rate of Mass Change</p> <p>dmi/dt = N \u00d7 k_cond \u00d7 (p\u1d62, gas \u2212 p\u1d62, particle surface) \u00d7 (molar mass\u1d62 / (R \u00d7 T))</p> <p>Where:</p> <ul> <li>dmi/dt: Rate of change of mass of species i in the particle phase.</li> <li>N: Number of particles.</li> <li>k_cond: Per-particle first-order condensation coefficient.</li> <li>p\u1d62, gas: Partial pressure of species i in the gas phase.</li> <li>p\u1d62, particle surface: Partial pressure of species i at the particle surface, accounting for curvature and activity effects.</li> <li>molar mass\u1d62: Molar mass of species i.</li> <li>R: Ideal gas constant.</li> <li>T: Temperature.</li> </ul> <p>Description:</p> <p>This equation quantifies the net mass flux of species i from the gas phase to the particle phase (or vice versa) due to condensation or evaporation. The driving force is the difference in partial pressures (p\u1d62, gas \u2212 p\u1d62, particle surface), and it's scaled by the molar mass and thermodynamic constants to yield a mass rate.</p>"},{"location":"Theory/Technical/Dynamics/Condensation_Equations/#condensation-with-latent-heat","title":"Condensation with Latent Heat","text":"<p>When condensation results in significant heat release or absorption, the latent heat of vaporization must be considered. This scenario is critical in cloud droplet formation, where the heat effects can influence the condensation rate and local temperature.</p> <p>Derivation from Topping, D., &amp; Bane, M. (2022) equation 2.36.</p> <p>Equation 5: Rate of Mass Change with Latent Heat</p> <p>dm/dt = [N \u00d7 4 \u00d7 \u03c0 \u00d7 radius_wet \u00d7 D\u1d62 \u00d7 (p\u1d62, gas \u2212 p\u1d62, particle surface)] / { [ (D\u1d62 \u00d7 L\u1d62 \u00d7 p\u1d62) / (\u03ba \u00d7 T) ] \u00d7 [ (L\u1d62 / (R \u00d7 T)) \u2212 1 ] + R\u1d62 \u00d7 T }</p> <p>Where:</p> <ul> <li>dm/dt: Rate of change of mass of the droplet.</li> <li>m: Mass of the droplet.</li> <li>radius_wet: Wet radius of the droplet.</li> <li>D\u1d62: Diffusion coefficient of species i.</li> <li>p\u1d62, gas: Partial pressure of species i in the gas phase.</li> <li>p\u1d62, particle surface: Partial pressure at the particle surface.</li> <li>L\u1d62: Latent heat of vaporization for species i.</li> <li>\u03ba: Thermal conductivity of air.</li> <li>T: Temperature.</li> <li>R\u1d62: Specific gas constant for species i (R / molar mass\u1d62).</li> </ul> <p>Description:</p> <p>This equation modifies the isothermal rate to include thermal effects due to latent heat. The denominator accounts for the additional resistance to mass transfer caused by the temperature gradient established from heat release or absorption during phase change.</p>"},{"location":"Theory/Technical/Dynamics/Condensation_Equations/#additional-parameters","title":"Additional Parameters","text":""},{"location":"Theory/Technical/Dynamics/Condensation_Equations/#first-order-condensation-coefficient","title":"First-Order Condensation Coefficient","text":"<p>Equation 2: Condensation Coefficient</p> <p>k_cond = 4 \u00d7 \u03c0 \u00d7 radius_particle \u00d7 D\u1d62 \u00d7 f(Kn, \u03b1\u1d62)</p> <p>Where:</p> <ul> <li>radius_particle: Radius of the particle.</li> <li>D\u1d62: Diffusion coefficient of species i in the gas phase.</li> <li>f(Kn, \u03b1\u1d62): Correction factor accounting for the transition between free-molecular and continuum regimes.</li> <li>Kn: Knudsen number.</li> <li>\u03b1\u1d62: Mass accommodation coefficient.</li> </ul> <p>Description:</p> <p>The condensation coefficient k_cond represents the flux of molecules to the particle surface per unit concentration difference. It combines geometric factors with diffusion dynamics and corrections for different flow regimes.</p>"},{"location":"Theory/Technical/Dynamics/Condensation_Equations/#correction-factor-fkn-i","title":"Correction Factor f(Kn, \u03b1\u1d62)","text":"<p>Equation 3: Correction Factor</p> <p>f = [0.75 \u00d7 \u03b1\u1d62 \u00d7 (1 + Kn)] / [Kn\u00b2 + Kn + 0.283 \u00d7 \u03b1\u1d62 \u00d7 Kn + 0.75 \u00d7 \u03b1\u1d62]</p> <p>Where:</p> <ul> <li>\u03b1\u1d62: Mass accommodation coefficient for species i.</li> <li>Kn: Knudsen number.</li> </ul> <p>Knudsen Number:</p> <p>Equation 4: Knudsen Number</p> <p>Kn = \u03bb\u1d62 / radius_particle</p> <p>Where:</p> <ul> <li>\u03bb\u1d62: Mean free path of gas molecules for species i.</li> <li>radius_particle: Particle radius.</li> </ul> <p>Description:</p> <p>The correction factor f(Kn, \u03b1\u1d62) adjusts the condensation coefficient to account for the finite mean free path of gas molecules relative to the particle size. It ensures accurate depiction of mass transfer in both the free-molecular (high Kn) and continuum (low Kn) regimes.</p>"},{"location":"Theory/Technical/Dynamics/Condensation_Equations/#partial-pressures","title":"Partial Pressures","text":"<p>Understanding the partial pressures in the gas phase and at the particle surface is essential for calculating the condensation rate.</p> <p>Gas Phase Partial Pressure:</p> <p>Equation 6: Gas Phase Partial Pressure</p> <p>p\u1d62, gas = conc\u1d62, gas \u00d7 (R \u00d7 T) / molar mass\u1d62</p> <p>Where:</p> <ul> <li>conc\u1d62, gas: Concentration of species i in the gas phase.</li> </ul> <p>Description:</p> <p>This equation relates the concentration of a gas-phase species to its partial pressure using the ideal gas law, adjusted for the molar mass of the species.</p> <p>Particle Surface Partial Pressure:</p> <p>Equation 7: Particle Surface Partial Pressure</p> <p>p\u1d62, particle surface = p\u1d62^pure \u00d7 \u03b3\u1d62 \u00d7 x\u1d62 \u00d7 k\u1d62, Kelvin</p> <p>Where:</p> <ul> <li>p\u1d62^pure: Saturation vapor pressure of pure species i (also denoted as p\u1d62^sat, p\u1d62^vap, or p\u1d62^0).</li> <li>\u03b3\u1d62: Activity coefficient of species i in the particle phase.</li> <li>x\u1d62: Mole fraction of species i in the particle phase.</li> <li>k\u1d62, Kelvin: Kelvin effect correction factor.</li> </ul> <p>Description:</p> <p>This equation adjusts the pure saturation vapor pressure to account for solution non-idealities (via \u03b3\u1d62 and x\u1d62) and curvature effects (via k\u1d62, Kelvin).</p>"},{"location":"Theory/Technical/Dynamics/Condensation_Equations/#kelvin-effect-correction-factor","title":"Kelvin Effect Correction Factor","text":"<p>Equation 8: Kelvin Effect</p> <p>k\u1d62, Kelvin = exp( k\u1d62, Kelvin radius / radius_particle )</p> <p>Where:</p> <ul> <li>k\u1d62, Kelvin radius: Kelvin radius factor.</li> </ul> <p>Equation 9: Kelvin Radius Factor</p> <p>k\u1d62, Kelvin radius = [2 \u00d7 \u03c3_surface \u00d7 molar mass\u1d62] / [ R \u00d7 T \u00d7 density ]</p> <p>Where:</p> <ul> <li>\u03c3_surface: Surface tension of the particle.</li> <li>density: Density of the particle.</li> </ul> <p>Description:</p> <p>The Kelvin effect expresses how vapor pressure over a curved surface differs from that over a flat surface. Small particles exhibit increased vapor pressure due to curvature, influencing condensation and evaporation rates.</p>"},{"location":"Theory/Technical/Dynamics/Condensation_Equations/#variable-descriptions","title":"Variable Descriptions","text":"<p>Understanding the Parameters:</p> <ol> <li> <p>Mass Accommodation Coefficient (\u03b1\u1d62):</p> </li> <li> <p>Represents the probability that a molecule colliding with the particle surface will stick and be incorporated into the particle.</p> </li> <li>Values range from 0 (no sticking) to 1 (all molecules stick upon collision).</li> <li> <p>Influenced by surface properties, temperature, and species-specific interactions.</p> </li> <li> <p>Diffusion Coefficient (D\u1d62):</p> </li> <li> <p>Indicates how quickly species i diffuses through the gas phase.</p> </li> <li>Dependent on temperature, pressure, and molecular characteristics.</li> <li> <p>Higher D\u1d62 leads to faster mass transfer to the particle surface.</p> </li> <li> <p>Mean Free Path (\u03bb\u1d62):</p> </li> <li> <p>Average distance a gas molecule travels before colliding with another molecule.</p> </li> <li>Inversely proportional to pressure; decreases as pressure increases.</li> <li> <p>Important for calculating the Knudsen number and determining the appropriate flow regime.</p> </li> <li> <p>Knudsen Number (Kn):</p> </li> <li> <p>Dimensionless number that characterizes the flow regime.</p> <ul> <li>Kn &lt;&lt; 1: Continuum regime; diffusion dominates.</li> <li>Kn &gt;&gt; 1: Free-molecular regime; ballistic motion dominates.</li> </ul> </li> <li> <p>Essential for selecting the correct correction factor f(Kn, \u03b1\u1d62).</p> </li> <li> <p>Latent Heat of Vaporization (L\u1d62):</p> </li> <li> <p>Energy required to convert species i from liquid to vapor without temperature change.</p> </li> <li> <p>Affects the heat balance during condensation and influences the condensation rate when significant.</p> </li> <li> <p>Thermal Conductivity (\u03ba):</p> </li> <li> <p>Measures the ability of air to conduct heat.</p> </li> <li> <p>Determines how quickly heat generated or absorbed at the particle surface is dissipated.</p> </li> <li> <p>Activity Coefficient (\u03b3\u1d62):</p> </li> <li> <p>Accounts for non-ideal interactions between molecules in the particle phase.</p> </li> <li> <p>Deviations from ideality can significantly impact the equilibrium vapor pressure.</p> </li> <li> <p>Surface Tension (\u03c3_surface):</p> </li> <li> <p>Affects the Kelvin effect.</p> </li> <li>Dependent on particle composition and temperature.</li> <li>Influential for small particles where curvature effects are pronounced.</li> </ol> <p>Applications and Implications:</p> <ul> <li> <p>Aerosol Growth: These equations are vital for predicting how aerosols grow through condensation, impacting visibility, climate forcing, and human health.</p> </li> <li> <p>Cloud Formation: Understanding condensation with latent heat is essential for cloud microphysics, influencing cloud droplet activation and lifetime.</p> </li> <li> <p>Air Quality Modeling: Accurately modeling gas-particle partitioning helps in predicting pollutant behavior and secondary aerosol formation.</p> </li> </ul> <p>Assumptions and Limitations:</p> <ul> <li> <p>Isothermal Assumption: In the isothermal equation, neglecting latent heat is valid only when temperature changes are negligible. For processes involving significant heat exchange, the non-isothermal equation should be used.</p> </li> <li> <p>Spherical Particles: The equations assume particles are spherical, which may not hold true for all aerosols (e.g., fractal soot particles).</p> </li> <li> <p>Uniform Composition: Assumes homogeneous particle composition. In reality, phase separation or gradients may exist within particles.</p> </li> </ul> <p>Further Considerations:</p> <ul> <li> <p>Multicomponent Systems: In mixtures, interactions between different species can complicate calculations. Mutual diffusion coefficients and interactive effects need to be considered.</p> </li> <li> <p>Dynamic Conditions: Environmental factors like fluctuating temperature and pressure can affect condensation rates. Real-world applications may require time-dependent modeling.</p> </li> <li> <p>Parameter Estimation: Accurate values for parameters like D\u1d62, \u03b1\u1d62, and \u03b3\u1d62 are necessary for precise predictions but can be challenging to obtain, especially for complex organic species.</p> </li> </ul>"},{"location":"Theory/Technical/Dynamics/Condensation_Equations/#conclusion","title":"Conclusion","text":"<p>By reviewing the equations and expanding on the descriptions, we enhance the understanding of condensation processes in aerosol dynamics. The interplay between mass transfer, thermodynamics, and kinetics is critical for accurately modeling aerosol behavior. Recognizing the importance of each parameter and the assumptions inherent in these equations allows for more informed application and interpretation in research and environmental modeling.</p>"},{"location":"Theory/Technical/Dynamics/Condensation_Equations/#references","title":"References","text":"<ol> <li> <p>Topping, D., &amp; Bane, M. (2022). Introduction to Aerosol Modelling. Wiley. DOI: 10.1002/9781119625728</p> </li> <li> <p>Seinfeld, J. H., &amp; Pandis, S. N. (2016). Atmospheric Chemistry and Physics: From Air Pollution to Climate Change (3<sup>rd</sup> ed.). Wiley.</p> </li> </ol>"},{"location":"Theory/Technical/Dynamics/ionparticle_coagulation/","title":"Ion\u2013Particle Coagulation","text":"In\u00a0[\u00a0]: Copied! <pre># In Colab uncomment the following command to install particula:\n#!pip install particula[extra] --quiet\nimport numpy as np\nfrom matplotlib import pyplot as plt\n\n# from particula.util.lf2013_coagulation import lf2013_coag_full\nimport particula as par\n</pre> # In Colab uncomment the following command to install particula: #!pip install particula[extra] --quiet import numpy as np from matplotlib import pyplot as plt  # from particula.util.lf2013_coagulation import lf2013_coag_full import particula as par In\u00a0[3]: Copied! <pre># environment\ntemperature = 278.0\npressure = 101325.0\n\n# get each particle properties\nparticle_radius = np.array(\n    [\n        0.45e-9,\n        3e-9,\n        3e-9,\n        3e-9,\n        3e-9,\n        3e-9,\n        3e-9,\n        3e-9,\n        3e-9,\n        3e-9,\n        3e-9,\n        3e-9,\n        3e-9,\n    ]\n)\ncharge = np.array([-1, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11])\nparticle_density = np.array(\n    [\n        1860,\n        1700,\n        1700,\n        1700,\n        1700,\n        1700,\n        1700,\n        1700,\n        1700,\n        1700,\n        1700,\n        1700,\n        1700,\n    ]\n)\n\n# calculate mass\nparticle_mass = 4 / 3 * np.pi * particle_radius**3 * particle_density\n\n# get properties\ndynamic_viscosity = par.gas.get_dynamic_viscosity(temperature=temperature)\n\n# get knudsen number\nknudsen_number = par.particles.get_knudsen_number(\n    mean_free_path=par.gas.get_molecule_mean_free_path(\n        temperature=temperature,\n        dynamic_viscosity=dynamic_viscosity,\n        pressure=pressure,\n    ),\n    particle_radius=particle_radius,\n)\n# get friction factor\nfriction_factor = par.particles.get_friction_factor(\n    particle_radius=particle_radius,\n    dynamic_viscosity=par.gas.get_dynamic_viscosity(temperature=temperature),\n    slip_correction=par.particles.get_cunningham_slip_correction(\n        knudsen_number=knudsen_number\n    ),\n)\n\n# get coulomb potential ratio\ncoulomb_potential_ratio = par.particles.get_coulomb_enhancement_ratio(\n    particle_radius=particle_radius,\n    charge=charge,\n    temperature=temperature,\n)\n\n# get diffusive knudsen number\ndiffusive_knudsen = par.particles.get_diffusive_knudsen_number(\n    particle_radius=particle_radius,\n    particle_mass=particle_mass,\n    friction_factor=friction_factor,\n    coulomb_potential_ratio=coulomb_potential_ratio,\n    temperature=temperature,\n)\n</pre> # environment temperature = 278.0 pressure = 101325.0  # get each particle properties particle_radius = np.array(     [         0.45e-9,         3e-9,         3e-9,         3e-9,         3e-9,         3e-9,         3e-9,         3e-9,         3e-9,         3e-9,         3e-9,         3e-9,         3e-9,     ] ) charge = np.array([-1, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]) particle_density = np.array(     [         1860,         1700,         1700,         1700,         1700,         1700,         1700,         1700,         1700,         1700,         1700,         1700,         1700,     ] )  # calculate mass particle_mass = 4 / 3 * np.pi * particle_radius**3 * particle_density  # get properties dynamic_viscosity = par.gas.get_dynamic_viscosity(temperature=temperature)  # get knudsen number knudsen_number = par.particles.get_knudsen_number(     mean_free_path=par.gas.get_molecule_mean_free_path(         temperature=temperature,         dynamic_viscosity=dynamic_viscosity,         pressure=pressure,     ),     particle_radius=particle_radius, ) # get friction factor friction_factor = par.particles.get_friction_factor(     particle_radius=particle_radius,     dynamic_viscosity=par.gas.get_dynamic_viscosity(temperature=temperature),     slip_correction=par.particles.get_cunningham_slip_correction(         knudsen_number=knudsen_number     ), )  # get coulomb potential ratio coulomb_potential_ratio = par.particles.get_coulomb_enhancement_ratio(     particle_radius=particle_radius,     charge=charge,     temperature=temperature, )  # get diffusive knudsen number diffusive_knudsen = par.particles.get_diffusive_knudsen_number(     particle_radius=particle_radius,     particle_mass=particle_mass,     friction_factor=friction_factor,     coulomb_potential_ratio=coulomb_potential_ratio,     temperature=temperature, ) In\u00a0[4]: Copied! <pre># hard sphere dimensionless kernel\nhard_sphere_dimensionless_kernel = par.dynamics.get_hard_sphere_kernel(\n    diffusive_knudsen=diffusive_knudsen,\n)\n# coulomb dimensionless kernel for Dyachkov et al. (2007)\ncoulomb_dyachkov2007_dimensionless_kernel = (\n    par.dynamics.get_coulomb_kernel_dyachkov2007(\n        diffusive_knudsen=diffusive_knudsen,\n        coulomb_potential_ratio=coulomb_potential_ratio,\n    )\n)\n\n# coulomb dimensionless kernel for Gatti et al. (2008)\ncoulomb_gatti2008_dimensionless_kernel = (\n    par.dynamics.get_coulomb_kernel_gatti2008(\n        diffusive_knudsen=diffusive_knudsen,\n        coulomb_potential_ratio=coulomb_potential_ratio,\n    )\n)\n\n# coulomb dimensionless kernel for Gopalakrishnan et al. (2012)\ncoulomb_g2012_dimensionless_kernel = (\n    par.dynamics.get_coulomb_kernel_gopalakrishnan2012(\n        diffusive_knudsen=diffusive_knudsen,\n        coulomb_potential_ratio=coulomb_potential_ratio,\n    )\n)\n\n# coulomb dimensionless kernel for Chahl et al. (2019)\ncoulomb_chahl20019_dimensionless_kernel = (\n    par.dynamics.get_coulomb_kernel_chahl2019(\n        diffusive_knudsen=diffusive_knudsen,\n        coulomb_potential_ratio=coulomb_potential_ratio,\n    )\n)\n\n# plot the first index ion attachment to the other particles\nfig, ax = plt.subplots()\nax.plot(\n    charge[1:], hard_sphere_dimensionless_kernel[0, 1:], label=\"Hard Sphere\"\n)\nax.plot(\n    charge[1:],\n    coulomb_dyachkov2007_dimensionless_kernel[0, 1:],\n    label=\"Coulomb Dyachkov 2007\",\n)\nax.plot(\n    charge[1:],\n    coulomb_gatti2008_dimensionless_kernel[0, 1:],\n    label=\"Coulomb Gatti 2008\",\n)\nax.plot(\n    charge[1:],\n    coulomb_g2012_dimensionless_kernel[0, 1:],\n    label=\"Coulomb Gopalakrishnan 2012\",\n)\nax.plot(\n    charge[1:],\n    coulomb_chahl20019_dimensionless_kernel[0, 1:],\n    label=\"Coulomb Chahl 2019\",\n)\nax.set_yscale(\"log\")\nax.set_xlim(-1, 12)\nax.set_xlabel(\"Charge\")\nax.set_ylabel(\"Dimensionless Kernel (unitless)\")\nax.set_title(\"Dimensionless Kernel for Ion Attachment\")\nax.legend()\nplt.show()\n</pre> # hard sphere dimensionless kernel hard_sphere_dimensionless_kernel = par.dynamics.get_hard_sphere_kernel(     diffusive_knudsen=diffusive_knudsen, ) # coulomb dimensionless kernel for Dyachkov et al. (2007) coulomb_dyachkov2007_dimensionless_kernel = (     par.dynamics.get_coulomb_kernel_dyachkov2007(         diffusive_knudsen=diffusive_knudsen,         coulomb_potential_ratio=coulomb_potential_ratio,     ) )  # coulomb dimensionless kernel for Gatti et al. (2008) coulomb_gatti2008_dimensionless_kernel = (     par.dynamics.get_coulomb_kernel_gatti2008(         diffusive_knudsen=diffusive_knudsen,         coulomb_potential_ratio=coulomb_potential_ratio,     ) )  # coulomb dimensionless kernel for Gopalakrishnan et al. (2012) coulomb_g2012_dimensionless_kernel = (     par.dynamics.get_coulomb_kernel_gopalakrishnan2012(         diffusive_knudsen=diffusive_knudsen,         coulomb_potential_ratio=coulomb_potential_ratio,     ) )  # coulomb dimensionless kernel for Chahl et al. (2019) coulomb_chahl20019_dimensionless_kernel = (     par.dynamics.get_coulomb_kernel_chahl2019(         diffusive_knudsen=diffusive_knudsen,         coulomb_potential_ratio=coulomb_potential_ratio,     ) )  # plot the first index ion attachment to the other particles fig, ax = plt.subplots() ax.plot(     charge[1:], hard_sphere_dimensionless_kernel[0, 1:], label=\"Hard Sphere\" ) ax.plot(     charge[1:],     coulomb_dyachkov2007_dimensionless_kernel[0, 1:],     label=\"Coulomb Dyachkov 2007\", ) ax.plot(     charge[1:],     coulomb_gatti2008_dimensionless_kernel[0, 1:],     label=\"Coulomb Gatti 2008\", ) ax.plot(     charge[1:],     coulomb_g2012_dimensionless_kernel[0, 1:],     label=\"Coulomb Gopalakrishnan 2012\", ) ax.plot(     charge[1:],     coulomb_chahl20019_dimensionless_kernel[0, 1:],     label=\"Coulomb Chahl 2019\", ) ax.set_yscale(\"log\") ax.set_xlim(-1, 12) ax.set_xlabel(\"Charge\") ax.set_ylabel(\"Dimensionless Kernel (unitless)\") ax.set_title(\"Dimensionless Kernel for Ion Attachment\") ax.legend() plt.show() In\u00a0[6]: Copied! <pre>sum_of_radii = particle_radius[:, np.newaxis] + particle_radius[np.newaxis, :]\nreduced_mass = par.util.get_reduced_self_broadcast(particle_mass)\nreduced_friction_factor = par.util.get_reduced_self_broadcast(friction_factor)\n\n# hard sphere dimensional kernel\nhard_sphere_dimensional_kernel = par.dynamics.get_dimensional_kernel(\n    dimensionless_kernel=hard_sphere_dimensionless_kernel,\n    coulomb_potential_ratio=coulomb_potential_ratio,\n    sum_of_radii=sum_of_radii,\n    reduced_mass=reduced_mass,\n    reduced_friction_factor=reduced_friction_factor,\n)\n\n# coulomb dimensional kernel for Dyachkov et al. (2007)\ncoulomb_dyachkov2007_dimensional_kernel = par.dynamics.get_dimensional_kernel(\n    dimensionless_kernel=coulomb_dyachkov2007_dimensionless_kernel,\n    coulomb_potential_ratio=coulomb_potential_ratio,\n    sum_of_radii=sum_of_radii,\n    reduced_mass=reduced_mass,\n    reduced_friction_factor=reduced_friction_factor,\n)\n\n# coulomb dimensional kernel for Gatti et al. (2008)\ncoulomb_gatti2008_dimensional_kernel = par.dynamics.get_dimensional_kernel(\n    dimensionless_kernel=coulomb_gatti2008_dimensionless_kernel,\n    coulomb_potential_ratio=coulomb_potential_ratio,\n    sum_of_radii=sum_of_radii,\n    reduced_mass=reduced_mass,\n    reduced_friction_factor=reduced_friction_factor,\n)\n\n# coulomb dimensional kernel for Gopalakrishnan et al. (2012)\ncoulomb_g2012_dimensional_kernel = par.dynamics.get_dimensional_kernel(\n    dimensionless_kernel=coulomb_g2012_dimensionless_kernel,\n    coulomb_potential_ratio=coulomb_potential_ratio,\n    sum_of_radii=sum_of_radii,\n    reduced_mass=reduced_mass,\n    reduced_friction_factor=reduced_friction_factor,\n)\n\n# coulomb dimensional kernel for Chahl et al. (2019) via system state\ncoulomb_chahl20019_dimensional_kernel = par.dynamics.get_coulomb_kernel_dyachkov2007_via_system_state(\n    particle_radius=particle_radius,\n    particle_mass=particle_mass,\n    particle_charge=charge,\n    temperature=temperature,\n    pressure=pressure,\n)\n\n# plot the first index ion attachment to the other particles\nfig, ax = plt.subplots()\nax.plot(charge[1:], hard_sphere_dimensional_kernel[0, 1:], label=\"Hard Sphere\")\nax.plot(\n    charge[1:],\n    coulomb_dyachkov2007_dimensional_kernel[0, 1:],\n    label=\"Coulomb Dyachkov 2007\",\n)\nax.plot(\n    charge[1:],\n    coulomb_gatti2008_dimensional_kernel[0, 1:],\n    label=\"Coulomb Gatti 2008\",\n)\nax.plot(\n    charge[1:],\n    coulomb_g2012_dimensional_kernel[0, 1:],\n    label=\"Coulomb Gopalakrishnan 2012\",\n)\nax.plot(\n    charge[1:],\n    coulomb_chahl20019_dimensional_kernel[0, 1:],\n    label=\"Coulomb Chahl 2019\",\n)\nax.set_yscale(\"log\")\nax.set_xlim(-1, 12)\nax.set_xlabel(\"Charge (integer count)\")\nax.set_ylabel(r\"Dimensional Kernel $m^3/s$\")\nax.set_title(\"Dimensional Kernel for Ion Attachment\")\nax.legend(loc=\"lower right\")\nplt.show()\n</pre> sum_of_radii = particle_radius[:, np.newaxis] + particle_radius[np.newaxis, :] reduced_mass = par.util.get_reduced_self_broadcast(particle_mass) reduced_friction_factor = par.util.get_reduced_self_broadcast(friction_factor)  # hard sphere dimensional kernel hard_sphere_dimensional_kernel = par.dynamics.get_dimensional_kernel(     dimensionless_kernel=hard_sphere_dimensionless_kernel,     coulomb_potential_ratio=coulomb_potential_ratio,     sum_of_radii=sum_of_radii,     reduced_mass=reduced_mass,     reduced_friction_factor=reduced_friction_factor, )  # coulomb dimensional kernel for Dyachkov et al. (2007) coulomb_dyachkov2007_dimensional_kernel = par.dynamics.get_dimensional_kernel(     dimensionless_kernel=coulomb_dyachkov2007_dimensionless_kernel,     coulomb_potential_ratio=coulomb_potential_ratio,     sum_of_radii=sum_of_radii,     reduced_mass=reduced_mass,     reduced_friction_factor=reduced_friction_factor, )  # coulomb dimensional kernel for Gatti et al. (2008) coulomb_gatti2008_dimensional_kernel = par.dynamics.get_dimensional_kernel(     dimensionless_kernel=coulomb_gatti2008_dimensionless_kernel,     coulomb_potential_ratio=coulomb_potential_ratio,     sum_of_radii=sum_of_radii,     reduced_mass=reduced_mass,     reduced_friction_factor=reduced_friction_factor, )  # coulomb dimensional kernel for Gopalakrishnan et al. (2012) coulomb_g2012_dimensional_kernel = par.dynamics.get_dimensional_kernel(     dimensionless_kernel=coulomb_g2012_dimensionless_kernel,     coulomb_potential_ratio=coulomb_potential_ratio,     sum_of_radii=sum_of_radii,     reduced_mass=reduced_mass,     reduced_friction_factor=reduced_friction_factor, )  # coulomb dimensional kernel for Chahl et al. (2019) via system state coulomb_chahl20019_dimensional_kernel = par.dynamics.get_coulomb_kernel_dyachkov2007_via_system_state(     particle_radius=particle_radius,     particle_mass=particle_mass,     particle_charge=charge,     temperature=temperature,     pressure=pressure, )  # plot the first index ion attachment to the other particles fig, ax = plt.subplots() ax.plot(charge[1:], hard_sphere_dimensional_kernel[0, 1:], label=\"Hard Sphere\") ax.plot(     charge[1:],     coulomb_dyachkov2007_dimensional_kernel[0, 1:],     label=\"Coulomb Dyachkov 2007\", ) ax.plot(     charge[1:],     coulomb_gatti2008_dimensional_kernel[0, 1:],     label=\"Coulomb Gatti 2008\", ) ax.plot(     charge[1:],     coulomb_g2012_dimensional_kernel[0, 1:],     label=\"Coulomb Gopalakrishnan 2012\", ) ax.plot(     charge[1:],     coulomb_chahl20019_dimensional_kernel[0, 1:],     label=\"Coulomb Chahl 2019\", ) ax.set_yscale(\"log\") ax.set_xlim(-1, 12) ax.set_xlabel(\"Charge (integer count)\") ax.set_ylabel(r\"Dimensional Kernel $m^3/s$\") ax.set_title(\"Dimensional Kernel for Ion Attachment\") ax.legend(loc=\"lower right\") plt.show()"},{"location":"Theory/Technical/Dynamics/ionparticle_coagulation/#ionparticle-coagulation","title":"Ion\u2013Particle Coagulation\u00b6","text":"<p>This notebook investigates the coagulation of positively charged aerosol particles (0 to 11 elementary charges) with negatively charged ions. Specifically, we analyze collisions between a 3 nm radius particle and a 0.45 nm radius ion under various coagulation models.</p>"},{"location":"Theory/Technical/Dynamics/ionparticle_coagulation/#coagulation-kernels","title":"Coagulation Kernels\u00b6","text":"<p>To model ion\u2013particle interactions, we compare several coagulation kernels, each incorporating different physical effects:</p> <ul> <li>Hard Sphere Kernel: Assumes Brownian collisions with idealized electrostatic interactions.</li> <li>Dyachkov et al. (2007) Kernel \u2013 J. Chem. Phys., 126, 094501</li> <li>Gatti &amp; Kortshagen (2008) Kernel \u2013 Phys. Rev. E, 78, 046402</li> <li>Gopalakrishnan et al. (2012) Kernel \u2013 Phys. Rev. E, 85, 026410</li> <li>Chahl et al. (2019) Kernel \u2013 Aerosol Sci. Technol., 53(8), 877-892</li> </ul> <p>Each kernel accounts for charge-dependent coagulation efficiencies. This study aims to compare these models to evaluate how charge influences ion\u2013particle collision rates.</p>"},{"location":"Theory/Technical/Dynamics/ionparticle_coagulation/#setup","title":"Setup\u00b6","text":"<p>This block is setting up the properties of a set of aerosol particles, calculating key parameters related to their movement and interaction within a gaseous environment, and determining their diffusion behavior.</p>"},{"location":"Theory/Technical/Dynamics/ionparticle_coagulation/#1-environmental-setup","title":"1. Environmental Setup\u00b6","text":"<ul> <li>The temperature is set to 278.0 K, which will be used for further calculations.</li> </ul>"},{"location":"Theory/Technical/Dynamics/ionparticle_coagulation/#2-particle-properties","title":"2. Particle Properties\u00b6","text":"<ul> <li>Particle Radius: A set of particles is defined with radii ranging from 0.45 nm to 3 nm.</li> <li>Charge: The particles have a range of electric charges from -1 to +12.</li> <li>Density: The particle density is primarily set to 1700 kg/m\u00b3, with one particle (ion) at 1860 kg/m\u00b3.</li> </ul>"},{"location":"Theory/Technical/Dynamics/ionparticle_coagulation/#3-mass-calculation","title":"3. Mass Calculation\u00b6","text":"<ul> <li>Using the formula for the volume of a sphere and the given densities, the mass of each particle is computed.</li> </ul>"},{"location":"Theory/Technical/Dynamics/ionparticle_coagulation/#4-gas-properties","title":"4. Gas Properties\u00b6","text":"<ul> <li>The dynamic viscosity of the surrounding gas is obtained using the <code>par.gas.get_dynamic_viscosity()</code> function.</li> </ul>"},{"location":"Theory/Technical/Dynamics/ionparticle_coagulation/#5-knudsen-number-calculation","title":"5. Knudsen Number Calculation\u00b6","text":"<ul> <li>The Knudsen number, which determines whether the particle behavior is in the free molecular, transition, or continuum regime, is computed using:<ul> <li>The mean free path of gas molecules (from <code>par.gas.get_molecule_mean_free_path()</code>).</li> <li>The particle radius.</li> </ul> </li> </ul>"},{"location":"Theory/Technical/Dynamics/ionparticle_coagulation/#6-friction-factor","title":"6. Friction Factor\u00b6","text":"<ul> <li>The friction factor, which influences the motion and diffusion of the particles, is calculated using:<ul> <li>Particle radius</li> <li>Dynamic viscosity</li> <li>Slip correction factor (using <code>par.particles.get_cunningham_slip_correction()</code>).</li> </ul> </li> </ul>"},{"location":"Theory/Technical/Dynamics/ionparticle_coagulation/#7-coulomb-enhancement-ratio","title":"7. Coulomb Enhancement Ratio\u00b6","text":"<ul> <li>The Coulomb potential ratio, which determines how electrostatic forces influence particle interactions, is computed using:<ul> <li>Particle radius</li> <li>Charge</li> <li>Temperature</li> </ul> </li> </ul>"},{"location":"Theory/Technical/Dynamics/ionparticle_coagulation/#8-diffusive-knudsen-number","title":"8. Diffusive Knudsen Number\u00b6","text":"<ul> <li>Finally, the diffusive Knudsen number, which governs diffusion behavior, is computed using:<ul> <li>Particle radius</li> <li>Particle mass</li> <li>Friction factor</li> <li>Coulomb potential ratio</li> <li>Temperature</li> </ul> </li> </ul>"},{"location":"Theory/Technical/Dynamics/ionparticle_coagulation/#dimensionless-kernel","title":"Dimensionless Kernel\u00b6","text":"<p>These kernels are used in aerosol dynamics to quantify the frequency at which particles of different sizes collide and coagulate.</p>"},{"location":"Theory/Technical/Dynamics/ionparticle_coagulation/#types-of-kernels","title":"Types of Kernels\u00b6","text":"<ol> <li><p>Hard-Sphere Dimensionless Kernel (<code>get_hard_sphere_kernel</code>)</p> <ul> <li>Represents the baseline collision frequency assuming hard-sphere interactions.</li> <li>Accounts for the Brownian motion of particles and their idealized electrostatic interactions.</li> </ul> </li> <li><p>Coulomb Dimensionless Kernels</p> <ul> <li>These extend the hard-sphere kernel by incorporating parameterized (non-ideal) electrostatic interactions.</li> <li>Used to model particle coagulation in charged aerosol systems.</li> </ul> <p>The different Coulomb kernels included are:</p> <ul> <li><code>get_coulomb_kernel_dyachkov2007</code>: Based on Dyachkov et al. (2007), suitable for small Knudsen number scenarios.</li> <li><code>get_coulomb_kernel_gatti2008</code>: Developed by Gatti et al. (2008), useful for intermediate Knudsen regimes.</li> <li><code>get_coulomb_kernel_gopalakrishnan2012</code>: From Gopalakrishnan et al. (2012), used for describing charge-dominated coagulation.</li> <li><code>get_coulomb_kernel_chahl2019</code>: Derived from Chahl et al. (2019), relevant for advanced charge-driven aggregation modeling.</li> </ul> </li> </ol>"},{"location":"Theory/Technical/Dynamics/ionparticle_coagulation/#parameters-used","title":"Parameters Used\u00b6","text":"<ul> <li><code>diffusive_knudsen</code>: The diffusive Knudsen number, which defines whether the particles are in the free molecular or continuum regime, accounting for electrostatic interactions.</li> <li><code>coulomb_potential_ratio</code>: A dimensionless parameter describing the ratio of Coulombic forces to thermal energy, determining the effect of electrostatic interactions.</li> </ul>"},{"location":"Theory/Technical/Dynamics/ionparticle_coagulation/#dimensional-kernel","title":"Dimensional Kernel\u00b6","text":"<p>The code below transforms dimensionless coagulation kernels into dimensional kernels using the <code>get_dimensional_kernel</code> function from the <code>Particula</code> library. This transformation is necessary because dimensionless kernels provide normalized interaction rates that need to be rescaled to physical units for real-world applications.</p> <p>The function <code>get_dimensional_kernel</code> requires several physical parameters to properly scale the dimensionless kernel:</p> <ol> <li><p>Sum of Particle Radii (<code>sum_of_radii</code>)</p> <pre>sum_of_radii = particle_radius[:, np.newaxis] + particle_radius[np.newaxis, :]\n</pre> <ul> <li>This computes a 2D array where each entry represents the sum of the radii of two interacting particles.</li> <li>The broadcasting ensures that each pairwise combination of particle sizes is considered.</li> </ul> </li> <li><p>Reduced Mass (<code>reduced_mass</code>)</p> <ul> <li>The reduced mass is a standard concept in two-body problems, defined as: \u03bc = {m_1 m_2}/{m_1 + m_2}</li> <li>This accounts for how mass differences influence the dynamics of collisions.</li> </ul> </li> <li><p>Reduced Friction Factor (<code>reduced_friction_factor</code>)</p> <pre>reduced_friction_factor = par.util.get_reduced_self_broadcast(friction_factor)\n</pre> <ul> <li>The friction factor relates to the drag experienced by particles in a medium.</li> <li>Using a reduced version ensures that the calculation remains valid for all possible particle pairings.</li> </ul> </li> <li><p>Applying Scaling to Compute Dimensional Kernel Each dimensional kernel is computed by combining:</p> <ul> <li>The precomputed dimensionless kernel</li> <li>The coulomb potential ratio, which determines the electrostatic influence.</li> <li>The sum of radii, reduced mass, and reduced friction factor, which introduce physical units.</li> </ul> </li> </ol> <p>The transition from dimensionless to dimensional kernels is required to:</p> <ul> <li>Convert relative interaction rates into absolute coagulation frequencies (e.g., collisions per second per cubic meter).</li> </ul>"},{"location":"Theory/Technical/Dynamics/ionparticle_coagulation/#kernel-via-system-state","title":"Kernel via System State\u00b6","text":"<p>The shortest method to get the kernel is via <code>par.dynamics.get_coulomb_kernel_dyachkov2007_via_system_state</code>. This function combines the steps above into a single call, allowing for a more streamlined approach to obtaining the kernel.</p> <p>However, depending on you program the properties calculated above may already be available. In this case, you can use the <code>par.dynamics.get_coulomb_kernel_dyachkov2007</code> function to reduce duplicate calculations.</p>"},{"location":"Theory/Technical/Dynamics/ionparticle_coagulation/#conclusion","title":"Conclusion\u00b6","text":"<p>In this notebook, we explored the ion-particle coagulation process by calculating various dimensionless and dimensional kernels for different coagulation approximations. The key steps and findings are summarized below:</p> <ol> <li><p>Environmental and Particle Properties Setup:</p> <ul> <li>Temperature: 278.0 K</li> <li>Particle radii ranged from 0.45 nm to 3 nm.</li> <li>Charges ranged from -1 to +12.</li> <li>Particle densities were set to 1700 kg/m\u00b3 and 1860 kg/m\u00b3.</li> </ul> </li> <li><p>Key Calculations:</p> <ul> <li>Mass Calculation: Using the volume of a sphere and given densities.</li> <li>Dynamic Viscosity: Obtained using the <code>par.gas.get_dynamic_viscosity()</code> function.</li> <li>Knudsen Number: Calculated using the mean free path and particle radius.</li> <li>Friction Factor: Influences the motion and diffusion of particles.</li> <li>Coulomb Potential Ratio: Determines the effect of electrostatic interactions.</li> <li>Diffusive Knudsen Number: Governs diffusion behavior.</li> </ul> </li> <li><p>Dimensionless Kernels:</p> <ul> <li>Hard-Sphere Kernel: Represents baseline collision frequency with idealized electrostatic interactions.</li> <li>Coulomb Kernels: Incorporate electrostatic interactions for different parameterization (Dyachkov 2007, Gatti 2008, Gopalakrishnan 2012, Chahl 2019).</li> </ul> </li> <li><p>Dimensional Kernels:</p> <ul> <li>Transformed dimensionless kernels into dimensional kernels using physical parameters.</li> <li>Plotted the dimensional kernels for ion attachment to other particles.</li> </ul> </li> </ol> <p>The analysis provided insights into how different coagulation approximations affect the collision frequencies and coagulation rates of charged particles. The results can be used to better understand and model aerosol dynamics in various environmental and industrial applications.</p>"},{"location":"Theory/Technical/Dynamics/Cloud_Droplet_Coagulation/","title":"Cloud Droplet Coagulation","text":"<p>In this folder, we discuss the implementation of the geometric collision kernel for cloud droplets as described in Part II by Ayala et al. (2008). Part I provides a detailed explanation of the direct numerical simulations. Where as Part II is the parameterization of the collision kernel for cloud droplets in turbulent flows. The implementation involves calculating the geometric collision rate of sedimenting droplets based on the turbulent flow properties and droplet characteristics.</p> <p>Ayala, O., Rosa, B., Wang, L. P., &amp; Grabowski, W. W. (2008). Effects of turbulence on the geometric collision rate of sedimenting droplets. Part 1. Results from direct numerical simulation. New Journal of Physics, 10. https://doi.org/10.1088/1367-2630/10/7/075015</p> <p>Ayala, O., Rosa, B., &amp; Wang, L. P. (2008). Effects of turbulence on the geometric collision rate of sedimenting droplets. Part 2. Theory and parameterization. New Journal of Physics, 10. https://doi.org/10.1088/1367-2630/10/7/075016</p>"},{"location":"Theory/Technical/Dynamics/Cloud_Droplet_Coagulation/#geometric-collision-kernel-12","title":"Geometric Collision Kernel \u0393\u2081\u2082","text":"<p>The geometric collision kernel from the paper is outlined in Ayala et al. (2008).</p>"},{"location":"Theory/Technical/Dynamics/Cloud_Droplet_Coagulation/#validations","title":"Validations","text":"<p>We validate our implementation of the geometric collision kernel against the results from Ayala et al. (2008) via jupyter notebooks. The notebooks cover comparison graphs and tables from the original paper and Direct Numerical Simulations (DNS) results.</p> <ul> <li>DNS Fluid and Particle Properties</li> <li>DNS Horizontal Velocity</li> <li>DNS Radial Relative Velocity</li> <li>DNS Radial Distribution</li> <li>DNS Kernel Comparison</li> </ul>"},{"location":"Theory/Technical/Dynamics/Cloud_Droplet_Coagulation/DNS_Fluid_and_Particle_Properties_Comparison/","title":"Fluid and Particle Properties for Cloud Droplet Coagulation","text":"In\u00a0[20]: Copied! <pre>import numpy as np\nimport matplotlib.pyplot as plt\nimport particula as par\n\nimport pandas as pd\nfrom IPython.display import display\n</pre> import numpy as np import matplotlib.pyplot as plt import particula as par  import pandas as pd from IPython.display import display In\u00a0[21]: Copied! <pre># %%\n\nparticle_radius = np.linspace(10e-6, 60e-6, 6)\ntemperature = 273  # Temperature in Kelvin\nparticle_density = 1000  # Particle density in kg/m\u00b3\nfluid_density = 1.0  # Fluid (air) density in kg/m\u00b3\nair_velocity = 1e-9  # Relative velocity in m/s\n\nturbulent_dissipation = 400 * par.util.get_unit_conversion(\n    \"cm^2/s^3\", \"m^2/s^3\"\n)  # Example value in m\u00b2/s\u00b3\nreynolds_lambda = 72.41  # Example value\n</pre> # %%  particle_radius = np.linspace(10e-6, 60e-6, 6) temperature = 273  # Temperature in Kelvin particle_density = 1000  # Particle density in kg/m\u00b3 fluid_density = 1.0  # Fluid (air) density in kg/m\u00b3 air_velocity = 1e-9  # Relative velocity in m/s  turbulent_dissipation = 400 * par.util.get_unit_conversion(     \"cm^2/s^3\", \"m^2/s^3\" )  # Example value in m\u00b2/s\u00b3 reynolds_lambda = 72.41  # Example value In\u00a0[22]: Copied! <pre>dynamic_viscosity = par.gas.get_dynamic_viscosity(temperature)\nkinematic_viscosity = par.gas.get_kinematic_viscosity(\n    dynamic_viscosity, fluid_density\n)\nkolmogorov_time = par.gas.get_kolmogorov_time(\n    kinematic_viscosity=kinematic_viscosity,\n    turbulent_dissipation=turbulent_dissipation,\n)\n</pre> dynamic_viscosity = par.gas.get_dynamic_viscosity(temperature) kinematic_viscosity = par.gas.get_kinematic_viscosity(     dynamic_viscosity, fluid_density ) kolmogorov_time = par.gas.get_kolmogorov_time(     kinematic_viscosity=kinematic_viscosity,     turbulent_dissipation=turbulent_dissipation, ) In\u00a0[23]: Copied! <pre># %%\n\nmean_free_path = par.gas.get_molecule_mean_free_path(\n    temperature=temperature, dynamic_viscosity=dynamic_viscosity\n)\n\n# 2. Slip correction factors\nknudsen_number = par.particles.get_knudsen_number(\n    mean_free_path=mean_free_path, particle_radius=particle_radius\n)\nslip_correction_factor = par.particles.get_cunningham_slip_correction(knudsen_number)\n# iterative terminal settling velocity\niterative_settling_velocity = (\n    par.particles.get_particle_settling_velocity_with_drag(\n        particle_radius=particle_radius,\n        particle_density=particle_density,\n        fluid_density=fluid_density,\n        dynamic_viscosity=dynamic_viscosity,\n        slip_correction_factor=slip_correction_factor,\n    )\n)\nsettling_velocity = par.particles.get_particle_settling_velocity(\n    particle_radius=particle_radius,\n    particle_density=particle_density,\n    slip_correction_factor=slip_correction_factor,\n    dynamic_viscosity=dynamic_viscosity,\n)\nrelative_velocity = iterative_settling_velocity - air_velocity\n</pre> # %%  mean_free_path = par.gas.get_molecule_mean_free_path(     temperature=temperature, dynamic_viscosity=dynamic_viscosity )  # 2. Slip correction factors knudsen_number = par.particles.get_knudsen_number(     mean_free_path=mean_free_path, particle_radius=particle_radius ) slip_correction_factor = par.particles.get_cunningham_slip_correction(knudsen_number) # iterative terminal settling velocity iterative_settling_velocity = (     par.particles.get_particle_settling_velocity_with_drag(         particle_radius=particle_radius,         particle_density=particle_density,         fluid_density=fluid_density,         dynamic_viscosity=dynamic_viscosity,         slip_correction_factor=slip_correction_factor,     ) ) settling_velocity = par.particles.get_particle_settling_velocity(     particle_radius=particle_radius,     particle_density=particle_density,     slip_correction_factor=slip_correction_factor,     dynamic_viscosity=dynamic_viscosity, ) relative_velocity = iterative_settling_velocity - air_velocity In\u00a0[24]: Copied! <pre># %%\n\nparticle_inertia_time = par.particles.get_particle_inertia_time(\n    particle_radius=particle_radius,\n    particle_density=particle_density,\n    fluid_density=fluid_density,\n    kinematic_viscosity=kinematic_viscosity,\n)\n\nre_p = 2 * particle_radius * relative_velocity / kinematic_viscosity\nf_re_p = 1 + 0.15 * re_p**0.687\n\nao2008_re_p = np.array([0.015, 0.116, 0.378, 0.851, 1.566, 2.537])\nao2008_t_p = np.array([0.0013, 0.0052, 0.0118, 0.0209, 0.0327, 0.0471])\nao2008_f_re_p = np.array([1.008, 1.034, 1.077, 1.134, 1.204, 1.284])\n\n# calculate relative velocity from re_p\nao2008_velocity = ao2008_re_p * kinematic_viscosity / (2 * particle_radius)\n\n\nparticle_settling_velocity = (\n    par.particles.get_particle_settling_velocity_via_inertia(\n        particle_inertia_time=particle_inertia_time,\n        particle_radius=particle_radius,\n        relative_velocity=iterative_settling_velocity,\n        slip_correction_factor=slip_correction_factor,\n        gravitational_acceleration=par.util.constants.STANDARD_GRAVITY,\n        kinematic_viscosity=kinematic_viscosity,\n    )\n)\n</pre> # %%  particle_inertia_time = par.particles.get_particle_inertia_time(     particle_radius=particle_radius,     particle_density=particle_density,     fluid_density=fluid_density,     kinematic_viscosity=kinematic_viscosity, )  re_p = 2 * particle_radius * relative_velocity / kinematic_viscosity f_re_p = 1 + 0.15 * re_p**0.687  ao2008_re_p = np.array([0.015, 0.116, 0.378, 0.851, 1.566, 2.537]) ao2008_t_p = np.array([0.0013, 0.0052, 0.0118, 0.0209, 0.0327, 0.0471]) ao2008_f_re_p = np.array([1.008, 1.034, 1.077, 1.134, 1.204, 1.284])  # calculate relative velocity from re_p ao2008_velocity = ao2008_re_p * kinematic_viscosity / (2 * particle_radius)   particle_settling_velocity = (     par.particles.get_particle_settling_velocity_via_inertia(         particle_inertia_time=particle_inertia_time,         particle_radius=particle_radius,         relative_velocity=iterative_settling_velocity,         slip_correction_factor=slip_correction_factor,         gravitational_acceleration=par.util.constants.STANDARD_GRAVITY,         kinematic_viscosity=kinematic_viscosity,     ) ) In\u00a0[25]: Copied! <pre># Plot comparison\nfig, ax = plt.subplots(3, 1, figsize=(5, 7))\n\nax[0].plot(\n    particle_radius * 1e6,\n    ao2008_re_p,\n    \"o-\",\n    color=\"black\",\n    alpha=0.6,\n    label=\"ao2008 Re_p\",\n)\nax[0].plot(\n    particle_radius * 1e6, re_p, \"x--\", color=\"black\", label=\"Particula Re_p\"\n)\nax[0].set_title(\"Reynolds Number Comparison\")\nax[0].set_xlabel(\"Particle Radius (micrometers)\")\nax[0].set_ylabel(\"Reynolds Number (Re_p)\")\nax[0].legend()\n\nax[1].plot(\n    particle_radius * 1e6,\n    ao2008_t_p,\n    \"o-\",\n    color=\"#E69F00\",\n    alpha=0.6,\n    label=\"ao2008 t_p\",\n)\nax[1].plot(\n    particle_radius * 1e6,\n    particle_inertia_time,\n    \"x--\",\n    color=\"#E69F00\",\n    label=\"Particula t_p\",\n)\nax[1].set_title(\"Particle Inertia Time Comparison\")\nax[1].set_xlabel(\"Particle Radius (micrometers)\")\nax[1].set_ylabel(\"Inertia Time (seconds)\")\nax[1].legend()\n\nax[2].plot(\n    particle_radius * 1e6,\n    ao2008_velocity * 100,\n    \"o-\",\n    color=\"#56B4E9\",\n    alpha=0.6,\n    label=\"ao2008 Velocity\",\n)\nax[2].plot(\n    particle_radius * 1e6,\n    particle_settling_velocity * 100,\n    \"x--\",\n    color=\"#56B4E9\",\n    label=\"Particula Velocity\",\n)\nax[2].set_title(\"Particle Settling Velocity Comparison\")\nax[2].set_xlabel(\"Particle Radius (micrometers)\")\nax[2].set_ylabel(\"Settling Velocity (centimeters per second)\")\nax[2].legend()\n\nplt.tight_layout()\nplt.show()\n</pre> # Plot comparison fig, ax = plt.subplots(3, 1, figsize=(5, 7))  ax[0].plot(     particle_radius * 1e6,     ao2008_re_p,     \"o-\",     color=\"black\",     alpha=0.6,     label=\"ao2008 Re_p\", ) ax[0].plot(     particle_radius * 1e6, re_p, \"x--\", color=\"black\", label=\"Particula Re_p\" ) ax[0].set_title(\"Reynolds Number Comparison\") ax[0].set_xlabel(\"Particle Radius (micrometers)\") ax[0].set_ylabel(\"Reynolds Number (Re_p)\") ax[0].legend()  ax[1].plot(     particle_radius * 1e6,     ao2008_t_p,     \"o-\",     color=\"#E69F00\",     alpha=0.6,     label=\"ao2008 t_p\", ) ax[1].plot(     particle_radius * 1e6,     particle_inertia_time,     \"x--\",     color=\"#E69F00\",     label=\"Particula t_p\", ) ax[1].set_title(\"Particle Inertia Time Comparison\") ax[1].set_xlabel(\"Particle Radius (micrometers)\") ax[1].set_ylabel(\"Inertia Time (seconds)\") ax[1].legend()  ax[2].plot(     particle_radius * 1e6,     ao2008_velocity * 100,     \"o-\",     color=\"#56B4E9\",     alpha=0.6,     label=\"ao2008 Velocity\", ) ax[2].plot(     particle_radius * 1e6,     particle_settling_velocity * 100,     \"x--\",     color=\"#56B4E9\",     label=\"Particula Velocity\", ) ax[2].set_title(\"Particle Settling Velocity Comparison\") ax[2].set_xlabel(\"Particle Radius (micrometers)\") ax[2].set_ylabel(\"Settling Velocity (centimeters per second)\") ax[2].legend()  plt.tight_layout() plt.show() <p>Table 2: Values for Reynolds number, inertia time, settling velocity, and correction factors for different particle sizes.</p> <p>Percents of error are calculated as: $$\\text{Error} = \\frac{\\text{Computed Value} - \\text{Paper Value}}{\\text{Paper Value}} \\times 100$$</p> In\u00a0[26]: Copied! <pre># Calculate percent error\npercent_error_re_p = 100 * (re_p - ao2008_re_p) / ao2008_re_p\npercent_error_tp = 100 * (particle_inertia_time - ao2008_t_p) / ao2008_t_p\npercent_error_velocity = (\n    100 * (particle_settling_velocity - ao2008_velocity) / ao2008_velocity\n)\npercent_error_f_re_p = 100 * (f_re_p - ao2008_f_re_p) / ao2008_f_re_p\n\n# Create DataFrame for Paper Values From Table 2\npaper_values_df = pd.DataFrame(\n    {\n        \"Radius (\u00b5m)\": particle_radius * 1e6,\n        \"t_p (s)\": ao2008_t_p,\n        \"Settling Velocity (cm/s)\": ao2008_velocity * 100,\n        \"Re_p\": ao2008_re_p,\n        \"f(Re_p)\": ao2008_f_re_p,\n    }\n)\nprint(\"Paper Values From Table 2\")\ndisplay(paper_values_df)\n\n# print settling velocity in a table format\n# Create DataFrame for Particula Computed Values\ncomputed_values_df = pd.DataFrame(\n    {\n        \"Radius (\u00b5m)\": particle_radius * 1e6,\n        \"t_p (s)\": particle_inertia_time,\n        \"Settling Velocity (cm/s)\": particle_settling_velocity * 100,\n        \"Re_p\": re_p,\n        \"f(Re_p)\": f_re_p,\n    }\n)\nprint(\"Particula Computed Values\")\ndisplay(computed_values_df)\n\n# Create a DataFrame for percent errors\npercent_errors_df = pd.DataFrame(\n    {\n        \"Radius (\u00b5m)\": particle_radius * 1e6,\n        \"Percent Error in t_p (%)\": percent_error_tp,\n        \"Percent Error in Settling Velocity (%)\": percent_error_velocity,\n        \"Percent Error in Re_p (%)\": percent_error_re_p,\n        \"Percent Error in f(Re_p) (%)\": percent_error_f_re_p,\n    }\n)\nprint(\"Percent Errors for Re_p, t_p, and Settling Velocity\")\ndisplay(percent_errors_df)\n</pre> # Calculate percent error percent_error_re_p = 100 * (re_p - ao2008_re_p) / ao2008_re_p percent_error_tp = 100 * (particle_inertia_time - ao2008_t_p) / ao2008_t_p percent_error_velocity = (     100 * (particle_settling_velocity - ao2008_velocity) / ao2008_velocity ) percent_error_f_re_p = 100 * (f_re_p - ao2008_f_re_p) / ao2008_f_re_p  # Create DataFrame for Paper Values From Table 2 paper_values_df = pd.DataFrame(     {         \"Radius (\u00b5m)\": particle_radius * 1e6,         \"t_p (s)\": ao2008_t_p,         \"Settling Velocity (cm/s)\": ao2008_velocity * 100,         \"Re_p\": ao2008_re_p,         \"f(Re_p)\": ao2008_f_re_p,     } ) print(\"Paper Values From Table 2\") display(paper_values_df)  # print settling velocity in a table format # Create DataFrame for Particula Computed Values computed_values_df = pd.DataFrame(     {         \"Radius (\u00b5m)\": particle_radius * 1e6,         \"t_p (s)\": particle_inertia_time,         \"Settling Velocity (cm/s)\": particle_settling_velocity * 100,         \"Re_p\": re_p,         \"f(Re_p)\": f_re_p,     } ) print(\"Particula Computed Values\") display(computed_values_df)  # Create a DataFrame for percent errors percent_errors_df = pd.DataFrame(     {         \"Radius (\u00b5m)\": particle_radius * 1e6,         \"Percent Error in t_p (%)\": percent_error_tp,         \"Percent Error in Settling Velocity (%)\": percent_error_velocity,         \"Percent Error in Re_p (%)\": percent_error_re_p,         \"Percent Error in f(Re_p) (%)\": percent_error_f_re_p,     } ) print(\"Percent Errors for Re_p, t_p, and Settling Velocity\") display(percent_errors_df) <pre>Paper Values From Table 2\n</pre> Radius (\u00b5m) t_p (s) Settling Velocity (cm/s) Re_p f(Re_p) 0 10.0 0.0013 1.286443 0.015 1.008 1 20.0 0.0052 4.974247 0.116 1.034 2 30.0 0.0118 10.806122 0.378 1.077 3 40.0 0.0209 18.246052 0.851 1.134 4 50.0 0.0327 26.860932 1.566 1.204 5 60.0 0.0471 36.263402 2.537 1.284 <pre>Particula Computed Values\n</pre> Radius (\u00b5m) t_p (s) Settling Velocity (cm/s) Re_p f(Re_p) 0 10.0 0.001296 1.269408 0.014910 1.008342 1 20.0 0.005182 4.930276 0.118395 1.034632 2 30.0 0.011660 10.615204 0.399585 1.079872 3 40.0 0.020729 17.794648 0.947163 1.144509 4 50.0 0.032389 26.470099 1.539373 1.201742 5 60.0 0.046640 35.746128 2.495207 1.281128 <pre>Percent Errors for Re_p, t_p, and Settling Velocity\n</pre> Radius (\u00b5m) Percent Error in t_p (%) Percent Error in Settling Velocity (%) Percent Error in Re_p (%) Percent Error in f(Re_p) (%) 0 10.0 -0.341394 -1.324191 -0.600546 0.033926 1 20.0 -0.341394 -0.883963 2.064960 0.061080 2 30.0 -1.185958 -1.766755 5.710198 0.266699 3 40.0 -0.818229 -2.473979 11.300040 0.926727 4 50.0 -0.950927 -1.455025 -1.700333 -0.187536 5 60.0 -0.976162 -1.426436 -1.647344 -0.223708 In\u00a0[27]: Copied! <pre>length_kolmogorov = par.gas.get_kolmogorov_length(\n    kinematic_viscosity=kinematic_viscosity,\n    turbulent_dissipation=turbulent_dissipation,\n)\n\ntimescale_kolmogorov_10 = par.gas.get_kolmogorov_time(\n    kinematic_viscosity=kinematic_viscosity,\n    turbulent_dissipation=10 * par.util.get_unit_conversion(\"cm^2/s^3\", \"m^2/s^3\"),\n)\nvelocity_kolmogorov_10 = par.gas.get_kolmogorov_velocity(\n    kinematic_viscosity=kinematic_viscosity,\n    turbulent_dissipation=10 * par.util.get_unit_conversion(\"cm^2/s^3\", \"m^2/s^3\"),\n)\nstokes_number_10 = par.particles.get_stokes_number(\n    particle_inertia_time=particle_inertia_time,\n    kolmogorov_time=timescale_kolmogorov_10,\n)\nstokes_velocity_10 = particle_settling_velocity / velocity_kolmogorov_10\n\n# 100 cm^2/s^3\ntimescale_kolmogorov_100 = par.gas.get_kolmogorov_time(\n    kinematic_viscosity=kinematic_viscosity,\n    turbulent_dissipation=100 * par.util.get_unit_conversion(\"cm^2/s^3\", \"m^2/s^3\"),\n)\nvelocity_kolmogorov_100 = par.gas.get_kolmogorov_velocity(\n    kinematic_viscosity=kinematic_viscosity,\n    turbulent_dissipation=100 * par.util.get_unit_conversion(\"cm^2/s^3\", \"m^2/s^3\"),\n)\nstokes_number_100 = par.particles.get_stokes_number(\n    particle_inertia_time=particle_inertia_time,\n    kolmogorov_time=timescale_kolmogorov_100,\n)\nstokes_velocity_100 = particle_settling_velocity / velocity_kolmogorov_100\n\n# 400 cm^2/s^3\ntimescale_kolmogorov_400 = par.gas.get_kolmogorov_time(\n    kinematic_viscosity=kinematic_viscosity,\n    turbulent_dissipation=400 * par.util.get_unit_conversion(\"cm^2/s^3\", \"m^2/s^3\"),\n)\nvelocity_kolmogorov_400 = par.gas.get_kolmogorov_velocity(\n    kinematic_viscosity=kinematic_viscosity,\n    turbulent_dissipation=400 * par.util.get_unit_conversion(\"cm^2/s^3\", \"m^2/s^3\"),\n)\nstokes_number_400 = par.particles.get_stokes_number(\n    particle_inertia_time=particle_inertia_time,\n    kolmogorov_time=timescale_kolmogorov_400,\n)\nstokes_velocity_400 = particle_settling_velocity / velocity_kolmogorov_400\n\n\n# from paper\n\nst_ao2008 = np.array(\n    [\n        [0.010, 0.032, 0.063],\n        [0.040, 0.127, 0.253],\n        [0.090, 0.285, 0.570],\n        [0.160, 0.507, 1.014],\n        [0.250, 0.792, 1.585],\n        [0.361, 1.141, 2.282],\n    ]\n)\nsv_ao2008 = np.array(\n    [\n        [1.113, 0.626, 0.442],\n        [4.343, 2.442, 1.727],\n        [9.385, 5.278, 3.732],\n        [15.841, 8.908, 6.299],\n        [23.316, 13.111, 9.271],\n        [31.478, 17.701, 12.516],\n    ]\n)\n</pre> length_kolmogorov = par.gas.get_kolmogorov_length(     kinematic_viscosity=kinematic_viscosity,     turbulent_dissipation=turbulent_dissipation, )  timescale_kolmogorov_10 = par.gas.get_kolmogorov_time(     kinematic_viscosity=kinematic_viscosity,     turbulent_dissipation=10 * par.util.get_unit_conversion(\"cm^2/s^3\", \"m^2/s^3\"), ) velocity_kolmogorov_10 = par.gas.get_kolmogorov_velocity(     kinematic_viscosity=kinematic_viscosity,     turbulent_dissipation=10 * par.util.get_unit_conversion(\"cm^2/s^3\", \"m^2/s^3\"), ) stokes_number_10 = par.particles.get_stokes_number(     particle_inertia_time=particle_inertia_time,     kolmogorov_time=timescale_kolmogorov_10, ) stokes_velocity_10 = particle_settling_velocity / velocity_kolmogorov_10  # 100 cm^2/s^3 timescale_kolmogorov_100 = par.gas.get_kolmogorov_time(     kinematic_viscosity=kinematic_viscosity,     turbulent_dissipation=100 * par.util.get_unit_conversion(\"cm^2/s^3\", \"m^2/s^3\"), ) velocity_kolmogorov_100 = par.gas.get_kolmogorov_velocity(     kinematic_viscosity=kinematic_viscosity,     turbulent_dissipation=100 * par.util.get_unit_conversion(\"cm^2/s^3\", \"m^2/s^3\"), ) stokes_number_100 = par.particles.get_stokes_number(     particle_inertia_time=particle_inertia_time,     kolmogorov_time=timescale_kolmogorov_100, ) stokes_velocity_100 = particle_settling_velocity / velocity_kolmogorov_100  # 400 cm^2/s^3 timescale_kolmogorov_400 = par.gas.get_kolmogorov_time(     kinematic_viscosity=kinematic_viscosity,     turbulent_dissipation=400 * par.util.get_unit_conversion(\"cm^2/s^3\", \"m^2/s^3\"), ) velocity_kolmogorov_400 = par.gas.get_kolmogorov_velocity(     kinematic_viscosity=kinematic_viscosity,     turbulent_dissipation=400 * par.util.get_unit_conversion(\"cm^2/s^3\", \"m^2/s^3\"), ) stokes_number_400 = par.particles.get_stokes_number(     particle_inertia_time=particle_inertia_time,     kolmogorov_time=timescale_kolmogorov_400, ) stokes_velocity_400 = particle_settling_velocity / velocity_kolmogorov_400   # from paper  st_ao2008 = np.array(     [         [0.010, 0.032, 0.063],         [0.040, 0.127, 0.253],         [0.090, 0.285, 0.570],         [0.160, 0.507, 1.014],         [0.250, 0.792, 1.585],         [0.361, 1.141, 2.282],     ] ) sv_ao2008 = np.array(     [         [1.113, 0.626, 0.442],         [4.343, 2.442, 1.727],         [9.385, 5.278, 3.732],         [15.841, 8.908, 6.299],         [23.316, 13.111, 9.271],         [31.478, 17.701, 12.516],     ] ) In\u00a0[28]: Copied! <pre># Plot Stokes number comparison\nfig, ax = plt.subplots(2, 1, figsize=(6, 6))\n\nax[0].plot(\n    particle_radius * 1e6,\n    st_ao2008[:, 0],\n    \"o-\",\n    color=\"black\",\n    alpha=0.6,\n    label=\"ao2008 St (10 cm^2/s^3)\",\n)\nax[0].plot(\n    particle_radius * 1e6,\n    stokes_number_10,\n    \"x--\",\n    color=\"black\",\n    label=\"Particula St (10 cm^2/s^3)\",\n)\nax[0].plot(\n    particle_radius * 1e6,\n    st_ao2008[:, 1],\n    \"o-\",\n    color=\"#E69F00\",\n    alpha=0.6,\n    label=\"ao2008 St (100 cm^2/s^3)\",\n)\nax[0].plot(\n    particle_radius * 1e6,\n    stokes_number_100,\n    \"x--\",\n    color=\"#E69F00\",\n    label=\"Particula St (100 cm^2/s^3)\",\n)\nax[0].plot(\n    particle_radius * 1e6,\n    st_ao2008[:, 2],\n    \"o-\",\n    color=\"#56B4E9\",\n    alpha=0.6,\n    label=\"ao2008 St (400 cm^2/s^3)\",\n)\nax[0].plot(\n    particle_radius * 1e6,\n    stokes_number_400,\n    \"x--\",\n    color=\"#56B4E9\",\n    label=\"Particula St (400 cm^2/s^3)\",\n)\nax[0].set_title(\"Stokes Number Comparison\")\nax[0].set_xlabel(\"Particle Radius (micrometers)\")\nax[0].set_ylabel(\"Stokes Number (St)\")\n\n# Plot Stokes velocity comparison\nax[1].plot(\n    particle_radius * 1e6,\n    sv_ao2008[:, 0],\n    \"o-\",\n    color=\"black\",\n    alpha=0.6,\n    label=\"ao2008 Sv (10 cm^2/s^3)\",\n)\nax[1].plot(\n    particle_radius * 1e6,\n    stokes_velocity_10,\n    \"x--\",\n    color=\"black\",\n    label=\"Particula Sv (10 cm^2/s^3)\",\n)\nax[1].plot(\n    particle_radius * 1e6,\n    sv_ao2008[:, 1],\n    \"o-\",\n    color=\"#E69F00\",\n    alpha=0.6,\n    label=\"ao2008 Sv (100 cm^2/s^3)\",\n)\nax[1].plot(\n    particle_radius * 1e6,\n    stokes_velocity_100,\n    \"x--\",\n    color=\"#E69F00\",\n    label=\"Particula Sv (100 cm^2/s^3)\",\n)\nax[1].plot(\n    particle_radius * 1e6,\n    sv_ao2008[:, 2],\n    \"o-\",\n    color=\"#56B4E9\",\n    alpha=0.6,\n    label=\"ao2008 Sv (400 cm^2/s^3)\",\n)\nax[1].plot(\n    particle_radius * 1e6,\n    stokes_velocity_400,\n    \"x--\",\n    color=\"#56B4E9\",\n    label=\"Particula Sv (400 cm^2/s^3)\",\n)\nax[1].set_title(\"Stokes Velocity Comparison\")\nax[1].set_xlabel(\"Particle Radius (micrometers)\")\nax[1].set_ylabel(\"Stokes Velocity (dimensionless)\")\n\nax[1].legend(loc=\"lower center\", ncol=2, bbox_to_anchor=(0.5, -0.8))\nplt.tight_layout()\nplt.show()\n</pre> # Plot Stokes number comparison fig, ax = plt.subplots(2, 1, figsize=(6, 6))  ax[0].plot(     particle_radius * 1e6,     st_ao2008[:, 0],     \"o-\",     color=\"black\",     alpha=0.6,     label=\"ao2008 St (10 cm^2/s^3)\", ) ax[0].plot(     particle_radius * 1e6,     stokes_number_10,     \"x--\",     color=\"black\",     label=\"Particula St (10 cm^2/s^3)\", ) ax[0].plot(     particle_radius * 1e6,     st_ao2008[:, 1],     \"o-\",     color=\"#E69F00\",     alpha=0.6,     label=\"ao2008 St (100 cm^2/s^3)\", ) ax[0].plot(     particle_radius * 1e6,     stokes_number_100,     \"x--\",     color=\"#E69F00\",     label=\"Particula St (100 cm^2/s^3)\", ) ax[0].plot(     particle_radius * 1e6,     st_ao2008[:, 2],     \"o-\",     color=\"#56B4E9\",     alpha=0.6,     label=\"ao2008 St (400 cm^2/s^3)\", ) ax[0].plot(     particle_radius * 1e6,     stokes_number_400,     \"x--\",     color=\"#56B4E9\",     label=\"Particula St (400 cm^2/s^3)\", ) ax[0].set_title(\"Stokes Number Comparison\") ax[0].set_xlabel(\"Particle Radius (micrometers)\") ax[0].set_ylabel(\"Stokes Number (St)\")  # Plot Stokes velocity comparison ax[1].plot(     particle_radius * 1e6,     sv_ao2008[:, 0],     \"o-\",     color=\"black\",     alpha=0.6,     label=\"ao2008 Sv (10 cm^2/s^3)\", ) ax[1].plot(     particle_radius * 1e6,     stokes_velocity_10,     \"x--\",     color=\"black\",     label=\"Particula Sv (10 cm^2/s^3)\", ) ax[1].plot(     particle_radius * 1e6,     sv_ao2008[:, 1],     \"o-\",     color=\"#E69F00\",     alpha=0.6,     label=\"ao2008 Sv (100 cm^2/s^3)\", ) ax[1].plot(     particle_radius * 1e6,     stokes_velocity_100,     \"x--\",     color=\"#E69F00\",     label=\"Particula Sv (100 cm^2/s^3)\", ) ax[1].plot(     particle_radius * 1e6,     sv_ao2008[:, 2],     \"o-\",     color=\"#56B4E9\",     alpha=0.6,     label=\"ao2008 Sv (400 cm^2/s^3)\", ) ax[1].plot(     particle_radius * 1e6,     stokes_velocity_400,     \"x--\",     color=\"#56B4E9\",     label=\"Particula Sv (400 cm^2/s^3)\", ) ax[1].set_title(\"Stokes Velocity Comparison\") ax[1].set_xlabel(\"Particle Radius (micrometers)\") ax[1].set_ylabel(\"Stokes Velocity (dimensionless)\")  ax[1].legend(loc=\"lower center\", ncol=2, bbox_to_anchor=(0.5, -0.8)) plt.tight_layout() plt.show() In\u00a0[29]: Copied! <pre># Create DataFrame for Paper Values From Table 3 (Stokes Numbers)\nstokes_number_paper_df = pd.DataFrame(\n    {\n        \"Radius (\u00b5m)\": particle_radius * 1e6,\n        \"St (10 cm^2/s^3)\": st_ao2008[:, 0],\n        \"St (100 cm^2/s^3)\": st_ao2008[:, 1],\n        \"St (400 cm^2/s^3)\": st_ao2008[:, 2],\n    }\n)\nprint(\"Paper Values From Table 3 (Stokes Numbers)\")\ndisplay(stokes_number_paper_df)\n\n# Create DataFrame for Particula Computed Stokes Numbers\nstokes_number_particula_df = pd.DataFrame(\n    {\n        \"Radius (\u00b5m)\": particle_radius * 1e6,\n        \"St (10 cm^2/s^3)\": stokes_number_10,\n        \"St (100 cm^2/s^3)\": stokes_number_100,\n        \"St (400 cm^2/s^3)\": stokes_number_400,\n    }\n)\nprint(\"Particula Computed Stokes Numbers\")\ndisplay(stokes_number_particula_df)\n\n# Calculate percent errors for Stokes Numbers\npercent_error_stokes_number_10 = (\n    100 * (stokes_number_10 - st_ao2008[:, 0]) / st_ao2008[:, 0]\n)\npercent_error_stokes_number_100 = (\n    100 * (stokes_number_100 - st_ao2008[:, 1]) / st_ao2008[:, 1]\n)\npercent_error_stokes_number_400 = (\n    100 * (stokes_number_400 - st_ao2008[:, 2]) / st_ao2008[:, 2]\n)\n\npercent_errors_stokes_df = pd.DataFrame(\n    {\n        \"Radius (\u00b5m)\": particle_radius * 1e6,\n        \"Percent Error in St (10 cm^2/s^3)\": percent_error_stokes_number_10,\n        \"Percent Error in St (100 cm^2/s^3)\": percent_error_stokes_number_100,\n        \"Percent Error in St (400 cm^2/s^3)\": percent_error_stokes_number_400,\n    }\n)\nprint(\"Percent Errors for Stokes Numbers\")\ndisplay(percent_errors_stokes_df)\n\n\n# print ao2008 values\n# Create DataFrame for Paper Values From Table 3 (Scaled Velocities)\nsv_paper_df = pd.DataFrame(\n    {\n        \"Radius (\u00b5m)\": particle_radius * 1e6,\n        \"Stokes Velocity (10 cm^2/s^3)\": sv_ao2008[:, 0],\n        \"Stokes Velocity (100 cm^2/s^3)\": sv_ao2008[:, 1],\n        \"Stokes Velocity (400 cm^2/s^3)\": sv_ao2008[:, 2],\n    }\n)\nprint(\"Paper Values From Table 3 (Stokes Velocities)\")\ndisplay(sv_paper_df)\n\n# print stokes velocity in a table format\n# Create DataFrame for Particula Computed Stokes Velocities\nsv_particula_df = pd.DataFrame(\n    {\n        \"Radius (\u00b5m)\": particle_radius * 1e6,\n        \"Stokes Velocity (10 cm^2/s^3)\": stokes_velocity_10,\n        \"Stokes Velocity (100 cm^2/s^3)\": stokes_velocity_100,\n        \"Stokes Velocity (400 cm^2/s^3)\": stokes_velocity_400,\n    }\n)\nprint(\"Particula Computed Stokes Velocities\")\ndisplay(sv_particula_df)\n\n# Calculate percent errors for Stokes Velocities\npercent_error_sv_10 = (\n    100 * (stokes_velocity_10 - sv_ao2008[:, 0]) / sv_ao2008[:, 0]\n)\npercent_error_sv_100 = (\n    100 * (stokes_velocity_100 - sv_ao2008[:, 1]) / sv_ao2008[:, 1]\n)\npercent_error_sv_400 = (\n    100 * (stokes_velocity_400 - sv_ao2008[:, 2]) / sv_ao2008[:, 2]\n)\n\npercent_errors_sv_df = pd.DataFrame(\n    {\n        \"Radius (\u00b5m)\": particle_radius * 1e6,\n        \"Percent Error in Sv (10 cm^2/s^3)\": percent_error_sv_10,\n        \"Percent Error in Sv (100 cm^2/s^3)\": percent_error_sv_100,\n        \"Percent Error in Sv (400 cm^2/s^3)\": percent_error_sv_400,\n    }\n)\nprint(\"Percent Errors for Stokes Velocities\")\ndisplay(percent_errors_sv_df)\n</pre> # Create DataFrame for Paper Values From Table 3 (Stokes Numbers) stokes_number_paper_df = pd.DataFrame(     {         \"Radius (\u00b5m)\": particle_radius * 1e6,         \"St (10 cm^2/s^3)\": st_ao2008[:, 0],         \"St (100 cm^2/s^3)\": st_ao2008[:, 1],         \"St (400 cm^2/s^3)\": st_ao2008[:, 2],     } ) print(\"Paper Values From Table 3 (Stokes Numbers)\") display(stokes_number_paper_df)  # Create DataFrame for Particula Computed Stokes Numbers stokes_number_particula_df = pd.DataFrame(     {         \"Radius (\u00b5m)\": particle_radius * 1e6,         \"St (10 cm^2/s^3)\": stokes_number_10,         \"St (100 cm^2/s^3)\": stokes_number_100,         \"St (400 cm^2/s^3)\": stokes_number_400,     } ) print(\"Particula Computed Stokes Numbers\") display(stokes_number_particula_df)  # Calculate percent errors for Stokes Numbers percent_error_stokes_number_10 = (     100 * (stokes_number_10 - st_ao2008[:, 0]) / st_ao2008[:, 0] ) percent_error_stokes_number_100 = (     100 * (stokes_number_100 - st_ao2008[:, 1]) / st_ao2008[:, 1] ) percent_error_stokes_number_400 = (     100 * (stokes_number_400 - st_ao2008[:, 2]) / st_ao2008[:, 2] )  percent_errors_stokes_df = pd.DataFrame(     {         \"Radius (\u00b5m)\": particle_radius * 1e6,         \"Percent Error in St (10 cm^2/s^3)\": percent_error_stokes_number_10,         \"Percent Error in St (100 cm^2/s^3)\": percent_error_stokes_number_100,         \"Percent Error in St (400 cm^2/s^3)\": percent_error_stokes_number_400,     } ) print(\"Percent Errors for Stokes Numbers\") display(percent_errors_stokes_df)   # print ao2008 values # Create DataFrame for Paper Values From Table 3 (Scaled Velocities) sv_paper_df = pd.DataFrame(     {         \"Radius (\u00b5m)\": particle_radius * 1e6,         \"Stokes Velocity (10 cm^2/s^3)\": sv_ao2008[:, 0],         \"Stokes Velocity (100 cm^2/s^3)\": sv_ao2008[:, 1],         \"Stokes Velocity (400 cm^2/s^3)\": sv_ao2008[:, 2],     } ) print(\"Paper Values From Table 3 (Stokes Velocities)\") display(sv_paper_df)  # print stokes velocity in a table format # Create DataFrame for Particula Computed Stokes Velocities sv_particula_df = pd.DataFrame(     {         \"Radius (\u00b5m)\": particle_radius * 1e6,         \"Stokes Velocity (10 cm^2/s^3)\": stokes_velocity_10,         \"Stokes Velocity (100 cm^2/s^3)\": stokes_velocity_100,         \"Stokes Velocity (400 cm^2/s^3)\": stokes_velocity_400,     } ) print(\"Particula Computed Stokes Velocities\") display(sv_particula_df)  # Calculate percent errors for Stokes Velocities percent_error_sv_10 = (     100 * (stokes_velocity_10 - sv_ao2008[:, 0]) / sv_ao2008[:, 0] ) percent_error_sv_100 = (     100 * (stokes_velocity_100 - sv_ao2008[:, 1]) / sv_ao2008[:, 1] ) percent_error_sv_400 = (     100 * (stokes_velocity_400 - sv_ao2008[:, 2]) / sv_ao2008[:, 2] )  percent_errors_sv_df = pd.DataFrame(     {         \"Radius (\u00b5m)\": particle_radius * 1e6,         \"Percent Error in Sv (10 cm^2/s^3)\": percent_error_sv_10,         \"Percent Error in Sv (100 cm^2/s^3)\": percent_error_sv_100,         \"Percent Error in Sv (400 cm^2/s^3)\": percent_error_sv_400,     } ) print(\"Percent Errors for Stokes Velocities\") display(percent_errors_sv_df) <pre>Paper Values From Table 3 (Stokes Numbers)\n</pre> Radius (\u00b5m) St (10 cm^2/s^3) St (100 cm^2/s^3) St (400 cm^2/s^3) 0 10.0 0.010 0.032 0.063 1 20.0 0.040 0.127 0.253 2 30.0 0.090 0.285 0.570 3 40.0 0.160 0.507 1.014 4 50.0 0.250 0.792 1.585 5 60.0 0.361 1.141 2.282 <pre>Particula Computed Stokes Numbers\n</pre> Radius (\u00b5m) St (10 cm^2/s^3) St (100 cm^2/s^3) St (400 cm^2/s^3) 0 10.0 0.009892 0.031282 0.062564 1 20.0 0.039569 0.125128 0.250255 2 30.0 0.089030 0.281537 0.563075 3 40.0 0.158275 0.500511 1.001022 4 50.0 0.247305 0.782048 1.564096 5 60.0 0.356120 1.126149 2.252299 <pre>Percent Errors for Stokes Numbers\n</pre> Radius (\u00b5m) Percent Error in St (10 cm^2/s^3) Percent Error in St (100 cm^2/s^3) Percent Error in St (400 cm^2/s^3) 0 10.0 -1.077861 -2.243978 -0.692295 1 20.0 -1.077861 -1.474246 -1.084816 2 30.0 -1.077861 -1.214967 -1.214967 3 40.0 -1.077861 -1.279915 -1.279915 4 50.0 -1.077861 -1.256544 -1.318842 5 60.0 -1.351884 -1.301545 -1.301545 <pre>Paper Values From Table 3 (Stokes Velocities)\n</pre> Radius (\u00b5m) Stokes Velocity (10 cm^2/s^3) Stokes Velocity (100 cm^2/s^3) Stokes Velocity (400 cm^2/s^3) 0 10.0 1.113 0.626 0.442 1 20.0 4.343 2.442 1.727 2 30.0 9.385 5.278 3.732 3 40.0 15.841 8.908 6.299 4 50.0 23.316 13.111 9.271 5 60.0 31.478 17.701 12.516 <pre>Particula Computed Stokes Velocities\n</pre> Radius (\u00b5m) Stokes Velocity (10 cm^2/s^3) Stokes Velocity (100 cm^2/s^3) Stokes Velocity (400 cm^2/s^3) 0 10.0 1.109223 0.623762 0.441066 1 20.0 4.308131 2.422640 1.713065 2 30.0 9.275686 5.216101 3.688341 3 40.0 15.549165 8.743938 6.182898 4 50.0 23.129872 13.006883 9.197255 5 60.0 31.235372 17.564940 12.420288 <pre>Percent Errors for Stokes Velocities\n</pre> Radius (\u00b5m) Percent Error in Sv (10 cm^2/s^3) Percent Error in Sv (100 cm^2/s^3) Percent Error in Sv (400 cm^2/s^3) 0 10.0 -0.339333 -0.357498 -0.211226 1 20.0 -0.802873 -0.792784 -0.806872 2 30.0 -1.164775 -1.172765 -1.169862 3 40.0 -1.842276 -1.841737 -1.843183 4 50.0 -0.798283 -0.794119 -0.795435 5 60.0 -0.770787 -0.768656 -0.764714"},{"location":"Theory/Technical/Dynamics/Cloud_Droplet_Coagulation/DNS_Fluid_and_Particle_Properties_Comparison/#fluid-and-particle-properties-for-cloud-droplet-coagulation","title":"Fluid and Particle Properties for Cloud Droplet Coagulation\u00b6","text":"<p>This notebook verifies the computations performed by the <code>Particula</code> library by comparing its results with those presented in the paper by Ayala et al. (2008). The comparisons focus on key parameters that influence cloud droplet coagulation processes, such as Reynolds number, inertia time, settling velocity, Stokes number, and scaled velocities. Objective:</p> <ul> <li>To validate the accuracy of the <code>Particula</code> library in computing fluid and particle properties relevant to cloud droplet coagulation. Reference Tables:</li> <li>Table 2: Provides values for Reynolds number, inertia time, settling velocity, and correction factors for different particle sizes.</li> <li>Table 3: Includes characteristic scales for cloud droplets, such as Stokes numbers and scaled velocities at various turbulent dissipation rates.</li> </ul> <p>Reference Paper: Ayala, O., Rosa, B., Wang, L. P., &amp; Grabowski, W. W. (2008). Effects of turbulence on the geometric collision rate of sedimenting droplets. Part 1. Results from direct numerical simulation. New Journal of Physics, 10. https://doi.org/10.1088/1367-2630/10/7/075015 By conducting this comparison, we aim to ensure that the <code>Particula</code> library produces reliable results that align with established literature, which is crucial for accurate simulations in aerosol science and cloud physics.</p>"},{"location":"Theory/Technical/Dynamics/Cloud_Droplet_Coagulation/DNS_Fluid_and_Particle_Properties_Comparison/#model-equations-and-parameters","title":"Model Equations and Parameters\u00b6","text":"<p>In this section, we define the particle radii and other parameters needed for the calculations. These include temperature, particle density, fluid density, and air velocity.</p>"},{"location":"Theory/Technical/Dynamics/Cloud_Droplet_Coagulation/DNS_Fluid_and_Particle_Properties_Comparison/#calculate-dynamic-and-kinematic-viscosity","title":"Calculate Dynamic and Kinematic Viscosity\u00b6","text":"<p>We calculate the dynamic and kinematic viscosity of the fluid using the temperature and fluid density.</p>"},{"location":"Theory/Technical/Dynamics/Cloud_Droplet_Coagulation/DNS_Fluid_and_Particle_Properties_Comparison/#calculate-particle-settling-velocity","title":"Calculate Particle Settling Velocity\u00b6","text":"<p>This section calculates the particle settling velocity using the slip correction factor and other parameters.</p>"},{"location":"Theory/Technical/Dynamics/Cloud_Droplet_Coagulation/DNS_Fluid_and_Particle_Properties_Comparison/#calculate-particle-inertia-time","title":"Calculate Particle Inertia Time\u00b6","text":"<p>We calculate the particle inertia time, which is a measure of how quickly a particle responds to changes in the surrounding fluid.</p>"},{"location":"Theory/Technical/Dynamics/Cloud_Droplet_Coagulation/DNS_Fluid_and_Particle_Properties_Comparison/#comparison-of-paper-values-and-computed-values","title":"Comparison of Paper Values and Computed Values\u00b6","text":"<p>We compare the values from the paper with the computed values from the Particula library. This includes the Reynolds number, inertia time, and settling velocity.</p>"},{"location":"Theory/Technical/Dynamics/Cloud_Droplet_Coagulation/DNS_Fluid_and_Particle_Properties_Comparison/#analysis","title":"Analysis\u00b6","text":"<p>The plots below show the comparison between the values reported in Ayala et al. (2008) and the values computed using the <code>Particula</code> library. The percent errors are also calculated to quantify the discrepancies.</p> <ul> <li>Reynolds Number (Re_p): The Reynolds number is a dimensionless quantity representing the ratio of inertial forces to viscous forces acting on the particles. The comparison shows that the computed Reynolds numbers closely match the paper values, with minimal percent errors (typically less than a few percent), indicating accurate modeling of particle-fluid interactions.</li> <li>Inertia Time (t_p): The inertia time signifies how quickly a particle adjusts its velocity relative to the surrounding fluid. The computed inertia times align well with the paper values, validating the correctness of particle inertia calculations in <code>Particula</code>.</li> <li>Settling Velocity: This is the terminal velocity at which particles settle under gravity in a quiescent fluid. The computed settling velocities are in good agreement with the paper values, demonstrating accurate calculations of gravitational settling influenced by particle size and fluid properties. Overall, the <code>Particula</code> library provides results consistent with established literature, affirming its reliability for simulating particle dynamics in atmospheric studies.</li> </ul>"},{"location":"Theory/Technical/Dynamics/Cloud_Droplet_Coagulation/DNS_Fluid_and_Particle_Properties_Comparison/#stokes-number-and-velocity-comparison","title":"Stokes Number and Velocity Comparison\u00b6","text":"<p>We calculate and compare the Stokes number and velocity for different turbulent dissipation rates.</p>"},{"location":"Theory/Technical/Dynamics/Cloud_Droplet_Coagulation/DNS_Fluid_and_Particle_Properties_Comparison/#significance","title":"Significance\u00b6","text":"<p>The Stokes number (St) is a dimensionless parameter that characterizes the behavior of particles suspended in a fluid flow, defined as the ratio of the particle's response time to a characteristic time scale of the flow (e.g., the Kolmogorov time scale in turbulence). It indicates how much the particle's motion is influenced by the fluid's turbulence. A small Stokes number implies that the particle closely follows the fluid motion, while a large Stokes number suggests that the particle's inertia dominates, and it is less affected by the fluid fluctuations. By comparing the computed Stokes numbers and Stokes velocities with the values from Ayala et al. (2008), we can assess the accuracy of the <code>Particula</code> library in capturing particle dynamics within turbulent flows at different intensities (represented by different turbulent dissipation rates). The plots below illustrate these comparisons for three turbulent dissipation rates: 10 cm\u00b2/s\u00b3 (weak turbulence), 100 cm\u00b2/s\u00b3 (moderate turbulence), and 400 cm\u00b2/s\u00b3 (strong turbulence).</p>"},{"location":"Theory/Technical/Dynamics/Cloud_Droplet_Coagulation/DNS_Fluid_and_Particle_Properties_Comparison/#analysis","title":"Analysis\u00b6","text":"<ul> <li>Stokes Number (St): The computed Stokes numbers show excellent agreement with the paper values across all particle sizes and turbulence levels. This consistency confirms that <code>Particula</code> accurately models the interplay between particle inertia and turbulent flow scales.</li> <li>Stokes Velocity (Sv): The Stokes velocities (particle settling velocity normalized by the Kolmogorov velocity scale) also match closely with the paper values. This indicates that <code>Particula</code> effectively captures how turbulence modulates particle settling rates. These results validate the <code>Particula</code> library's capability to simulate particle-turbulence interactions, which are critical for understanding processes like cloud droplet collision-coalescence in atmospheric physics.</li> </ul>"},{"location":"Theory/Technical/Dynamics/Cloud_Droplet_Coagulation/DNS_Fluid_and_Particle_Properties_Comparison/#comparison-of-stokes-number-and-velocity","title":"Comparison of Stokes Number and Velocity\u00b6","text":"<p>We compare the Stokes number and velocity from the paper with the computed values for different turbulent dissipation rates.</p>"},{"location":"Theory/Technical/Dynamics/Cloud_Droplet_Coagulation/DNS_Fluid_and_Particle_Properties_Comparison/#summary-of-notebook-comparisons","title":"Summary of Notebook Comparisons\u00b6","text":"<p>Overall, the comparisons between the computed values from the <code>Particula</code> library and the values reported in Ayala et al. (2008) show good agreement. However, there are some errors observed in the calculations:</p> <ul> <li>Reynolds Number (Re_p): The computed Reynolds numbers closely match the paper values, with percent errors typically less than a few percent. The maximum error observed is around 11.5%.</li> <li>Inertia Time (t_p): The computed inertia times align well with the paper values, with percent errors generally below 1.2%. The maximum error observed is around 1.19%.</li> <li>Settling Velocity: The computed settling velocities are in good agreement with the paper values, with percent errors typically less than 2.5%. The maximum error observed is around 2.49%.</li> <li>Stokes Number (St): The computed Stokes numbers show excellent agreement with the paper values across all particle sizes and turbulence levels. The percent errors are generally below 2.25%. The maximum error observed is around 2.24%.</li> <li>Stokes Velocity (Sv): The Stokes velocities also match closely with the paper values, with percent errors typically less than 1.86%. The maximum error observed is around 1.86%.</li> </ul> <p>These results validate the <code>Particula</code> library's capability to simulate particle dynamics accurately, with discrepancies observed in some cases.</p>"},{"location":"Theory/Technical/Dynamics/Cloud_Droplet_Coagulation/DNS_Horizontal_Velocity_Comparison/","title":"Horizontal Velocity Comparison","text":"In\u00a0[6]: Copied! <pre>import numpy as np\nimport matplotlib.pyplot as plt\nimport particula as par\n\nfrom particula.dynamics.coagulation.turbulent_dns_kernel.sigma_relative_velocity_ao2008 import (\n    _compute_rms_fluctuation_velocity,\n    VelocityCorrelationTerms,\n)\n\nfrom particula.dynamics.coagulation.turbulent_dns_kernel.velocity_correlation_terms_ao2008 import (\n    compute_b1,\n    compute_b2,\n    compute_c1,\n    compute_c2,\n    compute_d1,\n    compute_d2,\n    compute_e1,\n    compute_e2,\n    compute_z,\n    compute_beta,\n)\n</pre> import numpy as np import matplotlib.pyplot as plt import particula as par  from particula.dynamics.coagulation.turbulent_dns_kernel.sigma_relative_velocity_ao2008 import (     _compute_rms_fluctuation_velocity,     VelocityCorrelationTerms, )  from particula.dynamics.coagulation.turbulent_dns_kernel.velocity_correlation_terms_ao2008 import (     compute_b1,     compute_b2,     compute_c1,     compute_c2,     compute_d1,     compute_d2,     compute_e1,     compute_e2,     compute_z,     compute_beta, ) In\u00a0[7]: Copied! <pre># %% DNS values\n\n# Figure 12: Comparison of the predicted and simulated mean-square horizontal\n# particle velocities for droplets falling in a turbulent \ufb02ow of R\u03bb = 72.41 and\n# turbulent_dissipation = 400 cm2 s\u22123\n\n# droplet radius (a2, microns) vs rms_velocity (cm2/s2)\n\n# dns_10cm2/s3: 6 rows, 2 columns (X, Y)\ndns_10cm2_s3 = np.array(\n    [\n        [9.938118812, 26.66666667],\n        [20.02475248, 26.41975309],\n        [30.04950495, 26.41975309],\n        [40.01237624, 24.69135802],\n        [50.16089109, 22.71604938],\n        [60.06188119, 18.51851852],\n    ]\n)\n\n# dns_100_cm2/s3: 6 rows, 2 columns (X, Y)\ndns_100_cm2_s3 = np.array(\n    [\n        [9.938118812, 84.44444444],\n        [20.02475248, 80.98765432],\n        [29.98762376, 77.03703704],\n        [39.95049505, 71.11111111],\n        [49.97524752, 59.25925926],\n        [60.06188119, 44.19753086],\n    ]\n)\n\n# dns_400_cm2/s3: 6 rows, 2 columns (X, Y)\ndns_400_cm2_s3 = np.array(\n    [\n        [9.876237624, 166.9135802],\n        [20.08663366, 163.9506173],\n        [30.11138614, 150.1234568],\n        [40.07425743, 129.1358025],\n        [50.03712871, 100.4938272],\n        [60.06188119, 69.62962963],\n    ]\n)\n</pre> # %% DNS values  # Figure 12: Comparison of the predicted and simulated mean-square horizontal # particle velocities for droplets falling in a turbulent \ufb02ow of R\u03bb = 72.41 and # turbulent_dissipation = 400 cm2 s\u22123  # droplet radius (a2, microns) vs rms_velocity (cm2/s2)  # dns_10cm2/s3: 6 rows, 2 columns (X, Y) dns_10cm2_s3 = np.array(     [         [9.938118812, 26.66666667],         [20.02475248, 26.41975309],         [30.04950495, 26.41975309],         [40.01237624, 24.69135802],         [50.16089109, 22.71604938],         [60.06188119, 18.51851852],     ] )  # dns_100_cm2/s3: 6 rows, 2 columns (X, Y) dns_100_cm2_s3 = np.array(     [         [9.938118812, 84.44444444],         [20.02475248, 80.98765432],         [29.98762376, 77.03703704],         [39.95049505, 71.11111111],         [49.97524752, 59.25925926],         [60.06188119, 44.19753086],     ] )  # dns_400_cm2/s3: 6 rows, 2 columns (X, Y) dns_400_cm2_s3 = np.array(     [         [9.876237624, 166.9135802],         [20.08663366, 163.9506173],         [30.11138614, 150.1234568],         [40.07425743, 129.1358025],         [50.03712871, 100.4938272],         [60.06188119, 69.62962963],     ] ) In\u00a0[8]: Copied! <pre># %% Model equations\n\n# Define Particle Radii and Parameters\nparticle_radius = np.linspace(10e-6, 60e-6, 6)\ntemperature = 273  # Temperature in Kelvin\nparticle_density = 1000  # Particle density in kg/m\u00b3\nfluid_density = 1.0  # Fluid (air) density in kg/m\u00b3\nair_velocity = 1e-9  # Relative velocity in m/s\n\nreynolds_lambda = 72.41  # Example value\n\n\n# Calculate dynamic and kinematic viscosity\ndynamic_viscosity = par.gas.get_dynamic_viscosity(temperature)\nkinematic_viscosity = par.gas.get_kinematic_viscosity(\n    dynamic_viscosity, fluid_density\n)\n\n# Calculate Particle Settling Velocity\nmean_free_path = par.gas.get_molecule_mean_free_path(\n    temperature=temperature, dynamic_viscosity=dynamic_viscosity\n)\n\n# 2. Slip correction factors\nknudsen_number = par.particles.get_knudsen_number(\n    mean_free_path=mean_free_path, particle_radius=particle_radius\n)\nslip_correction_factor = par.particles.get_cunningham_slip_correction(knudsen_number)\n# iterative terminal settling velocity\nparticle_settling_velocity = (\n    par.particles.get_particle_settling_velocity_with_drag(\n        particle_radius=particle_radius,\n        particle_density=particle_density,\n        fluid_density=fluid_density,\n        dynamic_viscosity=dynamic_viscosity,\n        slip_correction_factor=slip_correction_factor,\n    )\n)\n# Calculate Particle Inertia Time\nparticle_inertia_time = par.particles.get_particle_inertia_time(\n    particle_radius=particle_radius,\n    particle_density=particle_density,\n    fluid_density=fluid_density,\n    kinematic_viscosity=kinematic_viscosity,\n)\n\n\ndef calculate_horizontal_velocity(turbulent_dissipation, reynolds_lambda):\n    \"\"\"\n    Helper function to calculate the mean-square horizontal velocity of particles\n    for these specific cases.\n    \"\"\"\n    # Calculate Fluid RMS Velocity\n    fluid_rms_velocity = par.gas.get_fluid_rms_velocity(\n        re_lambda=reynolds_lambda,\n        kinematic_viscosity=kinematic_viscosity,\n        turbulent_dissipation=turbulent_dissipation,\n    )\n\n    # Calculate Turbulence Scales\n    taylor_microscale = par.gas.get_taylor_microscale(\n        fluid_rms_velocity=fluid_rms_velocity,\n        kinematic_viscosity=kinematic_viscosity,\n        turbulent_dissipation=turbulent_dissipation,\n    )\n    eulerian_integral_length = par.gas.get_eulerian_integral_length(\n        fluid_rms_velocity=fluid_rms_velocity,\n        turbulent_dissipation=turbulent_dissipation,\n    )\n    lagrangian_integral_time = par.gas.get_lagrangian_integral_time(\n        fluid_rms_velocity=fluid_rms_velocity,\n        turbulent_dissipation=turbulent_dissipation,\n    )\n    normalized_accel_variance = (\n        par.gas.get_normalized_accel_variance_ao2008(\n            re_lambda=reynolds_lambda\n        )\n    )\n    kolmogorov_time = par.gas.get_kolmogorov_time(\n        kinematic_viscosity=kinematic_viscosity,\n        turbulent_dissipation=turbulent_dissipation,\n    )\n    lagrangian_taylor_microscale_time = (\n        par.gas.get_lagrangian_taylor_microscale_time(\n            kolmogorov_time=kolmogorov_time,\n            re_lambda=reynolds_lambda,\n            accel_variance=normalized_accel_variance,\n        )\n    )\n\n    z = compute_z(lagrangian_taylor_microscale_time, lagrangian_integral_time)\n    beta = compute_beta(taylor_microscale, eulerian_integral_length)\n\n    # Calculate v'\u00b2 Values\n    vel_corr_terms = VelocityCorrelationTerms(\n        b1=compute_b1(z),\n        b2=compute_b2(z),\n        d1=compute_d1(beta),\n        d2=compute_d2(beta),\n        c1=compute_c1(z, lagrangian_integral_time),\n        c2=compute_c2(z, lagrangian_integral_time),\n        e1=compute_e1(z, eulerian_integral_length),\n        e2=compute_e2(z, eulerian_integral_length),\n    )\n\n    return _compute_rms_fluctuation_velocity(\n        fluid_rms_velocity,\n        particle_inertia_time,\n        particle_settling_velocity,\n        vel_corr_terms,\n    )\n</pre> # %% Model equations  # Define Particle Radii and Parameters particle_radius = np.linspace(10e-6, 60e-6, 6) temperature = 273  # Temperature in Kelvin particle_density = 1000  # Particle density in kg/m\u00b3 fluid_density = 1.0  # Fluid (air) density in kg/m\u00b3 air_velocity = 1e-9  # Relative velocity in m/s  reynolds_lambda = 72.41  # Example value   # Calculate dynamic and kinematic viscosity dynamic_viscosity = par.gas.get_dynamic_viscosity(temperature) kinematic_viscosity = par.gas.get_kinematic_viscosity(     dynamic_viscosity, fluid_density )  # Calculate Particle Settling Velocity mean_free_path = par.gas.get_molecule_mean_free_path(     temperature=temperature, dynamic_viscosity=dynamic_viscosity )  # 2. Slip correction factors knudsen_number = par.particles.get_knudsen_number(     mean_free_path=mean_free_path, particle_radius=particle_radius ) slip_correction_factor = par.particles.get_cunningham_slip_correction(knudsen_number) # iterative terminal settling velocity particle_settling_velocity = (     par.particles.get_particle_settling_velocity_with_drag(         particle_radius=particle_radius,         particle_density=particle_density,         fluid_density=fluid_density,         dynamic_viscosity=dynamic_viscosity,         slip_correction_factor=slip_correction_factor,     ) ) # Calculate Particle Inertia Time particle_inertia_time = par.particles.get_particle_inertia_time(     particle_radius=particle_radius,     particle_density=particle_density,     fluid_density=fluid_density,     kinematic_viscosity=kinematic_viscosity, )   def calculate_horizontal_velocity(turbulent_dissipation, reynolds_lambda):     \"\"\"     Helper function to calculate the mean-square horizontal velocity of particles     for these specific cases.     \"\"\"     # Calculate Fluid RMS Velocity     fluid_rms_velocity = par.gas.get_fluid_rms_velocity(         re_lambda=reynolds_lambda,         kinematic_viscosity=kinematic_viscosity,         turbulent_dissipation=turbulent_dissipation,     )      # Calculate Turbulence Scales     taylor_microscale = par.gas.get_taylor_microscale(         fluid_rms_velocity=fluid_rms_velocity,         kinematic_viscosity=kinematic_viscosity,         turbulent_dissipation=turbulent_dissipation,     )     eulerian_integral_length = par.gas.get_eulerian_integral_length(         fluid_rms_velocity=fluid_rms_velocity,         turbulent_dissipation=turbulent_dissipation,     )     lagrangian_integral_time = par.gas.get_lagrangian_integral_time(         fluid_rms_velocity=fluid_rms_velocity,         turbulent_dissipation=turbulent_dissipation,     )     normalized_accel_variance = (         par.gas.get_normalized_accel_variance_ao2008(             re_lambda=reynolds_lambda         )     )     kolmogorov_time = par.gas.get_kolmogorov_time(         kinematic_viscosity=kinematic_viscosity,         turbulent_dissipation=turbulent_dissipation,     )     lagrangian_taylor_microscale_time = (         par.gas.get_lagrangian_taylor_microscale_time(             kolmogorov_time=kolmogorov_time,             re_lambda=reynolds_lambda,             accel_variance=normalized_accel_variance,         )     )      z = compute_z(lagrangian_taylor_microscale_time, lagrangian_integral_time)     beta = compute_beta(taylor_microscale, eulerian_integral_length)      # Calculate v'\u00b2 Values     vel_corr_terms = VelocityCorrelationTerms(         b1=compute_b1(z),         b2=compute_b2(z),         d1=compute_d1(beta),         d2=compute_d2(beta),         c1=compute_c1(z, lagrangian_integral_time),         c2=compute_c2(z, lagrangian_integral_time),         e1=compute_e1(z, eulerian_integral_length),         e2=compute_e2(z, eulerian_integral_length),     )      return _compute_rms_fluctuation_velocity(         fluid_rms_velocity,         particle_inertia_time,         particle_settling_velocity,         vel_corr_terms,     ) In\u00a0[9]: Copied! <pre>model_rms_10cm2_s3 = calculate_horizontal_velocity(\n    turbulent_dissipation=10 * par.util.get_unit_conversion(\"cm^2/s^3\", \"m^2/s^3\"),\n    reynolds_lambda=reynolds_lambda,\n)\nmodel_rms_100cm2_s3 = calculate_horizontal_velocity(\n    turbulent_dissipation=100 * par.util.get_unit_conversion(\"cm^2/s^3\", \"m^2/s^3\"),\n    reynolds_lambda=reynolds_lambda,\n)\n\nmodel_rms_400cm2_s3 = calculate_horizontal_velocity(\n    turbulent_dissipation=400 * par.util.get_unit_conversion(\"cm^2/s^3\", \"m^2/s^3\"),\n    reynolds_lambda=reynolds_lambda,\n)\n</pre> model_rms_10cm2_s3 = calculate_horizontal_velocity(     turbulent_dissipation=10 * par.util.get_unit_conversion(\"cm^2/s^3\", \"m^2/s^3\"),     reynolds_lambda=reynolds_lambda, ) model_rms_100cm2_s3 = calculate_horizontal_velocity(     turbulent_dissipation=100 * par.util.get_unit_conversion(\"cm^2/s^3\", \"m^2/s^3\"),     reynolds_lambda=reynolds_lambda, )  model_rms_400cm2_s3 = calculate_horizontal_velocity(     turbulent_dissipation=400 * par.util.get_unit_conversion(\"cm^2/s^3\", \"m^2/s^3\"),     reynolds_lambda=reynolds_lambda, ) In\u00a0[10]: Copied! <pre>fig, ax = plt.subplots(figsize=(8, 6))\n\n# Case 1: R_lambda = 72.41, epsilon = 10 cm\u00b2/s\u00b3\nax.scatter(\n    dns_10cm2_s3[:, 0],\n    dns_10cm2_s3[:, 1],\n    label=r\"DNS: $R_\\lambda=72.41$, $\\varepsilon=10$\",\n    color=\"blue\",\n    marker=\"o\",\n)\nax.plot(\n    particle_radius * 1e6,\n    model_rms_10cm2_s3 * 1e4,\n    label=r\"Model: $R_\\lambda=72.41$, $\\varepsilon=10$\",\n    color=\"blue\",\n)\n\n# Case 2: R_lambda = 72.41, epsilon = 100 cm\u00b2/s\u00b3\nax.scatter(\n    dns_100_cm2_s3[:, 0],\n    dns_100_cm2_s3[:, 1],\n    label=r\"DNS: $R_\\lambda=72.41$, $\\varepsilon=100$\",\n    color=\"green\",\n    marker=\"^\",\n)\nax.plot(\n    particle_radius * 1e6,\n    model_rms_100cm2_s3 * 1e4,\n    label=r\"Model: $R_\\lambda=72.41$, $\\varepsilon=100$\",\n    color=\"green\",\n)\n\n# Case 3: R_lambda = 72.41, epsilon = 400 cm\u00b2/s\u00b3\nax.scatter(\n    dns_400_cm2_s3[:, 0],\n    dns_400_cm2_s3[:, 1],\n    label=r\"DNS: $R_\\lambda=72.41$, $\\varepsilon=400$\",\n    color=\"red\",\n    marker=\"s\",\n)\nax.plot(\n    particle_radius * 1e6,\n    model_rms_400cm2_s3 * 1e4,\n    label=r\"Model: $R_\\lambda=72.41$, $\\varepsilon=400$\",\n    color=\"red\",\n)\n\n# Set labels, title, legend, etc.\nax.set_xlabel(\"Particle Radius (\u00b5m)\")\nax.set_ylabel(r\"$&lt;(v'_x)^2&gt;$ (cm\u00b2/s\u00b2)\")\nax.set_ylim(0, 180)\nax.set_xlim(5, 65)\nax.set_title(\"Mean-Square Horizontal Velocity Comparison\")\nax.legend(loc=\"upper right\")\nax.grid(True)\nplt.subplots_adjust(bottom=0.2)\nplt.show()\n</pre> fig, ax = plt.subplots(figsize=(8, 6))  # Case 1: R_lambda = 72.41, epsilon = 10 cm\u00b2/s\u00b3 ax.scatter(     dns_10cm2_s3[:, 0],     dns_10cm2_s3[:, 1],     label=r\"DNS: $R_\\lambda=72.41$, $\\varepsilon=10$\",     color=\"blue\",     marker=\"o\", ) ax.plot(     particle_radius * 1e6,     model_rms_10cm2_s3 * 1e4,     label=r\"Model: $R_\\lambda=72.41$, $\\varepsilon=10$\",     color=\"blue\", )  # Case 2: R_lambda = 72.41, epsilon = 100 cm\u00b2/s\u00b3 ax.scatter(     dns_100_cm2_s3[:, 0],     dns_100_cm2_s3[:, 1],     label=r\"DNS: $R_\\lambda=72.41$, $\\varepsilon=100$\",     color=\"green\",     marker=\"^\", ) ax.plot(     particle_radius * 1e6,     model_rms_100cm2_s3 * 1e4,     label=r\"Model: $R_\\lambda=72.41$, $\\varepsilon=100$\",     color=\"green\", )  # Case 3: R_lambda = 72.41, epsilon = 400 cm\u00b2/s\u00b3 ax.scatter(     dns_400_cm2_s3[:, 0],     dns_400_cm2_s3[:, 1],     label=r\"DNS: $R_\\lambda=72.41$, $\\varepsilon=400$\",     color=\"red\",     marker=\"s\", ) ax.plot(     particle_radius * 1e6,     model_rms_400cm2_s3 * 1e4,     label=r\"Model: $R_\\lambda=72.41$, $\\varepsilon=400$\",     color=\"red\", )  # Set labels, title, legend, etc. ax.set_xlabel(\"Particle Radius (\u00b5m)\") ax.set_ylabel(r\"$&lt;(v'_x)^2&gt;$ (cm\u00b2/s\u00b2)\") ax.set_ylim(0, 180) ax.set_xlim(5, 65) ax.set_title(\"Mean-Square Horizontal Velocity Comparison\") ax.legend(loc=\"upper right\") ax.grid(True) plt.subplots_adjust(bottom=0.2) plt.show()"},{"location":"Theory/Technical/Dynamics/Cloud_Droplet_Coagulation/DNS_Horizontal_Velocity_Comparison/#horizontal-velocity-comparison","title":"Horizontal Velocity Comparison\u00b6","text":"<p>This notebook compares the mean-square horizontal velocities between DNS data and the model prediction.</p> <ul> <li>Data Loading</li> <li>Function Definitions for Reusable Calculations</li> <li>Plotting and Graph Comparisons</li> </ul> <p>In this notebook, we replicate and compare the collision kernels from the DNS data as presented in Figure 12 of the following reference:</p> <p>Reference: Ayala, O., Rosa, B., &amp; Wang, L. P. (2008). Effects of turbulence on the geometric collision rate of sedimenting droplets. Part 2. Theory and parameterization. New Journal of Physics, 10. https://doi.org/10.1088/1367-2630/10/7/075016</p>"},{"location":"Theory/Technical/Dynamics/Cloud_Droplet_Coagulation/DNS_Horizontal_Velocity_Comparison/#data-loading","title":"Data Loading\u00b6","text":"<p>This section loads the necessary DNS datasets and corresponding model predictions. Verify that the file paths and dataset formats are correct.</p>"},{"location":"Theory/Technical/Dynamics/Cloud_Droplet_Coagulation/DNS_Horizontal_Velocity_Comparison/#function-definitions","title":"Function Definitions\u00b6","text":"<p>The following functions perform repeated calculations and data manipulations:</p> <ul> <li>calculate_horizontal_velocity: Computes the mean-square horizontal velocity of particles.</li> </ul>"},{"location":"Theory/Technical/Dynamics/Cloud_Droplet_Coagulation/DNS_Horizontal_Velocity_Comparison/#running-the-code","title":"Running the Code\u00b6","text":"<p>Here we run the code for each configuration.</p>"},{"location":"Theory/Technical/Dynamics/Cloud_Droplet_Coagulation/DNS_Horizontal_Velocity_Comparison/#plotting-and-graph-comparisons","title":"Plotting and Graph Comparisons\u00b6","text":"<p>The graphs include:</p> <ul> <li>DNS Data: Raw experimental or simulation data.</li> <li>Model Predictions: Analytical or simulated forecasts.</li> </ul>"},{"location":"Theory/Technical/Dynamics/Cloud_Droplet_Coagulation/DNS_Horizontal_Velocity_Comparison/#summary","title":"Summary\u00b6","text":"<p>Overall we have a similar comparison as Ayala et al. (2008) for the horizontal velocity of particles in a turbulent flow. The model predictions align well with the DNS data, confirming the validity of the model.</p> <p>The curves are very sensitive to the temperature, and you can increase the temperature to move the curves up.</p>"},{"location":"Theory/Technical/Dynamics/Cloud_Droplet_Coagulation/DNS_Kernel_Comparison/","title":"DNS Kernel Comparison","text":"In\u00a0[\u00a0]: Copied! <pre># In Colab uncomment the following command to install particula:\n#!pip install particula[extra] --quiet\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport particula as par\n\nfrom particula.dynamics import (\n    get_turbulent_dns_kernel_ao2008,\n)\nfrom particula.dynamics.coagulation.turbulent_dns_kernel.radial_velocity_module import (\n    get_radial_relative_velocity_dz2002,\n)\nfrom particula.dynamics.coagulation.turbulent_dns_kernel.g12_radial_distribution_ao2008 import (\n    get_g12_radial_distribution_ao2008,\n)\nfrom particula.dynamics.coagulation.turbulent_dns_kernel.sigma_relative_velocity_ao2008 import (\n    get_relative_velocity_variance,\n)\nfrom particula.util import get_unit_conversion\nfrom particula.util.constants import STANDARD_GRAVITY\n\n# Case 1: Comparison of Collision Kernel\n\n# DNS dynamic collision kernel and predicted collision kernel of\n# sedimenting droplets in a turbulent \ufb02ow. (a) a1 = 30\u00b5m, R\u03bb = 72.41 and \ue00f =\n# 400 cm2 s\u22123\n\n# Dataset for kernel comparison\ndata = np.array(\n    [\n        [10.06067961, 0.000581818],\n        [14.97572816, 0.000654545],\n        [19.8907767, 0.000642424],\n        [25.1092233, 0.000581818],\n        [27.53640777, 0.000484848],\n        [29.96359223, 0.000315152],\n        [32.51213592, 0.000666667],\n        [40.03640777, 0.001963636],\n        [50.04854369, 0.004618182],\n        [60, 0.009127273],\n    ]\n)\n</pre> # In Colab uncomment the following command to install particula: #!pip install particula[extra] --quiet import numpy as np import matplotlib.pyplot as plt import particula as par  from particula.dynamics import (     get_turbulent_dns_kernel_ao2008, ) from particula.dynamics.coagulation.turbulent_dns_kernel.radial_velocity_module import (     get_radial_relative_velocity_dz2002, ) from particula.dynamics.coagulation.turbulent_dns_kernel.g12_radial_distribution_ao2008 import (     get_g12_radial_distribution_ao2008, ) from particula.dynamics.coagulation.turbulent_dns_kernel.sigma_relative_velocity_ao2008 import (     get_relative_velocity_variance, ) from particula.util import get_unit_conversion from particula.util.constants import STANDARD_GRAVITY  # Case 1: Comparison of Collision Kernel  # DNS dynamic collision kernel and predicted collision kernel of # sedimenting droplets in a turbulent \ufb02ow. (a) a1 = 30\u00b5m, R\u03bb = 72.41 and \ue00f = # 400 cm2 s\u22123  # Dataset for kernel comparison data = np.array(     [         [10.06067961, 0.000581818],         [14.97572816, 0.000654545],         [19.8907767, 0.000642424],         [25.1092233, 0.000581818],         [27.53640777, 0.000484848],         [29.96359223, 0.000315152],         [32.51213592, 0.000666667],         [40.03640777, 0.001963636],         [50.04854369, 0.004618182],         [60, 0.009127273],     ] ) In\u00a0[14]: Copied! <pre>particle_radius = np.linspace(1e-6, 60e-6, 200)  # From 1 \u00b5m to 60 \u00b5m\n\n# Convert turbulent dissipation from cm\u00b2/s\u00b3 to m\u00b2/s\u00b3\nturbulent_dissipation = 400 * get_unit_conversion(\"cm^2/s^3\", \"m^2/s^3\")\nreynolds_lambda = 72.41  # Example value\n</pre> particle_radius = np.linspace(1e-6, 60e-6, 200)  # From 1 \u00b5m to 60 \u00b5m  # Convert turbulent dissipation from cm\u00b2/s\u00b3 to m\u00b2/s\u00b3 turbulent_dissipation = 400 * get_unit_conversion(\"cm^2/s^3\", \"m^2/s^3\") reynolds_lambda = 72.41  # Example value In\u00a0[15]: Copied! <pre>def kernel_calc(particle_radius, turbulent_dissipation, reynolds_lambda):\n    # Define constants and parameters\n    temperature = 273  # Temperature in Kelvin\n    particle_density = 1000  # Particle density in kg/m\u00b3\n    fluid_density = 1.0  # Fluid (air) density in kg/m\u00b3\n\n    # 1. Basic fluid par.particles\n    dynamic_viscosity = par.gas.get_dynamic_viscosity(temperature)\n    kinematic_viscosity = par.gas.get_kinematic_viscosity(\n        dynamic_viscosity=dynamic_viscosity, fluid_density=fluid_density\n    )\n    mean_free_path = par.gas.get_molecule_mean_free_path(\n        temperature=temperature, dynamic_viscosity=dynamic_viscosity\n    )\n\n    # 2. Slip correction factors\n    knudsen_number = par.particles.get_knudsen_number(\n        mean_free_path=mean_free_path, particle_radius=particle_radius\n    )\n    slip_correction_factor = par.particles.get_cunningham_slip_correction(\n        knudsen_number\n    )\n\n    # Handle radius addition properly for arrays\n    collisional_radius = (\n        particle_radius[:, np.newaxis] + particle_radius[np.newaxis, :]\n        if isinstance(particle_radius, np.ndarray)\n        else 2.0 * particle_radius\n    )\n\n    # 3. Particle inertia and settling velocity\n    particle_inertia_time = par.particles.get_particle_inertia_time(\n        particle_radius=particle_radius,\n        particle_density=particle_density,\n        fluid_density=fluid_density,\n        kinematic_viscosity=kinematic_viscosity,\n    )\n    particle_settling_velocity = (\n        par.particles.get_particle_settling_velocity_with_drag(\n            particle_radius=particle_radius,\n            particle_density=particle_density,\n            fluid_density=fluid_density,\n            dynamic_viscosity=dynamic_viscosity,\n            slip_correction_factor=slip_correction_factor,\n            re_threshold=0.1,\n        )\n    )\n\n    # 4. Turbulence scales\n    fluid_rms_velocity = par.gas.get_fluid_rms_velocity(\n        re_lambda=reynolds_lambda,\n        kinematic_viscosity=kinematic_viscosity,\n        turbulent_dissipation=turbulent_dissipation,\n    )\n    taylor_microscale = par.gas.get_taylor_microscale(\n        fluid_rms_velocity=fluid_rms_velocity,\n        kinematic_viscosity=kinematic_viscosity,\n        turbulent_dissipation=turbulent_dissipation,\n    )\n    eulerian_integral_length = par.gas.get_eulerian_integral_length(\n        fluid_rms_velocity=fluid_rms_velocity,\n        turbulent_dissipation=turbulent_dissipation,\n    )\n    lagrangian_integral_time = par.gas.get_lagrangian_integral_time(\n        fluid_rms_velocity=fluid_rms_velocity,\n        turbulent_dissipation=turbulent_dissipation,\n    )\n\n    # 6. Additional turbulence-based quantities\n    kolmogorov_time = par.gas.get_kolmogorov_time(\n        kinematic_viscosity=kinematic_viscosity,\n        turbulent_dissipation=turbulent_dissipation,\n    )\n    stokes_number = par.particles.get_stokes_number(\n        particle_inertia_time=particle_inertia_time,\n        kolmogorov_time=kolmogorov_time,\n    )\n    kolmogorov_length_scale = par.gas.get_kolmogorov_length(\n        kinematic_viscosity=kinematic_viscosity,\n        turbulent_dissipation=turbulent_dissipation,\n    )\n    reynolds_lambda = par.particles.get_particle_reynolds_number(\n        particle_radius=particle_radius,\n        particle_velocity=particle_settling_velocity,\n        kinematic_viscosity=kinematic_viscosity,\n    )\n    normalized_accel_variance = (\n        par.gas.get_normalized_accel_variance_ao2008(\n            re_lambda=reynolds_lambda,\n        )\n    )\n    kolmogorov_velocity = par.gas.get_kolmogorov_velocity(\n        kinematic_viscosity=kinematic_viscosity,\n        turbulent_dissipation=turbulent_dissipation,\n    )\n    lagrangian_taylor_microscale_time = (\n        par.gas.get_lagrangian_taylor_microscale_time(\n            kolmogorov_time=kolmogorov_time,\n            re_lambda=reynolds_lambda,\n            accel_variance=normalized_accel_variance,\n        )\n    )\n\n    # 5. Relative velocity variance\n    velocity_dispersion = get_relative_velocity_variance(\n        fluid_rms_velocity=fluid_rms_velocity,\n        collisional_radius=collisional_radius,\n        particle_inertia_time=particle_inertia_time,\n        particle_velocity=np.abs(particle_settling_velocity),\n        taylor_microscale=taylor_microscale,\n        eulerian_integral_length=eulerian_integral_length,\n        lagrangian_integral_time=lagrangian_integral_time,\n        lagrangian_taylor_microscale_time=lagrangian_taylor_microscale_time,\n    )\n\n    # Compute Kernel Values\n    kernel_values = get_turbulent_dns_kernel_ao2008(\n        particle_radius=particle_radius,\n        velocity_dispersion=np.abs(velocity_dispersion),\n        particle_inertia_time=particle_inertia_time,\n        stokes_number=stokes_number,\n        kolmogorov_length_scale=kolmogorov_length_scale,\n        reynolds_lambda=reynolds_lambda,\n        normalized_accel_variance=normalized_accel_variance,\n        kolmogorov_velocity=kolmogorov_velocity,\n        kolmogorov_time=kolmogorov_time,\n    )\n\n    return kernel_values\n\n\n# Compute Kernel Values\nkernel_values = kernel_calc(\n    particle_radius, turbulent_dissipation, reynolds_lambda\n)\n</pre> def kernel_calc(particle_radius, turbulent_dissipation, reynolds_lambda):     # Define constants and parameters     temperature = 273  # Temperature in Kelvin     particle_density = 1000  # Particle density in kg/m\u00b3     fluid_density = 1.0  # Fluid (air) density in kg/m\u00b3      # 1. Basic fluid par.particles     dynamic_viscosity = par.gas.get_dynamic_viscosity(temperature)     kinematic_viscosity = par.gas.get_kinematic_viscosity(         dynamic_viscosity=dynamic_viscosity, fluid_density=fluid_density     )     mean_free_path = par.gas.get_molecule_mean_free_path(         temperature=temperature, dynamic_viscosity=dynamic_viscosity     )      # 2. Slip correction factors     knudsen_number = par.particles.get_knudsen_number(         mean_free_path=mean_free_path, particle_radius=particle_radius     )     slip_correction_factor = par.particles.get_cunningham_slip_correction(         knudsen_number     )      # Handle radius addition properly for arrays     collisional_radius = (         particle_radius[:, np.newaxis] + particle_radius[np.newaxis, :]         if isinstance(particle_radius, np.ndarray)         else 2.0 * particle_radius     )      # 3. Particle inertia and settling velocity     particle_inertia_time = par.particles.get_particle_inertia_time(         particle_radius=particle_radius,         particle_density=particle_density,         fluid_density=fluid_density,         kinematic_viscosity=kinematic_viscosity,     )     particle_settling_velocity = (         par.particles.get_particle_settling_velocity_with_drag(             particle_radius=particle_radius,             particle_density=particle_density,             fluid_density=fluid_density,             dynamic_viscosity=dynamic_viscosity,             slip_correction_factor=slip_correction_factor,             re_threshold=0.1,         )     )      # 4. Turbulence scales     fluid_rms_velocity = par.gas.get_fluid_rms_velocity(         re_lambda=reynolds_lambda,         kinematic_viscosity=kinematic_viscosity,         turbulent_dissipation=turbulent_dissipation,     )     taylor_microscale = par.gas.get_taylor_microscale(         fluid_rms_velocity=fluid_rms_velocity,         kinematic_viscosity=kinematic_viscosity,         turbulent_dissipation=turbulent_dissipation,     )     eulerian_integral_length = par.gas.get_eulerian_integral_length(         fluid_rms_velocity=fluid_rms_velocity,         turbulent_dissipation=turbulent_dissipation,     )     lagrangian_integral_time = par.gas.get_lagrangian_integral_time(         fluid_rms_velocity=fluid_rms_velocity,         turbulent_dissipation=turbulent_dissipation,     )      # 6. Additional turbulence-based quantities     kolmogorov_time = par.gas.get_kolmogorov_time(         kinematic_viscosity=kinematic_viscosity,         turbulent_dissipation=turbulent_dissipation,     )     stokes_number = par.particles.get_stokes_number(         particle_inertia_time=particle_inertia_time,         kolmogorov_time=kolmogorov_time,     )     kolmogorov_length_scale = par.gas.get_kolmogorov_length(         kinematic_viscosity=kinematic_viscosity,         turbulent_dissipation=turbulent_dissipation,     )     reynolds_lambda = par.particles.get_particle_reynolds_number(         particle_radius=particle_radius,         particle_velocity=particle_settling_velocity,         kinematic_viscosity=kinematic_viscosity,     )     normalized_accel_variance = (         par.gas.get_normalized_accel_variance_ao2008(             re_lambda=reynolds_lambda,         )     )     kolmogorov_velocity = par.gas.get_kolmogorov_velocity(         kinematic_viscosity=kinematic_viscosity,         turbulent_dissipation=turbulent_dissipation,     )     lagrangian_taylor_microscale_time = (         par.gas.get_lagrangian_taylor_microscale_time(             kolmogorov_time=kolmogorov_time,             re_lambda=reynolds_lambda,             accel_variance=normalized_accel_variance,         )     )      # 5. Relative velocity variance     velocity_dispersion = get_relative_velocity_variance(         fluid_rms_velocity=fluid_rms_velocity,         collisional_radius=collisional_radius,         particle_inertia_time=particle_inertia_time,         particle_velocity=np.abs(particle_settling_velocity),         taylor_microscale=taylor_microscale,         eulerian_integral_length=eulerian_integral_length,         lagrangian_integral_time=lagrangian_integral_time,         lagrangian_taylor_microscale_time=lagrangian_taylor_microscale_time,     )      # Compute Kernel Values     kernel_values = get_turbulent_dns_kernel_ao2008(         particle_radius=particle_radius,         velocity_dispersion=np.abs(velocity_dispersion),         particle_inertia_time=particle_inertia_time,         stokes_number=stokes_number,         kolmogorov_length_scale=kolmogorov_length_scale,         reynolds_lambda=reynolds_lambda,         normalized_accel_variance=normalized_accel_variance,         kolmogorov_velocity=kolmogorov_velocity,         kolmogorov_time=kolmogorov_time,     )      return kernel_values   # Compute Kernel Values kernel_values = kernel_calc(     particle_radius, turbulent_dissipation, reynolds_lambda ) In\u00a0[16]: Copied! <pre>kernel_via_system_state = par.dynamics.get_turbulent_dns_kernel_ao2008_via_system_state(\n    particle_radius=particle_radius,\n    particle_density=1000,\n    fluid_density=1.0,\n    temperature=273,\n    turbulent_dissipation=400 * get_unit_conversion(\"cm^2/s^3\", \"m^2/s^3\"),\n    re_lambda=72.41,\n    relative_velocity=0.0,\n)\n</pre> kernel_via_system_state = par.dynamics.get_turbulent_dns_kernel_ao2008_via_system_state(     particle_radius=particle_radius,     particle_density=1000,     fluid_density=1.0,     temperature=273,     turbulent_dissipation=400 * get_unit_conversion(\"cm^2/s^3\", \"m^2/s^3\"),     re_lambda=72.41,     relative_velocity=0.0, ) In\u00a0[17]: Copied! <pre>index = np.argmin(np.abs(particle_radius - 30e-6))\n\nfig, ax = plt.subplots(figsize=(5, 4))\n\nax.scatter(data[:, 0], data[:, 1], label=\"DNS Data\", color=\"blue\")\nax.plot(\n    particle_radius * 1e6,\n    kernel_values[:, index] * get_unit_conversion(\"m^3/s\", \"cm^3/s\"),\n    label=\"Kernel\",\n    color=\"orange\",\n    alpha=0.5,\n    linewidth=5,\n)\nax.plot(\n    particle_radius * 1e6,\n    kernel_via_system_state[:, index] * get_unit_conversion(\"m^3/s\", \"cm^3/s\"),\n    label=\"Kernel via System State\",\n    color=\"green\",\n    alpha=0.5,\n)\nax.set_xlabel(\"Particle Radius (\u00b5m)\")\nax.set_ylabel(\"Collision Kernel (cm\u00b3/s)\")\nplt.title(\"Collision Kernel Comparison\")\nax.legend()\nax.grid(True)\nplt.show()\n</pre> index = np.argmin(np.abs(particle_radius - 30e-6))  fig, ax = plt.subplots(figsize=(5, 4))  ax.scatter(data[:, 0], data[:, 1], label=\"DNS Data\", color=\"blue\") ax.plot(     particle_radius * 1e6,     kernel_values[:, index] * get_unit_conversion(\"m^3/s\", \"cm^3/s\"),     label=\"Kernel\",     color=\"orange\",     alpha=0.5,     linewidth=5, ) ax.plot(     particle_radius * 1e6,     kernel_via_system_state[:, index] * get_unit_conversion(\"m^3/s\", \"cm^3/s\"),     label=\"Kernel via System State\",     color=\"green\",     alpha=0.5, ) ax.set_xlabel(\"Particle Radius (\u00b5m)\") ax.set_ylabel(\"Collision Kernel (cm\u00b3/s)\") plt.title(\"Collision Kernel Comparison\") ax.legend() ax.grid(True) plt.show() In\u00a0[18]: Copied! <pre>dns_radii = data[:, 0] * 1e-6  # Convert from \u00b5m to meters\ndns_kernels = data[:, 1] * get_unit_conversion(\"cm^3/s\", \"m^3/s\")\n\n# Interpolate model predictions at DNS radii\nfrom scipy.interpolate import interp1d\n\ninterpolator = interp1d(\n    particle_radius,\n    kernel_values[:, np.argmin(np.abs(particle_radius - 30e-6))],\n    kind=\"linear\",\n    fill_value=\"extrapolate\",\n)\nmodel_kernels_at_dns = interpolator(dns_radii)\n\n# Calculate percent error\npercent_errors = (model_kernels_at_dns - dns_kernels) / dns_kernels * 100\n</pre> dns_radii = data[:, 0] * 1e-6  # Convert from \u00b5m to meters dns_kernels = data[:, 1] * get_unit_conversion(\"cm^3/s\", \"m^3/s\")  # Interpolate model predictions at DNS radii from scipy.interpolate import interp1d  interpolator = interp1d(     particle_radius,     kernel_values[:, np.argmin(np.abs(particle_radius - 30e-6))],     kind=\"linear\",     fill_value=\"extrapolate\", ) model_kernels_at_dns = interpolator(dns_radii)  # Calculate percent error percent_errors = (model_kernels_at_dns - dns_kernels) / dns_kernels * 100 In\u00a0[19]: Copied! <pre>import pandas as pd\n\nresults_df = pd.DataFrame(\n    {\n        \"Radius (\u00b5m)\": data[:, 0],\n        \"DNS Kernel (cm\u00b3/s)\": data[:, 1],\n        \"Model Kernel (cm\u00b3/s)\": model_kernels_at_dns\n        * get_unit_conversion(\"m^3/s\", \"cm^3/s\"),\n        \"Percent Error (%)\": percent_errors,\n    }\n)\n\ndisplay(results_df)\n</pre> import pandas as pd  results_df = pd.DataFrame(     {         \"Radius (\u00b5m)\": data[:, 0],         \"DNS Kernel (cm\u00b3/s)\": data[:, 1],         \"Model Kernel (cm\u00b3/s)\": model_kernels_at_dns         * get_unit_conversion(\"m^3/s\", \"cm^3/s\"),         \"Percent Error (%)\": percent_errors,     } )  display(results_df) Radius (\u00b5m) DNS Kernel (cm\u00b3/s) Model Kernel (cm\u00b3/s) Percent Error (%) 0 10.060680 0.000582 0.000515 -11.436263 1 14.975728 0.000655 0.000550 -16.026446 2 19.890777 0.000642 0.000505 -21.319316 3 25.109223 0.000582 0.000331 -43.042365 4 27.536408 0.000485 0.000192 -60.360381 5 29.963592 0.000315 0.000014 -95.676393 6 32.512136 0.000667 0.000241 -63.882460 7 40.036408 0.001964 0.001372 -30.128723 8 50.048544 0.004618 0.004102 -11.173559 9 60.000000 0.009127 0.008730 -4.348430"},{"location":"Theory/Technical/Dynamics/Cloud_Droplet_Coagulation/DNS_Kernel_Comparison/#dns-kernel-comparison","title":"DNS Kernel Comparison\u00b6","text":"<p>This notebook provides a comprehensive comparison between DNS (Direct Numerical Simulation) collision kernels and the model predictions using the <code>particula</code> package. It serves as an introduction for new users to understand how DNS data and coagulation kernels are utilized in atmospheric and aerosol science.</p>"},{"location":"Theory/Technical/Dynamics/Cloud_Droplet_Coagulation/DNS_Kernel_Comparison/#introduction-to-dns-and-coagulation-kernels","title":"Introduction to DNS and Coagulation Kernels\u00b6","text":"<p>Direct Numerical Simulation (DNS) is a computational method that solves the Navier-Stokes equations directly, without any turbulence models, to simulate turbulent flows with all scales of motion resolved. This allows for detailed investigation of particle interactions in turbulent flows, which is essential for understanding processes like coagulation.</p> <p>Coagulation Kernels quantify the rate at which particles collide and potentially coalesce in a medium, often influenced by factors like turbulence, Brownian motion, and external forces such as gravity. Understanding these kernels is crucial for predicting particle size distributions in aerosols, clouds, and other particulate systems.</p> <p>In this notebook, we replicate and compare the collision kernels from the DNS data as presented in Figure 18a of the following reference:</p> <p>Reference: Ayala, O., Rosa, B., &amp; Wang, L. P. (2008). Effects of turbulence on the geometric collision rate of sedimenting droplets. Part 2. Theory and parameterization. New Journal of Physics, 10. https://doi.org/10.1088/1367-2630/10/7/075016</p>"},{"location":"Theory/Technical/Dynamics/Cloud_Droplet_Coagulation/DNS_Kernel_Comparison/#define-particle-radii-and-physical-parameters","title":"Define Particle Radii and Physical Parameters\u00b6","text":"<p>In this section, we set up the range of particle radii and other essential physical parameters required for the collision kernel calculations.</p> <ul> <li>Particle Radii: We consider particles ranging from 1 \u00b5m to 60 \u00b5m in radius, which are typical sizes for cloud droplets.</li> <li>Turbulent Dissipation Rate (\u03b5): Represents the rate at which turbulent kinetic energy is converted into thermal energy. A higher \u03b5 indicates more vigorous turbulence, affecting particle collision rates.</li> <li>Reynolds Number (Re\u03bb): The Reynolds number based on the Taylor microscale, indicating the intensity of turbulence in the flow.</li> <li>Particle and Fluid Densities: Densities of the particles and the surrounding fluid (air) are necessary for calculating settling velocities and inertia times.</li> <li>Temperature: The ambient temperature affects fluid properties like viscosity and mean free path. These parameters are critical for simulating realistic atmospheric conditions and ensuring that the model predictions are comparable with DNS data.</li> </ul>"},{"location":"Theory/Technical/Dynamics/Cloud_Droplet_Coagulation/DNS_Kernel_Comparison/#define-the-kernel-calculation-function","title":"Define the Kernel Calculation Function\u00b6","text":"<p>This function calculates the collision kernel values using the specified parameters and the <code>particula</code> package implementations. This are the full steps of the function. Use this as a reference to understand how the kernels are calculated.</p>"},{"location":"Theory/Technical/Dynamics/Cloud_Droplet_Coagulation/DNS_Kernel_Comparison/#compute-kernel-via-system-state","title":"Compute Kernel via System State\u00b6","text":"<p>The previous method can be a bit much to put in code. We have implemented the same code above in a <code>get_kernel_ao2008_via_system_state</code> function. This function takes the system state directly and computes the kernel. This is a more direct way to compute the kernel, and hides the complexity of the previous method.</p>"},{"location":"Theory/Technical/Dynamics/Cloud_Droplet_Coagulation/DNS_Kernel_Comparison/#plot-the-comparison-graph","title":"Plot the Comparison Graph\u00b6","text":"<p>We plot the DNS data and their corresponding model predictions on the same graph for easy comparison.</p>"},{"location":"Theory/Technical/Dynamics/Cloud_Droplet_Coagulation/DNS_Kernel_Comparison/#calculate-percent-error","title":"Calculate Percent Error\u00b6","text":"<p>We calculate the percent error between the model predictions and the DNS data to assess the accuracy of our implementation. Extract DNS data</p>"},{"location":"Theory/Technical/Dynamics/Cloud_Droplet_Coagulation/DNS_Kernel_Comparison/#display-comparison-table","title":"Display Comparison Table\u00b6","text":"<p>We display the DNS data, model predictions, and percent errors in a table for comparison.</p>"},{"location":"Theory/Technical/Dynamics/Cloud_Droplet_Coagulation/DNS_Kernel_Comparison/#summary","title":"Summary\u00b6","text":"<p>This notebook compares DNS collision kernels with model predictions using the Ayala and Rosa (2008) model implemented in the <code>particula</code> package. It provides a detailed analysis of the collision kernels and their application in atmospheric and aerosol science. The comparison graph and table help visualize the differences between DNS data and model predictions, along with the corresponding percent errors. This serves as a useful guide for understanding and utilizing collision kernels in turbulent flows and particulate systems.</p>"},{"location":"Theory/Technical/Dynamics/Cloud_Droplet_Coagulation/DNS_Kernel_Comparison/#results","title":"Results\u00b6","text":"<ul> <li>The notebook computes and compares DNS collision kernels with model predictions.</li> <li>Percent error shows varying accuracy, But consistent with the accuracy reported in the original paper.</li> <li>Graph and table visualize differences between DNS data and model predictions.</li> </ul> <p>This notebook guides understanding and comparing DNS collision kernels and model predictions in atmospheric and aerosol science.</p>"},{"location":"Theory/Technical/Dynamics/Cloud_Droplet_Coagulation/DNS_Radial_Distribution_Comparison/","title":"Radial Distribution Function Comparison","text":"In\u00a0[6]: Copied! <pre>import numpy as np\nimport matplotlib.pyplot as plt\nimport particula as par\nfrom particula.dynamics.coagulation.turbulent_dns_kernel.g12_radial_distribution_ao2008 import (\n    get_g12_radial_distribution_ao2008,\n)\n\n\ndef g12_calc(particle_radius, turbulent_dissipation, reynolds_lambda):\n    # Define constants and parameters\n    temperature = 300  # Temperature in Kelvin\n    particle_density = 1000  # Particle density in kg/m\u00b3\n    fluid_density = 1.0  # Fluid (air) density in kg/m\u00b3\n\n    # Basic fluid par.particles\n    dynamic_viscosity = par.gas.get_dynamic_viscosity(temperature)\n    kinematic_viscosity = par.gas.get_kinematic_viscosity(\n        dynamic_viscosity=dynamic_viscosity, fluid_density=fluid_density\n    )\n\n    # Particle inertia and settling velocity\n    particle_inertia_time = par.particles.get_particle_inertia_time(\n        particle_radius=particle_radius,\n        particle_density=particle_density,\n        fluid_density=fluid_density,\n        kinematic_viscosity=kinematic_viscosity,\n    )\n\n    # Kolmogorov parameters\n    kolmogorov_time = par.gas.get_kolmogorov_time(\n        kinematic_viscosity=kinematic_viscosity,\n        turbulent_dissipation=turbulent_dissipation,\n    )\n    kolmogorov_length_scale = par.gas.get_kolmogorov_length(\n        kinematic_viscosity=kinematic_viscosity,\n        turbulent_dissipation=turbulent_dissipation,\n    )\n    normalized_accel_variance = (\n        par.gas.get_normalized_accel_variance_ao2008(\n            re_lambda=reynolds_lambda\n        )\n    )\n    kolmogorov_velocity = par.gas.get_kolmogorov_velocity(\n        kinematic_viscosity=kinematic_viscosity,\n        turbulent_dissipation=turbulent_dissipation,\n    )\n\n    stokes_number = par.particles.get_stokes_number(\n        particle_inertia_time=particle_inertia_time,\n        kolmogorov_time=kolmogorov_time,\n    )\n\n    # Compute g\u2081\u2082 Values\n    g12_values = get_g12_radial_distribution_ao2008(\n        particle_radius,\n        stokes_number,\n        kolmogorov_length_scale,\n        reynolds_lambda,\n        normalized_accel_variance,\n        kolmogorov_velocity,\n        kolmogorov_time,\n    )\n\n    return g12_values\n</pre> import numpy as np import matplotlib.pyplot as plt import particula as par from particula.dynamics.coagulation.turbulent_dns_kernel.g12_radial_distribution_ao2008 import (     get_g12_radial_distribution_ao2008, )   def g12_calc(particle_radius, turbulent_dissipation, reynolds_lambda):     # Define constants and parameters     temperature = 300  # Temperature in Kelvin     particle_density = 1000  # Particle density in kg/m\u00b3     fluid_density = 1.0  # Fluid (air) density in kg/m\u00b3      # Basic fluid par.particles     dynamic_viscosity = par.gas.get_dynamic_viscosity(temperature)     kinematic_viscosity = par.gas.get_kinematic_viscosity(         dynamic_viscosity=dynamic_viscosity, fluid_density=fluid_density     )      # Particle inertia and settling velocity     particle_inertia_time = par.particles.get_particle_inertia_time(         particle_radius=particle_radius,         particle_density=particle_density,         fluid_density=fluid_density,         kinematic_viscosity=kinematic_viscosity,     )      # Kolmogorov parameters     kolmogorov_time = par.gas.get_kolmogorov_time(         kinematic_viscosity=kinematic_viscosity,         turbulent_dissipation=turbulent_dissipation,     )     kolmogorov_length_scale = par.gas.get_kolmogorov_length(         kinematic_viscosity=kinematic_viscosity,         turbulent_dissipation=turbulent_dissipation,     )     normalized_accel_variance = (         par.gas.get_normalized_accel_variance_ao2008(             re_lambda=reynolds_lambda         )     )     kolmogorov_velocity = par.gas.get_kolmogorov_velocity(         kinematic_viscosity=kinematic_viscosity,         turbulent_dissipation=turbulent_dissipation,     )      stokes_number = par.particles.get_stokes_number(         particle_inertia_time=particle_inertia_time,         kolmogorov_time=kolmogorov_time,     )      # Compute g\u2081\u2082 Values     g12_values = get_g12_radial_distribution_ao2008(         particle_radius,         stokes_number,         kolmogorov_length_scale,         reynolds_lambda,         normalized_accel_variance,         kolmogorov_velocity,         kolmogorov_time,     )      return g12_values In\u00a0[7]: Copied! <pre># Case R_lambda = 23, turbulent_dissipation = 100 cm2/s3\nr23_e100 = np.array(\n    [\n        [9.937578027, 1.532846715],\n        [19.98751561, 1.094890511],\n        [29.91260924, 2.299270073],\n        [40.02496879, 3.686131387],\n        [49.95006242, 2.919708029],\n        [60, 2.737226277],\n    ]\n)\n\n\n# case: R_lambda = 23, turbulent_dissipation = 400 cm2 s\u22123\n# r23_e400: 6 rows, 2 columns (X, Y)\nr23_e400 = np.array(\n    [\n        [10.18726592, 1.094890511],\n        [20.17478152, 3.248175182],\n        [30.09987516, 8.175182482],\n        [40.14981273, 8.686131387],\n        [50.13732834, 7.226277372],\n        [60.24968789, 5.620437956],\n    ]\n)\n\n# case: R_lambda = 72.4, turbulent_dissipation = 100 cm2 s\u22123\n# r72.4_e100: 6 rows, 2 columns (X, Y)\nr72_4_e100 = np.array(\n    [\n        [10.12484395, 1.204379562],\n        [19.92509363, 1.788321168],\n        [29.97503121, 3.211678832],\n        [40.08739076, 7.919708029],\n        [50.01248439, 10.76642336],\n        [59.93757803, 9.525547445],\n    ]\n)\n\n# case: R_lambda = 72.4, turbulent_dissipation = 400 cm2 s\u22123\n# r72.4_e400: 6 rows, 2 columns (X, Y)\nr72_4_e400 = np.array(\n    [\n        [10, 0.875912409],\n        [20.11235955, 5.145985401],\n        [30.03745318, 16.82481752],\n        [40.08739076, 15.72992701],\n        [50.01248439, 14.48905109],\n        [60, 13.72262774],\n    ]\n)\n</pre> # Case R_lambda = 23, turbulent_dissipation = 100 cm2/s3 r23_e100 = np.array(     [         [9.937578027, 1.532846715],         [19.98751561, 1.094890511],         [29.91260924, 2.299270073],         [40.02496879, 3.686131387],         [49.95006242, 2.919708029],         [60, 2.737226277],     ] )   # case: R_lambda = 23, turbulent_dissipation = 400 cm2 s\u22123 # r23_e400: 6 rows, 2 columns (X, Y) r23_e400 = np.array(     [         [10.18726592, 1.094890511],         [20.17478152, 3.248175182],         [30.09987516, 8.175182482],         [40.14981273, 8.686131387],         [50.13732834, 7.226277372],         [60.24968789, 5.620437956],     ] )  # case: R_lambda = 72.4, turbulent_dissipation = 100 cm2 s\u22123 # r72.4_e100: 6 rows, 2 columns (X, Y) r72_4_e100 = np.array(     [         [10.12484395, 1.204379562],         [19.92509363, 1.788321168],         [29.97503121, 3.211678832],         [40.08739076, 7.919708029],         [50.01248439, 10.76642336],         [59.93757803, 9.525547445],     ] )  # case: R_lambda = 72.4, turbulent_dissipation = 400 cm2 s\u22123 # r72.4_e400: 6 rows, 2 columns (X, Y) r72_4_e400 = np.array(     [         [10, 0.875912409],         [20.11235955, 5.145985401],         [30.03745318, 16.82481752],         [40.08739076, 15.72992701],         [50.01248439, 14.48905109],         [60, 13.72262774],     ] ) In\u00a0[8]: Copied! <pre>particle_radius = np.linspace(1e-6, 60e-6, 100)  # From 1 \u00b5m to 60 \u00b5m\n\n# Convert turbulent dissipation from cm\u00b2/s\u00b3 to m\u00b2/s\u00b3\nturbulent_dissipation_100 = 100 * par.util.get_unit_conversion(\"cm^2/s^3\", \"m^2/s^3\")\nturbulent_dissipation_400 = 400 * par.util.get_unit_conversion(\"cm^2/s^3\", \"m^2/s^3\")\n</pre> particle_radius = np.linspace(1e-6, 60e-6, 100)  # From 1 \u00b5m to 60 \u00b5m  # Convert turbulent dissipation from cm\u00b2/s\u00b3 to m\u00b2/s\u00b3 turbulent_dissipation_100 = 100 * par.util.get_unit_conversion(\"cm^2/s^3\", \"m^2/s^3\") turbulent_dissipation_400 = 400 * par.util.get_unit_conversion(\"cm^2/s^3\", \"m^2/s^3\") In\u00a0[9]: Copied! <pre>g12_values_re23_e100 = g12_calc(\n    particle_radius, turbulent_dissipation_100, reynolds_lambda=23\n)\ng12_values_re23_e400 = g12_calc(\n    particle_radius, turbulent_dissipation_400, reynolds_lambda=23\n)\ng12_values_re72_4_e100 = g12_calc(\n    particle_radius, turbulent_dissipation_100, reynolds_lambda=72.4\n)\ng12_values_re72_4_e400 = g12_calc(\n    particle_radius, turbulent_dissipation_400, reynolds_lambda=72.4\n)\n</pre> g12_values_re23_e100 = g12_calc(     particle_radius, turbulent_dissipation_100, reynolds_lambda=23 ) g12_values_re23_e400 = g12_calc(     particle_radius, turbulent_dissipation_400, reynolds_lambda=23 ) g12_values_re72_4_e100 = g12_calc(     particle_radius, turbulent_dissipation_100, reynolds_lambda=72.4 ) g12_values_re72_4_e400 = g12_calc(     particle_radius, turbulent_dissipation_400, reynolds_lambda=72.4 ) In\u00a0[10]: Copied! <pre>fig, ax = plt.subplots(figsize=(6, 6))\n\n# case 1: R_lambda = 23, epsilon = 100\nax.scatter(\n    r23_e100[:, 0],\n    r23_e100[:, 1],\n    label=r\"DNS: $R_\\lambda=23$, $\\varepsilon=100$\",\n    color=\"blue\",\n    marker=\"o\",\n)\nax.plot(\n    particle_radius * 1e6,\n    np.diagonal(g12_values_re23_e100),\n    label=r\"Model: $R_\\lambda=23$, $\\varepsilon=100$\",\n    color=\"blue\",\n)\n\n# Case 2: R_lambda = 23, epsilon = 400\nax.scatter(\n    r23_e400[:, 0],\n    r23_e400[:, 1],\n    label=r\"DNS: $R_\\lambda=23$, $\\varepsilon=400$\",\n    color=\"green\",\n    marker=\"^\",\n)\nax.plot(\n    particle_radius * 1e6,\n    np.diagonal(g12_values_re23_e400),\n    label=r\"Model: $R_\\lambda=23$, $\\varepsilon=400$\",\n    color=\"green\",\n)\n\n# Case 3: R_lambda = 72.4, epsilon = 100\nax.scatter(\n    r72_4_e100[:, 0],\n    r72_4_e100[:, 1],\n    label=r\"DNS: $R_\\lambda=72.4$, $\\varepsilon=100$\",\n    color=\"red\",\n    marker=\"s\",\n)\nax.plot(\n    particle_radius * 1e6,\n    np.diagonal(g12_values_re72_4_e100),\n    label=r\"Model: $R_\\lambda=72.4$, $\\varepsilon=100$\",\n    color=\"red\",\n)\n\n# Case 4: R_lambda = 72.4, epsilon = 400\nax.scatter(\n    r72_4_e400[:, 0],\n    r72_4_e400[:, 1],\n    label=r\"DNS: $R_\\lambda=72.4$, $\\varepsilon=400$\",\n    color=\"purple\",\n    marker=\"d\",\n)\nax.plot(\n    particle_radius * 1e6,\n    np.diagonal(g12_values_re72_4_e400),\n    label=r\"Model: $R_\\lambda=72.4$, $\\varepsilon=400$\",\n    color=\"purple\",\n)\n\n# Set labels, title, legend, etc.\nax.set_xlabel(\"Particle Radius (\u00b5m)\")\nax.set_ylabel(\"Radial Distribution Function $g_{12}$\")\nax.set_title(\"Radial Distribution Function Comparison\")\nax.legend(loc=\"upper left\")\nax.grid(True)\nax.set_ylim(0, 40)\nplt.show()\n</pre> fig, ax = plt.subplots(figsize=(6, 6))  # case 1: R_lambda = 23, epsilon = 100 ax.scatter(     r23_e100[:, 0],     r23_e100[:, 1],     label=r\"DNS: $R_\\lambda=23$, $\\varepsilon=100$\",     color=\"blue\",     marker=\"o\", ) ax.plot(     particle_radius * 1e6,     np.diagonal(g12_values_re23_e100),     label=r\"Model: $R_\\lambda=23$, $\\varepsilon=100$\",     color=\"blue\", )  # Case 2: R_lambda = 23, epsilon = 400 ax.scatter(     r23_e400[:, 0],     r23_e400[:, 1],     label=r\"DNS: $R_\\lambda=23$, $\\varepsilon=400$\",     color=\"green\",     marker=\"^\", ) ax.plot(     particle_radius * 1e6,     np.diagonal(g12_values_re23_e400),     label=r\"Model: $R_\\lambda=23$, $\\varepsilon=400$\",     color=\"green\", )  # Case 3: R_lambda = 72.4, epsilon = 100 ax.scatter(     r72_4_e100[:, 0],     r72_4_e100[:, 1],     label=r\"DNS: $R_\\lambda=72.4$, $\\varepsilon=100$\",     color=\"red\",     marker=\"s\", ) ax.plot(     particle_radius * 1e6,     np.diagonal(g12_values_re72_4_e100),     label=r\"Model: $R_\\lambda=72.4$, $\\varepsilon=100$\",     color=\"red\", )  # Case 4: R_lambda = 72.4, epsilon = 400 ax.scatter(     r72_4_e400[:, 0],     r72_4_e400[:, 1],     label=r\"DNS: $R_\\lambda=72.4$, $\\varepsilon=400$\",     color=\"purple\",     marker=\"d\", ) ax.plot(     particle_radius * 1e6,     np.diagonal(g12_values_re72_4_e400),     label=r\"Model: $R_\\lambda=72.4$, $\\varepsilon=400$\",     color=\"purple\", )  # Set labels, title, legend, etc. ax.set_xlabel(\"Particle Radius (\u00b5m)\") ax.set_ylabel(\"Radial Distribution Function $g_{12}$\") ax.set_title(\"Radial Distribution Function Comparison\") ax.legend(loc=\"upper left\") ax.grid(True) ax.set_ylim(0, 40) plt.show()"},{"location":"Theory/Technical/Dynamics/Cloud_Droplet_Coagulation/DNS_Radial_Distribution_Comparison/#radial-distribution-function-comparison","title":"Radial Distribution Function Comparison\u00b6","text":"<p>This script compares the radial distribution function g\u2081\u2082 between DNS data and the model predictions from Ayala et al. (2008) for a range of particle radii. It uses the function <code>get_g12_radial_distribution_ao2008</code> from the <code>particula</code> library to compute g\u2081\u2082 values over a range of particle radii. The script then plots these computed values against the DNS datasets for visual comparison.</p> <p>Reference: Figure 16 in Ayala et al. (2008).</p> <p>Ayala, O., Rosa, B., &amp; Wang, L. P. (2008). Effects of turbulence on the geometric collision rate of sedimenting droplets. Part 2. Theory and parameterization. New Journal of Physics, 10. https://doi.org/10.1088/1367-2630/10/7/07501</p> <p>Usage:</p> <ul> <li>Run this script to generate and display the comparison graph.</li> </ul>"},{"location":"Theory/Technical/Dynamics/Cloud_Droplet_Coagulation/DNS_Radial_Distribution_Comparison/#dns-datasets","title":"DNS Datasets\u00b6","text":"<p>We have the following DNS datasets for the radial distribution function g\u2081\u2082:</p> <ul> <li>Case 1: R_\u03bb = 23, \u03b5 = 100 cm\u00b2/s\u00b3</li> <li>Case 2: R_\u03bb = 23, \u03b5 = 400 cm\u00b2/s\u00b3</li> <li>Case 3: R_\u03bb = 72.4, \u03b5 = 100 cm\u00b2/s\u00b3</li> <li>Case 4: R_\u03bb = 72.4, \u03b5 = 400 cm\u00b2/s\u00b3</li> </ul> <p>DNS datasets for radial distribution function are from Ayala et al. (2008).</p>"},{"location":"Theory/Technical/Dynamics/Cloud_Droplet_Coagulation/DNS_Radial_Distribution_Comparison/#define-particle-radii-and-parameters","title":"Define Particle Radii and Parameters\u00b6","text":"<p>We define the particle radii range and other necessary parameters for the calculations.</p> <ul> <li>Particle Radii: Ranging from 1 \u00b5m to 60 \u00b5m.</li> <li>Turbulent Dissipation Rates: 100 cm\u00b2/s\u00b3 and 400 cm\u00b2/s\u00b3 converted to m\u00b2/s\u00b3.</li> <li>Reynolds Lambda Numbers: 23 and 72.4.</li> </ul>"},{"location":"Theory/Technical/Dynamics/Cloud_Droplet_Coagulation/DNS_Radial_Distribution_Comparison/#compute-g12-values-for-each-case","title":"Compute g\u2081\u2082 Values for Each Case\u00b6","text":"<p>Using the <code>g12_calc</code> function, we compute the radial distribution function for each case:</p> <ul> <li>Case 1: R_\u03bb = 23, \u03b5 = 100 cm\u00b2/s\u00b3</li> <li>Case 2: R_\u03bb = 23, \u03b5 = 400 cm\u00b2/s\u00b3</li> <li>Case 3: R_\u03bb = 72.4, \u03b5 = 100 cm\u00b2/s\u00b3</li> <li>Case 4: R_\u03bb = 72.4, \u03b5 = 400 cm\u00b2/s\u00b3</li> </ul>"},{"location":"Theory/Technical/Dynamics/Cloud_Droplet_Coagulation/DNS_Radial_Distribution_Comparison/#plot-the-comparison-graph","title":"Plot the Comparison Graph\u00b6","text":"<p>We plot the DNS data and their corresponding model predictions on the same graph for easy comparison.</p> <ul> <li>Each DNS dataset and its model prediction are plotted sequentially with the same color.</li> <li>The legend entries follow the order of DNS data and model prediction for each case.</li> </ul>"},{"location":"Theory/Technical/Dynamics/Cloud_Droplet_Coagulation/DNS_Radial_Distribution_Comparison/#summary","title":"Summary\u00b6","text":"<p>Overall the comparison is good, and the curves are visually similar to Figure 16 in Ayala et al. (2008).</p>"},{"location":"Theory/Technical/Dynamics/Cloud_Droplet_Coagulation/DNS_Radial_Relative_Velocity_Comparison/","title":"Radial Relative Velocity Comparison","text":"In\u00a0[6]: Copied! <pre>import numpy as np\nimport matplotlib.pyplot as plt\nimport particula as par\n\nfrom particula.dynamics.coagulation.turbulent_dns_kernel.radial_velocity_module import (\n    get_radial_relative_velocity_dz2002,\n)\nfrom particula.dynamics.coagulation.turbulent_dns_kernel.sigma_relative_velocity_ao2008 import (\n    get_relative_velocity_variance,\n)\n\n# data from AO2008 Fig. 13\ndata = np.array(\n    [\n        [10.06195787, 5.602409639],\n        [15.01858736, 5.13253012],\n        [19.97521685, 3.506024096],\n        [25.11771995, 2.096385542],\n        [27.53407683, 1.265060241],\n        [30.01239157, 0.108433735],\n        [32.49070632, 1.518072289],\n        [40.04956629, 5.746987952],\n        [49.96282528, 11.85542169],\n        [60, 19.37349398],\n    ]\n)\n</pre> import numpy as np import matplotlib.pyplot as plt import particula as par  from particula.dynamics.coagulation.turbulent_dns_kernel.radial_velocity_module import (     get_radial_relative_velocity_dz2002, ) from particula.dynamics.coagulation.turbulent_dns_kernel.sigma_relative_velocity_ao2008 import (     get_relative_velocity_variance, )  # data from AO2008 Fig. 13 data = np.array(     [         [10.06195787, 5.602409639],         [15.01858736, 5.13253012],         [19.97521685, 3.506024096],         [25.11771995, 2.096385542],         [27.53407683, 1.265060241],         [30.01239157, 0.108433735],         [32.49070632, 1.518072289],         [40.04956629, 5.746987952],         [49.96282528, 11.85542169],         [60, 19.37349398],     ] ) In\u00a0[7]: Copied! <pre>particle_radius = np.linspace(10e-6, 60e-6, 50)\ntemperature = 273  # Temperature in Kelvin\nparticle_density = 1000  # Particle density in kg/m\u00b3\nfluid_density = 1.0  # Fluid (air) density in kg/m\u00b3\n\n# Convert turbulent dissipation rate from cm\u00b2/s\u00b3 to m\u00b2/s\u00b3\nturbulent_dissipation = 400 * par.util.get_unit_conversion(\"cm^2/s^3\", \"m^2/s^3\")\nreynolds_lambda = 72.41  # Example value\n\n\ndynamic_viscosity = par.gas.get_dynamic_viscosity(temperature)\nkinematic_viscosity = par.gas.get_kinematic_viscosity(\n    dynamic_viscosity, fluid_density\n)\nkolmogorov_time = par.gas.get_kolmogorov_time(\n    kinematic_viscosity=kinematic_viscosity,\n    turbulent_dissipation=turbulent_dissipation,\n)\n</pre> particle_radius = np.linspace(10e-6, 60e-6, 50) temperature = 273  # Temperature in Kelvin particle_density = 1000  # Particle density in kg/m\u00b3 fluid_density = 1.0  # Fluid (air) density in kg/m\u00b3  # Convert turbulent dissipation rate from cm\u00b2/s\u00b3 to m\u00b2/s\u00b3 turbulent_dissipation = 400 * par.util.get_unit_conversion(\"cm^2/s^3\", \"m^2/s^3\") reynolds_lambda = 72.41  # Example value   dynamic_viscosity = par.gas.get_dynamic_viscosity(temperature) kinematic_viscosity = par.gas.get_kinematic_viscosity(     dynamic_viscosity, fluid_density ) kolmogorov_time = par.gas.get_kolmogorov_time(     kinematic_viscosity=kinematic_viscosity,     turbulent_dissipation=turbulent_dissipation, ) In\u00a0[8]: Copied! <pre>particle_inertia_time = par.particles.get_particle_inertia_time(\n    particle_radius=particle_radius,\n    particle_density=particle_density,\n    fluid_density=fluid_density,\n    kinematic_viscosity=kinematic_viscosity,\n)\n\nmean_free_path = par.gas.get_molecule_mean_free_path(\n    temperature=temperature, dynamic_viscosity=dynamic_viscosity\n)\n# 2. Slip correction factors\nknudsen_number = par.particles.get_knudsen_number(\n    mean_free_path=mean_free_path, particle_radius=particle_radius\n)\nslip_correction_factor = par.particles.get_cunningham_slip_correction(knudsen_number)\nparticle_settling_velocity = (\n    par.particles.get_particle_settling_velocity_with_drag(\n        particle_radius=particle_radius,\n        particle_density=particle_density,\n        fluid_density=fluid_density,\n        dynamic_viscosity=dynamic_viscosity,\n        slip_correction_factor=slip_correction_factor,\n        re_threshold=0.1,\n    )\n)\n</pre> particle_inertia_time = par.particles.get_particle_inertia_time(     particle_radius=particle_radius,     particle_density=particle_density,     fluid_density=fluid_density,     kinematic_viscosity=kinematic_viscosity, )  mean_free_path = par.gas.get_molecule_mean_free_path(     temperature=temperature, dynamic_viscosity=dynamic_viscosity ) # 2. Slip correction factors knudsen_number = par.particles.get_knudsen_number(     mean_free_path=mean_free_path, particle_radius=particle_radius ) slip_correction_factor = par.particles.get_cunningham_slip_correction(knudsen_number) particle_settling_velocity = (     par.particles.get_particle_settling_velocity_with_drag(         particle_radius=particle_radius,         particle_density=particle_density,         fluid_density=fluid_density,         dynamic_viscosity=dynamic_viscosity,         slip_correction_factor=slip_correction_factor,         re_threshold=0.1,     ) ) In\u00a0[9]: Copied! <pre>fluid_rms_velocity = par.gas.get_fluid_rms_velocity(\n    re_lambda=reynolds_lambda,\n    kinematic_viscosity=kinematic_viscosity,\n    turbulent_dissipation=turbulent_dissipation,\n)\n\ntaylor_microscale = par.gas.get_taylor_microscale(\n    fluid_rms_velocity=fluid_rms_velocity,\n    kinematic_viscosity=kinematic_viscosity,\n    turbulent_dissipation=turbulent_dissipation,\n)\neulerian_integral_length = par.gas.get_eulerian_integral_length(\n    fluid_rms_velocity=fluid_rms_velocity,\n    turbulent_dissipation=turbulent_dissipation,\n)\nlagrangian_integral_time = par.gas.get_lagrangian_integral_time(\n    fluid_rms_velocity=fluid_rms_velocity,\n    turbulent_dissipation=turbulent_dissipation,\n)\nnormalized_accel_variance = (\n    par.gas.get_normalized_accel_variance_ao2008(\n        re_lambda=reynolds_lambda\n    )\n)\nlagrangian_taylor_microscale_time = (\n    par.gas.get_lagrangian_taylor_microscale_time(\n        kolmogorov_time=kolmogorov_time,\n        re_lambda=reynolds_lambda,\n        accel_variance=normalized_accel_variance,\n    )\n)\n</pre> fluid_rms_velocity = par.gas.get_fluid_rms_velocity(     re_lambda=reynolds_lambda,     kinematic_viscosity=kinematic_viscosity,     turbulent_dissipation=turbulent_dissipation, )  taylor_microscale = par.gas.get_taylor_microscale(     fluid_rms_velocity=fluid_rms_velocity,     kinematic_viscosity=kinematic_viscosity,     turbulent_dissipation=turbulent_dissipation, ) eulerian_integral_length = par.gas.get_eulerian_integral_length(     fluid_rms_velocity=fluid_rms_velocity,     turbulent_dissipation=turbulent_dissipation, ) lagrangian_integral_time = par.gas.get_lagrangian_integral_time(     fluid_rms_velocity=fluid_rms_velocity,     turbulent_dissipation=turbulent_dissipation, ) normalized_accel_variance = (     par.gas.get_normalized_accel_variance_ao2008(         re_lambda=reynolds_lambda     ) ) lagrangian_taylor_microscale_time = (     par.gas.get_lagrangian_taylor_microscale_time(         kolmogorov_time=kolmogorov_time,         re_lambda=reynolds_lambda,         accel_variance=normalized_accel_variance,     ) ) In\u00a0[10]: Copied! <pre>collisional_radius = (\n    particle_radius[:, np.newaxis] + particle_radius[np.newaxis, :]\n)\n\nvelocity_dispersion = get_relative_velocity_variance(\n    fluid_rms_velocity=fluid_rms_velocity,\n    collisional_radius=collisional_radius,\n    particle_inertia_time=particle_inertia_time,\n    particle_velocity=particle_settling_velocity,\n    taylor_microscale=taylor_microscale,\n    eulerian_integral_length=eulerian_integral_length,\n    lagrangian_integral_time=lagrangian_integral_time,\n    lagrangian_taylor_microscale_time=lagrangian_taylor_microscale_time,\n)\n\nfig, ax = plt.subplots(figsize=(5, 5))\ngraph = ax.contourf(velocity_dispersion, cmap=\"viridis\", origin=\"lower\")\nax.set_xlabel(\"Particle Radius\")\nax.set_ylabel(\"Particle Radius\")\nax.set_title(\"Velocity Dispersion\")\nplt.colorbar(graph)\nplt.show()\n</pre> collisional_radius = (     particle_radius[:, np.newaxis] + particle_radius[np.newaxis, :] )  velocity_dispersion = get_relative_velocity_variance(     fluid_rms_velocity=fluid_rms_velocity,     collisional_radius=collisional_radius,     particle_inertia_time=particle_inertia_time,     particle_velocity=particle_settling_velocity,     taylor_microscale=taylor_microscale,     eulerian_integral_length=eulerian_integral_length,     lagrangian_integral_time=lagrangian_integral_time,     lagrangian_taylor_microscale_time=lagrangian_taylor_microscale_time, )  fig, ax = plt.subplots(figsize=(5, 5)) graph = ax.contourf(velocity_dispersion, cmap=\"viridis\", origin=\"lower\") ax.set_xlabel(\"Particle Radius\") ax.set_ylabel(\"Particle Radius\") ax.set_title(\"Velocity Dispersion\") plt.colorbar(graph) plt.show() In\u00a0[11]: Copied! <pre>def radial_velocity_calc(velocity_dispersion, particle_inertia_time):\n    # Check if velocity_dispersion contains NaN\n    if np.isnan(velocity_dispersion).any():\n        print(\"Warning: velocity_dispersion contains NaN\")\n\n    # Compute Radial Relative Velocities\n    radial_relative_velocity = get_radial_relative_velocity_dz2002(\n        velocity_dispersion,\n        particle_inertia_time,\n    )\n\n    return radial_relative_velocity\n</pre> def radial_velocity_calc(velocity_dispersion, particle_inertia_time):     # Check if velocity_dispersion contains NaN     if np.isnan(velocity_dispersion).any():         print(\"Warning: velocity_dispersion contains NaN\")      # Compute Radial Relative Velocities     radial_relative_velocity = get_radial_relative_velocity_dz2002(         velocity_dispersion,         particle_inertia_time,     )      return radial_relative_velocity In\u00a0[12]: Copied! <pre>radial_relative_velocity = radial_velocity_calc(\n    np.abs(velocity_dispersion), particle_inertia_time\n)\n</pre> radial_relative_velocity = radial_velocity_calc(     np.abs(velocity_dispersion), particle_inertia_time ) In\u00a0[13]: Copied! <pre>index = np.argmin(np.abs(particle_radius - 30e-6))\nfig, ax = plt.subplots(figsize=(5, 5))\n# Plot the average radial relative velocity over all particle pairs\nax.plot(\n    particle_radius * 1e6,\n    radial_relative_velocity * 100,\n    label=\"Model Prediction\",\n    color=\"brown\",\n    alpha=0.2,\n)\nax.plot(\n    particle_radius * 1e6,\n    radial_relative_velocity[:, index] * 100,\n    label=\"Model Prediction at 30 \u00b5m\",\n    color=\"blue\",\n    linestyle=\"--\",\n)\nax.scatter(data[:, 0], data[:, 1], label=\"DNS Data\", color=\"purple\")\nax.set_xlabel(\"Particle Radius (\u00b5m)\")\nax.set_ylabel(\"Radial Relative Velocity (cm/s)\")\nax.set_title(\"Radial Relative Velocity Comparison\")\nax.grid(True)\nplt.show()\n\nfig, ax = plt.subplots(figsize=(5, 5))\ngraph = ax.contourf(radial_relative_velocity, cmap=\"viridis\", origin=\"lower\")\nax.set_xlabel(\"Particle Radius (\u00b5m)\")\nax.set_ylabel(\"Particle Radius (\u00b5m)\")\nax.set_title(\"Radial Relative Velocity\")\nplt.colorbar(graph)\nplt.show()\n</pre> index = np.argmin(np.abs(particle_radius - 30e-6)) fig, ax = plt.subplots(figsize=(5, 5)) # Plot the average radial relative velocity over all particle pairs ax.plot(     particle_radius * 1e6,     radial_relative_velocity * 100,     label=\"Model Prediction\",     color=\"brown\",     alpha=0.2, ) ax.plot(     particle_radius * 1e6,     radial_relative_velocity[:, index] * 100,     label=\"Model Prediction at 30 \u00b5m\",     color=\"blue\",     linestyle=\"--\", ) ax.scatter(data[:, 0], data[:, 1], label=\"DNS Data\", color=\"purple\") ax.set_xlabel(\"Particle Radius (\u00b5m)\") ax.set_ylabel(\"Radial Relative Velocity (cm/s)\") ax.set_title(\"Radial Relative Velocity Comparison\") ax.grid(True) plt.show()  fig, ax = plt.subplots(figsize=(5, 5)) graph = ax.contourf(radial_relative_velocity, cmap=\"viridis\", origin=\"lower\") ax.set_xlabel(\"Particle Radius (\u00b5m)\") ax.set_ylabel(\"Particle Radius (\u00b5m)\") ax.set_title(\"Radial Relative Velocity\") plt.colorbar(graph) plt.show()"},{"location":"Theory/Technical/Dynamics/Cloud_Droplet_Coagulation/DNS_Radial_Relative_Velocity_Comparison/#radial-relative-velocity-comparison","title":"Radial Relative Velocity Comparison\u00b6","text":"<p>This notebook provides a comparison between DNS (Direct Numerical Simulation) radial relative velocities and the model predictions from the particula library.</p> <p>In this notebook, we replicate and compare the collision kernels from the DNS data as presented in Figure 13 of the following reference:</p> <p>Reference: Ayala, O., Rosa, B., &amp; Wang, L. P. (2008). Effects of turbulence on the geometric collision rate of sedimenting droplets. Part 2. Theory and parameterization. New Journal of Physics, 10. https://doi.org/10.1088/1367-2630/10/7/075016</p>"},{"location":"Theory/Technical/Dynamics/Cloud_Droplet_Coagulation/DNS_Radial_Relative_Velocity_Comparison/#parameter-definition-and-viscosity-calculation","title":"Parameter Definition and Viscosity Calculation\u00b6","text":"<p>Define the particle radii and other parameters such as temperature, particle density, and fluid density. These parameters are essential for calculating various par.particles and velocities. Calculate the dynamic and kinematic viscosity of the fluid, as well as turbulence par.particles like Kolmogorov time. These are used in subsequent calculations of particle par.particles.</p>"},{"location":"Theory/Technical/Dynamics/Cloud_Droplet_Coagulation/DNS_Radial_Relative_Velocity_Comparison/#particle-inertia-and-settling-velocity","title":"Particle Inertia and Settling Velocity\u00b6","text":"<p>Calculate the particle inertia time, which is a measure of how quickly particles respond to changes in the surrounding fluid flow. Also, calculate the settling velocity of particles using the drag model, which involves calculating the mean free path, Knudsen number, and slip correction factor.</p>"},{"location":"Theory/Technical/Dynamics/Cloud_Droplet_Coagulation/DNS_Radial_Relative_Velocity_Comparison/#turbulence-and-velocity-calculations","title":"Turbulence and Velocity Calculations\u00b6","text":"<p>Calculate the root mean square (RMS) velocity of the fluid, which is used to determine the intensity of turbulence in the fluid. Additionally, calculate various turbulence scales such as the Taylor microscale, Eulerian integral length, and Lagrangian integral time. These scales are important for understanding the turbulence characteristics.</p>"},{"location":"Theory/Technical/Dynamics/Cloud_Droplet_Coagulation/DNS_Radial_Relative_Velocity_Comparison/#collision-and-velocity-dispersion","title":"Collision and Velocity Dispersion\u00b6","text":"<p>Calculate the collisional radius, which is the sum of the radii of two colliding particles. This is used in the calculation of collision rates and velocities. Also, calculate the velocity dispersion, which is a measure of the spread of particle velocities. This is used to compute the radial relative velocities.</p>"},{"location":"Theory/Technical/Dynamics/Cloud_Droplet_Coagulation/DNS_Radial_Relative_Velocity_Comparison/#radial-relative-velocities-and-plotting","title":"Radial Relative Velocities and Plotting\u00b6","text":"<p>Define a function to compute the radial relative velocities using the velocity dispersion and particle inertia time. This function includes a check for NaN values in the velocity dispersion. Plot the radial relative velocities for different particle radii, including both the model predictions and the DNS data for comparison. Additionally, create an image plot of the radial relative velocity using a contour plot to provide a visual representation of the velocity field.</p>"},{"location":"Theory/Technical/Dynamics/Cloud_Droplet_Coagulation/DNS_Radial_Relative_Velocity_Comparison/#summary","title":"Summary\u00b6","text":"<p>This notebook provides a comparison of the radial relative velocities between DNS data and model predictions.</p> <p>There are non-realistic jumps in the <code>particula</code> library predictions, which are not present in the DNS data. These are due to errors in the calculation of the settling velocity, which should be improved in future versions of the library.</p>"},{"location":"Theory/Technical/Dynamics/Cloud_Droplet_Coagulation/Droplet_Coagulation_Kernel_Ayala2008/","title":"Droplet Coagulation Kernel Ayala 2008","text":"<p>Here, we discuss the implementation of the geometric collision kernel for cloud droplets as described in Part II by Ayala et al. (2008). Part I provides a detailed explanation of the direct numerical simulations. Where as Part II is the parameterization of the collision kernel for cloud droplets in turbulent flows. The implementation involves calculating the geometric collision rate of sedimenting droplets based on the turbulent flow properties and droplet characteristics.</p> <p>Ayala, O., Rosa, B., Wang, L. P., &amp; Grabowski, W. W. (2008). Effects of turbulence on the geometric collision rate of sedimenting droplets. Part 1. Results from direct numerical simulation. New Journal of Physics, 10. https://doi.org/10.1088/1367-2630/10/7/075015</p> <p>Ayala, O., Rosa, B., &amp; Wang, L. P. (2008). Effects of turbulence on the geometric collision rate of sedimenting droplets. Part 2. Theory and parameterization. New Journal of Physics, 10. https://doi.org/10.1088/1367-2630/10/7/075016</p>"},{"location":"Theory/Technical/Dynamics/Cloud_Droplet_Coagulation/Droplet_Coagulation_Kernel_Ayala2008/#12-kernel-description","title":"\u0393\u2081\u2082: Kernel Description","text":"<p>In the parameterization below, the input parameters are:</p> <ul> <li>The radii a\u2081 and a\u2082 of the droplets</li> <li>The water density \u03c1_w</li> <li>Turbulent air flow requires:<ul> <li>The density \u03c1</li> <li>The viscosity \u03bd</li> <li>The turbulence dissipation rate \u03b5</li> <li>The Taylor-microscale Reynolds number R_\u03bb</li> </ul> </li> <li>The gravitational acceleration |g|</li> </ul> <p>The output is the collision kernel \u0393\u2081\u2082</p> <p>This is valid under the conditions when a_k \u226a \u03b7, \u03c1_w \u226b \u03c1, and Sv &gt; 1, the geometric collision kernel can be calculated as follows:</p> <p>\u0393\u2081\u2082 = 2\u03c0R\u00b2 \u27e8|w\u1d63|\u27e9 g\u2081\u2082</p>"},{"location":"Theory/Technical/Dynamics/Cloud_Droplet_Coagulation/Droplet_Coagulation_Kernel_Ayala2008/#wr-radial-relative-velocity","title":"\u27e8|w\u1d63|\u27e9: Radial Relative Velocity","text":"<p>There are two options for calculating the radial relative velocity:</p>"},{"location":"Theory/Technical/Dynamics/Cloud_Droplet_Coagulation/Droplet_Coagulation_Kernel_Ayala2008/#wr-dodin-2002","title":"\u27e8|w\u1d63|\u27e9 Dodin 2002:","text":"<p>Using the spherical formulation, Dodin and Elperin (2002), decomposed the relative velocity into turbulent and gravity-induced components and assumed that the turbulent component is normally distributed.</p> <p>Dodin Z and Elperin T 2002 Phys. Fluids 14 2921\u201324</p> <p>\u27e8|w\u1d63|\u27e9 = \u221a(2\u2044\u03c0)\u202f\u03c3\u202ff(b)</p> <p>where:</p> <p>f(b) = (\u00bd)\u221a\u03c0\u202f(b + 0.5\u2044b)\u202ferf(b) + (\u00bd)\u202fexp(\u2212b\u00b2)</p> <p>b = [g\u202f|\u03c4\u209a\u2081 \u2212 \u03c4\u209a\u2082|]\u2044[\u221a2\u202f\u03c3]</p>"},{"location":"Theory/Technical/Dynamics/Cloud_Droplet_Coagulation/Droplet_Coagulation_Kernel_Ayala2008/#wr-ayala-2008","title":"\u27e8|w\u1d63|\u27e9 Ayala 2008:","text":"<p>Here both particle inertia and gravitational effects are accounted for in the relative velocity calculation. Derived by Ayala et al. (2008) based on DNS results.</p> <p>\u27e8|w\u1d63|\u27e9 = \u221a(2\u2044\u03c0)\u202f\u221a[\u03c3\u00b2 + (\u03c0\u20448)(\u03c4\u209a\u2081 + \u03c4\u209a\u2082)\u00b2\u202f|g|\u00b2]</p>"},{"location":"Theory/Technical/Dynamics/Cloud_Droplet_Coagulation/Droplet_Coagulation_Kernel_Ayala2008/#2-direct-numerical-simulation-fit","title":"\u03c3\u00b2: Direct Numerical Simulation Fit","text":"<p>\u03c3\u00b2 = \u27e8(v\u2032^(2))\u00b2\u27e9 + \u27e8(v\u2032^(1))\u00b2\u27e9 \u2212 2\u202f\u27e8v\u2032^(1)\u202fv\u2032^(2)\u27e9</p> <p>The term \u27e8(v\u2032^(2))\u00b2\u27e9 is the square of the RMS fluctuation velocity of droplet 2, and \u27e8v\u2032^(1) v\u2032^(2)\u27e9 is the cross-correlation of the fluctuating velocities of droplets 1 and 2.</p> <p>The square of the RMS fluctuation velocity is given by, for k-th droplet:</p> <p>\u27e8(v\u2032^(k))\u00b2\u27e9 = [u\u2032\u00b2\u202f\u2044\u202f\u03c4\u209a\u2096]\u202f\u00d7\u202f[b\u2081 d\u2081\u202f\u03a8(c\u2081,\u202fe\u2081) \u2212 b\u2081 d\u2082\u202f\u03a8(c\u2081,\u202fe\u2082) \u2212 b\u2082 d\u2081\u202f\u03a8(c\u2082,\u202fe\u2081) + b\u2082 d\u2082\u202f\u03a8(c\u2082,\u202fe\u2082)],</p> <p>Cross term is defined as:</p> <p>\u27e8v\u2032^(1)\u202fv\u2032^(2)\u27e9 = [u\u2032\u00b2\u202ff\u2082(R)]\u2044[\u03c4\u209a\u2081\u202f\u03c4\u209a\u2082]\u202f\u00d7\u202f[b\u2081 d\u2081\u202f\u03a6(c\u2081,\u202fe\u2081) \u2212 b\u2081 d\u2082\u202f\u03a6(c\u2081,\u202fe\u2082) \u2212 b\u2082 d\u2081\u202f\u03a6(c\u2082,\u202fe\u2081) + b\u2082 d\u2082\u202f\u03a6(c\u2082,\u202fe\u2082)].</p>"},{"location":"Theory/Technical/Dynamics/Cloud_Droplet_Coagulation/Droplet_Coagulation_Kernel_Ayala2008/#f2r-longitudinal-velocity-correlation","title":"f\u2082(R): Longitudinal velocity correlation","text":"<p>f\u2082(R) = [1\u202f\u2044\u202f2\u221a(1 \u2212 2\u03b2\u00b2)] { \u2003[1 + \u221a(1 \u2212 2\u03b2\u00b2)] \u2003e^[-2R\u2044((1 + \u221a(1 \u2212 2\u03b2\u00b2))\u202fL\u2091)] \u2003\u2212 [1 \u2212 \u221a(1 \u2212 2\u03b2\u00b2)] \u2003e^[-2R\u2044((1 \u2212 \u221a(1 \u2212 2\u03b2\u00b2))\u202fL\u2091)] }</p>"},{"location":"Theory/Technical/Dynamics/Cloud_Droplet_Coagulation/Droplet_Coagulation_Kernel_Ayala2008/#b1-b2-c1-c2-d1-d2-e1-e2-definitions","title":"b\u2081, b\u2082, c\u2081, c\u2082, d\u2081, d\u2082, e\u2081, e\u2082: Definitions","text":"<p>b\u2081 = (1 + \u221a(1 \u2212 2z\u00b2)) / (2\u221a(1 \u2212 2z\u00b2))</p> <p>b\u2082 = (1 \u2212 \u221a(1 \u2212 2z\u00b2)) / (2\u221a(1 \u2212 2z\u00b2))</p> <p>c\u2081 = ((1 + \u221a(1 \u2212 2z\u00b2))T_L) / 2</p> <p>c\u2082 = ((1 \u2212 \u221a(1 \u2212 2z\u00b2))T_L) / 2</p> <p>d\u2081 = (1 + \u221a(1 \u2212 2\u03b2\u00b2)) / (2\u221a(1 \u2212 2\u03b2\u00b2))</p> <p>d\u2082 = (1 \u2212 \u221a(1 \u2212 2\u03b2\u00b2)) / (2\u221a(1 \u2212 2\u03b2\u00b2))</p> <p>e\u2081 = ((1 + \u221a(1 \u2212 2\u03b2\u00b2))L_e) / 2</p> <p>e\u2082 = ((1 \u2212 \u221a(1 \u2212 2\u03b2\u00b2))L_e) / 2</p>"},{"location":"Theory/Technical/Dynamics/Cloud_Droplet_Coagulation/Droplet_Coagulation_Kernel_Ayala2008/#z-and-definitions","title":"z and \u03b2: Definitions","text":"<p>z = \u03c4_T \u2044 T_L</p> <p>\u03b2 = (\u221a2\u202f\u03bb) \u2044 L_e</p>"},{"location":"Theory/Technical/Dynamics/Cloud_Droplet_Coagulation/Droplet_Coagulation_Kernel_Ayala2008/#definitions","title":"\u03a6(\u03b1, \u03c6): Definitions","text":"<p>For the case when taking v\u209a\u2081 &gt; v\u209a\u2082.</p> <p>\u03a6(\u03b1, \u03c6) = term_1 + term_2 + term_3</p> <p>term_1 = {  \u20031 / ( (v\u209a2/\u03c6) \u2212 (1/\u03c4\u209a2) \u2212 (1/\u03b1) ) \u2212  \u20031 / ( (v\u209a1/\u03c6) + (1/\u03c4\u209a1) + (1/\u03b1) )  } \u00d7 [ (v\u209a1 \u2212 v\u209a2) / (2\u03c6 ((v\u209a1 \u2212 (v\u209a2/\u03c6)) + (1/\u03c4\u209a1) + (1/\u03c4\u209a2))\u00b2 ) ]</p> <p>term_2 = {  \u20034 / [ ( (v\u209a2/\u03c6) + (1/\u03c4\u209a2) + (1/\u03b1) )\u00b2 \u2212 ( (v\u209a2/\u03c6) \u2212 (1/\u03c4\u209a2) \u2212 (1/\u03b1) )\u00b2 ]  } \u00d7 [ (v\u209a2) / (2\u03c6 ((1/\u03c4\u209a1) \u2212 (1/\u03b1) + ((1/\u03c4\u209a2) + (1/\u03b1))(v\u209a1/v\u209a2)) ) ]</p> <p>term_3 = {  \u20032\u03c6 / ( (v\u209a1/\u03c6) + (1/\u03c4\u209a1) + (1/\u03b1) ) \u2212  \u20032\u03c6 / ( (v\u209a2/\u03c6) \u2212 (1/\u03c4\u209a2) \u2212 (1/\u03b1) )  } \u00d7 [ 1 / (2\u03c6 ((v\u209a1 \u2212 (v\u209a2/\u03c6)) + (1/\u03c4\u209a1) + (1/\u03c4\u209a2)) ) ]</p>"},{"location":"Theory/Technical/Dynamics/Cloud_Droplet_Coagulation/Droplet_Coagulation_Kernel_Ayala2008/#definitions_1","title":"\u03a8(\u03b1, \u03c6): Definitions","text":"<p>For the case when taking for the k-th droplet:</p> <p>\u03a8(\u03b1, \u03c6) = 1 / ( (1/\u03c4\u209a\u2096) + (1/\u03b1) + (v\u209a\u2096/\u03c6) ) \u2212  \u2003(v\u209a\u2096) / (2\u03c6 ((1/\u03c4\u209a\u2096) + (1/\u03b1) + (v\u209a\u2096/\u03c6))\u00b2)</p>"},{"location":"Theory/Technical/Dynamics/Cloud_Droplet_Coagulation/Droplet_Coagulation_Kernel_Ayala2008/#g12-radial-distribution-function","title":"g\u2081\u2082: Radial Distribution Function","text":"<p>The radial distribution function is given by:</p> <p>g\u2081\u2082 = ( (\u03b7\u00b2 + r_c\u00b2) / (R\u00b2 + r_c\u00b2) )^(C\u2081/2)</p> <p>Where C\u2081 and r_c are derived based on droplet and turbulence properties.</p>"},{"location":"Theory/Technical/Dynamics/Cloud_Droplet_Coagulation/Droplet_Coagulation_Kernel_Ayala2008/#c1-calculation","title":"C\u2081: Calculation","text":"<p>C\u2081 = y(St)\u202f\u2044\u202f[|g|\u202f\u2044\u202f(v_k\u202f\u2044\u202f\u03c4_k)]^(f\u2083(R_\u03bb))</p> <p>y(St) = -0.1988 St^4 + 1.5275 St^3 - 4.2942 St^2 + 5.3406 St</p> <p>f\u2083(R_\u03bb) = 0.1886 exp(20.306 / R_\u03bb)</p> <p>Where:</p> <p>St = max(St\u2081, St\u2082)</p> <p>Since the fitting for y(St) was done for a limited range of St in DNS, it should be set to zero for large St when the function y(St) becomes negative.</p>"},{"location":"Theory/Technical/Dynamics/Cloud_Droplet_Coagulation/Droplet_Coagulation_Kernel_Ayala2008/#r_c-expression","title":"r_c: Expression","text":"<p>(r_c / \u03b7)\u00b2 = |St\u2082 - St\u2081| F(a\u2092, R_\u03bb)</p> <p>solving for r_c:</p> <p>r_c = \u03b7 \u221a(|St\u2082 - St\u2081| F(a\u2092, R_\u03bb))</p> <p>where:</p> <p>a\u2092 = a\u2092 + (\u03c0 / 8) (|g| / (v_k / \u03c4_k))\u00b2</p> <p>F(a\u2092, R_\u03bb) = 20.115 (a\u2092 / R_\u03bb)^(\u00bd)</p>"},{"location":"Theory/Technical/Dynamics/Cloud_Droplet_Coagulation/Droplet_Coagulation_Kernel_Ayala2008/#derived-parameters","title":"Derived Parameters","text":""},{"location":"Theory/Technical/Dynamics/Cloud_Droplet_Coagulation/Droplet_Coagulation_Kernel_Ayala2008/#_k-kolmogorov-time","title":"\u03c4_k: Kolmogorov Time","text":"<p>The smallest timescale in turbulence where viscous forces dominate:</p> <p>\u03c4_k = \u221a(\u03bd\u2044\u03b5)</p>"},{"location":"Theory/Technical/Dynamics/Cloud_Droplet_Coagulation/Droplet_Coagulation_Kernel_Ayala2008/#kolmogorov-length-scale","title":"\u03b7: Kolmogorov Length Scale","text":"<p>The smallest scale in turbulence:</p> <p>\u03b7 = [\u03bd\u00b3\u2044\u03b5]^(\u00bc)</p>"},{"location":"Theory/Technical/Dynamics/Cloud_Droplet_Coagulation/Droplet_Coagulation_Kernel_Ayala2008/#v_k-kolmogorov-velocity-scale","title":"v_k: Kolmogorov Velocity Scale","text":"<p>A velocity scale related to the smallest turbulent eddies:</p> <p>v_k = [\u03bd\u202f\u03b5]^(\u00bc)</p>"},{"location":"Theory/Technical/Dynamics/Cloud_Droplet_Coagulation/Droplet_Coagulation_Kernel_Ayala2008/#u-fluid-rms-fluctuation-velocity","title":"u\u2032: Fluid RMS Fluctuation Velocity","text":"<p>Quantifies turbulence intensity:</p> <p>u\u2032 = [R_\u03bb^(\u00bd)\u202fv_k]\u2044[15^(\u00bc)]</p>"},{"location":"Theory/Technical/Dynamics/Cloud_Droplet_Coagulation/Droplet_Coagulation_Kernel_Ayala2008/#t_l-lagrangian-integral-scale","title":"T_L: Lagrangian Integral Scale","text":"<p>Describes large-scale turbulence:</p> <p>T_L = u'\u00b2 / \u03b5</p>"},{"location":"Theory/Technical/Dynamics/Cloud_Droplet_Coagulation/Droplet_Coagulation_Kernel_Ayala2008/#le-eulerian-integral-scale","title":"L\u2091: Eulerian Integral Scale","text":"<p>Length scale for large eddies:</p> <p>L\u2091 = 0.5 u'\u00b3 / \u03b5</p>"},{"location":"Theory/Technical/Dynamics/Cloud_Droplet_Coagulation/Droplet_Coagulation_Kernel_Ayala2008/#ao-coefficient","title":"a\u2092: Coefficient","text":"<p>A Reynolds-dependent parameter:</p> <p>a\u2092 = [11 + 7\u202fR_\u03bb]\u202f\u2044\u202f[205 + R_\u03bb]</p>"},{"location":"Theory/Technical/Dynamics/Cloud_Droplet_Coagulation/Droplet_Coagulation_Kernel_Ayala2008/#_t-lagrangian-taylor-microscale-time","title":"\u03c4_T: Lagrangian Taylor Microscale Time","text":"<p>Time correlation decay for turbulent trajectories:</p> <p>\u03c4_T = \u03c4_k\u202f\u221a[2\u202fR_\u03bb\u202f\u2044\u202f(15^(\u00bd)\u202fa\u2092)]</p>"},{"location":"Theory/Technical/Dynamics/Cloud_Droplet_Coagulation/Droplet_Coagulation_Kernel_Ayala2008/#taylor-microscale","title":"\u03bb: Taylor Microscale","text":"<p>Length scale linked to fluid flow:</p> <p>\u03bb = u'\u202f\u221a[15\u202f\u03bd\u00b2\u202f\u2044\u202f\u03b5]</p>"},{"location":"Theory/Technical/Dynamics/Cloud_Droplet_Coagulation/Droplet_Coagulation_Kernel_Ayala2008/#_p-droplet-inertia-time","title":"\u03c4_p: Droplet Inertia Time","text":"<p>Adjusts droplet inertia:</p> <p>\u03c4_p = [2\u20449]\u202f\u00d7[\u03c1_w\u2044\u03c1]\u00d7[a\u00b2\u2044(\u03bd\u202ff(Re_p))]</p> <p>with:</p> <p>f(Re_p) = 1 + 0.15\u202fRe_p^(0.687)</p>"},{"location":"Theory/Technical/Dynamics/Cloud_Droplet_Coagulation/Droplet_Coagulation_Kernel_Ayala2008/#v_p-droplet-settling-velocity","title":"v_p: Droplet Settling Velocity","text":"<p>The settling velocity under gravity:</p> <p>v_p = \u03c4_p\u202f|g|</p>"},{"location":"Theory/Technical/Dynamics/Cloud_Droplet_Coagulation/Droplet_Coagulation_Kernel_Ayala2008/#re_p-particle-reynolds-number","title":"Re_p: Particle Reynolds Number","text":"<p>Characterizes droplet flow:</p> <p>Re_p = 2 a v_p / \u03bd</p>"},{"location":"Theory/Technical/Dynamics/Cloud_Droplet_Coagulation/Droplet_Coagulation_Kernel_Ayala2008/#st-stokes-number","title":"St: Stokes Number","text":"<p>Non-dimensional inertia parameter:</p> <p>St = \u03c4_p\u2044\u03c4_k</p>"},{"location":"Theory/Technical/Dynamics/Cloud_Droplet_Coagulation/Droplet_Coagulation_Kernel_Ayala2008/#variable-descriptions","title":"Variable Descriptions","text":"<p>Here are the variables, their definitions.</p>"},{"location":"Theory/Technical/Dynamics/Cloud_Droplet_Coagulation/Droplet_Coagulation_Kernel_Ayala2008/#droplet-particle-properties","title":"Droplet (Particle) Properties","text":"<ul> <li> <p>a\u2081, a\u2082: Radii of the droplets. These determine size-dependent properties such as droplet inertia and terminal velocity. </p> </li> <li> <p>\u03c1_w: Density of water. The mass per unit volume of water, typically 1000\u202fkg/m\u00b3. It is essential for calculating droplet inertia and terminal velocity.</p> </li> <li> <p>\u03c1: Density of air. The mass per unit volume of air, affecting drag and settling velocity. Typical sea-level values are around 1.225\u202fkg/m\u00b3.</p> </li> <li> <p>\u03bd: Kinematic viscosity. The ratio of dynamic viscosity to fluid density, quantifying resistance to flow.</p> </li> <li> <p>\u03c4_p: Droplet inertial response time. The characteristic time it takes for a droplet to adjust to changes in the surrounding airflow, critical for droplet motion analysis.</p> </li> <li> <p>v\u2032^{(i)}_p: Particle RMS fluctuation velocity. The root mean square of the fluctuating velocity component, representing variability in turbulent flow.</p> </li> <li> <p>f_u: Particle response coefficient. Measures how particles respond to fluid velocity fluctuations, helping quantify their turbulent motion.</p> </li> <li> <p>f(R): Spatial correlation coefficient. Describes the correlation of fluid velocities at two points separated by a distance R, influencing droplet interactions.</p> </li> <li> <p>g\u2081\u2082: Radial distribution function (RDF). A measure of how particle pairs are spatially distributed due to turbulence and gravity.</p> </li> </ul>"},{"location":"Theory/Technical/Dynamics/Cloud_Droplet_Coagulation/Droplet_Coagulation_Kernel_Ayala2008/#turbulent-flow-properties","title":"Turbulent Flow Properties","text":"<ul> <li> <p>Y\u1da0(t): Fluid Lagrangian trajectory. The path traced by a fluid particle as it moves through turbulence.</p> </li> <li> <p>\u03b5: Turbulence dissipation rate. The rate at which turbulent kinetic energy is converted into thermal energy per unit mass.</p> </li> <li> <p>R_\u03bb: Reynolds number. A dimensionless number that characterizes the flow regime, depending on turbulence intensity and scale.</p> </li> <li> <p>\u03bb_D: Longitudinal Taylor-type microscale. A characteristic length scale of fluid acceleration in turbulence, related to energy dissipation and viscosity.</p> </li> <li> <p>T_L: Lagrangian integral scale. The timescale over which fluid particles maintain velocity correlations, describing large-scale turbulence behavior.</p> </li> <li> <p>u\u2032: Fluid RMS fluctuation velocity. The root mean square of fluid velocity fluctuations, characterizing turbulence intensity.</p> </li> <li> <p>S: Skewness of longitudinal velocity gradient. A measure of asymmetry in velocity gradient fluctuations, significant for small-scale turbulence analysis.</p> </li> <li> <p>Y\u1da0(t): Fluid Lagrangian trajectory. The path traced by a fluid particle as it moves through turbulence.</p> </li> <li> <p>\u03c4\u209c: Lagrangian Taylor microscale time. A timescale describing the decay of velocity correlation along a fluid particle trajectory.</p> </li> </ul>"},{"location":"Theory/Technical/Dynamics/Cloud_Droplet_Coagulation/Droplet_Coagulation_Kernel_Ayala2008/#g-gravitational-acceleration","title":"g: Gravitational Acceleration","text":"<p>The acceleration due to gravity, approximately 9.81 m/s\u00b2 on Earth's surface. This force drives droplet sedimentation in turbulent air.</p>"},{"location":"Theory/Technical/Properties/dynamic_viscosity/","title":"Dynamic Viscosity","text":"In\u00a0[\u00a0]: Copied! <pre># In Colab uncomment the following command to install particula:\n#!pip install particula[extra] --quiet\nimport particula as par\n\n\nair_dynamic_viscosity = par.gas.get_dynamic_viscosity(\n    temperature=298.15\n)  # will produce approx 1.84e-5 kg/m/s\n\nprint(\n    f\"Air dynamic viscosity at 298.15 K is {air_dynamic_viscosity:.2e} kg/m/s\"\n)\n</pre> # In Colab uncomment the following command to install particula: #!pip install particula[extra] --quiet import particula as par   air_dynamic_viscosity = par.gas.get_dynamic_viscosity(     temperature=298.15 )  # will produce approx 1.84e-5 kg/m/s  print(     f\"Air dynamic viscosity at 298.15 K is {air_dynamic_viscosity:.2e} kg/m/s\" ) <pre>Air dynamic viscosity at 298.15 K is 1.84e-05 kg/m/s\n</pre>"},{"location":"Theory/Technical/Properties/dynamic_viscosity/#dynamic-viscosity","title":"Dynamic Viscosity\u00b6","text":"<p>The dynamic viscosity is a property of the fluid, defining the resistance of the fluid to its own movement. The dynamic viscosity is calculated using the Sutherland formula (reference). The function can be found and is documented in <code>util.dynamic_viscosity.py</code>. It takes inputs of <code>temperature</code>, <code>reference_viscosity</code>, <code>reference_temperature</code>, and <code>sutherland_constant</code>. It returns a value for the dynamic viscosity at those variables. At default conditions (298.15 K and 101325 Pa), the dynamic viscosity is approximately 1.84e-5 kg/m/s. The Sutherland formula is</p> <p>$$ \\mu = \\frac{\\mu_{0}\\, (T/T_{0})^{3/2}\\, (T_{0} + C)}{C + T} $$</p> <p>where $\\mu$ is the dynamic viscosity, $\\mu_{0}$ is the reference dynamic viscosity, $T$ is temperature, $T_{0}$ is the reference temperature, and $C$ is the Sutherland constant.</p>"},{"location":"Theory/Technical/Properties/mean_free_path/","title":"Mean Free Path","text":"In\u00a0[\u00a0]: Copied! <pre># In Colab uncomment the following command to install particula:\n#!pip install particula[extra] --quiet\nimport particula as par\n\nair_dynamic_viscosity = par.gas.get_dynamic_viscosity(temperature=298.15)\n\nmean_free_path = par.gas.get_molecule_mean_free_path(\n    molar_mass=28.97e-3,\n    temperature=298.15,\n    pressure=101325,\n    dynamic_viscosity=air_dynamic_viscosity,\n)\n\nprint(f\"mean free path is {mean_free_path} m\")  # will produce approx 66.5 nm\n</pre> # In Colab uncomment the following command to install particula: #!pip install particula[extra] --quiet import particula as par  air_dynamic_viscosity = par.gas.get_dynamic_viscosity(temperature=298.15)  mean_free_path = par.gas.get_molecule_mean_free_path(     molar_mass=28.97e-3,     temperature=298.15,     pressure=101325,     dynamic_viscosity=air_dynamic_viscosity, )  print(f\"mean free path is {mean_free_path} m\")  # will produce approx 66.5 nm <pre>mean free path is 6.647342358988276e-08 m\n</pre>"},{"location":"Theory/Technical/Properties/mean_free_path/#mean-free-path","title":"Mean Free Path\u00b6","text":"<p>The mean free path is the average distance of a molecule between collisions with other molecules present in the medium. We use the kinetic theory of gases to calculate the mean free path in an ideal gas as</p> <p>$$ \\lambda = \\frac{2 \\mu / p}{(8 \\, \\mathrm{MW} / (\\pi R T))^{1/2}}  $$</p> <p>where $\\lambda$ is the mean free path, $\\mu$ is the dynamic viscosity, $p$ is the pressure, $\\mathrm{MW}$ is the molecular weight, $R$ is the gas constant, $T$ is the temperature. As noted above, the user can provide an explicit value for $\\mu$ or it can be calculated using the above formula (that is, the user can provide the inputs to the above formula for $\\mu$). At default conditions, $\\lambda$ is about 66.5 nm.</p>"},{"location":"contribute/","title":"Contribute","text":"<p>Welcome \u2014 we\u2019re thrilled that you\u2019d like to help make Particula better!</p> <p>All detailed guides, workflow diagrams, and coding standards can be found in the navigation menu on the left.  Use those links whenever you need more information about a specific step or requirement.</p> <p>Start with Contributing for a high-level overview of the process. Then, branch out to the specific sections for more details on each step.</p>"},{"location":"contribute/CODE_OF_CONDUCT/","title":"Code of Conduct","text":""},{"location":"contribute/CODE_OF_CONDUCT/#our-pledge","title":"Our Pledge","text":"<p>We as members, contributors, and leaders pledge to make participation in our community a harassment-free experience for everyone, regardless of age, body size, visible or invisible disability, ethnicity, sex characteristics, gender identity and expression, level of experience, education, socio-economic status, nationality, personal appearance, race, religion, or sexual identity and orientation.</p> <p>We pledge to act and interact in ways that contribute to an open, welcoming, diverse, inclusive, and healthy community.</p>"},{"location":"contribute/CODE_OF_CONDUCT/#our-standards","title":"Our Standards","text":"<p>Examples of behavior that contributes to a positive environment for our community include:</p> <ul> <li>Demonstrating empathy and kindness toward other people</li> <li>Being respectful of differing opinions, viewpoints, and experiences</li> <li>Giving and gracefully accepting constructive feedback</li> <li>Accepting responsibility and apologizing to those affected by our mistakes,   and learning from the experience</li> <li>Focusing on what is best not just for us as individuals, but for the   overall community</li> </ul> <p>Examples of unacceptable behavior include:</p> <ul> <li>The use of sexualized language or imagery, and sexual attention or   advances of any kind</li> <li>Trolling, insulting or derogatory comments, and personal or political attacks</li> <li>Public or private harassment</li> <li>Publishing others' private information, such as a physical or email   address, without their explicit permission</li> <li>Other conduct which could reasonably be considered inappropriate in a   professional setting</li> </ul>"},{"location":"contribute/CODE_OF_CONDUCT/#enforcement-responsibilities","title":"Enforcement Responsibilities","text":"<p>Community leaders are responsible for clarifying and enforcing our standards of acceptable behavior and will take appropriate and fair corrective action in response to any behavior that they deem inappropriate, threatening, offensive, or harmful.</p> <p>Community leaders have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, and will communicate reasons for moderation decisions when appropriate.</p>"},{"location":"contribute/CODE_OF_CONDUCT/#scope","title":"Scope","text":"<p>This Code of Conduct applies within all community spaces, and also applies when an individual is officially representing the community in public spaces. Examples of representing our community include using an official e-mail address, posting via an official social media account, or acting as an appointed representative at an online or offline event.</p>"},{"location":"contribute/CODE_OF_CONDUCT/#enforcement","title":"Enforcement","text":"<p>Instances of abusive, harassing, or otherwise unacceptable behavior may be reported to the community leaders responsible for enforcement at . All complaints will be reviewed and investigated promptly and fairly.</p> <p>All community leaders are obligated to respect the privacy and security of the reporter of any incident.</p>"},{"location":"contribute/CODE_OF_CONDUCT/#enforcement-guidelines","title":"Enforcement Guidelines","text":"<p>Community leaders will follow these Community Impact Guidelines in determining the consequences for any action they deem in violation of this Code of Conduct:</p>"},{"location":"contribute/CODE_OF_CONDUCT/#1-correction","title":"1. Correction","text":"<p>Community Impact: Use of inappropriate language or other behavior deemed unprofessional or unwelcome in the community.</p> <p>Consequence: A private, written warning from community leaders, providing clarity around the nature of the violation and an explanation of why the behavior was inappropriate. A public apology may be requested.</p>"},{"location":"contribute/CODE_OF_CONDUCT/#2-warning","title":"2. Warning","text":"<p>Community Impact: A violation through a single incident or series of actions.</p> <p>Consequence: A warning with consequences for continued behavior. No interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, for a specified period of time. This includes avoiding interactions in community spaces as well as external channels like social media. Violating these terms may lead to a temporary or permanent ban.</p>"},{"location":"contribute/CODE_OF_CONDUCT/#3-temporary-ban","title":"3. Temporary Ban","text":"<p>Community Impact: A serious violation of community standards, including sustained inappropriate behavior.</p> <p>Consequence: A temporary ban from any sort of interaction or public communication with the community for a specified period of time. No public or private interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, is allowed during this period. Violating these terms may lead to a permanent ban.</p>"},{"location":"contribute/CODE_OF_CONDUCT/#4-permanent-ban","title":"4. Permanent Ban","text":"<p>Community Impact: Demonstrating a pattern of violation of community standards, including sustained inappropriate behavior,  harassment of an individual, or aggression toward or disparagement of classes of individuals.</p> <p>Consequence: A permanent ban from any sort of public interaction within the community.</p>"},{"location":"contribute/CODE_OF_CONDUCT/#attribution","title":"Attribution","text":"<p>This Code of Conduct is adapted from the Contributor Covenant, version 2.0, available at https://www.contributor-covenant.org/version/2/0/code_of_conduct.html.</p> <p>Community Impact Guidelines were inspired by Mozilla's code of conduct enforcement ladder.</p> <p>For answers to common questions about this code of conduct, see the FAQ at https://www.contributor-covenant.org/faq. Translations are available at https://www.contributor-covenant.org/translations.</p>"},{"location":"contribute/CONTRIBUTING/","title":"CONTRIBUTING","text":""},{"location":"contribute/CONTRIBUTING/#contributing-to-particula","title":"Contributing\u00a0to\u00a0Particula","text":"<p>Thanks for thinking about contributing! Our goal is to make your first pull request (PR) smooth\u2014whether you are brand\u2011new to open\u2011source or a seasoned developer.</p>"},{"location":"contribute/CONTRIBUTING/#1-choose-the-right-path","title":"1. Choose the Right Path","text":"You are\u2026 Start here Experienced with Git\u00a0+\u00a0Python Jump straight to Github workflow below. New to GitHub or virtual\u2011envs Follow setup\u00a0for\u00a0new\u00a0contributors and the Contributor\u00a0Setup guide. Planning to contribute major code or new features Follow Feature\u00a0Workflow and Code\u00a0Specifications before you begin."},{"location":"contribute/CONTRIBUTING/#2-setup-for-new-contributors","title":"2. Setup for New Contributors","text":"<p>For the complete, click\u2011through tutorial (fork \u2192 clone \u2192 virtual\u2011env \u2192 editable install) see the Contributor\u00a0Setup guide.</p> <p>If you already have Python, Git, and a preferred editor, skim this section.</p> <ol> <li>Install Git &amp; VS\u00a0Code </li> <li>Git: https://git\u2011scm.com/downloads </li> <li> <p>VS\u00a0Code: https://code.visualstudio.com/ (recommended extensions: Python, GitHub Pull Requests &amp; Issues).</p> </li> <li> <p>Fork the repository    Click Fork on https://github.com/uncscode/particula. This creates <code>yourname/particula</code>.</p> </li> <li> <p>Clone your fork <pre><code>git clone https://github.com/&lt;your\u2011username&gt;/particula.git\ncd particula\n</code></pre></p> </li> <li> <p>Create a virtual environment (pick one)</p> </li> </ol> Tool Command Instructions uv (fast, minimal) <code>uv venv .venv</code><code>source .venv/bin/activate</code><code>uv pip install -e \".[dev,extra]\"</code> uv setup guide pip + venv <code>python -m venv .venv</code><code>source .venv/bin/activate</code><code>pip install -e \".[dev,extra]\"</code> pip setup guide conda <code>conda create -n particula-dev</code><code>conda activate particula-dev</code><code>pip install -e \".[dev,extra]\"</code> conda setup guide <ol> <li>Verify installation <pre><code>pytest -q    # all tests should pass\nparticula --help\n</code></pre></li> </ol>"},{"location":"contribute/CONTRIBUTING/#3-github-flow","title":"3. GitHub Flow","text":"Step What you do Why 1 Fork \u2192 Clone \u2192 Set up <code>.venv</code> \u2192 <code>pip install -e \".[dev,extra]\"</code> Gives you a local, editable checkout with all dev tools. 2 Sync with upstream(keeps your <code>main</code> current) Avoids merge conflicts later. 3 Discuss your feature Helps us understand your goals and avoid duplication of effort. 4 Theory \u2192 Code \u2192 Test \u2192 Examples Adds value without breaking existing functionality. 5 Commit\u00a0+\u00a0Push to your fork Publishes your branch to GitHub. 6 Open a Pull Request to <code>uncscode/particula</code> Starts the review &amp; CI pipeline. 7 Discuss &amp; Iterate with reviewers Polishes the contribution. 8 Rebase (done by maintainer) Your code lands in <code>main</code>. 9 Celebrate \ud83c\udf89 You just helped improve Particula!"},{"location":"contribute/CONTRIBUTING/#expanded-github-flow","title":"Expanded GitHub Flow","text":"<p>Step\u00a01\u00a0\u2013\u00a0Fork\u00a0\u2192\u00a0Clone\u00a0\u2192\u00a0Environment</p> <p>See setup guides above for details.</p> <p>Step\u00a02\u00a0\u2013\u00a0Sync your fork with upstream (repeat as needed)</p> <pre><code>git remote add upstream https://github.com/uncscode/particula.git   # one\u2011time\ngit checkout main\ngit pull upstream main\ngit push origin main\n</code></pre> <p>Step\u00a03\u00a0\u2013\u00a0Discuss your feature</p> <p>If you are planning a large feature or change, please open a Discussion first. This helps us understand your goals and avoid duplication of effort. Or if you are new to the project, ask for guidance in the GitHub Discussions.</p> <p>If you have experience with the codebase and it is a small change, you can skip this step. Pure bug fixes or small features or new examples are usually fine to skip this step too.</p> <p>Step\u00a04\u00a0\u2013\u00a0Theory \u2192 Code \u2192 Test \u2192 Examples</p> <p>For a full step\u2011by\u2011step breakdown see the Feature Workflow guide and the Code Specifications.</p> <ul> <li>Create feature branch (e.g., <code>issue123-fix-simulation</code>).</li> <li>Add/adjust new code or documentation.</li> <li>Add/adjust tests.</li> <li>Add/adjust docstrings &amp; markdown pages.</li> </ul> <p>Step\u00a05\u00a0\u2013\u00a0Commit &amp; push</p> <p>For an overview of git standards we use, see Linear Git Repository.</p> <pre><code>git add .\ngit commit -m \"FIX #123: timestep rollover in simulation\"\ngit push -u origin issue123-fix-simulation\n</code></pre> <p>Step\u00a06\u00a0\u2013\u00a0Open a Pull Request</p> <ul> <li>Go to your fork \u2192 Compare &amp; pull request.  </li> <li>Fill in the PR template; mark as Draft for early feedback if desired.</li> </ul> <p>Step\u00a07\u00a0\u2013\u00a0Discuss &amp; iterate</p> <ul> <li>GitHub Actions runs tests (<code>pytest -Werror</code>), linters (<code>flake8</code>, <code>pylint</code>), and docs build automatically.  </li> <li>Push additional commits to the same branch\u2014CI re\u2011runs and the PR updates.</li> </ul> <p>Step\u00a08\u00a0\u2013\u00a0Rebase When CI is green and reviews are approved, a maintainer will merge-rebase your PR into <code>main</code>.</p> <p>Step\u00a09\u00a0\u2013\u00a0Celebrate! \ud83c\udf89 Your contribution is now part of Particula\u2014thank you!</p>"},{"location":"contribute/CONTRIBUTING/#4-coding-standards-review-expectations","title":"4. Coding Standards &amp; Review Expectations","text":"Topic Rule Style Detailed rules: Code Specifications. Docstrings Follow the templates in Function\u00a0docstring\u00a0format and Class\u00a0docstring\u00a0format. One\u2011line summary\u00a0+ details\u00a0+ sections (<code>Arguments</code>, <code>Returns</code>, <code>Raises</code>, <code>Examples</code>, <code>References</code>). Typing Use <code>typing</code> annotations. Omit types in docstrings. Tests Every public function/class must have at least one <code>pytest</code> test. Aim for coverage \u2265\u00a090\u00a0%.  See Add\u00a0Unit\u00a0Tests. Commit messages Imperative mood, \u2264\u00a072\u00a0chars summary\u00a0+ context body if needed. Large changes Open a discussion first and discuss design before implementation."},{"location":"contribute/CONTRIBUTING/#5-common-commands","title":"5. Common Commands","text":"<p>one\u2011liners you can copy\u2011paste</p> Purpose Command Quick unit tests <code>pytest -q -Werror</code> Run tests in parallel <code>pytest -Werror</code> Static type\u2011checking (pytype, Mac/Linux) <code>pytype particula</code> Black auto\u2011format (79\u00a0cols) <code>black . --line-length 79</code> Flake8 lint <code>flake8 . --config .github/.flake8</code> Pylint lint <code>pylint particula</code> <p>CI note: Every pull request triggers GitHub Actions (Ubuntu\u00a0/\u00a0macOS\u00a0/\u00a0Windows). The workflow runs <code>pytest -n auto -Werror</code>, <code>flake8</code>, <code>pylint</code>, <code>pytype</code>, builds the docs, and checks coverage. Any warning promoted to an error (via\u00a0<code>-Werror</code>) or other failure marks the PR \u274c. Click \u201cDetails \u2192\u201d beside the failing job to view logs, fix locally, push again, and the checks will re\u2011run automatically.</p>"},{"location":"contribute/CONTRIBUTING/#6-need-help","title":"6. Need Help?","text":"<ul> <li>Questions: open a \u201cDiscussion\u201d or tag a maintainer in your PR.  </li> <li>Stuck on Git? Try <code>git status</code>, <code>git restore</code>, or ask for pairing in the chat.  </li> <li>Broken tests on CI? Click \u201cDetails\u201d next to the failing job; logs usually point to the exact line.</li> </ul> <p>We appreciate every contribution\u2014code, docs, tests, or ideas. Welcome to the Particula community! \ud83c\udf89</p>"},{"location":"contribute/Code_Specifications/","title":"Code Specifications","text":"<p>This document provides a concise overview of repository-wide coding and documentation standards. It serves as the single entry-point for newcomers and quick reference for experienced contributors.</p>"},{"location":"contribute/Code_Specifications/#folder-structure-quick-reference","title":"Folder Structure Quick Reference","text":"<ul> <li><code>particula/</code> \u2014 main source code</li> <li><code>particula/...tests/</code> \u2014 tests are located as close to the relevant code as possible, in a <code>tests/</code> folder.</li> <li><code>docs/</code> \u2014 documentation and specifications</li> </ul> <p>A stable directory layout keeps import paths constant across refactors, reducing churn in downstream notebooks and published papers.</p>"},{"location":"contribute/Code_Specifications/#high-level-principles","title":"High-Level Principles","text":"<ul> <li>Prioritize readability and maintainability.</li> <li>Ensure testability and type-safety.</li> <li>Write docstrings and examples that are LLM-friendly (clear, explicit, consistent).</li> <li>Prefer code explicitness over cleverness.</li> </ul>"},{"location":"contribute/Code_Specifications/#why-these-principles","title":"Why these principles?","text":"<p>Particula\u2019s goal is to enable rapid, verifiable scientific iteration. Readable code invites review; maintainable code survives graduate\u2011student turnover; testable and type\u2011safe code lets us refactor with confidence. Finally, being LLM\u2011friendly acknowledges that many contributors\u2014including the project itself\u2014will leverage AI tooling.  Clear, explicit patterns dramatically improve the quality of the machine suggestions we receive.</p>"},{"location":"contribute/Code_Specifications/#the-warmed-principles","title":"The WARMED Principles","text":"Letter Focus One-line guideline W Writing Write code that is direct, minimal, and fits the problem. A Agreeing Discuss and settle on how a feature is implemented before merging. R Reading Code and variable names must explain themselves; comments/docstring fill the gaps, not the voids. M Modifying Any competent dev should be able to extend or swap a component in minutes. E Executing Favor vectorization and avoid hidden <code>for</code> loops. D Debugging Fail fast with helpful messages and provide deterministic tests. <p>These six commitments underpin every rule that follows.  Each subsequent section calls out its relevant WARMED letter(s) so readers can see how an individual guideline maps back to the overall developer experience.</p>"},{"location":"contribute/Code_Specifications/#naming-conventions","title":"Naming Conventions","text":"<p>Focus: R\u00a0/\u00a0M \u2014 descriptive names ease reading and future extension.</p> <ul> <li>Functions:   Use <code>get_&lt;quantity&gt;</code> or, for functions with that use system state [e.g., standard temperature and pressure], use    <code>get_&lt;quantity&gt;[_via_system_state]</code>.</li> <li>Classes:   Use <code>&lt;Descriptor&gt;&lt;PatternName&gt;</code>, e.g., <code>TurbulentShearCoagulationStrategy</code>.</li> <li>Constants:   Use <code>ALL_CAPS</code>.</li> <li>Private:   Use <code>_leading_underscore</code> for private members.</li> </ul> <p>Rationale: Descriptive, structured names act as self\u2011healing documentation.  Prefixes like <code>get_</code> signal a side\u2011effect\u2011free accessor, while the <code>&lt;Descriptor&gt;&lt;PatternName&gt;</code> template exposes the design pattern in play (e.g., Strategy, Builder).  These conventions help human reviewers,  and language models infer intent without digging into the implementation.</p>"},{"location":"contribute/Code_Specifications/#docstring-style","title":"Docstring Style","text":"<p>Focus: R \u2014 rich docstrings turn code into readable, searchable documentation.</p> <ul> <li>Use the templates specifications for:</li> <li>Function docstrings: Function_docstring_format.</li> <li> <p>Class docstrings: Class_docstring_format.</p> </li> <li> <p>Emphasize:</p> <ul> <li>Unicode equations for mathematical expressions.</li> <li>Parameter list format: <code>- parameter : Description</code>.</li> <li>Include Examples and References sections.</li> <li>Keep line length \u2264 79 characters.</li> </ul> </li> </ul> <p>These templates are more than bureaucracy\u2014they power the auto\u2011documentation pipeline (code\u00a0\u2192\u00a0Mkdocs website) and give language models deterministic anchors when summarizing or refactoring code.</p> <p>The templates are also used by LLMs in a AI-developer-workflow to generate/revise the docstrings.</p>"},{"location":"contribute/Code_Specifications/#code-style-guidelines","title":"Code Style Guidelines","text":"<p>Focus: W\u00a0/\u00a0E \u2014 minimal, consistent style and vector\u2011friendly patterns improve writing and execution.</p> <ul> <li>When not otherwise specified in templates, default to the   Google Python Style Guide.</li> <li>Use <code>flake8</code> and <code>black</code> for linting and formatting.</li> </ul> <p>Why automated style?  Tools such as <code>flake8</code> and <code>black</code> eliminate \u201cformatting debate\u201d noise from reviews, keep diffs minimal, and help first\u2011time contributors pass CI without memorizing an idiosyncratic style.</p>"},{"location":"contribute/Code_Specifications/#git-repository","title":"Git Repository","text":"<p>The git repository follows a linear history model. For a clear and clean history. See more at Linear Git Repository</p>"},{"location":"contribute/Code_Specifications/Details/Class_docstring_format/","title":"Docstring Specification: Python Classes, Attributes, and Methods","text":"<p>Instruction Analyze all Class definitions provided and improve their docstrings for clarity, consistency, and adherence to best practices.</p>"},{"location":"contribute/Code_Specifications/Details/Class_docstring_format/#high-level-objectives","title":"High-Level Objectives","text":"<ol> <li>Improve Documentation Clarity </li> <li>Ensure all function docstrings follow a clear, structured format.  </li> <li> <p>Use concise parameter descriptions and clearly stated return values.</p> </li> <li> <p>Include Mathematical Equations </p> </li> <li> <p>When applicable, present equations in Unicode format for broader compatibility.</p> </li> <li> <p>Ensure Consistency </p> </li> <li> <p>Maintain uniform style for docstrings: proper indentation, spacing, formatting.</p> </li> <li> <p>Add Examples </p> </li> <li> <p>Provide code snippets to demonstrate usage of classes and methods.</p> </li> <li> <p>Include References </p> </li> <li>Insert a \"References\" section where needed, citing reliable sources (e.g., Wikipedia, journal articles, or books).</li> </ol>"},{"location":"contribute/Code_Specifications/Details/Class_docstring_format/#mid-level-objectives","title":"Mid-Level Objectives","text":"<ol> <li>Standardized Docstring Format    Use the following template as a guide:</li> </ol> <p>```python    class ExampleClassName:        \"\"\"        Short description of what the class is or does.</p> <pre><code>   Longer description of the class, including its purpose and functionality.\n   This can be multiple lines. Discuss why the class is important and how it\n   fits into a larger API or system.\n\n   Attributes:\n       - param1 : Description of param1.\n       - param2 : Description of param2.\n\n   Methods:\n       - method_name: Brief description or context.\n       - another_method: Brief description or context.\n\n   Examples:\n       ```py title=\"Example Usage\"\n       import particula as par\n       example_object = par.ExampleClassName(param1, param2)\n       output = example_object.method_name(value1, value2)\n       # Output: ...\n       ```\n\n   References:\n       - Author Name, \"Title of the Article,\" Journal Name,\n         Volume, Issue, Year.\n         [DOI](link)\n       - \"Article Title,\"\n         [Wikipedia](URL).\n   \"\"\"\n\n   def __init__(self, param1, param2):\n       \"\"\"\n       Initialize the ExampleClassName with parameters.\n\n       Arguments:\n           - param1 : Description of param1.\n           - param2 : Description of param2.\n\n       Returns:\n           - None\n       \"\"\"\n       self.param1 = param1\n       self.param2 = param2\n\n   def method_name(self, value1, value2):\n       \"\"\"\n       Brief description of what the method does.\n\n       A longer description of the method, including its purpose\n       and methodology. Can be multiple lines. For example:\n\n       - \u03c6 = (\u03b3 \u00d7 \u03b2) / c\n           - \u03c6 is Description of \u03c6.\n           - \u03b3 is Description of \u03b3.\n           - \u03b2 is Description of \u03b2.\n           - c is Description of the constant.\n\n       Arguments:\n           - value1 : Description of value1.\n           - value2 : Description of value2.\n\n       Returns:\n           - Description of the return value.\n\n       Examples:\n           ```py title=\"Example\"\n           example_object.method_name(2, 3)\n           # Output: 1.5\n           ```\n\n           ```py title=\"Example Usage with Arrays\"\n           example_object.method_name(np.array([4,5,5]), np.array([2,3,4]))\n           # Output: array([4.0, 1.66666667, 1.25])\n           ```\n\n       References:\n           - Author Name, \"Title of the Article,\" Journal Name,\n             Volume, Issue, Year.\n             [DOI](link)\n           - \"Article Title,\"\n             [Wikipedia](link).\n        \"\"\"\n        return (value1 * value2) / self.param1\n       ```\n</code></pre> <ol> <li>Mathematical Equation Representation </li> <li> <p>Include relevant mathematical equations in Unicode format (e.g., <code>C = (P \u00d7 M) / (R \u00d7 T)</code>).</p> </li> <li> <p>Consistent Spacing and Formatting </p> </li> <li>Insert a space after each colon in parameter descriptions (<code>- parameter : Description</code>).  </li> <li>Maintain proper line breaks and indentation.  </li> <li>Provide usage examples under an \"Examples\" subheading.  </li> <li>Include a \"References\" section whenever citing sources.</li> </ol>"},{"location":"contribute/Code_Specifications/Details/Class_docstring_format/#implementation-steps","title":"Implementation Steps","text":"<ol> <li>Analyze Existing Docstrings </li> <li>Identify missing or incorrect parameter names.  </li> <li> <p>Check for inconsistent formatting, unclear descriptions, or missing references.</p> </li> <li> <p>Update Docstrings for Clarity </p> </li> <li>Use a single, consistent style for parameter listings: <code>- parameter : Description</code>.  </li> <li>Verify each parameter and return value is accurately described.  </li> <li>Keep line lengths under 79 characters when possible.  </li> <li>Use equations in Unicode format where relevant.  </li> <li> <p>Add references for scientific or technical validity.</p> </li> <li> <p>Apply Consistency Rules </p> </li> <li>All arguments must follow the <code>parameter : Description</code> style.  </li> <li>Equations should be in Unicode format.  </li> <li>Insert a \"References\" section if any sources are used.  </li> <li>Ensure docstrings are consistently structured.</li> </ol>"},{"location":"contribute/Code_Specifications/Details/Class_docstring_format/#final-checklist","title":"Final Checklist","text":"<ul> <li> Docstrings follow the uniform format (brief description, parameters, returns, etc.).  </li> <li> Equations are presented in Unicode format if applicable.  </li> <li> Parameter names and descriptions are accurate and consistent.  </li> <li> Spacing and indentation are correct.  </li> <li> References are included when needed.  </li> <li> Every class and method has a complete, clear docstring.</li> </ul>"},{"location":"contribute/Code_Specifications/Details/Function_docstring_format/","title":"Docstring Specification: Python Functions","text":"<p>Analyze all function definitions provided, improve the docstrings, and ensure clarity, consistency, and adherence to best practices. </p>"},{"location":"contribute/Code_Specifications/Details/Function_docstring_format/#high-level-objective","title":"High-Level Objective","text":"<ul> <li> <p>Improve Documentation Clarity:   Ensure that all function docstrings follow a structured and readable format, using clear parameter descriptions and return values.  </p> </li> <li> <p>Include Mathematical Equations:   When applicable, include equations in Unicode format to enhance readability and scientific accuracy.  </p> </li> <li> <p>Ensure Consistency:   Maintain a uniform style for docstrings, ensuring proper indentation, spacing, and structure.</p> </li> <li> <p>ADD EXAMPLES:   Add examples to demonstrate function usage, if applicable.</p> </li> <li> <p>Include References:   Add a \"References\" section when applicable, citing sources such as Wikipedia pages, journal articles, or books for scientific validity.  </p> </li> </ul>"},{"location":"contribute/Code_Specifications/Details/Function_docstring_format/#mid-level-objectives","title":"Mid-Level Objectives","text":"<ul> <li>Standardized Docstring Format:   Use the following format:  </li> </ul> <pre><code>def function_name(param1: type, param2: type) -&gt; return_type:\n    \"\"\"\n    Brief description of what the function does.\n\n    A description of the function, including the purpose\n    and methodology. Can be multiple lines. Where calculated as:\n\n    - \u03c6 = (\u03b3 \u00d7 \u03b2) / c\n        - \u03c6 is Description of \u03c6.\n        - \u03b3 is Description of \u03b3.\n        - \u03b2 is Description of \u03b2.\n        - c is Description of the constant.\n\n    Arguments:\n        - param1 : Description of param1.\n        - param2 : Description of param2.\n\n    Returns:\n        - Description of the return value.\n\n    Examples:\n        ``` py title=\"Example title\"\n        import package_name as np\n        np.function_name(2, 3)\n        # Output: 1.5\n        ```\n\n        ``` py title=\"Example Usage 2 array input\"\n        import package_name as np\n        np.function_name(np.array([4,5,5]), np.array([2,3,4]))\n        # Output: array([4.0, 1.66666667, 1.25])\n        ```\n\n    References:\n        - Author Name, \"Title of the Article,\" Journal Name, Volume, Issue, Year.\n            [DOI](url_link)\n        - \"Article Title\",\n          [Wikipedia](link)\n    \"\"\"\n    return (param1 * param2) / CONSTANT\n</code></pre> <ul> <li>Mathematical Equation Representation: </li> <li> <p>If needed, include mathematical equations in Unicode format (e.g., <code>C = (P \u00d7 M) / (R \u00d7 T)</code>) for broader compatibility.  </p> </li> <li> <p>Consistent Spacing and Formatting: </p> </li> <li>Ensure a space after <code>:</code> in Arguments: descriptions.  </li> <li>Maintain proper indentation and line breaks, (<code>- parameter : Description</code>)</li> <li>Use examples to demonstrate function usage.</li> <li>Use a \"References\" section to cite sources.  </li> </ul>"},{"location":"contribute/Code_Specifications/Details/Function_docstring_format/#implementation-steps","title":"Implementation Steps","text":""},{"location":"contribute/Code_Specifications/Details/Function_docstring_format/#1-analyze-the-function-docstrings","title":"1. Analyze the Function Docstrings","text":"<p>Review each function's existing docstring to identify issues, including: - Incorrect parameter names - Inconsistent formatting - Missing or unclear descriptions - Lack of references when needed  </p>"},{"location":"contribute/Code_Specifications/Details/Function_docstring_format/#2-update-docstrings-for-clarity-and-readability","title":"2. Update Docstrings for Clarity and Readability","text":"<ul> <li>UPDATE function descriptions for clarity.  </li> <li>All parameter descriptions follow the same style (<code>- parameter : Description</code>). Using a hyphen, colon, and space before the description.</li> <li>UPDATE all parameters and return values are described.</li> <li>CHECK all line lengths are 79 characters or less, for readability.</li> <li>USE equations in Unicode format when applicable.  </li> <li>DEFINE each variable and the equation in a clear and concise manner, in style '- variable is describe variable'.</li> <li>ADD References for scientific accuracy.  </li> </ul> <p>Example Before: <pre><code>def calculate_concentration(partial_pressure, molar_mass, temperature):\n    \"\"\"Calculate the concentration of a gas from its partial pressure, molar mass, and temperature using the ideal gas law.\n\n    Parameters:\n    pressure (float or NDArray[np.float64]): Partial pressure of the gas\n    in Pascals (Pa).\n    molar_mass (float or NDArray[np.float64]): Molar mass of the gas in kg/mol\n    temperature (float or NDArray[np.float64]): Temperature in Kelvin.\n\n    Returns:\n    - concentration (float or NDArray[np.float64]): Concentration of the gas\n    in kg/m^3.\n    \"\"\"\n    return (partial_pressure * molar_mass) / (float(GAS_CONSTANT) * temperature)\n</code></pre></p> <p>Example After (With Reference): <pre><code>def get_calculate_concentration(\n    partial_pressure: Union[float, NDArray[np.float64]],\n    molar_mass: Union[float, NDArray[np.float64]],\n    temperature: Union[float, NDArray[np.float64]],\n) -&gt; Union[float, NDArray[np.float64]]:\n    \"\"\"\n    Calculate the concentration of a gas using the ideal gas law.\n\n    The concentration is determined using the equation:\n\n    - C = (P \u00d7 M) / (R \u00d7 T)\n        - C is the concentration in kg/m\u00b3,\n        - P is the partial pressure in Pascals (Pa),\n        - M is the molar mass in kg/mol,\n        - R is the universal gas constant (J/(mol\u00b7K)),\n        - T is the temperature in Kelvin.\n\n    Arguments:\n        - partial_pressure : Partial pressure of the gas in Pascals (Pa).\n        - molar_mass : Molar mass of the gas in kg/mol.\n        - temperature : Temperature in Kelvin.\n\n    Returns:\n        - Concentration of the gas in kg/m\u00b3.\n\n    Examples:\n        ``` py title=\"Example Usage\"\n        import particula as par\n        par.gas.get_calculate_concentration(1.5, 0.02897, 298)\n        # Output: 1.6175\n        ```\n\n    References:\n        - \"Ideal Gas Law,\"\n          [Wikipedia](https://en.wikipedia.org/wiki/Ideal_gas_law)\n        - J. D. Lee, *Physical Chemistry*, 5th ed., Oxford University\n          Press, 2019.\n    \"\"\"\n    return (partial_pressure * molar_mass) / (float(GAS_CONSTANT) * temperature)\n</code></pre></p>"},{"location":"contribute/Code_Specifications/Details/Function_docstring_format/#3-apply-consistency-rules","title":"3. Apply Consistency Rules","text":"<p>Ensure that: - All Argument descriptions follow the same style (<code>parameter : Description</code>). - Equations are formatted in Unicode for clarity. - A \"References\" section is included when citing sources. - All docstrings use a structured format for easy readability.  </p>"},{"location":"contribute/Code_Specifications/Details/Function_docstring_format/#final-checklist","title":"Final Checklist","text":"<ul> <li> Docstrings follow a consistent format (brief description, equation, arguments, return values, references).  </li> <li> Equations are formatted properly (Unicode, based on the context).  </li> <li> Parameter names and descriptions are accurate.  </li> <li> Proper spacing and indentation are used.  </li> <li> References are included when applicable.  </li> <li> All functions have complete and clear docstrings.  </li> </ul>"},{"location":"contribute/Code_Specifications/Details/Linear_Git_Repository/","title":"Linear Git Repository","text":"<p>Use a rebase\u2011then\u2011fast\u2011forward strategy to keep a linear history. Avoid the \u201cUpdate branch\u201d or \u201cSquash &amp; merge\u201d buttons on GitHub\u2014those create merge commits instead of a clean rebase.</p> <p>A linear timeline makes it trivial to:</p> <ul> <li>read the progression of a feature from top to bottom,</li> <li>bisect for bugs (<code>git bisect</code>), and</li> <li>cherry\u2011pick or revert single commits.</li> </ul> <p>In short, it keeps the repository human\u2013readable and tool\u2011friendly, so the extra rebase step pays off quickly.</p> <p>Rule of thumb</p> <ol> <li>Rebase early, rebase often \u2013 keep your PR branch current with <code>main</code>.</li> <li>Squash before review if your PR has dozens of commits.</li> <li>Always force\u2011push (<code>--force-with-lease</code>) after a rebase or squash so GitHub updates the PR without adding merge commits.</li> </ol>"},{"location":"contribute/Code_Specifications/Details/Linear_Git_Repository/#rebase-your-feature-branch-onto-main","title":"Rebase your feature branch onto <code>main</code>","text":"<p>Why rebase? </p> <p>Rebasing re\u2011plays your commits on top of the current <code>main</code>, avoiding the merge commit that GitHub\u2019s \u201cUpdate branch\u201d button would create.  </p> <p>Reviewers now see only the changes relevant to the feature, not a noisy merge diff.</p> <pre><code># Make sure you have the latest main\ngit fetch origin\n\n# Switch to your feature branch\ngit switch my\u2011feature\n\n# Rebase onto the tip of main with conflict checking\ngit rebase main\n# \u2011\u2010rebase merges your commits one\u2011by\u2011one\n# If conflicts appear:\n#   edit the files \u2192 git add &lt;files&gt; \u2192 git rebase --continue\n#   or git rebase --abort to cancel the rebase\n\n# Push the rebased branch to the PR\ngit push --force-with-lease   # safer than --force\n</code></pre> <p>Why CLI? GitHub\u2019s \u201cUpdate branch\u201d option performs a merge, polluting history with an extra merge commit. Rebasing in the terminal keeps history linear and bisect\u2011friendly.</p>"},{"location":"contribute/Code_Specifications/Details/Linear_Git_Repository/#squash-a-long-commit-history","title":"Squash a long commit history","text":"<p>Why squash?  </p> <p>A PR that contains dozens of \u201cfix typo\u201d or \u201cWIP\u201d commits is hard to review and clutters the permanent history.  Squashing groups these micro\u2011commits into logical units that tell a clear story.</p> <p>Interactive rebase lets you collapse many tiny commits into one (or a few) logical commits before review.</p> <pre><code># From your feature branch, start an interactive rebase\ngit rebase -i origin/main\n# In the editor, mark commits you want to combine as 'squash' or 'fixup'\n# Save &amp; close \u2192 Git opens a second editor window for the new commit message\n# Write a concise message, then save &amp; close\n\n# Push the squashed branch back to the PR\ngit push --force-with-lease\n</code></pre>"},{"location":"contribute/Code_Specifications/Details/Linear_Git_Repository/#troubleshooting-quick-reference","title":"Troubleshooting &amp; Quick Reference","text":""},{"location":"contribute/Code_Specifications/Details/Linear_Git_Repository/#reset-rebase-history-repair","title":"Reset, Rebase &amp; History Repair","text":"Task Command Soft-reset all commits since <code>FIRST_COMMIT_HASH</code> into the index <code>git reset --soft FIRST_COMMIT_HASH^</code> Abort an in-progress rebase <code>git rebase --abort</code> Continue after fixing conflicts in a rebase <code>git rebase --continue</code> Amend the most recent commit <code>git commit --amend</code> Cherry-pick a specific commit onto HEAD <code>git cherry-pick &lt;commit&gt;</code> Revert (invert) a specific commit <code>git revert &lt;commit&gt;</code>"},{"location":"contribute/Code_Specifications/Details/Linear_Git_Repository/#merge-conflict-resolution","title":"Merge &amp; Conflict Resolution","text":"Task Command Abort an in-progress merge <code>git merge --abort</code> Continue (finish) a merge after resolving conflicts <code>git commit</code>"},{"location":"contribute/Code_Specifications/Details/Linear_Git_Repository/#staging-snapshot-creation","title":"Staging &amp; Snapshot Creation","text":"Task Command Stage everything after a reset <code>git add .</code> Show unstaged changes <code>git diff</code> Show staged changes <code>git diff --cached</code> Discard local changes in a file <code>git restore &lt;file&gt;</code> Commit staged changes (concise, present-tense message) <code>git commit -m \"message\"</code>"},{"location":"contribute/Code_Specifications/Details/Linear_Git_Repository/#branch-management","title":"Branch Management","text":"Task Command Create a new branch and switch to it <code>git switch -c &lt;new-branch&gt;</code> Switch to an existing branch <code>git switch &lt;branch&gt;</code> Delete a local branch <code>git branch -d &lt;branch&gt;</code> Delete a remote branch <code>git push origin --delete &lt;branch&gt;</code> Pull with rebase (linear history) <code>git pull --rebase</code> Force-push safely (checks upstream) <code>git push --force-with-lease</code> Fetch all refs and prune deleted branches <code>git fetch --all --prune</code>"},{"location":"contribute/Code_Specifications/Details/Linear_Git_Repository/#stash-shelve-work","title":"Stash (Shelve) Work","text":"Task Command Stash current changes <code>git stash push -m \"msg\"</code> List stashes <code>git stash list</code> Re-apply and drop latest stash <code>git stash pop</code>"},{"location":"contribute/Code_Specifications/Details/Linear_Git_Repository/#clean-up-inspection","title":"Clean-up &amp; Inspection","text":"Task Command Remove untracked files &amp; dirs <code>git clean -fd</code> Compact one-line graph of history <code>git log --oneline --graph --decorate --all</code> <p>References:</p> <ul> <li>Git: References</li> <li>Firebase Git in 100s, Longer Video</li> <li>ArjanCodes Git Branches</li> </ul>"},{"location":"contribute/Feature_Workflow/","title":"Feature Workflow","text":"<p>The overall workflow depends on the extent of the feature being added. This outline covers how to add a completely new feature to the library. However, depending on your situation some of the steps may be skipped, if in doubt, please start a discussion in the GitHub Discussions.</p>"},{"location":"contribute/Feature_Workflow/#full-workflow","title":"Full Workflow","text":"<p>The overall workflow for adding a new feature to the library is as follows:</p> <pre><code>graph TD\n    A[Feature Proposal] --&gt; B[Add Theory]\n    B --&gt; C[Add Functions]\n    C --&gt; E[Add Class]\n    C &lt;--&gt; D[Add Unit Tests]\n    D &lt;--&gt; E[Add Class]\n    E --&gt; F[Add to __init__]\n    F --&gt; G[Add Examples]\n    G --&gt; H((End))</code></pre> <p>Feature Proposal: Create a new discussion in the GitHub Discussions to propose your vision and goals.</p> <ul> <li>Include a description of the feature, its purpose, and how it fits into the library.</li> <li>Add manuscripts or references to contextualize the feature and equations to implement.</li> <li>Discuss the feature with the community to gather feedback and suggestions.</li> <li>Get the okay from the maintainer(s) to proceed with the implementation.</li> </ul> <ol> <li>Add Theory: Write the theory behind the feature.</li> <li>Add Functions: Write the functions that implement the feature.</li> <li>Add Unit Tests: Write unit tests to ensure the function works as intended.</li> <li>Add Class: Write the class that implements the functions.</li> <li>Add Unit Tests: Write unit tests for the class to ensure it works as intended.</li> <li>Add to init: Add the new functions/class to the <code>__init__.py</code> file to make it accessible from the package.</li> <li>Add Examples: Write examples to demonstrate the feature.</li> </ol> <p>Note: Each step would be one or more issues, e.g., one for the theory, 1+ for the functions, etc.</p>"},{"location":"contribute/Feature_Workflow/Details/Add_Class/","title":"Add Class","text":"<p>Create a new class to implement the feature. This is typically a wrapper around the functions you wrote in the previous step.</p>"},{"location":"contribute/Feature_Workflow/Details/Add_Class/#choose-a-base","title":"Choose a base","text":"<ul> <li><code>BuilderABC</code> \u2013 when key/parameter checking is useful.</li> <li><code>dataclass</code> \u2013 for simple, immutable data containers.</li> <li>Regular class \u2013 for everything else.</li> </ul>"},{"location":"contribute/Feature_Workflow/Details/Add_Class/#required-sections","title":"Required Sections","text":"<ul> <li><code>__init__</code> with complete type hints.</li> <li>Public interface first (getters, setters, actions).</li> <li>Docstring that includes an \u201cExamples\u201d subsection.</li> <li>Follow Code Specifications for formatting.</li> </ul>"},{"location":"contribute/Feature_Workflow/Details/Add_Class/#steps","title":"Steps","text":"<ol> <li>Create a new issue on GitHub and assign it to yourself.</li> <li>Create a branch on your forked repo for this issue.</li> <li>Add a new class(s) to the appropriate module in particula//.</li> <li>If the module is new, add it to <code>__init__.py</code>.</li> <li>Use <code>ABC</code> for abstract classes and <code>BuilderABC</code> for builders.</li> <li>Call your functions in the class methods and keep most calculations in the functions (not directly in the class).</li> <li>Write a docstring.</li> <li>Add type hints for all parameters and return values.</li> <li>Add unit tests for the class (see Add Unit Tests).</li> <li>Commit this file in a branch.</li> <li>Create your pull\u2011request to the main repo.</li> </ol>"},{"location":"contribute/Feature_Workflow/Details/Add_Example/","title":"Add Examples","text":""},{"location":"contribute/Feature_Workflow/Details/Add_Example/#goal","title":"Goal","text":"<p>Provide a runnable demonstration in a Jupyter notebook.</p>"},{"location":"contribute/Feature_Workflow/Details/Add_Example/#rules","title":"Rules","text":"<ul> <li>Runtime &lt;30 s on a typical laptop (in most cases).</li> <li>Use only the public API \u2013 no private helpers.</li> <li><code>import particula as par</code></li> <li>End with at least one plot or printed result.</li> <li>Contextualize the example with a short description of what it does and why it's useful.</li> </ul>"},{"location":"contribute/Feature_Workflow/Details/Add_Example/#steps","title":"Steps","text":"<ol> <li>Create a new issue on GitHub and assign it to yourself.</li> <li>Create a branch on your forked repo for this issue.</li> <li>Create <code>docs/examples/**/&lt;feature_name&gt;.ipynb</code>.</li> <li>Add a new folder if needed, but please keep it organized.</li> <li>These can also be under <code>docs/Theory/**/&lt;feature_name&gt;.ipynb</code> to validate the implementation of the theory.</li> <li>Interleave Markdown explanations with code cells.</li> <li>Verify it runs top\u2011to\u2011bottom.</li> <li>Commit the .ipynb file in your PR branch.</li> <li>The website builder will automatically convert it to markdown and HTML during PR.</li> <li>Create your pull\u2011request description.</li> </ol>"},{"location":"contribute/Feature_Workflow/Details/Add_Function/","title":"Add Functions","text":""},{"location":"contribute/Feature_Workflow/Details/Add_Function/#where","title":"Where","text":"<p>Create or update a module under particula//.</p>"},{"location":"contribute/Feature_Workflow/Details/Add_Function/#checklist","title":"Checklist","text":"<ul> <li>Python \u2013 no I/O or global state changes.</li> <li>Follow Code Specifications for formatting.</li> <li>Input validation via util.validate_inputs when applicable.</li> <li>Logging: use <code>logger = logging.getLogger(\"particula\")</code> and log at DEBUG.</li> </ul>"},{"location":"contribute/Feature_Workflow/Details/Add_Function/#steps","title":"Steps","text":"<ol> <li>Create a new issue on GitHub and assign it to yourself.</li> <li>Create a branch on your forked repo for this issue.</li> <li>Add a new function(s) to the appropriate module in particula//.</li> <li>If the module is new, add it to <code>__init__.py</code>.</li> <li>If the function is a helper, add prefix <code>_</code> to the function name.</li> <li>Write a docstring.</li> <li>Add type hints for all parameters and return values.</li> <li>Add Unit Tests for the function (see Add Unit Tests).</li> <li>Commit this file in a branch.</li> <li>Create your pull\u2011request to the main repo.</li> </ol>"},{"location":"contribute/Feature_Workflow/Details/Add_Theory/","title":"Add Theory","text":""},{"location":"contribute/Feature_Workflow/Details/Add_Theory/#goal","title":"Goal","text":"<p>Create a short, citable document that explains the science behind the new feature.</p>"},{"location":"contribute/Feature_Workflow/Details/Add_Theory/#what-to-include","title":"What to include","text":"<p>Include enough information that a new reader would be able to understand and implement the feature. This should include:</p> <ul> <li>An overview of the physical/chemical process.</li> <li>Governing equations (Unicode symbols preferred) with variable definitions.</li> <li>Assumptions or limitations.</li> <li>At least one primary literature citation.</li> </ul>"},{"location":"contribute/Feature_Workflow/Details/Add_Theory/#steps","title":"Steps","text":"<ol> <li>Create a new issue on GitHub and assign it to yourself.</li> <li>Create a branch on your forked repo for this issue.</li> <li>Add a new markdown file at <code>docs/Theory/**/&lt;feature_name&gt;.md</code>. This can be a new folder if needed, but please keep it organized.</li> <li>Link the file in the index.md file in the same folder.</li> <li>Write using Markdown; no specific imports needed.</li> <li>Commit this file in a branch.</li> <li>Create your pull request.</li> </ol>"},{"location":"contribute/Feature_Workflow/Details/Add_Unit_Test/","title":"Add Unit Tests","text":""},{"location":"contribute/Feature_Workflow/Details/Add_Unit_Test/#philosophy","title":"Philosophy","text":"<p>Every new public function or class must have at least one test for accuracy and one edge case or failure mode.</p>"},{"location":"contribute/Feature_Workflow/Details/Add_Unit_Test/#location","title":"Location","text":"<p>particula//tests/test_.py  (mirror the package directory)"},{"location":"contribute/Feature_Workflow/Details/Add_Unit_Test/#template-for-functions","title":"Template for Functions","text":"<pre><code>\"\"\"Docstring for the test module.\"\"\"\nimport numpy as np  # if needed\nimport pytest\nfrom particula.&lt;area&gt; import &lt;symbol&gt;\n\ndef test_&lt;symbol&gt;_accuracy():\n    \"\"\"Docstring for the test.\"\"\"\n    result = &lt;symbol&gt;(&lt;valid_args&gt;)\n    assert np.isclose(result, &lt;expected&gt;)\n\n@pytest.mark.parametrize(\"bad_input\", [...])\n\ndef test_&lt;symbol&gt;_bad_inputs(bad_input):\n    \"\"\"Docstring for the test.\"\"\"\n    with pytest.raises(ValueError):\n        &lt;symbol&gt;(bad_input)\n</code></pre>"},{"location":"contribute/Feature_Workflow/Details/Add_Unit_Test/#template-for-classes","title":"Template for Classes","text":"<pre><code>\"\"\"Docstring for the test module.\"\"\"\nimport numpy as np  # if needed\nimport pytest\nfrom particula.&lt;area&gt; import &lt;ClassName&gt;\n\ndef test_&lt;ClassName&gt;_accuracy():\n    \"\"\"Docstring for the test.\"\"\"\n    obj = &lt;ClassName&gt;(&lt;valid_args&gt;)\n    result = obj.&lt;method_name&gt;(&lt;valid_args&gt;)\n    assert np.isclose(result, &lt;expected&gt;)\n\n\n@pytest.mark.parametrize(\"bad_input\", [...])\ndef test_&lt;ClassName&gt;_bad_inputs(bad_input):\n    \"\"\"Docstring for the test.\"\"\"\n    with pytest.raises(ValueError):\n        &lt;ClassName&gt;(bad_input)\n</code></pre>"},{"location":"contribute/Feature_Workflow/Details/Add_Unit_Test/#run-locally","title":"Run locally","text":"<p>Execute <code>pytest -q</code> before opening the pull request; all tests must be green.</p>"},{"location":"contribute/Feature_Workflow/Details/Add_to_init/","title":"Adding to <code>__init__.py</code>","text":""},{"location":"contribute/Feature_Workflow/Details/Add_to_init/#purpose","title":"Purpose","text":"<p>Make new public APIs available for easy imports.</p>"},{"location":"contribute/Feature_Workflow/Details/Add_to_init/#rules","title":"Rules","text":"<ul> <li>Only import important and relevant classes and functions.</li> <li>Do not import everything from a module (e.g., <code>from particula.&lt;area&gt; import *</code>).</li> <li>Only include public names (no leading <code>_</code>). These helpers are not intended for public use.</li> <li>Keep imports minimal and grouped logically.</li> <li>Maintain alphabetical order within groups.</li> </ul>"},{"location":"contribute/Feature_Workflow/Details/Add_to_init/#steps","title":"Steps","text":"<ol> <li>Open <code>particula/&lt;area&gt;/__init__.py</code>.</li> <li>Add under the right section:</li> </ol> <pre><code>from particula.&lt;area&gt; import ClassName, function_name\n</code></pre>"}]}