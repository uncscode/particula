{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  # Loading Data Part 3\n",
    "\n",
    "  This example shows how to work with data from multiple instruments, and how to load them into a single `Lake` object. A `Lake` object is a container of multiple `Stream`s from individual instruments.\n",
    "\n",
    "  This allows for easy access to the data from all instruments, and also allows for easy plotting of the data from all instruments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ## Working path\n",
    "\n",
    "  Set the working path where the data is stored. For now we'll use the\n",
    "  provided example data in this current directory.\n",
    "\n",
    "  But the path could be any where on your computer. For example, if you have a\n",
    "  folder called \"data\" in your home directory, you could set the path to:\n",
    "  `path = \"U:\\\\data\\\\processing\\\\Campgain2023_of_aswsome\\\\data\"`\n",
    "\n",
    " The folder structure should look like this:\n",
    "\n",
    " ```\n",
    " data\n",
    " ├── CPC_3010_data\n",
    " │   ├── CPC_3010_data_20220709_Jul.csv\n",
    " │   ├── CPC_3010_data_20220709_Jul.csv\n",
    " ├── SMPS_data\n",
    " │   ├── 2022-07-07_095151_SMPS.csv\n",
    " │   ├── 2022-07-10_094659_SMPS.csv\n",
    " ```\n",
    " The `path` is `data`. Within that folder are two folders, one for the CPC\n",
    " data and one for the SMPS data. These are your `relative_data_folder`\n",
    " keywords you put\n",
    " in the settings dictionary. The data within will be loaded as `Stream`\n",
    " objects.\n",
    " Then within each of those folders are the\n",
    " data files which are selected by the `filename_regex`. A regex is a\n",
    " regular expression that is used to match the files. In this case we are\n",
    " matching all files that end with `.csv`, then loading them into the\n",
    " `stream` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all the imports, but we'll go through them one by one as we use them\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from particula.data import loader_interface, settings_generator, lake_stats\n",
    "from particula.data.tests.example_data.get_example_data import get_data_folder\n",
    "from particula.data.lake import Lake\n",
    "\n",
    "# set the parent directory of the data folder\n",
    "path = get_data_folder()\n",
    "print('Path to data folder:')\n",
    "print(path.rsplit('particula')[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Load the data\n",
    "\n",
    " For this example we'll use the provided example data. But you can change the\n",
    " path to any folder on your computer. We then can used the settings generator to\n",
    " load the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# settings for the CPC data\n",
    "cpc_settings = settings_generator.for_general_1d_load(\n",
    "    relative_data_folder='CPC_3010_data',\n",
    "    filename_regex='*.csv',\n",
    "    file_min_size_bytes=10,\n",
    "    data_checks={\n",
    "        \"characters\": [10, 100],\n",
    "        \"char_counts\": {\",\": 4},\n",
    "        \"skip_rows\": 0,\n",
    "        \"skip_end\": 0,\n",
    "    },\n",
    "    data_column=[1, 2],\n",
    "    data_header=['CPC_count[#/sec]', 'Temperature[degC]'],\n",
    "    time_column=[0],\n",
    "    time_format='epoch',\n",
    "    delimiter=',',\n",
    "    time_shift_seconds=0,\n",
    "    timezone_identifier='UTC',\n",
    ")\n",
    "\n",
    "# settings for the SMPS data\n",
    "smps_1d_settings, smps_2d_settings = settings_generator.for_general_sizer_1d_2d_load(\n",
    "    relative_data_folder='SMPS_data',\n",
    "    filename_regex='*.csv',\n",
    "    file_min_size_bytes=10,\n",
    "    header_row=24,\n",
    "    data_checks={\n",
    "        \"characters\": [250],\n",
    "        \"skip_rows\": 25,\n",
    "        \"skip_end\": 0,\n",
    "        \"char_counts\": {\"/\": 2, \":\": 2}\n",
    "    },\n",
    "    data_1d_column=[\n",
    "        \"Lower Size (nm)\",\n",
    "        \"Upper Size (nm)\",\n",
    "        \"Sample Temp (C)\",\n",
    "        \"Sample Pressure (kPa)\",\n",
    "        \"Relative Humidity (%)\",\n",
    "        \"Median (nm)\",\n",
    "        \"Mean (nm)\",\n",
    "        \"Geo. Mean (nm)\",\n",
    "        \"Mode (nm)\",\n",
    "        \"Geo. Std. Dev.\",\n",
    "        \"Total Conc. (#/cm³)\"],\n",
    "    data_1d_header=[\n",
    "        \"Lower_Size_(nm)\",\n",
    "        \"Upper_Size_(nm)\",\n",
    "        \"Sample_Temp_(C)\",\n",
    "        \"Sample_Pressure_(kPa)\",\n",
    "        \"Relative_Humidity_(%)\",\n",
    "        \"Median_(nm)\",\n",
    "        \"Mean_(nm)\",\n",
    "        \"Geo_Mean_(nm)\",\n",
    "        \"Mode_(nm)\",\n",
    "        \"Geo_Std_Dev.\",\n",
    "        \"Total_Conc_(#/cc)\"],\n",
    "    data_2d_dp_start_keyword=\"20.72\",\n",
    "    data_2d_dp_end_keyword=\"784.39\",\n",
    "    data_2d_convert_concentration_from=\"dw/dlogdp\",\n",
    "    time_column=[1, 2],\n",
    "    time_format=\"%m/%d/%Y %H:%M:%S\",\n",
    "    delimiter=\",\",\n",
    "    time_shift_seconds=0,\n",
    "    timezone_identifier=\"UTC\",\n",
    ")\n",
    "\n",
    "# collect settings into a dictionary\n",
    "combined_settings = {\n",
    "    'cpc': cpc_settings,\n",
    "    'smps_1d': smps_1d_settings,\n",
    "    'smps_2d': smps_2d_settings,\n",
    "}\n",
    "\n",
    "# now call the loader interface for files\n",
    "lake = loader_interface.load_folders_interface(\n",
    "    path=path,\n",
    "    folder_settings=combined_settings,\n",
    ")\n",
    "\n",
    "print(' ')\n",
    "print(lake)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Lake\n",
    " The lake is a collection of streams, stored as a dictionary. The keys are the\n",
    " names of the streams, and the values are the streams themselves. We can access\n",
    " the streams by their name. For example, to get the CPC stream we can do:\n",
    " `lake['cpc']`. We can also get the names of the streams by doing\n",
    " `lake.keys()`. We can also loop through the streams by doing\n",
    " `for stream in lake.values():`. We can also loop through the names and streams\n",
    " by doing `for name, stream in lake.items():`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the names of the streams\n",
    "print(' ')\n",
    "print('Names of the streams:')\n",
    "print(dir(lake))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the streams\n",
    "print(' ')\n",
    "print('The streams:')\n",
    "for stream in lake:\n",
    "    print(stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the names and streams\n",
    "print(' ')\n",
    "print('The names and streams:')\n",
    "for name, stream in lake.items():\n",
    "    print(name, stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get just the keys\n",
    "print(' ')\n",
    "print('The keys:')\n",
    "for key in lake.keys():\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get just the values\n",
    "print(' ')\n",
    "print('The values:')\n",
    "for value in lake.values():\n",
    "    print(value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Pause to Plot the data\n",
    " We'll compare the CPC counts with the Mode of the SMPS data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get cpc data\n",
    "cpc_time = lake['cpc'].datetime64\n",
    "cpc_data = lake['cpc']['CPC_count[#/sec]']\n",
    "# get smps data\n",
    "smps_time = lake['smps_1d'].datetime64\n",
    "smps_data = lake['smps_1d']['Mode_(nm)']\n",
    "\n",
    "# plot the data on twinx axis\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(cpc_time,\n",
    "        cpc_data,\n",
    "        label='CPC',\n",
    "        color='blue') \n",
    "plt.xticks(rotation=45)\n",
    "axb = ax.twinx()\n",
    "axb.plot(smps_time,\n",
    "         smps_data,\n",
    "         label='SMPS',\n",
    "         color='orange',)\n",
    "axb.set_ylim(0, 200)\n",
    "ax.set_xlabel(\"Time (UTC)\")\n",
    "ax.set_ylabel('CPC_counts[#/sec]')\n",
    "axb.set_ylabel('SMPS_Mode[nm]')\n",
    "plt.show()\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Average the data\n",
    "\n",
    " Now that we have the data loaded, we can average the data over time. We'll use\n",
    " the 'particula.data.lake_stats' module to do this. The module has a function\n",
    " called 'averaged_std' that will take stream object and return a new stream\n",
    " object with the averaged data and the standard deviation of the data.\n",
    "\n",
    " If you recall this is the same naming convention as `stream_stats.average_std`\n",
    " which operates on stream objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lake_averaged = lake_stats.average_std(\n",
    "    lake=lake,\n",
    "    average_interval=600,\n",
    "    clone=True)\n",
    "\n",
    "print(lake_averaged)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Plot the Averaged Data\n",
    "\n",
    " get cpc data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpc_time = lake_averaged['cpc'].datetime64\n",
    "cpc_data = lake_averaged['cpc']['CPC_count[#/sec]']\n",
    "# get smps data\n",
    "smps_time = lake_averaged['smps_1d'].datetime64\n",
    "smps_data = lake_averaged['smps_1d']['Mode_(nm)']\n",
    "\n",
    "# plot the data on twinx axis\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(cpc_time,\n",
    "        cpc_data,\n",
    "        label='CPC',\n",
    "        color='blue')\n",
    "plt.xticks(rotation=45)\n",
    "axb = ax.twinx()\n",
    "axb.plot(smps_time,\n",
    "         smps_data,\n",
    "         label='SMPS',\n",
    "         color='orange',)\n",
    "axb.set_ylim(0, 200)\n",
    "ax.set_xlabel(\"Time (UTC)\")\n",
    "ax.set_ylabel('CPC_counts[#/sec]')\n",
    "axb.set_ylabel('SMPS_Mode[nm]')\n",
    "plt.show()\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    " This example showed how to load data from a folder and then average the data\n",
    " over time. The data was then plotted to show the difference between the\n",
    " averaged and non-averaged data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(Lake)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ParticulaDev_py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
